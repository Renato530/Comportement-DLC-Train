{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39814a74",
   "metadata": {},
   "source": [
    "# Entrainement de la camera du haut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06076be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DLClight\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a824d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 23:48:45.197430: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 23:48:45.276405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.276880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.755GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-02-19 23:48:45.276922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.277334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \n",
      "pciBusID: 0000:49:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.755GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-02-19 23:48:45.278893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-19 23:48:45.306324: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-19 23:48:45.323838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-19 23:48:45.327360: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-19 23:48:45.358000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-02-19 23:48:45.362076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-02-19 23:48:45.414236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-19 23:48:45.414400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.415090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.415691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.416275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.416833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1\n",
      "2022-02-19 23:48:45.418509: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2022-02-19 23:48:45.455210: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3800170000 Hz\n",
      "2022-02-19 23:48:45.457169: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cf3d319bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-02-19 23:48:45.457183: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-02-19 23:48:45.615359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.624279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.624789: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cf3e69bfa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-02-19 23:48:45.624806: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2022-02-19 23:48:45.624812: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2022-02-19 23:48:45.625665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.626307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.755GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-02-19 23:48:45.626385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.626970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \n",
      "pciBusID: 0000:49:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.755GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-02-19 23:48:45.627012: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-19 23:48:45.627025: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-19 23:48:45.627037: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-19 23:48:45.627048: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-19 23:48:45.627059: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-02-19 23:48:45.627071: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-02-19 23:48:45.627083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-19 23:48:45.627145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.627956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.628561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.629184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.629756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1\n",
      "2022-02-19 23:48:45.630074: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-19 23:48:45.631921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-02-19 23:48:45.631932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 \n",
      "2022-02-19 23:48:45.631938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N N \n",
      "2022-02-19 23:48:45.631943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   N N \n",
      "2022-02-19 23:48:45.632078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.632713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.633344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.633938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5326 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:21:00.0, compute capability: 7.5)\n",
      "2022-02-19 23:48:45.634978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:48:45.635589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 5491 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:49:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ae8e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c16ecf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le fichier de configuration du projet DEEPLABCUT \n",
    "pathConfig = '/home/comportement/Comportement-DLC-Train/AnnotationCamTop-Comportement-2022-02-19/config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22b72c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([ 40, 143,  69,  43,  78, 196,  23, 223, 205, 147, 102, 153, 117,\n",
       "          230, 108, 141,   8, 220, 210,  52, 193, 118, 168,  72,  75, 244,\n",
       "          121, 254, 215, 165,  29, 122,  71, 206,  73,  10,  49, 156, 277,\n",
       "           26, 198, 282,  42, 295,  33, 289, 255, 253,  83,  45,  61, 246,\n",
       "          287,  12, 272, 135,  82,  25, 227,  53, 204, 222, 299,   5, 256,\n",
       "          273, 234, 271, 107, 112, 106, 257,  64, 171, 127,   1,  41, 270,\n",
       "          128, 115, 197, 250,  30,  65,   6, 161, 101,  96, 279, 167, 260,\n",
       "          181, 175, 159, 120, 151,  91, 221, 228,  56, 268, 164, 249, 186,\n",
       "          266,   9,  87,  95, 269, 145, 261, 238,  84, 212,  89, 195, 217,\n",
       "          152, 119,  16,  35, 157, 190, 240,  51,  15, 192, 148, 252, 278,\n",
       "          149, 242, 226,  92, 132,  54, 288, 258,   3, 211,  50, 298, 200,\n",
       "          233,  44,  46, 218,  94, 267, 184, 176,  55, 160, 179, 293,  59,\n",
       "           47,  74, 208, 174, 194, 290, 248,  70, 124, 214,  88, 130, 155,\n",
       "          182, 109, 191, 207,  80, 294, 144,  36, 225, 229, 247, 133,  79,\n",
       "           17,  20, 241, 202, 286,  14,  24, 173, 183,  99,   4, 114,  77,\n",
       "          180,  31,  98, 166,  62, 224, 104,  48,  68, 236, 131, 163, 285,\n",
       "           27, 189,  37, 185,  67, 146, 284, 123,  76,  86, 126, 111, 169,\n",
       "          209, 129, 219, 139, 243, 263,  22, 187, 251,  38, 203, 177,   0,\n",
       "          297, 140,  39, 134,  28, 259, 100,  11,  60,  97, 136,  13, 105,\n",
       "          274,  32, 262, 276, 265, 110, 188, 150, 237,  63, 103, 239,   2,\n",
       "           21, 138, 162, 142,  18, 264, 232, 199, 213, 231, 283,  81,  93,\n",
       "          201, 113,  34,  66, 216, 116, 280,  58,  90, 154, 275, 125]),\n",
       "   array([  7, 170,  85, 281,  57, 172, 158, 292,  19, 296, 235, 137, 245,\n",
       "          291, 178])))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation des donnees pour effectuer l'entrainement du modele\n",
    "deeplabcut.create_training_dataset(pathConfig, net_type = 'resnet_50', augmenter_type = 'imgaug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdf3c653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],\n",
      " 'all_joints_names': ['snout',\n",
      "                      'middle back',\n",
      "                      'front L foot',\n",
      "                      'front R foot',\n",
      "                      'hind L foot',\n",
      "                      'hind R foot',\n",
      "                      'L ear',\n",
      "                      'R ear',\n",
      "                      'tail base',\n",
      "                      'tail end'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 1,\n",
      " 'clahe': True,\n",
      " 'claheratio': 0.1,\n",
      " 'crop_pad': 0,\n",
      " 'crop_sampling': 'hybrid',\n",
      " 'crop_size': [400, 400],\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_AnnotationCamTopFeb19/AnnotationCamTop_Comportement95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'edge': False,\n",
      " 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]},\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'histeq': True,\n",
      " 'histeqratio': 0.1,\n",
      " 'init_weights': '/home/comportement/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'max_shift': 0.4,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_AnnotationCamTopFeb19/Documentation_data-AnnotationCamTop_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 10,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'pre_resize': [],\n",
      " 'project_path': '/home/comportement/Comportement-DLC-Train/AnnotationCamTop-Comportement-2022-02-19',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'sharpen': False,\n",
      " 'sharpenratio': 0.3,\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/comportement/Comportement-DLC-Train/AnnotationCamTop-Comportement-2022-02-19/dlc-models/iteration-0/AnnotationCamTopFeb19-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Batch Size is 1\n",
      "Loading ImageNet-pretrained resnet_50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 23:56:40.649882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:56:40.650382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.755GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-02-19 23:56:40.650426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:56:40.650839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \n",
      "pciBusID: 0000:49:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.755GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-02-19 23:56:40.650874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-19 23:56:40.650881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-19 23:56:40.650887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-19 23:56:40.650893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-19 23:56:40.650899: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-02-19 23:56:40.650905: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-02-19 23:56:40.650920: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-19 23:56:40.650954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:56:40.651388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:56:40.651815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:56:40.652240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:56:40.652644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1\n",
      "2022-02-19 23:56:40.652668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-02-19 23:56:40.652671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 \n",
      "2022-02-19 23:56:40.652674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N N \n",
      "2022-02-19 23:56:40.652676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   N N \n",
      "2022-02-19 23:56:40.652750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:56:40.653179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:56:40.653610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:56:40.654015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5326 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:21:00.0, compute capability: 7.5)\n",
      "2022-02-19 23:56:40.654122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 23:56:40.654535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 5491 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:49:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display_iters overwritten as 10\n",
      "Save_iters overwritten as 500\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/home/comportement/Comportement-DLC-Train/AnnotationCamTop-Comportement-2022-02-19/dlc-models/iteration-0/AnnotationCamTopFeb19-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'imgaug', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]], 'all_joints_names': ['snout', 'middle back', 'front L foot', 'front R foot', 'hind L foot', 'hind R foot', 'L ear', 'R ear', 'tail base', 'tail end'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'clahe': True, 'claheratio': 0.1, 'crop_sampling': 'hybrid', 'crop_size': [400, 400], 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_AnnotationCamTopFeb19/AnnotationCamTop_Comportement95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]}, 'histeq': True, 'histeqratio': 0.1, 'init_weights': '/home/comportement/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'max_shift': 0.4, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_AnnotationCamTopFeb19/Documentation_data-AnnotationCamTop_95shuffle1.pickle', 'min_input_size': 64, 'multi_stage': False, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 10, 'pos_dist_thresh': 17, 'pre_resize': [], 'project_path': '/home/comportement/Comportement-DLC-Train/AnnotationCamTop-Comportement-2022-02-19', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'sharpen': False, 'sharpenratio': 0.3, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 23:56:44.980375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-19 23:56:46.155356: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-19 23:56:46.457051: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 3.70G (3975624704 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "iteration: 10 loss: 0.3634 lr: 0.005\n",
      "iteration: 20 loss: 0.0547 lr: 0.005\n",
      "iteration: 30 loss: 0.0315 lr: 0.005\n",
      "iteration: 40 loss: 0.0306 lr: 0.005\n",
      "iteration: 50 loss: 0.0265 lr: 0.005\n",
      "iteration: 60 loss: 0.0245 lr: 0.005\n",
      "iteration: 70 loss: 0.0203 lr: 0.005\n",
      "iteration: 80 loss: 0.0226 lr: 0.005\n",
      "iteration: 90 loss: 0.0273 lr: 0.005\n",
      "iteration: 100 loss: 0.0240 lr: 0.005\n",
      "iteration: 110 loss: 0.0230 lr: 0.005\n",
      "iteration: 120 loss: 0.0246 lr: 0.005\n",
      "iteration: 130 loss: 0.0231 lr: 0.005\n",
      "iteration: 140 loss: 0.0265 lr: 0.005\n",
      "iteration: 150 loss: 0.0253 lr: 0.005\n",
      "iteration: 160 loss: 0.0233 lr: 0.005\n",
      "iteration: 170 loss: 0.0218 lr: 0.005\n",
      "iteration: 180 loss: 0.0238 lr: 0.005\n",
      "iteration: 190 loss: 0.0254 lr: 0.005\n",
      "iteration: 200 loss: 0.0235 lr: 0.005\n",
      "iteration: 210 loss: 0.0226 lr: 0.005\n",
      "iteration: 220 loss: 0.0258 lr: 0.005\n",
      "iteration: 230 loss: 0.0244 lr: 0.005\n",
      "iteration: 240 loss: 0.0230 lr: 0.005\n",
      "iteration: 250 loss: 0.0207 lr: 0.005\n",
      "iteration: 260 loss: 0.0241 lr: 0.005\n",
      "iteration: 270 loss: 0.0207 lr: 0.005\n",
      "iteration: 280 loss: 0.0246 lr: 0.005\n",
      "iteration: 290 loss: 0.0242 lr: 0.005\n",
      "iteration: 300 loss: 0.0237 lr: 0.005\n",
      "iteration: 310 loss: 0.0218 lr: 0.005\n",
      "iteration: 320 loss: 0.0252 lr: 0.005\n",
      "iteration: 330 loss: 0.0194 lr: 0.005\n",
      "iteration: 340 loss: 0.0241 lr: 0.005\n",
      "iteration: 350 loss: 0.0234 lr: 0.005\n",
      "iteration: 360 loss: 0.0198 lr: 0.005\n",
      "iteration: 370 loss: 0.0241 lr: 0.005\n",
      "iteration: 380 loss: 0.0226 lr: 0.005\n",
      "iteration: 390 loss: 0.0188 lr: 0.005\n",
      "iteration: 400 loss: 0.0225 lr: 0.005\n",
      "iteration: 410 loss: 0.0240 lr: 0.005\n",
      "iteration: 420 loss: 0.0211 lr: 0.005\n",
      "iteration: 430 loss: 0.0220 lr: 0.005\n",
      "iteration: 440 loss: 0.0196 lr: 0.005\n",
      "iteration: 450 loss: 0.0190 lr: 0.005\n",
      "iteration: 460 loss: 0.0228 lr: 0.005\n",
      "iteration: 470 loss: 0.0228 lr: 0.005\n",
      "iteration: 480 loss: 0.0213 lr: 0.005\n",
      "iteration: 490 loss: 0.0242 lr: 0.005\n",
      "iteration: 500 loss: 0.0162 lr: 0.005\n",
      "iteration: 510 loss: 0.0182 lr: 0.005\n",
      "iteration: 520 loss: 0.0178 lr: 0.005\n",
      "iteration: 530 loss: 0.0239 lr: 0.005\n",
      "iteration: 540 loss: 0.0238 lr: 0.005\n",
      "iteration: 550 loss: 0.0175 lr: 0.005\n",
      "iteration: 560 loss: 0.0208 lr: 0.005\n",
      "iteration: 570 loss: 0.0226 lr: 0.005\n",
      "iteration: 580 loss: 0.0213 lr: 0.005\n",
      "iteration: 590 loss: 0.0221 lr: 0.005\n",
      "iteration: 600 loss: 0.0232 lr: 0.005\n",
      "iteration: 610 loss: 0.0164 lr: 0.005\n",
      "iteration: 620 loss: 0.0157 lr: 0.005\n",
      "iteration: 630 loss: 0.0196 lr: 0.005\n",
      "iteration: 640 loss: 0.0212 lr: 0.005\n",
      "iteration: 650 loss: 0.0213 lr: 0.005\n",
      "iteration: 660 loss: 0.0244 lr: 0.005\n",
      "iteration: 670 loss: 0.0245 lr: 0.005\n",
      "iteration: 680 loss: 0.0218 lr: 0.005\n",
      "iteration: 690 loss: 0.0161 lr: 0.005\n",
      "iteration: 700 loss: 0.0199 lr: 0.005\n",
      "iteration: 710 loss: 0.0200 lr: 0.005\n",
      "iteration: 720 loss: 0.0176 lr: 0.005\n",
      "iteration: 730 loss: 0.0225 lr: 0.005\n",
      "iteration: 740 loss: 0.0208 lr: 0.005\n",
      "iteration: 750 loss: 0.0210 lr: 0.005\n",
      "iteration: 760 loss: 0.0216 lr: 0.005\n",
      "iteration: 770 loss: 0.0193 lr: 0.005\n",
      "iteration: 780 loss: 0.0212 lr: 0.005\n",
      "iteration: 790 loss: 0.0190 lr: 0.005\n",
      "iteration: 800 loss: 0.0231 lr: 0.005\n",
      "iteration: 810 loss: 0.0198 lr: 0.005\n",
      "iteration: 820 loss: 0.0216 lr: 0.005\n",
      "iteration: 830 loss: 0.0201 lr: 0.005\n",
      "iteration: 840 loss: 0.0203 lr: 0.005\n",
      "iteration: 850 loss: 0.0193 lr: 0.005\n",
      "iteration: 860 loss: 0.0231 lr: 0.005\n",
      "iteration: 870 loss: 0.0177 lr: 0.005\n",
      "iteration: 880 loss: 0.0182 lr: 0.005\n",
      "iteration: 890 loss: 0.0201 lr: 0.005\n",
      "iteration: 900 loss: 0.0224 lr: 0.005\n",
      "iteration: 910 loss: 0.0217 lr: 0.005\n",
      "iteration: 920 loss: 0.0186 lr: 0.005\n",
      "iteration: 930 loss: 0.0211 lr: 0.005\n",
      "iteration: 940 loss: 0.0194 lr: 0.005\n",
      "iteration: 950 loss: 0.0213 lr: 0.005\n",
      "iteration: 960 loss: 0.0234 lr: 0.005\n",
      "iteration: 970 loss: 0.0195 lr: 0.005\n",
      "iteration: 980 loss: 0.0174 lr: 0.005\n",
      "iteration: 990 loss: 0.0215 lr: 0.005\n",
      "iteration: 1000 loss: 0.0204 lr: 0.005\n",
      "iteration: 1010 loss: 0.0211 lr: 0.005\n",
      "iteration: 1020 loss: 0.0222 lr: 0.005\n",
      "iteration: 1030 loss: 0.0228 lr: 0.005\n",
      "iteration: 1040 loss: 0.0192 lr: 0.005\n",
      "iteration: 1050 loss: 0.0187 lr: 0.005\n",
      "iteration: 1060 loss: 0.0226 lr: 0.005\n",
      "iteration: 1070 loss: 0.0207 lr: 0.005\n",
      "iteration: 1080 loss: 0.0220 lr: 0.005\n",
      "iteration: 1090 loss: 0.0175 lr: 0.005\n",
      "iteration: 1100 loss: 0.0204 lr: 0.005\n",
      "iteration: 1110 loss: 0.0182 lr: 0.005\n",
      "iteration: 1120 loss: 0.0206 lr: 0.005\n",
      "iteration: 1130 loss: 0.0178 lr: 0.005\n",
      "iteration: 1140 loss: 0.0212 lr: 0.005\n",
      "iteration: 1150 loss: 0.0205 lr: 0.005\n",
      "iteration: 1160 loss: 0.0241 lr: 0.005\n",
      "iteration: 1170 loss: 0.0176 lr: 0.005\n",
      "iteration: 1180 loss: 0.0169 lr: 0.005\n",
      "iteration: 1190 loss: 0.0175 lr: 0.005\n",
      "iteration: 1200 loss: 0.0177 lr: 0.005\n",
      "iteration: 1210 loss: 0.0204 lr: 0.005\n",
      "iteration: 1220 loss: 0.0161 lr: 0.005\n",
      "iteration: 1230 loss: 0.0192 lr: 0.005\n",
      "iteration: 1240 loss: 0.0205 lr: 0.005\n",
      "iteration: 1250 loss: 0.0153 lr: 0.005\n",
      "iteration: 1260 loss: 0.0203 lr: 0.005\n",
      "iteration: 1270 loss: 0.0236 lr: 0.005\n",
      "iteration: 1280 loss: 0.0187 lr: 0.005\n",
      "iteration: 1290 loss: 0.0226 lr: 0.005\n",
      "iteration: 1300 loss: 0.0205 lr: 0.005\n",
      "iteration: 1310 loss: 0.0191 lr: 0.005\n",
      "iteration: 1320 loss: 0.0188 lr: 0.005\n",
      "iteration: 1330 loss: 0.0191 lr: 0.005\n",
      "iteration: 1340 loss: 0.0178 lr: 0.005\n",
      "iteration: 1350 loss: 0.0202 lr: 0.005\n",
      "iteration: 1360 loss: 0.0197 lr: 0.005\n",
      "iteration: 1370 loss: 0.0175 lr: 0.005\n",
      "iteration: 1380 loss: 0.0215 lr: 0.005\n",
      "iteration: 1390 loss: 0.0171 lr: 0.005\n",
      "iteration: 1400 loss: 0.0202 lr: 0.005\n",
      "iteration: 1410 loss: 0.0159 lr: 0.005\n",
      "iteration: 1420 loss: 0.0215 lr: 0.005\n",
      "iteration: 1430 loss: 0.0214 lr: 0.005\n",
      "iteration: 1440 loss: 0.0158 lr: 0.005\n",
      "iteration: 1450 loss: 0.0195 lr: 0.005\n",
      "iteration: 1460 loss: 0.0201 lr: 0.005\n",
      "iteration: 1470 loss: 0.0192 lr: 0.005\n",
      "iteration: 1480 loss: 0.0187 lr: 0.005\n",
      "iteration: 1490 loss: 0.0221 lr: 0.005\n",
      "iteration: 1500 loss: 0.0202 lr: 0.005\n",
      "iteration: 1510 loss: 0.0206 lr: 0.005\n",
      "iteration: 1520 loss: 0.0171 lr: 0.005\n",
      "iteration: 1530 loss: 0.0174 lr: 0.005\n",
      "iteration: 1540 loss: 0.0193 lr: 0.005\n",
      "iteration: 1550 loss: 0.0188 lr: 0.005\n",
      "iteration: 1560 loss: 0.0174 lr: 0.005\n",
      "iteration: 1570 loss: 0.0200 lr: 0.005\n",
      "iteration: 1580 loss: 0.0189 lr: 0.005\n",
      "iteration: 1590 loss: 0.0181 lr: 0.005\n",
      "iteration: 1600 loss: 0.0201 lr: 0.005\n",
      "iteration: 1610 loss: 0.0184 lr: 0.005\n",
      "iteration: 1620 loss: 0.0199 lr: 0.005\n",
      "iteration: 1630 loss: 0.0175 lr: 0.005\n",
      "iteration: 1640 loss: 0.0184 lr: 0.005\n",
      "iteration: 1650 loss: 0.0154 lr: 0.005\n",
      "iteration: 1660 loss: 0.0199 lr: 0.005\n",
      "iteration: 1670 loss: 0.0232 lr: 0.005\n",
      "iteration: 1680 loss: 0.0209 lr: 0.005\n",
      "iteration: 1690 loss: 0.0155 lr: 0.005\n",
      "iteration: 1700 loss: 0.0161 lr: 0.005\n",
      "iteration: 1710 loss: 0.0207 lr: 0.005\n",
      "iteration: 1720 loss: 0.0185 lr: 0.005\n",
      "iteration: 1730 loss: 0.0169 lr: 0.005\n",
      "iteration: 1740 loss: 0.0160 lr: 0.005\n",
      "iteration: 1750 loss: 0.0194 lr: 0.005\n",
      "iteration: 1760 loss: 0.0167 lr: 0.005\n",
      "iteration: 1770 loss: 0.0187 lr: 0.005\n",
      "iteration: 1780 loss: 0.0196 lr: 0.005\n",
      "iteration: 1790 loss: 0.0160 lr: 0.005\n",
      "iteration: 1800 loss: 0.0193 lr: 0.005\n",
      "iteration: 1810 loss: 0.0175 lr: 0.005\n",
      "iteration: 1820 loss: 0.0194 lr: 0.005\n",
      "iteration: 1830 loss: 0.0149 lr: 0.005\n",
      "iteration: 1840 loss: 0.0183 lr: 0.005\n",
      "iteration: 1850 loss: 0.0156 lr: 0.005\n",
      "iteration: 1860 loss: 0.0209 lr: 0.005\n",
      "iteration: 1870 loss: 0.0172 lr: 0.005\n",
      "iteration: 1880 loss: 0.0184 lr: 0.005\n",
      "iteration: 1890 loss: 0.0165 lr: 0.005\n",
      "iteration: 1900 loss: 0.0162 lr: 0.005\n",
      "iteration: 1910 loss: 0.0173 lr: 0.005\n",
      "iteration: 1920 loss: 0.0184 lr: 0.005\n",
      "iteration: 1930 loss: 0.0160 lr: 0.005\n",
      "iteration: 1940 loss: 0.0177 lr: 0.005\n",
      "iteration: 1950 loss: 0.0186 lr: 0.005\n",
      "iteration: 1960 loss: 0.0180 lr: 0.005\n",
      "iteration: 1970 loss: 0.0175 lr: 0.005\n",
      "iteration: 1980 loss: 0.0197 lr: 0.005\n",
      "iteration: 1990 loss: 0.0155 lr: 0.005\n",
      "iteration: 2000 loss: 0.0200 lr: 0.005\n",
      "iteration: 2010 loss: 0.0206 lr: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 2020 loss: 0.0162 lr: 0.005\n",
      "iteration: 2030 loss: 0.0202 lr: 0.005\n",
      "iteration: 2040 loss: 0.0202 lr: 0.005\n",
      "iteration: 2050 loss: 0.0171 lr: 0.005\n",
      "iteration: 2060 loss: 0.0162 lr: 0.005\n",
      "iteration: 2070 loss: 0.0185 lr: 0.005\n",
      "iteration: 2080 loss: 0.0182 lr: 0.005\n",
      "iteration: 2090 loss: 0.0179 lr: 0.005\n",
      "iteration: 2100 loss: 0.0154 lr: 0.005\n",
      "iteration: 2110 loss: 0.0189 lr: 0.005\n",
      "iteration: 2120 loss: 0.0161 lr: 0.005\n",
      "iteration: 2130 loss: 0.0174 lr: 0.005\n",
      "iteration: 2140 loss: 0.0160 lr: 0.005\n",
      "iteration: 2150 loss: 0.0172 lr: 0.005\n",
      "iteration: 2160 loss: 0.0164 lr: 0.005\n",
      "iteration: 2170 loss: 0.0147 lr: 0.005\n",
      "iteration: 2180 loss: 0.0194 lr: 0.005\n",
      "iteration: 2190 loss: 0.0183 lr: 0.005\n",
      "iteration: 2200 loss: 0.0166 lr: 0.005\n",
      "iteration: 2210 loss: 0.0166 lr: 0.005\n",
      "iteration: 2220 loss: 0.0180 lr: 0.005\n",
      "iteration: 2230 loss: 0.0178 lr: 0.005\n",
      "iteration: 2240 loss: 0.0173 lr: 0.005\n",
      "iteration: 2250 loss: 0.0182 lr: 0.005\n",
      "iteration: 2260 loss: 0.0197 lr: 0.005\n",
      "iteration: 2270 loss: 0.0180 lr: 0.005\n",
      "iteration: 2280 loss: 0.0177 lr: 0.005\n",
      "iteration: 2290 loss: 0.0192 lr: 0.005\n",
      "iteration: 2300 loss: 0.0185 lr: 0.005\n",
      "iteration: 2310 loss: 0.0175 lr: 0.005\n",
      "iteration: 2320 loss: 0.0148 lr: 0.005\n",
      "iteration: 2330 loss: 0.0211 lr: 0.005\n",
      "iteration: 2340 loss: 0.0190 lr: 0.005\n",
      "iteration: 2350 loss: 0.0171 lr: 0.005\n",
      "iteration: 2360 loss: 0.0159 lr: 0.005\n",
      "iteration: 2370 loss: 0.0165 lr: 0.005\n",
      "iteration: 2380 loss: 0.0150 lr: 0.005\n",
      "iteration: 2390 loss: 0.0200 lr: 0.005\n",
      "iteration: 2400 loss: 0.0152 lr: 0.005\n",
      "iteration: 2410 loss: 0.0202 lr: 0.005\n",
      "iteration: 2420 loss: 0.0166 lr: 0.005\n",
      "iteration: 2430 loss: 0.0185 lr: 0.005\n",
      "iteration: 2440 loss: 0.0180 lr: 0.005\n",
      "iteration: 2450 loss: 0.0132 lr: 0.005\n",
      "iteration: 2460 loss: 0.0166 lr: 0.005\n",
      "iteration: 2470 loss: 0.0166 lr: 0.005\n",
      "iteration: 2480 loss: 0.0175 lr: 0.005\n",
      "iteration: 2490 loss: 0.0178 lr: 0.005\n",
      "iteration: 2500 loss: 0.0158 lr: 0.005\n",
      "iteration: 2510 loss: 0.0165 lr: 0.005\n",
      "iteration: 2520 loss: 0.0196 lr: 0.005\n",
      "iteration: 2530 loss: 0.0183 lr: 0.005\n",
      "iteration: 2540 loss: 0.0171 lr: 0.005\n",
      "iteration: 2550 loss: 0.0168 lr: 0.005\n",
      "iteration: 2560 loss: 0.0160 lr: 0.005\n",
      "iteration: 2570 loss: 0.0165 lr: 0.005\n",
      "iteration: 2580 loss: 0.0174 lr: 0.005\n",
      "iteration: 2590 loss: 0.0165 lr: 0.005\n",
      "iteration: 2600 loss: 0.0158 lr: 0.005\n",
      "iteration: 2610 loss: 0.0175 lr: 0.005\n",
      "iteration: 2620 loss: 0.0164 lr: 0.005\n",
      "iteration: 2630 loss: 0.0145 lr: 0.005\n",
      "iteration: 2640 loss: 0.0189 lr: 0.005\n",
      "iteration: 2650 loss: 0.0193 lr: 0.005\n",
      "iteration: 2660 loss: 0.0198 lr: 0.005\n",
      "iteration: 2670 loss: 0.0216 lr: 0.005\n",
      "iteration: 2680 loss: 0.0182 lr: 0.005\n",
      "iteration: 2690 loss: 0.0159 lr: 0.005\n",
      "iteration: 2700 loss: 0.0207 lr: 0.005\n",
      "iteration: 2710 loss: 0.0172 lr: 0.005\n",
      "iteration: 2720 loss: 0.0138 lr: 0.005\n",
      "iteration: 2730 loss: 0.0186 lr: 0.005\n",
      "iteration: 2740 loss: 0.0170 lr: 0.005\n",
      "iteration: 2750 loss: 0.0142 lr: 0.005\n",
      "iteration: 2760 loss: 0.0175 lr: 0.005\n",
      "iteration: 2770 loss: 0.0165 lr: 0.005\n",
      "iteration: 2780 loss: 0.0169 lr: 0.005\n",
      "iteration: 2790 loss: 0.0180 lr: 0.005\n",
      "iteration: 2800 loss: 0.0150 lr: 0.005\n",
      "iteration: 2810 loss: 0.0183 lr: 0.005\n",
      "iteration: 2820 loss: 0.0172 lr: 0.005\n",
      "iteration: 2830 loss: 0.0157 lr: 0.005\n",
      "iteration: 2840 loss: 0.0166 lr: 0.005\n",
      "iteration: 2850 loss: 0.0154 lr: 0.005\n",
      "iteration: 2860 loss: 0.0156 lr: 0.005\n",
      "iteration: 2870 loss: 0.0160 lr: 0.005\n",
      "iteration: 2880 loss: 0.0208 lr: 0.005\n",
      "iteration: 2890 loss: 0.0156 lr: 0.005\n",
      "iteration: 2900 loss: 0.0173 lr: 0.005\n",
      "iteration: 2910 loss: 0.0174 lr: 0.005\n",
      "iteration: 2920 loss: 0.0152 lr: 0.005\n",
      "iteration: 2930 loss: 0.0181 lr: 0.005\n",
      "iteration: 2940 loss: 0.0181 lr: 0.005\n",
      "iteration: 2950 loss: 0.0137 lr: 0.005\n",
      "iteration: 2960 loss: 0.0182 lr: 0.005\n",
      "iteration: 2970 loss: 0.0165 lr: 0.005\n",
      "iteration: 2980 loss: 0.0155 lr: 0.005\n",
      "iteration: 2990 loss: 0.0150 lr: 0.005\n",
      "iteration: 3000 loss: 0.0181 lr: 0.005\n",
      "iteration: 3010 loss: 0.0169 lr: 0.005\n",
      "iteration: 3020 loss: 0.0165 lr: 0.005\n",
      "iteration: 3030 loss: 0.0153 lr: 0.005\n",
      "iteration: 3040 loss: 0.0156 lr: 0.005\n",
      "iteration: 3050 loss: 0.0161 lr: 0.005\n",
      "iteration: 3060 loss: 0.0168 lr: 0.005\n",
      "iteration: 3070 loss: 0.0180 lr: 0.005\n",
      "iteration: 3080 loss: 0.0165 lr: 0.005\n",
      "iteration: 3090 loss: 0.0158 lr: 0.005\n",
      "iteration: 3100 loss: 0.0173 lr: 0.005\n",
      "iteration: 3110 loss: 0.0146 lr: 0.005\n",
      "iteration: 3120 loss: 0.0152 lr: 0.005\n",
      "iteration: 3130 loss: 0.0153 lr: 0.005\n",
      "iteration: 3140 loss: 0.0173 lr: 0.005\n",
      "iteration: 3150 loss: 0.0165 lr: 0.005\n",
      "iteration: 3160 loss: 0.0200 lr: 0.005\n",
      "iteration: 3170 loss: 0.0165 lr: 0.005\n",
      "iteration: 3180 loss: 0.0177 lr: 0.005\n",
      "iteration: 3190 loss: 0.0155 lr: 0.005\n",
      "iteration: 3200 loss: 0.0116 lr: 0.005\n",
      "iteration: 3210 loss: 0.0154 lr: 0.005\n",
      "iteration: 3220 loss: 0.0140 lr: 0.005\n",
      "iteration: 3230 loss: 0.0182 lr: 0.005\n",
      "iteration: 3240 loss: 0.0135 lr: 0.005\n",
      "iteration: 3250 loss: 0.0161 lr: 0.005\n",
      "iteration: 3260 loss: 0.0173 lr: 0.005\n",
      "iteration: 3270 loss: 0.0159 lr: 0.005\n",
      "iteration: 3280 loss: 0.0146 lr: 0.005\n",
      "iteration: 3290 loss: 0.0163 lr: 0.005\n",
      "iteration: 3300 loss: 0.0179 lr: 0.005\n",
      "iteration: 3310 loss: 0.0198 lr: 0.005\n",
      "iteration: 3320 loss: 0.0149 lr: 0.005\n",
      "iteration: 3330 loss: 0.0133 lr: 0.005\n",
      "iteration: 3340 loss: 0.0176 lr: 0.005\n",
      "iteration: 3350 loss: 0.0153 lr: 0.005\n",
      "iteration: 3360 loss: 0.0177 lr: 0.005\n",
      "iteration: 3370 loss: 0.0144 lr: 0.005\n",
      "iteration: 3380 loss: 0.0143 lr: 0.005\n",
      "iteration: 3390 loss: 0.0185 lr: 0.005\n",
      "iteration: 3400 loss: 0.0192 lr: 0.005\n",
      "iteration: 3410 loss: 0.0164 lr: 0.005\n",
      "iteration: 3420 loss: 0.0177 lr: 0.005\n",
      "iteration: 3430 loss: 0.0154 lr: 0.005\n",
      "iteration: 3440 loss: 0.0176 lr: 0.005\n",
      "iteration: 3450 loss: 0.0157 lr: 0.005\n",
      "iteration: 3460 loss: 0.0152 lr: 0.005\n",
      "iteration: 3470 loss: 0.0162 lr: 0.005\n",
      "iteration: 3480 loss: 0.0163 lr: 0.005\n",
      "iteration: 3490 loss: 0.0146 lr: 0.005\n",
      "iteration: 3500 loss: 0.0138 lr: 0.005\n",
      "iteration: 3510 loss: 0.0161 lr: 0.005\n",
      "iteration: 3520 loss: 0.0162 lr: 0.005\n",
      "iteration: 3530 loss: 0.0193 lr: 0.005\n",
      "iteration: 3540 loss: 0.0147 lr: 0.005\n",
      "iteration: 3550 loss: 0.0177 lr: 0.005\n",
      "iteration: 3560 loss: 0.0175 lr: 0.005\n",
      "iteration: 3570 loss: 0.0140 lr: 0.005\n",
      "iteration: 3580 loss: 0.0174 lr: 0.005\n",
      "iteration: 3590 loss: 0.0145 lr: 0.005\n",
      "iteration: 3600 loss: 0.0130 lr: 0.005\n",
      "iteration: 3610 loss: 0.0130 lr: 0.005\n",
      "iteration: 3620 loss: 0.0150 lr: 0.005\n",
      "iteration: 3630 loss: 0.0180 lr: 0.005\n",
      "iteration: 3640 loss: 0.0153 lr: 0.005\n",
      "iteration: 3650 loss: 0.0163 lr: 0.005\n",
      "iteration: 3660 loss: 0.0135 lr: 0.005\n",
      "iteration: 3670 loss: 0.0186 lr: 0.005\n",
      "iteration: 3680 loss: 0.0162 lr: 0.005\n",
      "iteration: 3690 loss: 0.0152 lr: 0.005\n",
      "iteration: 3700 loss: 0.0155 lr: 0.005\n",
      "iteration: 3710 loss: 0.0141 lr: 0.005\n",
      "iteration: 3720 loss: 0.0154 lr: 0.005\n",
      "iteration: 3730 loss: 0.0132 lr: 0.005\n",
      "iteration: 3740 loss: 0.0176 lr: 0.005\n",
      "iteration: 3750 loss: 0.0148 lr: 0.005\n",
      "iteration: 3760 loss: 0.0144 lr: 0.005\n",
      "iteration: 3770 loss: 0.0143 lr: 0.005\n",
      "iteration: 3780 loss: 0.0167 lr: 0.005\n",
      "iteration: 3790 loss: 0.0151 lr: 0.005\n",
      "iteration: 3800 loss: 0.0154 lr: 0.005\n",
      "iteration: 3810 loss: 0.0171 lr: 0.005\n",
      "iteration: 3820 loss: 0.0135 lr: 0.005\n",
      "iteration: 3830 loss: 0.0148 lr: 0.005\n",
      "iteration: 3840 loss: 0.0155 lr: 0.005\n",
      "iteration: 3850 loss: 0.0158 lr: 0.005\n",
      "iteration: 3860 loss: 0.0127 lr: 0.005\n",
      "iteration: 3870 loss: 0.0150 lr: 0.005\n",
      "iteration: 3880 loss: 0.0142 lr: 0.005\n",
      "iteration: 3890 loss: 0.0144 lr: 0.005\n",
      "iteration: 3900 loss: 0.0132 lr: 0.005\n",
      "iteration: 3910 loss: 0.0106 lr: 0.005\n",
      "iteration: 3920 loss: 0.0172 lr: 0.005\n",
      "iteration: 3930 loss: 0.0148 lr: 0.005\n",
      "iteration: 3940 loss: 0.0165 lr: 0.005\n",
      "iteration: 3950 loss: 0.0105 lr: 0.005\n",
      "iteration: 3960 loss: 0.0151 lr: 0.005\n",
      "iteration: 3970 loss: 0.0184 lr: 0.005\n",
      "iteration: 3980 loss: 0.0129 lr: 0.005\n",
      "iteration: 3990 loss: 0.0152 lr: 0.005\n",
      "iteration: 4000 loss: 0.0174 lr: 0.005\n",
      "iteration: 4010 loss: 0.0155 lr: 0.005\n",
      "iteration: 4020 loss: 0.0150 lr: 0.005\n",
      "iteration: 4030 loss: 0.0148 lr: 0.005\n",
      "iteration: 4040 loss: 0.0172 lr: 0.005\n",
      "iteration: 4050 loss: 0.0144 lr: 0.005\n",
      "iteration: 4060 loss: 0.0152 lr: 0.005\n",
      "iteration: 4070 loss: 0.0156 lr: 0.005\n",
      "iteration: 4080 loss: 0.0126 lr: 0.005\n",
      "iteration: 4090 loss: 0.0170 lr: 0.005\n",
      "iteration: 4100 loss: 0.0163 lr: 0.005\n",
      "iteration: 4110 loss: 0.0158 lr: 0.005\n",
      "iteration: 4120 loss: 0.0132 lr: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 4130 loss: 0.0138 lr: 0.005\n",
      "iteration: 4140 loss: 0.0167 lr: 0.005\n",
      "iteration: 4150 loss: 0.0144 lr: 0.005\n",
      "iteration: 4160 loss: 0.0135 lr: 0.005\n",
      "iteration: 4170 loss: 0.0165 lr: 0.005\n",
      "iteration: 4180 loss: 0.0144 lr: 0.005\n",
      "iteration: 4190 loss: 0.0151 lr: 0.005\n",
      "iteration: 4200 loss: 0.0134 lr: 0.005\n",
      "iteration: 4210 loss: 0.0168 lr: 0.005\n",
      "iteration: 4220 loss: 0.0151 lr: 0.005\n",
      "iteration: 4230 loss: 0.0150 lr: 0.005\n",
      "iteration: 4240 loss: 0.0141 lr: 0.005\n",
      "iteration: 4250 loss: 0.0153 lr: 0.005\n",
      "iteration: 4260 loss: 0.0150 lr: 0.005\n",
      "iteration: 4270 loss: 0.0151 lr: 0.005\n",
      "iteration: 4280 loss: 0.0173 lr: 0.005\n",
      "iteration: 4290 loss: 0.0135 lr: 0.005\n",
      "iteration: 4300 loss: 0.0177 lr: 0.005\n",
      "iteration: 4310 loss: 0.0148 lr: 0.005\n",
      "iteration: 4320 loss: 0.0141 lr: 0.005\n",
      "iteration: 4330 loss: 0.0177 lr: 0.005\n",
      "iteration: 4340 loss: 0.0158 lr: 0.005\n",
      "iteration: 4350 loss: 0.0132 lr: 0.005\n",
      "iteration: 4360 loss: 0.0142 lr: 0.005\n",
      "iteration: 4370 loss: 0.0144 lr: 0.005\n",
      "iteration: 4380 loss: 0.0168 lr: 0.005\n",
      "iteration: 4390 loss: 0.0169 lr: 0.005\n",
      "iteration: 4400 loss: 0.0180 lr: 0.005\n",
      "iteration: 4410 loss: 0.0145 lr: 0.005\n",
      "iteration: 4420 loss: 0.0106 lr: 0.005\n",
      "iteration: 4430 loss: 0.0155 lr: 0.005\n",
      "iteration: 4440 loss: 0.0159 lr: 0.005\n",
      "iteration: 4450 loss: 0.0133 lr: 0.005\n",
      "iteration: 4460 loss: 0.0179 lr: 0.005\n",
      "iteration: 4470 loss: 0.0163 lr: 0.005\n",
      "iteration: 4480 loss: 0.0185 lr: 0.005\n",
      "iteration: 4490 loss: 0.0159 lr: 0.005\n",
      "iteration: 4500 loss: 0.0127 lr: 0.005\n",
      "iteration: 4510 loss: 0.0161 lr: 0.005\n",
      "iteration: 4520 loss: 0.0135 lr: 0.005\n",
      "iteration: 4530 loss: 0.0157 lr: 0.005\n",
      "iteration: 4540 loss: 0.0149 lr: 0.005\n",
      "iteration: 4550 loss: 0.0167 lr: 0.005\n",
      "iteration: 4560 loss: 0.0153 lr: 0.005\n",
      "iteration: 4570 loss: 0.0103 lr: 0.005\n",
      "iteration: 4580 loss: 0.0135 lr: 0.005\n",
      "iteration: 4590 loss: 0.0168 lr: 0.005\n",
      "iteration: 4600 loss: 0.0140 lr: 0.005\n",
      "iteration: 4610 loss: 0.0144 lr: 0.005\n",
      "iteration: 4620 loss: 0.0161 lr: 0.005\n",
      "iteration: 4630 loss: 0.0150 lr: 0.005\n",
      "iteration: 4640 loss: 0.0159 lr: 0.005\n",
      "iteration: 4650 loss: 0.0155 lr: 0.005\n",
      "iteration: 4660 loss: 0.0154 lr: 0.005\n",
      "iteration: 4670 loss: 0.0174 lr: 0.005\n",
      "iteration: 4680 loss: 0.0148 lr: 0.005\n",
      "iteration: 4690 loss: 0.0154 lr: 0.005\n",
      "iteration: 4700 loss: 0.0121 lr: 0.005\n",
      "iteration: 4710 loss: 0.0147 lr: 0.005\n",
      "iteration: 4720 loss: 0.0134 lr: 0.005\n",
      "iteration: 4730 loss: 0.0108 lr: 0.005\n",
      "iteration: 4740 loss: 0.0135 lr: 0.005\n",
      "iteration: 4750 loss: 0.0129 lr: 0.005\n",
      "iteration: 4760 loss: 0.0156 lr: 0.005\n",
      "iteration: 4770 loss: 0.0155 lr: 0.005\n",
      "iteration: 4780 loss: 0.0150 lr: 0.005\n",
      "iteration: 4790 loss: 0.0177 lr: 0.005\n",
      "iteration: 4800 loss: 0.0152 lr: 0.005\n",
      "iteration: 4810 loss: 0.0125 lr: 0.005\n",
      "iteration: 4820 loss: 0.0140 lr: 0.005\n",
      "iteration: 4830 loss: 0.0126 lr: 0.005\n",
      "iteration: 4840 loss: 0.0132 lr: 0.005\n",
      "iteration: 4850 loss: 0.0131 lr: 0.005\n",
      "iteration: 4860 loss: 0.0129 lr: 0.005\n",
      "iteration: 4870 loss: 0.0137 lr: 0.005\n",
      "iteration: 4880 loss: 0.0126 lr: 0.005\n",
      "iteration: 4890 loss: 0.0146 lr: 0.005\n",
      "iteration: 4900 loss: 0.0150 lr: 0.005\n",
      "iteration: 4910 loss: 0.0175 lr: 0.005\n",
      "iteration: 4920 loss: 0.0126 lr: 0.005\n",
      "iteration: 4930 loss: 0.0165 lr: 0.005\n",
      "iteration: 4940 loss: 0.0164 lr: 0.005\n",
      "iteration: 4950 loss: 0.0140 lr: 0.005\n",
      "iteration: 4960 loss: 0.0216 lr: 0.005\n",
      "iteration: 4970 loss: 0.0131 lr: 0.005\n",
      "iteration: 4980 loss: 0.0132 lr: 0.005\n",
      "iteration: 4990 loss: 0.0145 lr: 0.005\n",
      "iteration: 5000 loss: 0.0141 lr: 0.005\n",
      "iteration: 5010 loss: 0.0136 lr: 0.005\n",
      "iteration: 5020 loss: 0.0138 lr: 0.005\n",
      "iteration: 5030 loss: 0.0147 lr: 0.005\n",
      "iteration: 5040 loss: 0.0137 lr: 0.005\n",
      "iteration: 5050 loss: 0.0122 lr: 0.005\n",
      "iteration: 5060 loss: 0.0122 lr: 0.005\n",
      "iteration: 5070 loss: 0.0161 lr: 0.005\n",
      "iteration: 5080 loss: 0.0151 lr: 0.005\n",
      "iteration: 5090 loss: 0.0122 lr: 0.005\n",
      "iteration: 5100 loss: 0.0115 lr: 0.005\n",
      "iteration: 5110 loss: 0.0184 lr: 0.005\n",
      "iteration: 5120 loss: 0.0158 lr: 0.005\n",
      "iteration: 5130 loss: 0.0136 lr: 0.005\n",
      "iteration: 5140 loss: 0.0133 lr: 0.005\n",
      "iteration: 5150 loss: 0.0136 lr: 0.005\n",
      "iteration: 5160 loss: 0.0158 lr: 0.005\n",
      "iteration: 5170 loss: 0.0145 lr: 0.005\n",
      "iteration: 5180 loss: 0.0135 lr: 0.005\n",
      "iteration: 5190 loss: 0.0124 lr: 0.005\n",
      "iteration: 5200 loss: 0.0143 lr: 0.005\n",
      "iteration: 5210 loss: 0.0132 lr: 0.005\n",
      "iteration: 5220 loss: 0.0140 lr: 0.005\n",
      "iteration: 5230 loss: 0.0160 lr: 0.005\n",
      "iteration: 5240 loss: 0.0137 lr: 0.005\n",
      "iteration: 5250 loss: 0.0129 lr: 0.005\n",
      "iteration: 5260 loss: 0.0118 lr: 0.005\n",
      "iteration: 5270 loss: 0.0135 lr: 0.005\n",
      "iteration: 5280 loss: 0.0138 lr: 0.005\n",
      "iteration: 5290 loss: 0.0143 lr: 0.005\n",
      "iteration: 5300 loss: 0.0134 lr: 0.005\n",
      "iteration: 5310 loss: 0.0144 lr: 0.005\n",
      "iteration: 5320 loss: 0.0160 lr: 0.005\n",
      "iteration: 5330 loss: 0.0157 lr: 0.005\n",
      "iteration: 5340 loss: 0.0106 lr: 0.005\n",
      "iteration: 5350 loss: 0.0150 lr: 0.005\n",
      "iteration: 5360 loss: 0.0144 lr: 0.005\n",
      "iteration: 5370 loss: 0.0146 lr: 0.005\n",
      "iteration: 5380 loss: 0.0144 lr: 0.005\n",
      "iteration: 5390 loss: 0.0143 lr: 0.005\n",
      "iteration: 5400 loss: 0.0145 lr: 0.005\n",
      "iteration: 5410 loss: 0.0141 lr: 0.005\n",
      "iteration: 5420 loss: 0.0121 lr: 0.005\n",
      "iteration: 5430 loss: 0.0129 lr: 0.005\n",
      "iteration: 5440 loss: 0.0138 lr: 0.005\n",
      "iteration: 5450 loss: 0.0139 lr: 0.005\n",
      "iteration: 5460 loss: 0.0101 lr: 0.005\n",
      "iteration: 5470 loss: 0.0118 lr: 0.005\n",
      "iteration: 5480 loss: 0.0122 lr: 0.005\n",
      "iteration: 5490 loss: 0.0142 lr: 0.005\n",
      "iteration: 5500 loss: 0.0151 lr: 0.005\n",
      "iteration: 5510 loss: 0.0134 lr: 0.005\n",
      "iteration: 5520 loss: 0.0147 lr: 0.005\n",
      "iteration: 5530 loss: 0.0126 lr: 0.005\n",
      "iteration: 5540 loss: 0.0159 lr: 0.005\n",
      "iteration: 5550 loss: 0.0147 lr: 0.005\n",
      "iteration: 5560 loss: 0.0136 lr: 0.005\n",
      "iteration: 5570 loss: 0.0129 lr: 0.005\n",
      "iteration: 5580 loss: 0.0115 lr: 0.005\n",
      "iteration: 5590 loss: 0.0114 lr: 0.005\n",
      "iteration: 5600 loss: 0.0157 lr: 0.005\n",
      "iteration: 5610 loss: 0.0132 lr: 0.005\n",
      "iteration: 5620 loss: 0.0162 lr: 0.005\n",
      "iteration: 5630 loss: 0.0114 lr: 0.005\n",
      "iteration: 5640 loss: 0.0150 lr: 0.005\n",
      "iteration: 5650 loss: 0.0169 lr: 0.005\n",
      "iteration: 5660 loss: 0.0156 lr: 0.005\n",
      "iteration: 5670 loss: 0.0146 lr: 0.005\n",
      "iteration: 5680 loss: 0.0125 lr: 0.005\n",
      "iteration: 5690 loss: 0.0118 lr: 0.005\n",
      "iteration: 5700 loss: 0.0126 lr: 0.005\n",
      "iteration: 5710 loss: 0.0130 lr: 0.005\n",
      "iteration: 5720 loss: 0.0153 lr: 0.005\n",
      "iteration: 5730 loss: 0.0126 lr: 0.005\n",
      "iteration: 5740 loss: 0.0124 lr: 0.005\n",
      "iteration: 5750 loss: 0.0155 lr: 0.005\n",
      "iteration: 5760 loss: 0.0121 lr: 0.005\n",
      "iteration: 5770 loss: 0.0118 lr: 0.005\n",
      "iteration: 5780 loss: 0.0117 lr: 0.005\n",
      "iteration: 5790 loss: 0.0125 lr: 0.005\n",
      "iteration: 5800 loss: 0.0125 lr: 0.005\n",
      "iteration: 5810 loss: 0.0148 lr: 0.005\n",
      "iteration: 5820 loss: 0.0147 lr: 0.005\n",
      "iteration: 5830 loss: 0.0144 lr: 0.005\n",
      "iteration: 5840 loss: 0.0126 lr: 0.005\n",
      "iteration: 5850 loss: 0.0118 lr: 0.005\n",
      "iteration: 5860 loss: 0.0136 lr: 0.005\n",
      "iteration: 5870 loss: 0.0130 lr: 0.005\n",
      "iteration: 5880 loss: 0.0148 lr: 0.005\n",
      "iteration: 5890 loss: 0.0152 lr: 0.005\n",
      "iteration: 5900 loss: 0.0135 lr: 0.005\n",
      "iteration: 5910 loss: 0.0149 lr: 0.005\n",
      "iteration: 5920 loss: 0.0142 lr: 0.005\n",
      "iteration: 5930 loss: 0.0124 lr: 0.005\n",
      "iteration: 5940 loss: 0.0130 lr: 0.005\n",
      "iteration: 5950 loss: 0.0112 lr: 0.005\n",
      "iteration: 5960 loss: 0.0143 lr: 0.005\n",
      "iteration: 5970 loss: 0.0127 lr: 0.005\n",
      "iteration: 5980 loss: 0.0132 lr: 0.005\n",
      "iteration: 5990 loss: 0.0138 lr: 0.005\n",
      "iteration: 6000 loss: 0.0132 lr: 0.005\n",
      "iteration: 6010 loss: 0.0124 lr: 0.005\n",
      "iteration: 6020 loss: 0.0146 lr: 0.005\n",
      "iteration: 6030 loss: 0.0129 lr: 0.005\n",
      "iteration: 6040 loss: 0.0120 lr: 0.005\n",
      "iteration: 6050 loss: 0.0119 lr: 0.005\n",
      "iteration: 6060 loss: 0.0132 lr: 0.005\n",
      "iteration: 6070 loss: 0.0128 lr: 0.005\n",
      "iteration: 6080 loss: 0.0131 lr: 0.005\n",
      "iteration: 6090 loss: 0.0129 lr: 0.005\n",
      "iteration: 6100 loss: 0.0131 lr: 0.005\n",
      "iteration: 6110 loss: 0.0129 lr: 0.005\n",
      "iteration: 6120 loss: 0.0126 lr: 0.005\n",
      "iteration: 6130 loss: 0.0134 lr: 0.005\n",
      "iteration: 6140 loss: 0.0123 lr: 0.005\n",
      "iteration: 6150 loss: 0.0139 lr: 0.005\n",
      "iteration: 6160 loss: 0.0135 lr: 0.005\n",
      "iteration: 6170 loss: 0.0169 lr: 0.005\n",
      "iteration: 6180 loss: 0.0107 lr: 0.005\n",
      "iteration: 6190 loss: 0.0132 lr: 0.005\n",
      "iteration: 6200 loss: 0.0143 lr: 0.005\n",
      "iteration: 6210 loss: 0.0114 lr: 0.005\n",
      "iteration: 6220 loss: 0.0115 lr: 0.005\n",
      "iteration: 6230 loss: 0.0142 lr: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 6240 loss: 0.0121 lr: 0.005\n",
      "iteration: 6250 loss: 0.0137 lr: 0.005\n",
      "iteration: 6260 loss: 0.0164 lr: 0.005\n",
      "iteration: 6270 loss: 0.0125 lr: 0.005\n",
      "iteration: 6280 loss: 0.0127 lr: 0.005\n",
      "iteration: 6290 loss: 0.0141 lr: 0.005\n",
      "iteration: 6300 loss: 0.0107 lr: 0.005\n",
      "iteration: 6310 loss: 0.0119 lr: 0.005\n",
      "iteration: 6320 loss: 0.0159 lr: 0.005\n",
      "iteration: 6330 loss: 0.0143 lr: 0.005\n",
      "iteration: 6340 loss: 0.0148 lr: 0.005\n",
      "iteration: 6350 loss: 0.0111 lr: 0.005\n",
      "iteration: 6360 loss: 0.0114 lr: 0.005\n",
      "iteration: 6370 loss: 0.0137 lr: 0.005\n",
      "iteration: 6380 loss: 0.0144 lr: 0.005\n",
      "iteration: 6390 loss: 0.0127 lr: 0.005\n",
      "iteration: 6400 loss: 0.0130 lr: 0.005\n",
      "iteration: 6410 loss: 0.0122 lr: 0.005\n",
      "iteration: 6420 loss: 0.0127 lr: 0.005\n",
      "iteration: 6430 loss: 0.0121 lr: 0.005\n",
      "iteration: 6440 loss: 0.0140 lr: 0.005\n",
      "iteration: 6450 loss: 0.0158 lr: 0.005\n",
      "iteration: 6460 loss: 0.0112 lr: 0.005\n",
      "iteration: 6470 loss: 0.0135 lr: 0.005\n",
      "iteration: 6480 loss: 0.0145 lr: 0.005\n",
      "iteration: 6490 loss: 0.0143 lr: 0.005\n",
      "iteration: 6500 loss: 0.0114 lr: 0.005\n",
      "iteration: 6510 loss: 0.0145 lr: 0.005\n",
      "iteration: 6520 loss: 0.0114 lr: 0.005\n",
      "iteration: 6530 loss: 0.0159 lr: 0.005\n",
      "iteration: 6540 loss: 0.0142 lr: 0.005\n",
      "iteration: 6550 loss: 0.0132 lr: 0.005\n",
      "iteration: 6560 loss: 0.0135 lr: 0.005\n",
      "iteration: 6570 loss: 0.0133 lr: 0.005\n",
      "iteration: 6580 loss: 0.0143 lr: 0.005\n",
      "iteration: 6590 loss: 0.0130 lr: 0.005\n",
      "iteration: 6600 loss: 0.0166 lr: 0.005\n",
      "iteration: 6610 loss: 0.0108 lr: 0.005\n",
      "iteration: 6620 loss: 0.0121 lr: 0.005\n",
      "iteration: 6630 loss: 0.0119 lr: 0.005\n",
      "iteration: 6640 loss: 0.0122 lr: 0.005\n",
      "iteration: 6650 loss: 0.0129 lr: 0.005\n",
      "iteration: 6660 loss: 0.0143 lr: 0.005\n",
      "iteration: 6670 loss: 0.0132 lr: 0.005\n",
      "iteration: 6680 loss: 0.0127 lr: 0.005\n",
      "iteration: 6690 loss: 0.0130 lr: 0.005\n",
      "iteration: 6700 loss: 0.0100 lr: 0.005\n",
      "iteration: 6710 loss: 0.0127 lr: 0.005\n",
      "iteration: 6720 loss: 0.0129 lr: 0.005\n",
      "iteration: 6730 loss: 0.0138 lr: 0.005\n",
      "iteration: 6740 loss: 0.0111 lr: 0.005\n",
      "iteration: 6750 loss: 0.0107 lr: 0.005\n",
      "iteration: 6760 loss: 0.0117 lr: 0.005\n",
      "iteration: 6770 loss: 0.0141 lr: 0.005\n",
      "iteration: 6780 loss: 0.0122 lr: 0.005\n",
      "iteration: 6790 loss: 0.0121 lr: 0.005\n",
      "iteration: 6800 loss: 0.0124 lr: 0.005\n",
      "iteration: 6810 loss: 0.0139 lr: 0.005\n",
      "iteration: 6820 loss: 0.0120 lr: 0.005\n",
      "iteration: 6830 loss: 0.0125 lr: 0.005\n",
      "iteration: 6840 loss: 0.0117 lr: 0.005\n",
      "iteration: 6850 loss: 0.0124 lr: 0.005\n",
      "iteration: 6860 loss: 0.0118 lr: 0.005\n",
      "iteration: 6870 loss: 0.0126 lr: 0.005\n",
      "iteration: 6880 loss: 0.0126 lr: 0.005\n",
      "iteration: 6890 loss: 0.0124 lr: 0.005\n",
      "iteration: 6900 loss: 0.0137 lr: 0.005\n",
      "iteration: 6910 loss: 0.0140 lr: 0.005\n",
      "iteration: 6920 loss: 0.0123 lr: 0.005\n",
      "iteration: 6930 loss: 0.0104 lr: 0.005\n",
      "iteration: 6940 loss: 0.0130 lr: 0.005\n",
      "iteration: 6950 loss: 0.0151 lr: 0.005\n",
      "iteration: 6960 loss: 0.0099 lr: 0.005\n",
      "iteration: 6970 loss: 0.0127 lr: 0.005\n",
      "iteration: 6980 loss: 0.0116 lr: 0.005\n",
      "iteration: 6990 loss: 0.0124 lr: 0.005\n",
      "iteration: 7000 loss: 0.0133 lr: 0.005\n",
      "iteration: 7010 loss: 0.0134 lr: 0.005\n",
      "iteration: 7020 loss: 0.0105 lr: 0.005\n",
      "iteration: 7030 loss: 0.0151 lr: 0.005\n",
      "iteration: 7040 loss: 0.0139 lr: 0.005\n",
      "iteration: 7050 loss: 0.0138 lr: 0.005\n",
      "iteration: 7060 loss: 0.0133 lr: 0.005\n",
      "iteration: 7070 loss: 0.0138 lr: 0.005\n",
      "iteration: 7080 loss: 0.0117 lr: 0.005\n",
      "iteration: 7090 loss: 0.0109 lr: 0.005\n",
      "iteration: 7100 loss: 0.0092 lr: 0.005\n",
      "iteration: 7110 loss: 0.0137 lr: 0.005\n",
      "iteration: 7120 loss: 0.0130 lr: 0.005\n",
      "iteration: 7130 loss: 0.0140 lr: 0.005\n",
      "iteration: 7140 loss: 0.0164 lr: 0.005\n",
      "iteration: 7150 loss: 0.0126 lr: 0.005\n",
      "iteration: 7160 loss: 0.0144 lr: 0.005\n",
      "iteration: 7170 loss: 0.0121 lr: 0.005\n",
      "iteration: 7180 loss: 0.0125 lr: 0.005\n",
      "iteration: 7190 loss: 0.0153 lr: 0.005\n",
      "iteration: 7200 loss: 0.0126 lr: 0.005\n",
      "iteration: 7210 loss: 0.0114 lr: 0.005\n",
      "iteration: 7220 loss: 0.0145 lr: 0.005\n",
      "iteration: 7230 loss: 0.0124 lr: 0.005\n",
      "iteration: 7240 loss: 0.0106 lr: 0.005\n",
      "iteration: 7250 loss: 0.0106 lr: 0.005\n",
      "iteration: 7260 loss: 0.0127 lr: 0.005\n",
      "iteration: 7270 loss: 0.0109 lr: 0.005\n",
      "iteration: 7280 loss: 0.0138 lr: 0.005\n",
      "iteration: 7290 loss: 0.0160 lr: 0.005\n",
      "iteration: 7300 loss: 0.0141 lr: 0.005\n",
      "iteration: 7310 loss: 0.0106 lr: 0.005\n",
      "iteration: 7320 loss: 0.0124 lr: 0.005\n",
      "iteration: 7330 loss: 0.0122 lr: 0.005\n",
      "iteration: 7340 loss: 0.0118 lr: 0.005\n",
      "iteration: 7350 loss: 0.0141 lr: 0.005\n",
      "iteration: 7360 loss: 0.0129 lr: 0.005\n",
      "iteration: 7370 loss: 0.0111 lr: 0.005\n",
      "iteration: 7380 loss: 0.0131 lr: 0.005\n",
      "iteration: 7390 loss: 0.0127 lr: 0.005\n",
      "iteration: 7400 loss: 0.0108 lr: 0.005\n",
      "iteration: 7410 loss: 0.0126 lr: 0.005\n",
      "iteration: 7420 loss: 0.0141 lr: 0.005\n",
      "iteration: 7430 loss: 0.0104 lr: 0.005\n",
      "iteration: 7440 loss: 0.0108 lr: 0.005\n",
      "iteration: 7450 loss: 0.0130 lr: 0.005\n",
      "iteration: 7460 loss: 0.0134 lr: 0.005\n",
      "iteration: 7470 loss: 0.0124 lr: 0.005\n",
      "iteration: 7480 loss: 0.0141 lr: 0.005\n",
      "iteration: 7490 loss: 0.0114 lr: 0.005\n",
      "iteration: 7500 loss: 0.0148 lr: 0.005\n",
      "iteration: 7510 loss: 0.0113 lr: 0.005\n",
      "iteration: 7520 loss: 0.0133 lr: 0.005\n",
      "iteration: 7530 loss: 0.0106 lr: 0.005\n",
      "iteration: 7540 loss: 0.0125 lr: 0.005\n",
      "iteration: 7550 loss: 0.0110 lr: 0.005\n",
      "iteration: 7560 loss: 0.0129 lr: 0.005\n",
      "iteration: 7570 loss: 0.0143 lr: 0.005\n",
      "iteration: 7580 loss: 0.0135 lr: 0.005\n",
      "iteration: 7590 loss: 0.0100 lr: 0.005\n",
      "iteration: 7600 loss: 0.0139 lr: 0.005\n",
      "iteration: 7610 loss: 0.0127 lr: 0.005\n",
      "iteration: 7620 loss: 0.0122 lr: 0.005\n",
      "iteration: 7630 loss: 0.0136 lr: 0.005\n",
      "iteration: 7640 loss: 0.0129 lr: 0.005\n",
      "iteration: 7650 loss: 0.0145 lr: 0.005\n",
      "iteration: 7660 loss: 0.0144 lr: 0.005\n",
      "iteration: 7670 loss: 0.0115 lr: 0.005\n",
      "iteration: 7680 loss: 0.0110 lr: 0.005\n",
      "iteration: 7690 loss: 0.0117 lr: 0.005\n",
      "iteration: 7700 loss: 0.0122 lr: 0.005\n",
      "iteration: 7710 loss: 0.0128 lr: 0.005\n",
      "iteration: 7720 loss: 0.0126 lr: 0.005\n",
      "iteration: 7730 loss: 0.0117 lr: 0.005\n",
      "iteration: 7740 loss: 0.0132 lr: 0.005\n",
      "iteration: 7750 loss: 0.0103 lr: 0.005\n",
      "iteration: 7760 loss: 0.0118 lr: 0.005\n",
      "iteration: 7770 loss: 0.0136 lr: 0.005\n",
      "iteration: 7780 loss: 0.0110 lr: 0.005\n",
      "iteration: 7790 loss: 0.0110 lr: 0.005\n",
      "iteration: 7800 loss: 0.0144 lr: 0.005\n",
      "iteration: 7810 loss: 0.0121 lr: 0.005\n",
      "iteration: 7820 loss: 0.0118 lr: 0.005\n",
      "iteration: 7830 loss: 0.0131 lr: 0.005\n",
      "iteration: 7840 loss: 0.0142 lr: 0.005\n",
      "iteration: 7850 loss: 0.0117 lr: 0.005\n",
      "iteration: 7860 loss: 0.0122 lr: 0.005\n",
      "iteration: 7870 loss: 0.0116 lr: 0.005\n",
      "iteration: 7880 loss: 0.0125 lr: 0.005\n",
      "iteration: 7890 loss: 0.0115 lr: 0.005\n",
      "iteration: 7900 loss: 0.0127 lr: 0.005\n",
      "iteration: 7910 loss: 0.0112 lr: 0.005\n",
      "iteration: 7920 loss: 0.0118 lr: 0.005\n",
      "iteration: 7930 loss: 0.0132 lr: 0.005\n",
      "iteration: 7940 loss: 0.0117 lr: 0.005\n",
      "iteration: 7950 loss: 0.0143 lr: 0.005\n",
      "iteration: 7960 loss: 0.0117 lr: 0.005\n",
      "iteration: 7970 loss: 0.0107 lr: 0.005\n",
      "iteration: 7980 loss: 0.0123 lr: 0.005\n",
      "iteration: 7990 loss: 0.0098 lr: 0.005\n",
      "iteration: 8000 loss: 0.0125 lr: 0.005\n",
      "iteration: 8010 loss: 0.0143 lr: 0.005\n",
      "iteration: 8020 loss: 0.0126 lr: 0.005\n",
      "iteration: 8030 loss: 0.0123 lr: 0.005\n",
      "iteration: 8040 loss: 0.0116 lr: 0.005\n",
      "iteration: 8050 loss: 0.0093 lr: 0.005\n",
      "iteration: 8060 loss: 0.0139 lr: 0.005\n",
      "iteration: 8070 loss: 0.0109 lr: 0.005\n",
      "iteration: 8080 loss: 0.0152 lr: 0.005\n",
      "iteration: 8090 loss: 0.0111 lr: 0.005\n",
      "iteration: 8100 loss: 0.0115 lr: 0.005\n",
      "iteration: 8110 loss: 0.0133 lr: 0.005\n",
      "iteration: 8120 loss: 0.0122 lr: 0.005\n",
      "iteration: 8130 loss: 0.0121 lr: 0.005\n",
      "iteration: 8140 loss: 0.0118 lr: 0.005\n",
      "iteration: 8150 loss: 0.0119 lr: 0.005\n",
      "iteration: 8160 loss: 0.0118 lr: 0.005\n",
      "iteration: 8170 loss: 0.0132 lr: 0.005\n",
      "iteration: 8180 loss: 0.0152 lr: 0.005\n",
      "iteration: 8190 loss: 0.0100 lr: 0.005\n",
      "iteration: 8200 loss: 0.0108 lr: 0.005\n",
      "iteration: 8210 loss: 0.0128 lr: 0.005\n",
      "iteration: 8220 loss: 0.0149 lr: 0.005\n",
      "iteration: 8230 loss: 0.0125 lr: 0.005\n",
      "iteration: 8240 loss: 0.0118 lr: 0.005\n",
      "iteration: 8250 loss: 0.0113 lr: 0.005\n",
      "iteration: 8260 loss: 0.0103 lr: 0.005\n",
      "iteration: 8270 loss: 0.0135 lr: 0.005\n",
      "iteration: 8280 loss: 0.0108 lr: 0.005\n",
      "iteration: 8290 loss: 0.0094 lr: 0.005\n",
      "iteration: 8300 loss: 0.0111 lr: 0.005\n",
      "iteration: 8310 loss: 0.0169 lr: 0.005\n",
      "iteration: 8320 loss: 0.0116 lr: 0.005\n",
      "iteration: 8330 loss: 0.0112 lr: 0.005\n",
      "iteration: 8340 loss: 0.0112 lr: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 8350 loss: 0.0120 lr: 0.005\n",
      "iteration: 8360 loss: 0.0118 lr: 0.005\n",
      "iteration: 8370 loss: 0.0095 lr: 0.005\n",
      "iteration: 8380 loss: 0.0104 lr: 0.005\n",
      "iteration: 8390 loss: 0.0128 lr: 0.005\n",
      "iteration: 8400 loss: 0.0120 lr: 0.005\n",
      "iteration: 8410 loss: 0.0124 lr: 0.005\n",
      "iteration: 8420 loss: 0.0127 lr: 0.005\n",
      "iteration: 8430 loss: 0.0101 lr: 0.005\n",
      "iteration: 8440 loss: 0.0129 lr: 0.005\n",
      "iteration: 8450 loss: 0.0116 lr: 0.005\n",
      "iteration: 8460 loss: 0.0114 lr: 0.005\n",
      "iteration: 8470 loss: 0.0118 lr: 0.005\n",
      "iteration: 8480 loss: 0.0096 lr: 0.005\n",
      "iteration: 8490 loss: 0.0117 lr: 0.005\n",
      "iteration: 8500 loss: 0.0103 lr: 0.005\n",
      "iteration: 8510 loss: 0.0119 lr: 0.005\n",
      "iteration: 8520 loss: 0.0110 lr: 0.005\n",
      "iteration: 8530 loss: 0.0128 lr: 0.005\n",
      "iteration: 8540 loss: 0.0118 lr: 0.005\n",
      "iteration: 8550 loss: 0.0122 lr: 0.005\n",
      "iteration: 8560 loss: 0.0123 lr: 0.005\n",
      "iteration: 8570 loss: 0.0124 lr: 0.005\n",
      "iteration: 8580 loss: 0.0150 lr: 0.005\n",
      "iteration: 8590 loss: 0.0117 lr: 0.005\n",
      "iteration: 8600 loss: 0.0119 lr: 0.005\n",
      "iteration: 8610 loss: 0.0124 lr: 0.005\n",
      "iteration: 8620 loss: 0.0120 lr: 0.005\n",
      "iteration: 8630 loss: 0.0123 lr: 0.005\n",
      "iteration: 8640 loss: 0.0113 lr: 0.005\n",
      "iteration: 8650 loss: 0.0113 lr: 0.005\n",
      "iteration: 8660 loss: 0.0108 lr: 0.005\n",
      "iteration: 8670 loss: 0.0094 lr: 0.005\n",
      "iteration: 8680 loss: 0.0119 lr: 0.005\n",
      "iteration: 8690 loss: 0.0141 lr: 0.005\n",
      "iteration: 8700 loss: 0.0121 lr: 0.005\n",
      "iteration: 8710 loss: 0.0105 lr: 0.005\n",
      "iteration: 8720 loss: 0.0127 lr: 0.005\n",
      "iteration: 8730 loss: 0.0094 lr: 0.005\n",
      "iteration: 8740 loss: 0.0108 lr: 0.005\n",
      "iteration: 8750 loss: 0.0122 lr: 0.005\n",
      "iteration: 8760 loss: 0.0133 lr: 0.005\n",
      "iteration: 8770 loss: 0.0128 lr: 0.005\n",
      "iteration: 8780 loss: 0.0098 lr: 0.005\n",
      "iteration: 8790 loss: 0.0133 lr: 0.005\n",
      "iteration: 8800 loss: 0.0126 lr: 0.005\n",
      "iteration: 8810 loss: 0.0118 lr: 0.005\n",
      "iteration: 8820 loss: 0.0109 lr: 0.005\n",
      "iteration: 8830 loss: 0.0133 lr: 0.005\n",
      "iteration: 8840 loss: 0.0123 lr: 0.005\n",
      "iteration: 8850 loss: 0.0124 lr: 0.005\n",
      "iteration: 8860 loss: 0.0129 lr: 0.005\n",
      "iteration: 8870 loss: 0.0117 lr: 0.005\n",
      "iteration: 8880 loss: 0.0112 lr: 0.005\n",
      "iteration: 8890 loss: 0.0123 lr: 0.005\n",
      "iteration: 8900 loss: 0.0129 lr: 0.005\n",
      "iteration: 8910 loss: 0.0141 lr: 0.005\n",
      "iteration: 8920 loss: 0.0120 lr: 0.005\n",
      "iteration: 8930 loss: 0.0133 lr: 0.005\n",
      "iteration: 8940 loss: 0.0123 lr: 0.005\n",
      "iteration: 8950 loss: 0.0090 lr: 0.005\n",
      "iteration: 8960 loss: 0.0101 lr: 0.005\n",
      "iteration: 8970 loss: 0.0094 lr: 0.005\n",
      "iteration: 8980 loss: 0.0124 lr: 0.005\n",
      "iteration: 8990 loss: 0.0115 lr: 0.005\n",
      "iteration: 9000 loss: 0.0113 lr: 0.005\n",
      "iteration: 9010 loss: 0.0120 lr: 0.005\n",
      "iteration: 9020 loss: 0.0130 lr: 0.005\n",
      "iteration: 9030 loss: 0.0093 lr: 0.005\n",
      "iteration: 9040 loss: 0.0107 lr: 0.005\n",
      "iteration: 9050 loss: 0.0093 lr: 0.005\n",
      "iteration: 9060 loss: 0.0121 lr: 0.005\n",
      "iteration: 9070 loss: 0.0122 lr: 0.005\n",
      "iteration: 9080 loss: 0.0113 lr: 0.005\n",
      "iteration: 9090 loss: 0.0121 lr: 0.005\n",
      "iteration: 9100 loss: 0.0120 lr: 0.005\n",
      "iteration: 9110 loss: 0.0110 lr: 0.005\n",
      "iteration: 9120 loss: 0.0103 lr: 0.005\n",
      "iteration: 9130 loss: 0.0116 lr: 0.005\n",
      "iteration: 9140 loss: 0.0101 lr: 0.005\n",
      "iteration: 9150 loss: 0.0125 lr: 0.005\n",
      "iteration: 9160 loss: 0.0116 lr: 0.005\n",
      "iteration: 9170 loss: 0.0109 lr: 0.005\n",
      "iteration: 9180 loss: 0.0104 lr: 0.005\n",
      "iteration: 9190 loss: 0.0132 lr: 0.005\n",
      "iteration: 9200 loss: 0.0132 lr: 0.005\n",
      "iteration: 9210 loss: 0.0091 lr: 0.005\n",
      "iteration: 9220 loss: 0.0112 lr: 0.005\n",
      "iteration: 9230 loss: 0.0118 lr: 0.005\n",
      "iteration: 9240 loss: 0.0114 lr: 0.005\n",
      "iteration: 9250 loss: 0.0116 lr: 0.005\n",
      "iteration: 9260 loss: 0.0117 lr: 0.005\n",
      "iteration: 9270 loss: 0.0128 lr: 0.005\n",
      "iteration: 9280 loss: 0.0123 lr: 0.005\n",
      "iteration: 9290 loss: 0.0114 lr: 0.005\n",
      "iteration: 9300 loss: 0.0107 lr: 0.005\n",
      "iteration: 9310 loss: 0.0108 lr: 0.005\n",
      "iteration: 9320 loss: 0.0129 lr: 0.005\n",
      "iteration: 9330 loss: 0.0115 lr: 0.005\n",
      "iteration: 9340 loss: 0.0119 lr: 0.005\n",
      "iteration: 9350 loss: 0.0140 lr: 0.005\n",
      "iteration: 9360 loss: 0.0115 lr: 0.005\n",
      "iteration: 9370 loss: 0.0093 lr: 0.005\n",
      "iteration: 9380 loss: 0.0106 lr: 0.005\n",
      "iteration: 9390 loss: 0.0113 lr: 0.005\n",
      "iteration: 9400 loss: 0.0117 lr: 0.005\n",
      "iteration: 9410 loss: 0.0116 lr: 0.005\n",
      "iteration: 9420 loss: 0.0113 lr: 0.005\n",
      "iteration: 9430 loss: 0.0136 lr: 0.005\n",
      "iteration: 9440 loss: 0.0116 lr: 0.005\n",
      "iteration: 9450 loss: 0.0123 lr: 0.005\n",
      "iteration: 9460 loss: 0.0112 lr: 0.005\n",
      "iteration: 9470 loss: 0.0137 lr: 0.005\n",
      "iteration: 9480 loss: 0.0105 lr: 0.005\n",
      "iteration: 9490 loss: 0.0105 lr: 0.005\n",
      "iteration: 9500 loss: 0.0113 lr: 0.005\n",
      "iteration: 9510 loss: 0.0129 lr: 0.005\n",
      "iteration: 9520 loss: 0.0128 lr: 0.005\n",
      "iteration: 9530 loss: 0.0105 lr: 0.005\n",
      "iteration: 9540 loss: 0.0096 lr: 0.005\n",
      "iteration: 9550 loss: 0.0112 lr: 0.005\n",
      "iteration: 9560 loss: 0.0110 lr: 0.005\n",
      "iteration: 9570 loss: 0.0134 lr: 0.005\n",
      "iteration: 9580 loss: 0.0098 lr: 0.005\n",
      "iteration: 9590 loss: 0.0109 lr: 0.005\n",
      "iteration: 9600 loss: 0.0120 lr: 0.005\n",
      "iteration: 9610 loss: 0.0107 lr: 0.005\n",
      "iteration: 9620 loss: 0.0127 lr: 0.005\n",
      "iteration: 9630 loss: 0.0094 lr: 0.005\n",
      "iteration: 9640 loss: 0.0117 lr: 0.005\n",
      "iteration: 9650 loss: 0.0134 lr: 0.005\n",
      "iteration: 9660 loss: 0.0106 lr: 0.005\n",
      "iteration: 9670 loss: 0.0131 lr: 0.005\n",
      "iteration: 9680 loss: 0.0124 lr: 0.005\n",
      "iteration: 9690 loss: 0.0117 lr: 0.005\n",
      "iteration: 9700 loss: 0.0086 lr: 0.005\n",
      "iteration: 9710 loss: 0.0098 lr: 0.005\n",
      "iteration: 9720 loss: 0.0120 lr: 0.005\n",
      "iteration: 9730 loss: 0.0119 lr: 0.005\n",
      "iteration: 9740 loss: 0.0100 lr: 0.005\n",
      "iteration: 9750 loss: 0.0121 lr: 0.005\n",
      "iteration: 9760 loss: 0.0105 lr: 0.005\n",
      "iteration: 9770 loss: 0.0098 lr: 0.005\n",
      "iteration: 9780 loss: 0.0113 lr: 0.005\n",
      "iteration: 9790 loss: 0.0101 lr: 0.005\n",
      "iteration: 9800 loss: 0.0136 lr: 0.005\n",
      "iteration: 9810 loss: 0.0090 lr: 0.005\n",
      "iteration: 9820 loss: 0.0089 lr: 0.005\n",
      "iteration: 9830 loss: 0.0101 lr: 0.005\n",
      "iteration: 9840 loss: 0.0109 lr: 0.005\n",
      "iteration: 9850 loss: 0.0101 lr: 0.005\n",
      "iteration: 9860 loss: 0.0105 lr: 0.005\n",
      "iteration: 9870 loss: 0.0121 lr: 0.005\n",
      "iteration: 9880 loss: 0.0114 lr: 0.005\n",
      "iteration: 9890 loss: 0.0118 lr: 0.005\n",
      "iteration: 9900 loss: 0.0109 lr: 0.005\n",
      "iteration: 9910 loss: 0.0089 lr: 0.005\n",
      "iteration: 9920 loss: 0.0112 lr: 0.005\n",
      "iteration: 9930 loss: 0.0101 lr: 0.005\n",
      "iteration: 9940 loss: 0.0129 lr: 0.005\n",
      "iteration: 9950 loss: 0.0132 lr: 0.005\n",
      "iteration: 9960 loss: 0.0130 lr: 0.005\n",
      "iteration: 9970 loss: 0.0090 lr: 0.005\n",
      "iteration: 9980 loss: 0.0106 lr: 0.005\n",
      "iteration: 9990 loss: 0.0114 lr: 0.005\n",
      "iteration: 10000 loss: 0.0139 lr: 0.005\n",
      "iteration: 10010 loss: 0.0125 lr: 0.02\n",
      "iteration: 10020 loss: 0.0135 lr: 0.02\n",
      "iteration: 10030 loss: 0.0169 lr: 0.02\n",
      "iteration: 10040 loss: 0.0144 lr: 0.02\n",
      "iteration: 10050 loss: 0.0150 lr: 0.02\n",
      "iteration: 10060 loss: 0.0136 lr: 0.02\n",
      "iteration: 10070 loss: 0.0128 lr: 0.02\n",
      "iteration: 10080 loss: 0.0142 lr: 0.02\n",
      "iteration: 10090 loss: 0.0146 lr: 0.02\n",
      "iteration: 10100 loss: 0.0152 lr: 0.02\n",
      "iteration: 10110 loss: 0.0131 lr: 0.02\n",
      "iteration: 10120 loss: 0.0130 lr: 0.02\n",
      "iteration: 10130 loss: 0.0154 lr: 0.02\n",
      "iteration: 10140 loss: 0.0229 lr: 0.02\n",
      "iteration: 10150 loss: 0.0152 lr: 0.02\n",
      "iteration: 10160 loss: 0.0163 lr: 0.02\n",
      "iteration: 10170 loss: 0.0152 lr: 0.02\n",
      "iteration: 10180 loss: 0.0130 lr: 0.02\n",
      "iteration: 10190 loss: 0.0127 lr: 0.02\n",
      "iteration: 10200 loss: 0.0128 lr: 0.02\n",
      "iteration: 10210 loss: 0.0151 lr: 0.02\n",
      "iteration: 10220 loss: 0.0144 lr: 0.02\n",
      "iteration: 10230 loss: 0.0156 lr: 0.02\n",
      "iteration: 10240 loss: 0.0155 lr: 0.02\n",
      "iteration: 10250 loss: 0.0153 lr: 0.02\n",
      "iteration: 10260 loss: 0.0167 lr: 0.02\n",
      "iteration: 10270 loss: 0.0138 lr: 0.02\n",
      "iteration: 10280 loss: 0.0148 lr: 0.02\n",
      "iteration: 10290 loss: 0.0121 lr: 0.02\n",
      "iteration: 10300 loss: 0.0129 lr: 0.02\n",
      "iteration: 10310 loss: 0.0120 lr: 0.02\n",
      "iteration: 10320 loss: 0.0130 lr: 0.02\n",
      "iteration: 10330 loss: 0.0148 lr: 0.02\n",
      "iteration: 10340 loss: 0.0110 lr: 0.02\n",
      "iteration: 10350 loss: 0.0158 lr: 0.02\n",
      "iteration: 10360 loss: 0.0127 lr: 0.02\n",
      "iteration: 10370 loss: 0.0124 lr: 0.02\n",
      "iteration: 10380 loss: 0.0148 lr: 0.02\n",
      "iteration: 10390 loss: 0.0175 lr: 0.02\n",
      "iteration: 10400 loss: 0.0120 lr: 0.02\n",
      "iteration: 10410 loss: 0.0125 lr: 0.02\n",
      "iteration: 10420 loss: 0.0144 lr: 0.02\n",
      "iteration: 10430 loss: 0.0118 lr: 0.02\n",
      "iteration: 10440 loss: 0.0179 lr: 0.02\n",
      "iteration: 10450 loss: 0.0138 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 10460 loss: 0.0144 lr: 0.02\n",
      "iteration: 10470 loss: 0.0147 lr: 0.02\n",
      "iteration: 10480 loss: 0.0138 lr: 0.02\n",
      "iteration: 10490 loss: 0.0160 lr: 0.02\n",
      "iteration: 10500 loss: 0.0125 lr: 0.02\n",
      "iteration: 10510 loss: 0.0137 lr: 0.02\n",
      "iteration: 10520 loss: 0.0119 lr: 0.02\n",
      "iteration: 10530 loss: 0.0113 lr: 0.02\n",
      "iteration: 10540 loss: 0.0122 lr: 0.02\n",
      "iteration: 10550 loss: 0.0145 lr: 0.02\n",
      "iteration: 10560 loss: 0.0142 lr: 0.02\n",
      "iteration: 10570 loss: 0.0135 lr: 0.02\n",
      "iteration: 10580 loss: 0.0139 lr: 0.02\n",
      "iteration: 10590 loss: 0.0117 lr: 0.02\n",
      "iteration: 10600 loss: 0.0127 lr: 0.02\n",
      "iteration: 10610 loss: 0.0129 lr: 0.02\n",
      "iteration: 10620 loss: 0.0114 lr: 0.02\n",
      "iteration: 10630 loss: 0.0136 lr: 0.02\n",
      "iteration: 10640 loss: 0.0142 lr: 0.02\n",
      "iteration: 10650 loss: 0.0112 lr: 0.02\n",
      "iteration: 10660 loss: 0.0126 lr: 0.02\n",
      "iteration: 10670 loss: 0.0124 lr: 0.02\n",
      "iteration: 10680 loss: 0.0146 lr: 0.02\n",
      "iteration: 10690 loss: 0.0110 lr: 0.02\n",
      "iteration: 10700 loss: 0.0147 lr: 0.02\n",
      "iteration: 10710 loss: 0.0124 lr: 0.02\n",
      "iteration: 10720 loss: 0.0119 lr: 0.02\n",
      "iteration: 10730 loss: 0.0139 lr: 0.02\n",
      "iteration: 10740 loss: 0.0112 lr: 0.02\n",
      "iteration: 10750 loss: 0.0139 lr: 0.02\n",
      "iteration: 10760 loss: 0.0124 lr: 0.02\n",
      "iteration: 10770 loss: 0.0135 lr: 0.02\n",
      "iteration: 10780 loss: 0.0130 lr: 0.02\n",
      "iteration: 10790 loss: 0.0145 lr: 0.02\n",
      "iteration: 10800 loss: 0.0133 lr: 0.02\n",
      "iteration: 10810 loss: 0.0145 lr: 0.02\n",
      "iteration: 10820 loss: 0.0150 lr: 0.02\n",
      "iteration: 10830 loss: 0.0127 lr: 0.02\n",
      "iteration: 10840 loss: 0.0135 lr: 0.02\n",
      "iteration: 10850 loss: 0.0100 lr: 0.02\n",
      "iteration: 10860 loss: 0.0150 lr: 0.02\n",
      "iteration: 10870 loss: 0.0169 lr: 0.02\n",
      "iteration: 10880 loss: 0.0144 lr: 0.02\n",
      "iteration: 10890 loss: 0.0129 lr: 0.02\n",
      "iteration: 10900 loss: 0.0166 lr: 0.02\n",
      "iteration: 10910 loss: 0.0147 lr: 0.02\n",
      "iteration: 10920 loss: 0.0143 lr: 0.02\n",
      "iteration: 10930 loss: 0.0108 lr: 0.02\n",
      "iteration: 10940 loss: 0.0143 lr: 0.02\n",
      "iteration: 10950 loss: 0.0119 lr: 0.02\n",
      "iteration: 10960 loss: 0.0124 lr: 0.02\n",
      "iteration: 10970 loss: 0.0110 lr: 0.02\n",
      "iteration: 10980 loss: 0.0108 lr: 0.02\n",
      "iteration: 10990 loss: 0.0102 lr: 0.02\n",
      "iteration: 11000 loss: 0.0138 lr: 0.02\n",
      "iteration: 11010 loss: 0.0123 lr: 0.02\n",
      "iteration: 11020 loss: 0.0124 lr: 0.02\n",
      "iteration: 11030 loss: 0.0129 lr: 0.02\n",
      "iteration: 11040 loss: 0.0123 lr: 0.02\n",
      "iteration: 11050 loss: 0.0118 lr: 0.02\n",
      "iteration: 11060 loss: 0.0115 lr: 0.02\n",
      "iteration: 11070 loss: 0.0120 lr: 0.02\n",
      "iteration: 11080 loss: 0.0132 lr: 0.02\n",
      "iteration: 11090 loss: 0.0128 lr: 0.02\n",
      "iteration: 11100 loss: 0.0115 lr: 0.02\n",
      "iteration: 11110 loss: 0.0149 lr: 0.02\n",
      "iteration: 11120 loss: 0.0138 lr: 0.02\n",
      "iteration: 11130 loss: 0.0148 lr: 0.02\n",
      "iteration: 11140 loss: 0.0125 lr: 0.02\n",
      "iteration: 11150 loss: 0.0113 lr: 0.02\n",
      "iteration: 11160 loss: 0.0120 lr: 0.02\n",
      "iteration: 11170 loss: 0.0099 lr: 0.02\n",
      "iteration: 11180 loss: 0.0104 lr: 0.02\n",
      "iteration: 11190 loss: 0.0146 lr: 0.02\n",
      "iteration: 11200 loss: 0.0117 lr: 0.02\n",
      "iteration: 11210 loss: 0.0112 lr: 0.02\n",
      "iteration: 11220 loss: 0.0129 lr: 0.02\n",
      "iteration: 11230 loss: 0.0085 lr: 0.02\n",
      "iteration: 11240 loss: 0.0140 lr: 0.02\n",
      "iteration: 11250 loss: 0.0113 lr: 0.02\n",
      "iteration: 11260 loss: 0.0126 lr: 0.02\n",
      "iteration: 11270 loss: 0.0113 lr: 0.02\n",
      "iteration: 11280 loss: 0.0120 lr: 0.02\n",
      "iteration: 11290 loss: 0.0106 lr: 0.02\n",
      "iteration: 11300 loss: 0.0117 lr: 0.02\n",
      "iteration: 11310 loss: 0.0125 lr: 0.02\n",
      "iteration: 11320 loss: 0.0131 lr: 0.02\n",
      "iteration: 11330 loss: 0.0110 lr: 0.02\n",
      "iteration: 11340 loss: 0.0116 lr: 0.02\n",
      "iteration: 11350 loss: 0.0126 lr: 0.02\n",
      "iteration: 11360 loss: 0.0110 lr: 0.02\n",
      "iteration: 11370 loss: 0.0161 lr: 0.02\n",
      "iteration: 11380 loss: 0.0141 lr: 0.02\n",
      "iteration: 11390 loss: 0.0131 lr: 0.02\n",
      "iteration: 11400 loss: 0.0108 lr: 0.02\n",
      "iteration: 11410 loss: 0.0165 lr: 0.02\n",
      "iteration: 11420 loss: 0.0095 lr: 0.02\n",
      "iteration: 11430 loss: 0.0134 lr: 0.02\n",
      "iteration: 11440 loss: 0.0088 lr: 0.02\n",
      "iteration: 11450 loss: 0.0127 lr: 0.02\n",
      "iteration: 11460 loss: 0.0119 lr: 0.02\n",
      "iteration: 11470 loss: 0.0146 lr: 0.02\n",
      "iteration: 11480 loss: 0.0108 lr: 0.02\n",
      "iteration: 11490 loss: 0.0113 lr: 0.02\n",
      "iteration: 11500 loss: 0.0130 lr: 0.02\n",
      "iteration: 11510 loss: 0.0130 lr: 0.02\n",
      "iteration: 11520 loss: 0.0117 lr: 0.02\n",
      "iteration: 11530 loss: 0.0116 lr: 0.02\n",
      "iteration: 11540 loss: 0.0105 lr: 0.02\n",
      "iteration: 11550 loss: 0.0113 lr: 0.02\n",
      "iteration: 11560 loss: 0.0117 lr: 0.02\n",
      "iteration: 11570 loss: 0.0128 lr: 0.02\n",
      "iteration: 11580 loss: 0.0100 lr: 0.02\n",
      "iteration: 11590 loss: 0.0134 lr: 0.02\n",
      "iteration: 11600 loss: 0.0101 lr: 0.02\n",
      "iteration: 11610 loss: 0.0099 lr: 0.02\n",
      "iteration: 11620 loss: 0.0123 lr: 0.02\n",
      "iteration: 11630 loss: 0.0113 lr: 0.02\n",
      "iteration: 11640 loss: 0.0100 lr: 0.02\n",
      "iteration: 11650 loss: 0.0128 lr: 0.02\n",
      "iteration: 11660 loss: 0.0138 lr: 0.02\n",
      "iteration: 11670 loss: 0.0097 lr: 0.02\n",
      "iteration: 11680 loss: 0.0123 lr: 0.02\n",
      "iteration: 11690 loss: 0.0135 lr: 0.02\n",
      "iteration: 11700 loss: 0.0131 lr: 0.02\n",
      "iteration: 11710 loss: 0.0117 lr: 0.02\n",
      "iteration: 11720 loss: 0.0130 lr: 0.02\n",
      "iteration: 11730 loss: 0.0114 lr: 0.02\n",
      "iteration: 11740 loss: 0.0126 lr: 0.02\n",
      "iteration: 11750 loss: 0.0116 lr: 0.02\n",
      "iteration: 11760 loss: 0.0106 lr: 0.02\n",
      "iteration: 11770 loss: 0.0114 lr: 0.02\n",
      "iteration: 11780 loss: 0.0112 lr: 0.02\n",
      "iteration: 11790 loss: 0.0129 lr: 0.02\n",
      "iteration: 11800 loss: 0.0109 lr: 0.02\n",
      "iteration: 11810 loss: 0.0158 lr: 0.02\n",
      "iteration: 11820 loss: 0.0117 lr: 0.02\n",
      "iteration: 11830 loss: 0.0098 lr: 0.02\n",
      "iteration: 11840 loss: 0.0111 lr: 0.02\n",
      "iteration: 11850 loss: 0.0120 lr: 0.02\n",
      "iteration: 11860 loss: 0.0143 lr: 0.02\n",
      "iteration: 11870 loss: 0.0122 lr: 0.02\n",
      "iteration: 11880 loss: 0.0152 lr: 0.02\n",
      "iteration: 11890 loss: 0.0133 lr: 0.02\n",
      "iteration: 11900 loss: 0.0120 lr: 0.02\n",
      "iteration: 11910 loss: 0.0117 lr: 0.02\n",
      "iteration: 11920 loss: 0.0119 lr: 0.02\n",
      "iteration: 11930 loss: 0.0126 lr: 0.02\n",
      "iteration: 11940 loss: 0.0128 lr: 0.02\n",
      "iteration: 11950 loss: 0.0107 lr: 0.02\n",
      "iteration: 11960 loss: 0.0127 lr: 0.02\n",
      "iteration: 11970 loss: 0.0138 lr: 0.02\n",
      "iteration: 11980 loss: 0.0112 lr: 0.02\n",
      "iteration: 11990 loss: 0.0102 lr: 0.02\n",
      "iteration: 12000 loss: 0.0124 lr: 0.02\n",
      "iteration: 12010 loss: 0.0114 lr: 0.02\n",
      "iteration: 12020 loss: 0.0117 lr: 0.02\n",
      "iteration: 12030 loss: 0.0101 lr: 0.02\n",
      "iteration: 12040 loss: 0.0102 lr: 0.02\n",
      "iteration: 12050 loss: 0.0124 lr: 0.02\n",
      "iteration: 12060 loss: 0.0126 lr: 0.02\n",
      "iteration: 12070 loss: 0.0108 lr: 0.02\n",
      "iteration: 12080 loss: 0.0109 lr: 0.02\n",
      "iteration: 12090 loss: 0.0131 lr: 0.02\n",
      "iteration: 12100 loss: 0.0117 lr: 0.02\n",
      "iteration: 12110 loss: 0.0101 lr: 0.02\n",
      "iteration: 12120 loss: 0.0101 lr: 0.02\n",
      "iteration: 12130 loss: 0.0098 lr: 0.02\n",
      "iteration: 12140 loss: 0.0103 lr: 0.02\n",
      "iteration: 12150 loss: 0.0098 lr: 0.02\n",
      "iteration: 12160 loss: 0.0144 lr: 0.02\n",
      "iteration: 12170 loss: 0.0113 lr: 0.02\n",
      "iteration: 12180 loss: 0.0136 lr: 0.02\n",
      "iteration: 12190 loss: 0.0119 lr: 0.02\n",
      "iteration: 12200 loss: 0.0105 lr: 0.02\n",
      "iteration: 12210 loss: 0.0111 lr: 0.02\n",
      "iteration: 12220 loss: 0.0112 lr: 0.02\n",
      "iteration: 12230 loss: 0.0111 lr: 0.02\n",
      "iteration: 12240 loss: 0.0121 lr: 0.02\n",
      "iteration: 12250 loss: 0.0120 lr: 0.02\n",
      "iteration: 12260 loss: 0.0115 lr: 0.02\n",
      "iteration: 12270 loss: 0.0148 lr: 0.02\n",
      "iteration: 12280 loss: 0.0125 lr: 0.02\n",
      "iteration: 12290 loss: 0.0113 lr: 0.02\n",
      "iteration: 12300 loss: 0.0086 lr: 0.02\n",
      "iteration: 12310 loss: 0.0123 lr: 0.02\n",
      "iteration: 12320 loss: 0.0094 lr: 0.02\n",
      "iteration: 12330 loss: 0.0098 lr: 0.02\n",
      "iteration: 12340 loss: 0.0090 lr: 0.02\n",
      "iteration: 12350 loss: 0.0117 lr: 0.02\n",
      "iteration: 12360 loss: 0.0108 lr: 0.02\n",
      "iteration: 12370 loss: 0.0139 lr: 0.02\n",
      "iteration: 12380 loss: 0.0086 lr: 0.02\n",
      "iteration: 12390 loss: 0.0107 lr: 0.02\n",
      "iteration: 12400 loss: 0.0106 lr: 0.02\n",
      "iteration: 12410 loss: 0.0120 lr: 0.02\n",
      "iteration: 12420 loss: 0.0096 lr: 0.02\n",
      "iteration: 12430 loss: 0.0116 lr: 0.02\n",
      "iteration: 12440 loss: 0.0102 lr: 0.02\n",
      "iteration: 12450 loss: 0.0108 lr: 0.02\n",
      "iteration: 12460 loss: 0.0095 lr: 0.02\n",
      "iteration: 12470 loss: 0.0096 lr: 0.02\n",
      "iteration: 12480 loss: 0.0108 lr: 0.02\n",
      "iteration: 12490 loss: 0.0090 lr: 0.02\n",
      "iteration: 12500 loss: 0.0115 lr: 0.02\n",
      "iteration: 12510 loss: 0.0106 lr: 0.02\n",
      "iteration: 12520 loss: 0.0120 lr: 0.02\n",
      "iteration: 12530 loss: 0.0124 lr: 0.02\n",
      "iteration: 12540 loss: 0.0122 lr: 0.02\n",
      "iteration: 12550 loss: 0.0099 lr: 0.02\n",
      "iteration: 12560 loss: 0.0105 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 12570 loss: 0.0096 lr: 0.02\n",
      "iteration: 12580 loss: 0.0118 lr: 0.02\n",
      "iteration: 12590 loss: 0.0123 lr: 0.02\n",
      "iteration: 12600 loss: 0.0089 lr: 0.02\n",
      "iteration: 12610 loss: 0.0103 lr: 0.02\n",
      "iteration: 12620 loss: 0.0114 lr: 0.02\n",
      "iteration: 12630 loss: 0.0103 lr: 0.02\n",
      "iteration: 12640 loss: 0.0122 lr: 0.02\n",
      "iteration: 12650 loss: 0.0100 lr: 0.02\n",
      "iteration: 12660 loss: 0.0094 lr: 0.02\n",
      "iteration: 12670 loss: 0.0098 lr: 0.02\n",
      "iteration: 12680 loss: 0.0104 lr: 0.02\n",
      "iteration: 12690 loss: 0.0123 lr: 0.02\n",
      "iteration: 12700 loss: 0.0105 lr: 0.02\n",
      "iteration: 12710 loss: 0.0129 lr: 0.02\n",
      "iteration: 12720 loss: 0.0102 lr: 0.02\n",
      "iteration: 12730 loss: 0.0100 lr: 0.02\n",
      "iteration: 12740 loss: 0.0086 lr: 0.02\n",
      "iteration: 12750 loss: 0.0114 lr: 0.02\n",
      "iteration: 12760 loss: 0.0100 lr: 0.02\n",
      "iteration: 12770 loss: 0.0115 lr: 0.02\n",
      "iteration: 12780 loss: 0.0086 lr: 0.02\n",
      "iteration: 12790 loss: 0.0086 lr: 0.02\n",
      "iteration: 12800 loss: 0.0116 lr: 0.02\n",
      "iteration: 12810 loss: 0.0117 lr: 0.02\n",
      "iteration: 12820 loss: 0.0126 lr: 0.02\n",
      "iteration: 12830 loss: 0.0118 lr: 0.02\n",
      "iteration: 12840 loss: 0.0098 lr: 0.02\n",
      "iteration: 12850 loss: 0.0123 lr: 0.02\n",
      "iteration: 12860 loss: 0.0102 lr: 0.02\n",
      "iteration: 12870 loss: 0.0075 lr: 0.02\n",
      "iteration: 12880 loss: 0.0119 lr: 0.02\n",
      "iteration: 12890 loss: 0.0105 lr: 0.02\n",
      "iteration: 12900 loss: 0.0098 lr: 0.02\n",
      "iteration: 12910 loss: 0.0099 lr: 0.02\n",
      "iteration: 12920 loss: 0.0110 lr: 0.02\n",
      "iteration: 12930 loss: 0.0091 lr: 0.02\n",
      "iteration: 12940 loss: 0.0109 lr: 0.02\n",
      "iteration: 12950 loss: 0.0133 lr: 0.02\n",
      "iteration: 12960 loss: 0.0106 lr: 0.02\n",
      "iteration: 12970 loss: 0.0102 lr: 0.02\n",
      "iteration: 12980 loss: 0.0102 lr: 0.02\n",
      "iteration: 12990 loss: 0.0099 lr: 0.02\n",
      "iteration: 13000 loss: 0.0123 lr: 0.02\n",
      "iteration: 13010 loss: 0.0102 lr: 0.02\n",
      "iteration: 13020 loss: 0.0072 lr: 0.02\n",
      "iteration: 13030 loss: 0.0097 lr: 0.02\n",
      "iteration: 13040 loss: 0.0087 lr: 0.02\n",
      "iteration: 13050 loss: 0.0104 lr: 0.02\n",
      "iteration: 13060 loss: 0.0125 lr: 0.02\n",
      "iteration: 13070 loss: 0.0103 lr: 0.02\n",
      "iteration: 13080 loss: 0.0137 lr: 0.02\n",
      "iteration: 13090 loss: 0.0104 lr: 0.02\n",
      "iteration: 13100 loss: 0.0094 lr: 0.02\n",
      "iteration: 13110 loss: 0.0083 lr: 0.02\n",
      "iteration: 13120 loss: 0.0102 lr: 0.02\n",
      "iteration: 13130 loss: 0.0121 lr: 0.02\n",
      "iteration: 13140 loss: 0.0096 lr: 0.02\n",
      "iteration: 13150 loss: 0.0086 lr: 0.02\n",
      "iteration: 13160 loss: 0.0105 lr: 0.02\n",
      "iteration: 13170 loss: 0.0107 lr: 0.02\n",
      "iteration: 13180 loss: 0.0127 lr: 0.02\n",
      "iteration: 13190 loss: 0.0089 lr: 0.02\n",
      "iteration: 13200 loss: 0.0101 lr: 0.02\n",
      "iteration: 13210 loss: 0.0105 lr: 0.02\n",
      "iteration: 13220 loss: 0.0099 lr: 0.02\n",
      "iteration: 13230 loss: 0.0124 lr: 0.02\n",
      "iteration: 13240 loss: 0.0113 lr: 0.02\n",
      "iteration: 13250 loss: 0.0113 lr: 0.02\n",
      "iteration: 13260 loss: 0.0092 lr: 0.02\n",
      "iteration: 13270 loss: 0.0106 lr: 0.02\n",
      "iteration: 13280 loss: 0.0095 lr: 0.02\n",
      "iteration: 13290 loss: 0.0080 lr: 0.02\n",
      "iteration: 13300 loss: 0.0113 lr: 0.02\n",
      "iteration: 13310 loss: 0.0095 lr: 0.02\n",
      "iteration: 13320 loss: 0.0120 lr: 0.02\n",
      "iteration: 13330 loss: 0.0089 lr: 0.02\n",
      "iteration: 13340 loss: 0.0089 lr: 0.02\n",
      "iteration: 13350 loss: 0.0112 lr: 0.02\n",
      "iteration: 13360 loss: 0.0104 lr: 0.02\n",
      "iteration: 13370 loss: 0.0099 lr: 0.02\n",
      "iteration: 13380 loss: 0.0093 lr: 0.02\n",
      "iteration: 13390 loss: 0.0090 lr: 0.02\n",
      "iteration: 13400 loss: 0.0101 lr: 0.02\n",
      "iteration: 13410 loss: 0.0111 lr: 0.02\n",
      "iteration: 13420 loss: 0.0099 lr: 0.02\n",
      "iteration: 13430 loss: 0.0098 lr: 0.02\n",
      "iteration: 13440 loss: 0.0096 lr: 0.02\n",
      "iteration: 13450 loss: 0.0104 lr: 0.02\n",
      "iteration: 13460 loss: 0.0094 lr: 0.02\n",
      "iteration: 13470 loss: 0.0109 lr: 0.02\n",
      "iteration: 13480 loss: 0.0093 lr: 0.02\n",
      "iteration: 13490 loss: 0.0102 lr: 0.02\n",
      "iteration: 13500 loss: 0.0133 lr: 0.02\n",
      "iteration: 13510 loss: 0.0117 lr: 0.02\n",
      "iteration: 13520 loss: 0.0090 lr: 0.02\n",
      "iteration: 13530 loss: 0.0101 lr: 0.02\n",
      "iteration: 13540 loss: 0.0114 lr: 0.02\n",
      "iteration: 13550 loss: 0.0114 lr: 0.02\n",
      "iteration: 13560 loss: 0.0101 lr: 0.02\n",
      "iteration: 13570 loss: 0.0107 lr: 0.02\n",
      "iteration: 13580 loss: 0.0091 lr: 0.02\n",
      "iteration: 13590 loss: 0.0121 lr: 0.02\n",
      "iteration: 13600 loss: 0.0099 lr: 0.02\n",
      "iteration: 13610 loss: 0.0095 lr: 0.02\n",
      "iteration: 13620 loss: 0.0095 lr: 0.02\n",
      "iteration: 13630 loss: 0.0085 lr: 0.02\n",
      "iteration: 13640 loss: 0.0134 lr: 0.02\n",
      "iteration: 13650 loss: 0.0125 lr: 0.02\n",
      "iteration: 13660 loss: 0.0095 lr: 0.02\n",
      "iteration: 13670 loss: 0.0097 lr: 0.02\n",
      "iteration: 13680 loss: 0.0103 lr: 0.02\n",
      "iteration: 13690 loss: 0.0099 lr: 0.02\n",
      "iteration: 13700 loss: 0.0098 lr: 0.02\n",
      "iteration: 13710 loss: 0.0087 lr: 0.02\n",
      "iteration: 13720 loss: 0.0119 lr: 0.02\n",
      "iteration: 13730 loss: 0.0095 lr: 0.02\n",
      "iteration: 13740 loss: 0.0116 lr: 0.02\n",
      "iteration: 13750 loss: 0.0091 lr: 0.02\n",
      "iteration: 13760 loss: 0.0082 lr: 0.02\n",
      "iteration: 13770 loss: 0.0107 lr: 0.02\n",
      "iteration: 13780 loss: 0.0084 lr: 0.02\n",
      "iteration: 13790 loss: 0.0137 lr: 0.02\n",
      "iteration: 13800 loss: 0.0090 lr: 0.02\n",
      "iteration: 13810 loss: 0.0125 lr: 0.02\n",
      "iteration: 13820 loss: 0.0112 lr: 0.02\n",
      "iteration: 13830 loss: 0.0115 lr: 0.02\n",
      "iteration: 13840 loss: 0.0083 lr: 0.02\n",
      "iteration: 13850 loss: 0.0089 lr: 0.02\n",
      "iteration: 13860 loss: 0.0098 lr: 0.02\n",
      "iteration: 13870 loss: 0.0126 lr: 0.02\n",
      "iteration: 13880 loss: 0.0129 lr: 0.02\n",
      "iteration: 13890 loss: 0.0091 lr: 0.02\n",
      "iteration: 13900 loss: 0.0111 lr: 0.02\n",
      "iteration: 13910 loss: 0.0096 lr: 0.02\n",
      "iteration: 13920 loss: 0.0098 lr: 0.02\n",
      "iteration: 13930 loss: 0.0094 lr: 0.02\n",
      "iteration: 13940 loss: 0.0119 lr: 0.02\n",
      "iteration: 13950 loss: 0.0089 lr: 0.02\n",
      "iteration: 13960 loss: 0.0133 lr: 0.02\n",
      "iteration: 13970 loss: 0.0132 lr: 0.02\n",
      "iteration: 13980 loss: 0.0093 lr: 0.02\n",
      "iteration: 13990 loss: 0.0119 lr: 0.02\n",
      "iteration: 14000 loss: 0.0124 lr: 0.02\n",
      "iteration: 14010 loss: 0.0092 lr: 0.02\n",
      "iteration: 14020 loss: 0.0077 lr: 0.02\n",
      "iteration: 14030 loss: 0.0129 lr: 0.02\n",
      "iteration: 14040 loss: 0.0118 lr: 0.02\n",
      "iteration: 14050 loss: 0.0098 lr: 0.02\n",
      "iteration: 14060 loss: 0.0116 lr: 0.02\n",
      "iteration: 14070 loss: 0.0117 lr: 0.02\n",
      "iteration: 14080 loss: 0.0100 lr: 0.02\n",
      "iteration: 14090 loss: 0.0108 lr: 0.02\n",
      "iteration: 14100 loss: 0.0093 lr: 0.02\n",
      "iteration: 14110 loss: 0.0111 lr: 0.02\n",
      "iteration: 14120 loss: 0.0118 lr: 0.02\n",
      "iteration: 14130 loss: 0.0101 lr: 0.02\n",
      "iteration: 14140 loss: 0.0085 lr: 0.02\n",
      "iteration: 14150 loss: 0.0089 lr: 0.02\n",
      "iteration: 14160 loss: 0.0107 lr: 0.02\n",
      "iteration: 14170 loss: 0.0099 lr: 0.02\n",
      "iteration: 14180 loss: 0.0096 lr: 0.02\n",
      "iteration: 14190 loss: 0.0089 lr: 0.02\n",
      "iteration: 14200 loss: 0.0099 lr: 0.02\n",
      "iteration: 14210 loss: 0.0107 lr: 0.02\n",
      "iteration: 14220 loss: 0.0088 lr: 0.02\n",
      "iteration: 14230 loss: 0.0089 lr: 0.02\n",
      "iteration: 14240 loss: 0.0093 lr: 0.02\n",
      "iteration: 14250 loss: 0.0103 lr: 0.02\n",
      "iteration: 14260 loss: 0.0100 lr: 0.02\n",
      "iteration: 14270 loss: 0.0099 lr: 0.02\n",
      "iteration: 14280 loss: 0.0128 lr: 0.02\n",
      "iteration: 14290 loss: 0.0084 lr: 0.02\n",
      "iteration: 14300 loss: 0.0104 lr: 0.02\n",
      "iteration: 14310 loss: 0.0099 lr: 0.02\n",
      "iteration: 14320 loss: 0.0088 lr: 0.02\n",
      "iteration: 14330 loss: 0.0134 lr: 0.02\n",
      "iteration: 14340 loss: 0.0106 lr: 0.02\n",
      "iteration: 14350 loss: 0.0106 lr: 0.02\n",
      "iteration: 14360 loss: 0.0096 lr: 0.02\n",
      "iteration: 14370 loss: 0.0094 lr: 0.02\n",
      "iteration: 14380 loss: 0.0094 lr: 0.02\n",
      "iteration: 14390 loss: 0.0098 lr: 0.02\n",
      "iteration: 14400 loss: 0.0096 lr: 0.02\n",
      "iteration: 14410 loss: 0.0102 lr: 0.02\n",
      "iteration: 14420 loss: 0.0107 lr: 0.02\n",
      "iteration: 14430 loss: 0.0093 lr: 0.02\n",
      "iteration: 14440 loss: 0.0100 lr: 0.02\n",
      "iteration: 14450 loss: 0.0076 lr: 0.02\n",
      "iteration: 14460 loss: 0.0088 lr: 0.02\n",
      "iteration: 14470 loss: 0.0113 lr: 0.02\n",
      "iteration: 14480 loss: 0.0083 lr: 0.02\n",
      "iteration: 14490 loss: 0.0093 lr: 0.02\n",
      "iteration: 14500 loss: 0.0087 lr: 0.02\n",
      "iteration: 14510 loss: 0.0081 lr: 0.02\n",
      "iteration: 14520 loss: 0.0084 lr: 0.02\n",
      "iteration: 14530 loss: 0.0101 lr: 0.02\n",
      "iteration: 14540 loss: 0.0089 lr: 0.02\n",
      "iteration: 14550 loss: 0.0108 lr: 0.02\n",
      "iteration: 14560 loss: 0.0101 lr: 0.02\n",
      "iteration: 14570 loss: 0.0095 lr: 0.02\n",
      "iteration: 14580 loss: 0.0103 lr: 0.02\n",
      "iteration: 14590 loss: 0.0108 lr: 0.02\n",
      "iteration: 14600 loss: 0.0089 lr: 0.02\n",
      "iteration: 14610 loss: 0.0082 lr: 0.02\n",
      "iteration: 14620 loss: 0.0108 lr: 0.02\n",
      "iteration: 14630 loss: 0.0108 lr: 0.02\n",
      "iteration: 14640 loss: 0.0095 lr: 0.02\n",
      "iteration: 14650 loss: 0.0109 lr: 0.02\n",
      "iteration: 14660 loss: 0.0102 lr: 0.02\n",
      "iteration: 14670 loss: 0.0093 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 14680 loss: 0.0083 lr: 0.02\n",
      "iteration: 14690 loss: 0.0100 lr: 0.02\n",
      "iteration: 14700 loss: 0.0099 lr: 0.02\n",
      "iteration: 14710 loss: 0.0075 lr: 0.02\n",
      "iteration: 14720 loss: 0.0094 lr: 0.02\n",
      "iteration: 14730 loss: 0.0088 lr: 0.02\n",
      "iteration: 14740 loss: 0.0088 lr: 0.02\n",
      "iteration: 14750 loss: 0.0096 lr: 0.02\n",
      "iteration: 14760 loss: 0.0103 lr: 0.02\n",
      "iteration: 14770 loss: 0.0128 lr: 0.02\n",
      "iteration: 14780 loss: 0.0095 lr: 0.02\n",
      "iteration: 14790 loss: 0.0094 lr: 0.02\n",
      "iteration: 14800 loss: 0.0109 lr: 0.02\n",
      "iteration: 14810 loss: 0.0127 lr: 0.02\n",
      "iteration: 14820 loss: 0.0092 lr: 0.02\n",
      "iteration: 14830 loss: 0.0089 lr: 0.02\n",
      "iteration: 14840 loss: 0.0087 lr: 0.02\n",
      "iteration: 14850 loss: 0.0103 lr: 0.02\n",
      "iteration: 14860 loss: 0.0087 lr: 0.02\n",
      "iteration: 14870 loss: 0.0088 lr: 0.02\n",
      "iteration: 14880 loss: 0.0085 lr: 0.02\n",
      "iteration: 14890 loss: 0.0104 lr: 0.02\n",
      "iteration: 14900 loss: 0.0095 lr: 0.02\n",
      "iteration: 14910 loss: 0.0086 lr: 0.02\n",
      "iteration: 14920 loss: 0.0089 lr: 0.02\n",
      "iteration: 14930 loss: 0.0087 lr: 0.02\n",
      "iteration: 14940 loss: 0.0081 lr: 0.02\n",
      "iteration: 14950 loss: 0.0096 lr: 0.02\n",
      "iteration: 14960 loss: 0.0121 lr: 0.02\n",
      "iteration: 14970 loss: 0.0109 lr: 0.02\n",
      "iteration: 14980 loss: 0.0084 lr: 0.02\n",
      "iteration: 14990 loss: 0.0109 lr: 0.02\n",
      "iteration: 15000 loss: 0.0092 lr: 0.02\n",
      "iteration: 15010 loss: 0.0079 lr: 0.02\n",
      "iteration: 15020 loss: 0.0077 lr: 0.02\n",
      "iteration: 15030 loss: 0.0095 lr: 0.02\n",
      "iteration: 15040 loss: 0.0095 lr: 0.02\n",
      "iteration: 15050 loss: 0.0091 lr: 0.02\n",
      "iteration: 15060 loss: 0.0088 lr: 0.02\n",
      "iteration: 15070 loss: 0.0093 lr: 0.02\n",
      "iteration: 15080 loss: 0.0109 lr: 0.02\n",
      "iteration: 15090 loss: 0.0086 lr: 0.02\n",
      "iteration: 15100 loss: 0.0100 lr: 0.02\n",
      "iteration: 15110 loss: 0.0098 lr: 0.02\n",
      "iteration: 15120 loss: 0.0089 lr: 0.02\n",
      "iteration: 15130 loss: 0.0101 lr: 0.02\n",
      "iteration: 15140 loss: 0.0108 lr: 0.02\n",
      "iteration: 15150 loss: 0.0111 lr: 0.02\n",
      "iteration: 15160 loss: 0.0112 lr: 0.02\n",
      "iteration: 15170 loss: 0.0096 lr: 0.02\n",
      "iteration: 15180 loss: 0.0086 lr: 0.02\n",
      "iteration: 15190 loss: 0.0102 lr: 0.02\n",
      "iteration: 15200 loss: 0.0095 lr: 0.02\n",
      "iteration: 15210 loss: 0.0103 lr: 0.02\n",
      "iteration: 15220 loss: 0.0104 lr: 0.02\n",
      "iteration: 15230 loss: 0.0082 lr: 0.02\n",
      "iteration: 15240 loss: 0.0088 lr: 0.02\n",
      "iteration: 15250 loss: 0.0093 lr: 0.02\n",
      "iteration: 15260 loss: 0.0086 lr: 0.02\n",
      "iteration: 15270 loss: 0.0106 lr: 0.02\n",
      "iteration: 15280 loss: 0.0089 lr: 0.02\n",
      "iteration: 15290 loss: 0.0116 lr: 0.02\n",
      "iteration: 15300 loss: 0.0086 lr: 0.02\n",
      "iteration: 15310 loss: 0.0086 lr: 0.02\n",
      "iteration: 15320 loss: 0.0090 lr: 0.02\n",
      "iteration: 15330 loss: 0.0092 lr: 0.02\n",
      "iteration: 15340 loss: 0.0081 lr: 0.02\n",
      "iteration: 15350 loss: 0.0117 lr: 0.02\n",
      "iteration: 15360 loss: 0.0083 lr: 0.02\n",
      "iteration: 15370 loss: 0.0092 lr: 0.02\n",
      "iteration: 15380 loss: 0.0086 lr: 0.02\n",
      "iteration: 15390 loss: 0.0090 lr: 0.02\n",
      "iteration: 15400 loss: 0.0101 lr: 0.02\n",
      "iteration: 15410 loss: 0.0098 lr: 0.02\n",
      "iteration: 15420 loss: 0.0105 lr: 0.02\n",
      "iteration: 15430 loss: 0.0092 lr: 0.02\n",
      "iteration: 15440 loss: 0.0096 lr: 0.02\n",
      "iteration: 15450 loss: 0.0099 lr: 0.02\n",
      "iteration: 15460 loss: 0.0089 lr: 0.02\n",
      "iteration: 15470 loss: 0.0100 lr: 0.02\n",
      "iteration: 15480 loss: 0.0105 lr: 0.02\n",
      "iteration: 15490 loss: 0.0103 lr: 0.02\n",
      "iteration: 15500 loss: 0.0113 lr: 0.02\n",
      "iteration: 15510 loss: 0.0078 lr: 0.02\n",
      "iteration: 15520 loss: 0.0132 lr: 0.02\n",
      "iteration: 15530 loss: 0.0093 lr: 0.02\n",
      "iteration: 15540 loss: 0.0083 lr: 0.02\n",
      "iteration: 15550 loss: 0.0098 lr: 0.02\n",
      "iteration: 15560 loss: 0.0104 lr: 0.02\n",
      "iteration: 15570 loss: 0.0096 lr: 0.02\n",
      "iteration: 15580 loss: 0.0120 lr: 0.02\n",
      "iteration: 15590 loss: 0.0081 lr: 0.02\n",
      "iteration: 15600 loss: 0.0087 lr: 0.02\n",
      "iteration: 15610 loss: 0.0094 lr: 0.02\n",
      "iteration: 15620 loss: 0.0119 lr: 0.02\n",
      "iteration: 15630 loss: 0.0097 lr: 0.02\n",
      "iteration: 15640 loss: 0.0117 lr: 0.02\n",
      "iteration: 15650 loss: 0.0102 lr: 0.02\n",
      "iteration: 15660 loss: 0.0097 lr: 0.02\n",
      "iteration: 15670 loss: 0.0091 lr: 0.02\n",
      "iteration: 15680 loss: 0.0096 lr: 0.02\n",
      "iteration: 15690 loss: 0.0097 lr: 0.02\n",
      "iteration: 15700 loss: 0.0117 lr: 0.02\n",
      "iteration: 15710 loss: 0.0091 lr: 0.02\n",
      "iteration: 15720 loss: 0.0105 lr: 0.02\n",
      "iteration: 15730 loss: 0.0083 lr: 0.02\n",
      "iteration: 15740 loss: 0.0101 lr: 0.02\n",
      "iteration: 15750 loss: 0.0113 lr: 0.02\n",
      "iteration: 15760 loss: 0.0094 lr: 0.02\n",
      "iteration: 15770 loss: 0.0114 lr: 0.02\n",
      "iteration: 15780 loss: 0.0098 lr: 0.02\n",
      "iteration: 15790 loss: 0.0087 lr: 0.02\n",
      "iteration: 15800 loss: 0.0101 lr: 0.02\n",
      "iteration: 15810 loss: 0.0076 lr: 0.02\n",
      "iteration: 15820 loss: 0.0096 lr: 0.02\n",
      "iteration: 15830 loss: 0.0107 lr: 0.02\n",
      "iteration: 15840 loss: 0.0089 lr: 0.02\n",
      "iteration: 15850 loss: 0.0089 lr: 0.02\n",
      "iteration: 15860 loss: 0.0088 lr: 0.02\n",
      "iteration: 15870 loss: 0.0090 lr: 0.02\n",
      "iteration: 15880 loss: 0.0092 lr: 0.02\n",
      "iteration: 15890 loss: 0.0104 lr: 0.02\n",
      "iteration: 15900 loss: 0.0101 lr: 0.02\n",
      "iteration: 15910 loss: 0.0081 lr: 0.02\n",
      "iteration: 15920 loss: 0.0083 lr: 0.02\n",
      "iteration: 15930 loss: 0.0083 lr: 0.02\n",
      "iteration: 15940 loss: 0.0100 lr: 0.02\n",
      "iteration: 15950 loss: 0.0078 lr: 0.02\n",
      "iteration: 15960 loss: 0.0096 lr: 0.02\n",
      "iteration: 15970 loss: 0.0088 lr: 0.02\n",
      "iteration: 15980 loss: 0.0083 lr: 0.02\n",
      "iteration: 15990 loss: 0.0097 lr: 0.02\n",
      "iteration: 16000 loss: 0.0103 lr: 0.02\n",
      "iteration: 16010 loss: 0.0062 lr: 0.02\n",
      "iteration: 16020 loss: 0.0112 lr: 0.02\n",
      "iteration: 16030 loss: 0.0088 lr: 0.02\n",
      "iteration: 16040 loss: 0.0088 lr: 0.02\n",
      "iteration: 16050 loss: 0.0107 lr: 0.02\n",
      "iteration: 16060 loss: 0.0135 lr: 0.02\n",
      "iteration: 16070 loss: 0.0097 lr: 0.02\n",
      "iteration: 16080 loss: 0.0103 lr: 0.02\n",
      "iteration: 16090 loss: 0.0103 lr: 0.02\n",
      "iteration: 16100 loss: 0.0099 lr: 0.02\n",
      "iteration: 16110 loss: 0.0094 lr: 0.02\n",
      "iteration: 16120 loss: 0.0092 lr: 0.02\n",
      "iteration: 16130 loss: 0.0074 lr: 0.02\n",
      "iteration: 16140 loss: 0.0101 lr: 0.02\n",
      "iteration: 16150 loss: 0.0099 lr: 0.02\n",
      "iteration: 16160 loss: 0.0092 lr: 0.02\n",
      "iteration: 16170 loss: 0.0098 lr: 0.02\n",
      "iteration: 16180 loss: 0.0093 lr: 0.02\n",
      "iteration: 16190 loss: 0.0125 lr: 0.02\n",
      "iteration: 16200 loss: 0.0098 lr: 0.02\n",
      "iteration: 16210 loss: 0.0095 lr: 0.02\n",
      "iteration: 16220 loss: 0.0083 lr: 0.02\n",
      "iteration: 16230 loss: 0.0097 lr: 0.02\n",
      "iteration: 16240 loss: 0.0095 lr: 0.02\n",
      "iteration: 16250 loss: 0.0087 lr: 0.02\n",
      "iteration: 16260 loss: 0.0072 lr: 0.02\n",
      "iteration: 16270 loss: 0.0081 lr: 0.02\n",
      "iteration: 16280 loss: 0.0107 lr: 0.02\n",
      "iteration: 16290 loss: 0.0092 lr: 0.02\n",
      "iteration: 16300 loss: 0.0096 lr: 0.02\n",
      "iteration: 16310 loss: 0.0092 lr: 0.02\n",
      "iteration: 16320 loss: 0.0125 lr: 0.02\n",
      "iteration: 16330 loss: 0.0081 lr: 0.02\n",
      "iteration: 16340 loss: 0.0094 lr: 0.02\n",
      "iteration: 16350 loss: 0.0091 lr: 0.02\n",
      "iteration: 16360 loss: 0.0088 lr: 0.02\n",
      "iteration: 16370 loss: 0.0109 lr: 0.02\n",
      "iteration: 16380 loss: 0.0084 lr: 0.02\n",
      "iteration: 16390 loss: 0.0089 lr: 0.02\n",
      "iteration: 16400 loss: 0.0076 lr: 0.02\n",
      "iteration: 16410 loss: 0.0092 lr: 0.02\n",
      "iteration: 16420 loss: 0.0085 lr: 0.02\n",
      "iteration: 16430 loss: 0.0084 lr: 0.02\n",
      "iteration: 16440 loss: 0.0087 lr: 0.02\n",
      "iteration: 16450 loss: 0.0093 lr: 0.02\n",
      "iteration: 16460 loss: 0.0111 lr: 0.02\n",
      "iteration: 16470 loss: 0.0101 lr: 0.02\n",
      "iteration: 16480 loss: 0.0087 lr: 0.02\n",
      "iteration: 16490 loss: 0.0086 lr: 0.02\n",
      "iteration: 16500 loss: 0.0077 lr: 0.02\n",
      "iteration: 16510 loss: 0.0091 lr: 0.02\n",
      "iteration: 16520 loss: 0.0084 lr: 0.02\n",
      "iteration: 16530 loss: 0.0093 lr: 0.02\n",
      "iteration: 16540 loss: 0.0101 lr: 0.02\n",
      "iteration: 16550 loss: 0.0077 lr: 0.02\n",
      "iteration: 16560 loss: 0.0099 lr: 0.02\n",
      "iteration: 16570 loss: 0.0104 lr: 0.02\n",
      "iteration: 16580 loss: 0.0099 lr: 0.02\n",
      "iteration: 16590 loss: 0.0086 lr: 0.02\n",
      "iteration: 16600 loss: 0.0095 lr: 0.02\n",
      "iteration: 16610 loss: 0.0090 lr: 0.02\n",
      "iteration: 16620 loss: 0.0089 lr: 0.02\n",
      "iteration: 16630 loss: 0.0095 lr: 0.02\n",
      "iteration: 16640 loss: 0.0082 lr: 0.02\n",
      "iteration: 16650 loss: 0.0089 lr: 0.02\n",
      "iteration: 16660 loss: 0.0082 lr: 0.02\n",
      "iteration: 16670 loss: 0.0096 lr: 0.02\n",
      "iteration: 16680 loss: 0.0090 lr: 0.02\n",
      "iteration: 16690 loss: 0.0108 lr: 0.02\n",
      "iteration: 16700 loss: 0.0089 lr: 0.02\n",
      "iteration: 16710 loss: 0.0115 lr: 0.02\n",
      "iteration: 16720 loss: 0.0105 lr: 0.02\n",
      "iteration: 16730 loss: 0.0098 lr: 0.02\n",
      "iteration: 16740 loss: 0.0083 lr: 0.02\n",
      "iteration: 16750 loss: 0.0066 lr: 0.02\n",
      "iteration: 16760 loss: 0.0084 lr: 0.02\n",
      "iteration: 16770 loss: 0.0090 lr: 0.02\n",
      "iteration: 16780 loss: 0.0082 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 16790 loss: 0.0091 lr: 0.02\n",
      "iteration: 16800 loss: 0.0086 lr: 0.02\n",
      "iteration: 16810 loss: 0.0074 lr: 0.02\n",
      "iteration: 16820 loss: 0.0098 lr: 0.02\n",
      "iteration: 16830 loss: 0.0075 lr: 0.02\n",
      "iteration: 16840 loss: 0.0093 lr: 0.02\n",
      "iteration: 16850 loss: 0.0079 lr: 0.02\n",
      "iteration: 16860 loss: 0.0084 lr: 0.02\n",
      "iteration: 16870 loss: 0.0109 lr: 0.02\n",
      "iteration: 16880 loss: 0.0086 lr: 0.02\n",
      "iteration: 16890 loss: 0.0075 lr: 0.02\n",
      "iteration: 16900 loss: 0.0084 lr: 0.02\n",
      "iteration: 16910 loss: 0.0071 lr: 0.02\n",
      "iteration: 16920 loss: 0.0099 lr: 0.02\n",
      "iteration: 16930 loss: 0.0087 lr: 0.02\n",
      "iteration: 16940 loss: 0.0096 lr: 0.02\n",
      "iteration: 16950 loss: 0.0091 lr: 0.02\n",
      "iteration: 16960 loss: 0.0081 lr: 0.02\n",
      "iteration: 16970 loss: 0.0093 lr: 0.02\n",
      "iteration: 16980 loss: 0.0083 lr: 0.02\n",
      "iteration: 16990 loss: 0.0081 lr: 0.02\n",
      "iteration: 17000 loss: 0.0090 lr: 0.02\n",
      "iteration: 17010 loss: 0.0087 lr: 0.02\n",
      "iteration: 17020 loss: 0.0068 lr: 0.02\n",
      "iteration: 17030 loss: 0.0090 lr: 0.02\n",
      "iteration: 17040 loss: 0.0094 lr: 0.02\n",
      "iteration: 17050 loss: 0.0068 lr: 0.02\n",
      "iteration: 17060 loss: 0.0085 lr: 0.02\n",
      "iteration: 17070 loss: 0.0082 lr: 0.02\n",
      "iteration: 17080 loss: 0.0083 lr: 0.02\n",
      "iteration: 17090 loss: 0.0089 lr: 0.02\n",
      "iteration: 17100 loss: 0.0076 lr: 0.02\n",
      "iteration: 17110 loss: 0.0106 lr: 0.02\n",
      "iteration: 17120 loss: 0.0069 lr: 0.02\n",
      "iteration: 17130 loss: 0.0089 lr: 0.02\n",
      "iteration: 17140 loss: 0.0094 lr: 0.02\n",
      "iteration: 17150 loss: 0.0082 lr: 0.02\n",
      "iteration: 17160 loss: 0.0083 lr: 0.02\n",
      "iteration: 17170 loss: 0.0085 lr: 0.02\n",
      "iteration: 17180 loss: 0.0089 lr: 0.02\n",
      "iteration: 17190 loss: 0.0099 lr: 0.02\n",
      "iteration: 17200 loss: 0.0084 lr: 0.02\n",
      "iteration: 17210 loss: 0.0090 lr: 0.02\n",
      "iteration: 17220 loss: 0.0085 lr: 0.02\n",
      "iteration: 17230 loss: 0.0093 lr: 0.02\n",
      "iteration: 17240 loss: 0.0095 lr: 0.02\n",
      "iteration: 17250 loss: 0.0090 lr: 0.02\n",
      "iteration: 17260 loss: 0.0083 lr: 0.02\n",
      "iteration: 17270 loss: 0.0088 lr: 0.02\n",
      "iteration: 17280 loss: 0.0100 lr: 0.02\n",
      "iteration: 17290 loss: 0.0092 lr: 0.02\n",
      "iteration: 17300 loss: 0.0066 lr: 0.02\n",
      "iteration: 17310 loss: 0.0088 lr: 0.02\n",
      "iteration: 17320 loss: 0.0085 lr: 0.02\n",
      "iteration: 17330 loss: 0.0100 lr: 0.02\n",
      "iteration: 17340 loss: 0.0095 lr: 0.02\n",
      "iteration: 17350 loss: 0.0078 lr: 0.02\n",
      "iteration: 17360 loss: 0.0088 lr: 0.02\n",
      "iteration: 17370 loss: 0.0073 lr: 0.02\n",
      "iteration: 17380 loss: 0.0077 lr: 0.02\n",
      "iteration: 17390 loss: 0.0066 lr: 0.02\n",
      "iteration: 17400 loss: 0.0113 lr: 0.02\n",
      "iteration: 17410 loss: 0.0097 lr: 0.02\n",
      "iteration: 17420 loss: 0.0085 lr: 0.02\n",
      "iteration: 17430 loss: 0.0100 lr: 0.02\n",
      "iteration: 17440 loss: 0.0076 lr: 0.02\n",
      "iteration: 17450 loss: 0.0082 lr: 0.02\n",
      "iteration: 17460 loss: 0.0072 lr: 0.02\n",
      "iteration: 17470 loss: 0.0109 lr: 0.02\n",
      "iteration: 17480 loss: 0.0091 lr: 0.02\n",
      "iteration: 17490 loss: 0.0076 lr: 0.02\n",
      "iteration: 17500 loss: 0.0083 lr: 0.02\n",
      "iteration: 17510 loss: 0.0088 lr: 0.02\n",
      "iteration: 17520 loss: 0.0085 lr: 0.02\n",
      "iteration: 17530 loss: 0.0085 lr: 0.02\n",
      "iteration: 17540 loss: 0.0095 lr: 0.02\n",
      "iteration: 17550 loss: 0.0078 lr: 0.02\n",
      "iteration: 17560 loss: 0.0103 lr: 0.02\n",
      "iteration: 17570 loss: 0.0085 lr: 0.02\n",
      "iteration: 17580 loss: 0.0074 lr: 0.02\n",
      "iteration: 17590 loss: 0.0078 lr: 0.02\n",
      "iteration: 17600 loss: 0.0085 lr: 0.02\n",
      "iteration: 17610 loss: 0.0097 lr: 0.02\n",
      "iteration: 17620 loss: 0.0108 lr: 0.02\n",
      "iteration: 17630 loss: 0.0075 lr: 0.02\n",
      "iteration: 17640 loss: 0.0097 lr: 0.02\n",
      "iteration: 17650 loss: 0.0076 lr: 0.02\n",
      "iteration: 17660 loss: 0.0092 lr: 0.02\n",
      "iteration: 17670 loss: 0.0088 lr: 0.02\n",
      "iteration: 17680 loss: 0.0089 lr: 0.02\n",
      "iteration: 17690 loss: 0.0075 lr: 0.02\n",
      "iteration: 17700 loss: 0.0068 lr: 0.02\n",
      "iteration: 17710 loss: 0.0078 lr: 0.02\n",
      "iteration: 17720 loss: 0.0065 lr: 0.02\n",
      "iteration: 17730 loss: 0.0089 lr: 0.02\n",
      "iteration: 17740 loss: 0.0094 lr: 0.02\n",
      "iteration: 17750 loss: 0.0102 lr: 0.02\n",
      "iteration: 17760 loss: 0.0074 lr: 0.02\n",
      "iteration: 17770 loss: 0.0070 lr: 0.02\n",
      "iteration: 17780 loss: 0.0083 lr: 0.02\n",
      "iteration: 17790 loss: 0.0067 lr: 0.02\n",
      "iteration: 17800 loss: 0.0083 lr: 0.02\n",
      "iteration: 17810 loss: 0.0086 lr: 0.02\n",
      "iteration: 17820 loss: 0.0071 lr: 0.02\n",
      "iteration: 17830 loss: 0.0093 lr: 0.02\n",
      "iteration: 17840 loss: 0.0113 lr: 0.02\n",
      "iteration: 17850 loss: 0.0073 lr: 0.02\n",
      "iteration: 17860 loss: 0.0087 lr: 0.02\n",
      "iteration: 17870 loss: 0.0085 lr: 0.02\n",
      "iteration: 17880 loss: 0.0080 lr: 0.02\n",
      "iteration: 17890 loss: 0.0081 lr: 0.02\n",
      "iteration: 17900 loss: 0.0072 lr: 0.02\n",
      "iteration: 17910 loss: 0.0088 lr: 0.02\n",
      "iteration: 17920 loss: 0.0076 lr: 0.02\n",
      "iteration: 17930 loss: 0.0070 lr: 0.02\n",
      "iteration: 17940 loss: 0.0076 lr: 0.02\n",
      "iteration: 17950 loss: 0.0071 lr: 0.02\n",
      "iteration: 17960 loss: 0.0072 lr: 0.02\n",
      "iteration: 17970 loss: 0.0108 lr: 0.02\n",
      "iteration: 17980 loss: 0.0095 lr: 0.02\n",
      "iteration: 17990 loss: 0.0088 lr: 0.02\n",
      "iteration: 18000 loss: 0.0080 lr: 0.02\n",
      "iteration: 18010 loss: 0.0098 lr: 0.02\n",
      "iteration: 18020 loss: 0.0094 lr: 0.02\n",
      "iteration: 18030 loss: 0.0067 lr: 0.02\n",
      "iteration: 18040 loss: 0.0096 lr: 0.02\n",
      "iteration: 18050 loss: 0.0089 lr: 0.02\n",
      "iteration: 18060 loss: 0.0094 lr: 0.02\n",
      "iteration: 18070 loss: 0.0065 lr: 0.02\n",
      "iteration: 18080 loss: 0.0096 lr: 0.02\n",
      "iteration: 18090 loss: 0.0093 lr: 0.02\n",
      "iteration: 18100 loss: 0.0067 lr: 0.02\n",
      "iteration: 18110 loss: 0.0087 lr: 0.02\n",
      "iteration: 18120 loss: 0.0081 lr: 0.02\n",
      "iteration: 18130 loss: 0.0096 lr: 0.02\n",
      "iteration: 18140 loss: 0.0089 lr: 0.02\n",
      "iteration: 18150 loss: 0.0089 lr: 0.02\n",
      "iteration: 18160 loss: 0.0080 lr: 0.02\n",
      "iteration: 18170 loss: 0.0080 lr: 0.02\n",
      "iteration: 18180 loss: 0.0069 lr: 0.02\n",
      "iteration: 18190 loss: 0.0080 lr: 0.02\n",
      "iteration: 18200 loss: 0.0104 lr: 0.02\n",
      "iteration: 18210 loss: 0.0090 lr: 0.02\n",
      "iteration: 18220 loss: 0.0080 lr: 0.02\n",
      "iteration: 18230 loss: 0.0080 lr: 0.02\n",
      "iteration: 18240 loss: 0.0096 lr: 0.02\n",
      "iteration: 18250 loss: 0.0082 lr: 0.02\n",
      "iteration: 18260 loss: 0.0086 lr: 0.02\n",
      "iteration: 18270 loss: 0.0066 lr: 0.02\n",
      "iteration: 18280 loss: 0.0077 lr: 0.02\n",
      "iteration: 18290 loss: 0.0074 lr: 0.02\n",
      "iteration: 18300 loss: 0.0085 lr: 0.02\n",
      "iteration: 18310 loss: 0.0088 lr: 0.02\n",
      "iteration: 18320 loss: 0.0098 lr: 0.02\n",
      "iteration: 18330 loss: 0.0060 lr: 0.02\n",
      "iteration: 18340 loss: 0.0072 lr: 0.02\n",
      "iteration: 18350 loss: 0.0078 lr: 0.02\n",
      "iteration: 18360 loss: 0.0091 lr: 0.02\n",
      "iteration: 18370 loss: 0.0084 lr: 0.02\n",
      "iteration: 18380 loss: 0.0083 lr: 0.02\n",
      "iteration: 18390 loss: 0.0079 lr: 0.02\n",
      "iteration: 18400 loss: 0.0085 lr: 0.02\n",
      "iteration: 18410 loss: 0.0084 lr: 0.02\n",
      "iteration: 18420 loss: 0.0080 lr: 0.02\n",
      "iteration: 18430 loss: 0.0085 lr: 0.02\n",
      "iteration: 18440 loss: 0.0084 lr: 0.02\n",
      "iteration: 18450 loss: 0.0086 lr: 0.02\n",
      "iteration: 18460 loss: 0.0109 lr: 0.02\n",
      "iteration: 18470 loss: 0.0078 lr: 0.02\n",
      "iteration: 18480 loss: 0.0091 lr: 0.02\n",
      "iteration: 18490 loss: 0.0096 lr: 0.02\n",
      "iteration: 18500 loss: 0.0083 lr: 0.02\n",
      "iteration: 18510 loss: 0.0070 lr: 0.02\n",
      "iteration: 18520 loss: 0.0078 lr: 0.02\n",
      "iteration: 18530 loss: 0.0063 lr: 0.02\n",
      "iteration: 18540 loss: 0.0099 lr: 0.02\n",
      "iteration: 18550 loss: 0.0094 lr: 0.02\n",
      "iteration: 18560 loss: 0.0085 lr: 0.02\n",
      "iteration: 18570 loss: 0.0075 lr: 0.02\n",
      "iteration: 18580 loss: 0.0081 lr: 0.02\n",
      "iteration: 18590 loss: 0.0082 lr: 0.02\n",
      "iteration: 18600 loss: 0.0075 lr: 0.02\n",
      "iteration: 18610 loss: 0.0097 lr: 0.02\n",
      "iteration: 18620 loss: 0.0101 lr: 0.02\n",
      "iteration: 18630 loss: 0.0073 lr: 0.02\n",
      "iteration: 18640 loss: 0.0101 lr: 0.02\n",
      "iteration: 18650 loss: 0.0077 lr: 0.02\n",
      "iteration: 18660 loss: 0.0080 lr: 0.02\n",
      "iteration: 18670 loss: 0.0093 lr: 0.02\n",
      "iteration: 18680 loss: 0.0069 lr: 0.02\n",
      "iteration: 18690 loss: 0.0082 lr: 0.02\n",
      "iteration: 18700 loss: 0.0098 lr: 0.02\n",
      "iteration: 18710 loss: 0.0107 lr: 0.02\n",
      "iteration: 18720 loss: 0.0085 lr: 0.02\n",
      "iteration: 18730 loss: 0.0076 lr: 0.02\n",
      "iteration: 18740 loss: 0.0105 lr: 0.02\n",
      "iteration: 18750 loss: 0.0090 lr: 0.02\n",
      "iteration: 18760 loss: 0.0079 lr: 0.02\n",
      "iteration: 18770 loss: 0.0067 lr: 0.02\n",
      "iteration: 18780 loss: 0.0091 lr: 0.02\n",
      "iteration: 18790 loss: 0.0089 lr: 0.02\n",
      "iteration: 18800 loss: 0.0082 lr: 0.02\n",
      "iteration: 18810 loss: 0.0085 lr: 0.02\n",
      "iteration: 18820 loss: 0.0079 lr: 0.02\n",
      "iteration: 18830 loss: 0.0074 lr: 0.02\n",
      "iteration: 18840 loss: 0.0092 lr: 0.02\n",
      "iteration: 18850 loss: 0.0080 lr: 0.02\n",
      "iteration: 18860 loss: 0.0092 lr: 0.02\n",
      "iteration: 18870 loss: 0.0080 lr: 0.02\n",
      "iteration: 18880 loss: 0.0082 lr: 0.02\n",
      "iteration: 18890 loss: 0.0079 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 18900 loss: 0.0094 lr: 0.02\n",
      "iteration: 18910 loss: 0.0111 lr: 0.02\n",
      "iteration: 18920 loss: 0.0097 lr: 0.02\n",
      "iteration: 18930 loss: 0.0086 lr: 0.02\n",
      "iteration: 18940 loss: 0.0091 lr: 0.02\n",
      "iteration: 18950 loss: 0.0090 lr: 0.02\n",
      "iteration: 18960 loss: 0.0083 lr: 0.02\n",
      "iteration: 18970 loss: 0.0073 lr: 0.02\n",
      "iteration: 18980 loss: 0.0082 lr: 0.02\n",
      "iteration: 18990 loss: 0.0084 lr: 0.02\n",
      "iteration: 19000 loss: 0.0072 lr: 0.02\n",
      "iteration: 19010 loss: 0.0069 lr: 0.02\n",
      "iteration: 19020 loss: 0.0090 lr: 0.02\n",
      "iteration: 19030 loss: 0.0088 lr: 0.02\n",
      "iteration: 19040 loss: 0.0076 lr: 0.02\n",
      "iteration: 19050 loss: 0.0087 lr: 0.02\n",
      "iteration: 19060 loss: 0.0057 lr: 0.02\n",
      "iteration: 19070 loss: 0.0062 lr: 0.02\n",
      "iteration: 19080 loss: 0.0063 lr: 0.02\n",
      "iteration: 19090 loss: 0.0079 lr: 0.02\n",
      "iteration: 19100 loss: 0.0088 lr: 0.02\n",
      "iteration: 19110 loss: 0.0062 lr: 0.02\n",
      "iteration: 19120 loss: 0.0070 lr: 0.02\n",
      "iteration: 19130 loss: 0.0074 lr: 0.02\n",
      "iteration: 19140 loss: 0.0074 lr: 0.02\n",
      "iteration: 19150 loss: 0.0075 lr: 0.02\n",
      "iteration: 19160 loss: 0.0080 lr: 0.02\n",
      "iteration: 19170 loss: 0.0079 lr: 0.02\n",
      "iteration: 19180 loss: 0.0082 lr: 0.02\n",
      "iteration: 19190 loss: 0.0087 lr: 0.02\n",
      "iteration: 19200 loss: 0.0092 lr: 0.02\n",
      "iteration: 19210 loss: 0.0084 lr: 0.02\n",
      "iteration: 19220 loss: 0.0073 lr: 0.02\n",
      "iteration: 19230 loss: 0.0080 lr: 0.02\n",
      "iteration: 19240 loss: 0.0067 lr: 0.02\n",
      "iteration: 19250 loss: 0.0086 lr: 0.02\n",
      "iteration: 19260 loss: 0.0071 lr: 0.02\n",
      "iteration: 19270 loss: 0.0081 lr: 0.02\n",
      "iteration: 19280 loss: 0.0074 lr: 0.02\n",
      "iteration: 19290 loss: 0.0056 lr: 0.02\n",
      "iteration: 19300 loss: 0.0084 lr: 0.02\n",
      "iteration: 19310 loss: 0.0076 lr: 0.02\n",
      "iteration: 19320 loss: 0.0088 lr: 0.02\n",
      "iteration: 19330 loss: 0.0072 lr: 0.02\n",
      "iteration: 19340 loss: 0.0081 lr: 0.02\n",
      "iteration: 19350 loss: 0.0077 lr: 0.02\n",
      "iteration: 19360 loss: 0.0072 lr: 0.02\n",
      "iteration: 19370 loss: 0.0080 lr: 0.02\n",
      "iteration: 19380 loss: 0.0087 lr: 0.02\n",
      "iteration: 19390 loss: 0.0083 lr: 0.02\n",
      "iteration: 19400 loss: 0.0068 lr: 0.02\n",
      "iteration: 19410 loss: 0.0071 lr: 0.02\n",
      "iteration: 19420 loss: 0.0079 lr: 0.02\n",
      "iteration: 19430 loss: 0.0076 lr: 0.02\n",
      "iteration: 19440 loss: 0.0082 lr: 0.02\n",
      "iteration: 19450 loss: 0.0077 lr: 0.02\n",
      "iteration: 19460 loss: 0.0073 lr: 0.02\n",
      "iteration: 19470 loss: 0.0096 lr: 0.02\n",
      "iteration: 19480 loss: 0.0082 lr: 0.02\n",
      "iteration: 19490 loss: 0.0084 lr: 0.02\n",
      "iteration: 19500 loss: 0.0078 lr: 0.02\n",
      "iteration: 19510 loss: 0.0094 lr: 0.02\n",
      "iteration: 19520 loss: 0.0085 lr: 0.02\n",
      "iteration: 19530 loss: 0.0085 lr: 0.02\n",
      "iteration: 19540 loss: 0.0070 lr: 0.02\n",
      "iteration: 19550 loss: 0.0075 lr: 0.02\n",
      "iteration: 19560 loss: 0.0090 lr: 0.02\n",
      "iteration: 19570 loss: 0.0079 lr: 0.02\n",
      "iteration: 19580 loss: 0.0074 lr: 0.02\n",
      "iteration: 19590 loss: 0.0066 lr: 0.02\n",
      "iteration: 19600 loss: 0.0081 lr: 0.02\n",
      "iteration: 19610 loss: 0.0069 lr: 0.02\n",
      "iteration: 19620 loss: 0.0070 lr: 0.02\n",
      "iteration: 19630 loss: 0.0065 lr: 0.02\n",
      "iteration: 19640 loss: 0.0088 lr: 0.02\n",
      "iteration: 19650 loss: 0.0086 lr: 0.02\n",
      "iteration: 19660 loss: 0.0099 lr: 0.02\n",
      "iteration: 19670 loss: 0.0076 lr: 0.02\n",
      "iteration: 19680 loss: 0.0083 lr: 0.02\n",
      "iteration: 19690 loss: 0.0067 lr: 0.02\n",
      "iteration: 19700 loss: 0.0080 lr: 0.02\n",
      "iteration: 19710 loss: 0.0073 lr: 0.02\n",
      "iteration: 19720 loss: 0.0094 lr: 0.02\n",
      "iteration: 19730 loss: 0.0089 lr: 0.02\n",
      "iteration: 19740 loss: 0.0072 lr: 0.02\n",
      "iteration: 19750 loss: 0.0073 lr: 0.02\n",
      "iteration: 19760 loss: 0.0071 lr: 0.02\n",
      "iteration: 19770 loss: 0.0091 lr: 0.02\n",
      "iteration: 19780 loss: 0.0081 lr: 0.02\n",
      "iteration: 19790 loss: 0.0094 lr: 0.02\n",
      "iteration: 19800 loss: 0.0067 lr: 0.02\n",
      "iteration: 19810 loss: 0.0097 lr: 0.02\n",
      "iteration: 19820 loss: 0.0080 lr: 0.02\n",
      "iteration: 19830 loss: 0.0092 lr: 0.02\n",
      "iteration: 19840 loss: 0.0065 lr: 0.02\n",
      "iteration: 19850 loss: 0.0103 lr: 0.02\n",
      "iteration: 19860 loss: 0.0081 lr: 0.02\n",
      "iteration: 19870 loss: 0.0076 lr: 0.02\n",
      "iteration: 19880 loss: 0.0089 lr: 0.02\n",
      "iteration: 19890 loss: 0.0072 lr: 0.02\n",
      "iteration: 19900 loss: 0.0095 lr: 0.02\n",
      "iteration: 19910 loss: 0.0092 lr: 0.02\n",
      "iteration: 19920 loss: 0.0077 lr: 0.02\n",
      "iteration: 19930 loss: 0.0066 lr: 0.02\n",
      "iteration: 19940 loss: 0.0068 lr: 0.02\n",
      "iteration: 19950 loss: 0.0073 lr: 0.02\n",
      "iteration: 19960 loss: 0.0084 lr: 0.02\n",
      "iteration: 19970 loss: 0.0073 lr: 0.02\n",
      "iteration: 19980 loss: 0.0076 lr: 0.02\n",
      "iteration: 19990 loss: 0.0089 lr: 0.02\n",
      "iteration: 20000 loss: 0.0081 lr: 0.02\n",
      "iteration: 20010 loss: 0.0083 lr: 0.02\n",
      "iteration: 20020 loss: 0.0073 lr: 0.02\n",
      "iteration: 20030 loss: 0.0079 lr: 0.02\n",
      "iteration: 20040 loss: 0.0089 lr: 0.02\n",
      "iteration: 20050 loss: 0.0071 lr: 0.02\n",
      "iteration: 20060 loss: 0.0077 lr: 0.02\n",
      "iteration: 20070 loss: 0.0073 lr: 0.02\n",
      "iteration: 20080 loss: 0.0072 lr: 0.02\n",
      "iteration: 20090 loss: 0.0070 lr: 0.02\n",
      "iteration: 20100 loss: 0.0073 lr: 0.02\n",
      "iteration: 20110 loss: 0.0079 lr: 0.02\n",
      "iteration: 20120 loss: 0.0074 lr: 0.02\n",
      "iteration: 20130 loss: 0.0079 lr: 0.02\n",
      "iteration: 20140 loss: 0.0084 lr: 0.02\n",
      "iteration: 20150 loss: 0.0068 lr: 0.02\n",
      "iteration: 20160 loss: 0.0098 lr: 0.02\n",
      "iteration: 20170 loss: 0.0069 lr: 0.02\n",
      "iteration: 20180 loss: 0.0086 lr: 0.02\n",
      "iteration: 20190 loss: 0.0071 lr: 0.02\n",
      "iteration: 20200 loss: 0.0070 lr: 0.02\n",
      "iteration: 20210 loss: 0.0077 lr: 0.02\n",
      "iteration: 20220 loss: 0.0068 lr: 0.02\n",
      "iteration: 20230 loss: 0.0085 lr: 0.02\n",
      "iteration: 20240 loss: 0.0083 lr: 0.02\n",
      "iteration: 20250 loss: 0.0077 lr: 0.02\n",
      "iteration: 20260 loss: 0.0083 lr: 0.02\n",
      "iteration: 20270 loss: 0.0075 lr: 0.02\n",
      "iteration: 20280 loss: 0.0071 lr: 0.02\n",
      "iteration: 20290 loss: 0.0067 lr: 0.02\n",
      "iteration: 20300 loss: 0.0080 lr: 0.02\n",
      "iteration: 20310 loss: 0.0056 lr: 0.02\n",
      "iteration: 20320 loss: 0.0074 lr: 0.02\n",
      "iteration: 20330 loss: 0.0073 lr: 0.02\n",
      "iteration: 20340 loss: 0.0067 lr: 0.02\n",
      "iteration: 20350 loss: 0.0081 lr: 0.02\n",
      "iteration: 20360 loss: 0.0068 lr: 0.02\n",
      "iteration: 20370 loss: 0.0087 lr: 0.02\n",
      "iteration: 20380 loss: 0.0073 lr: 0.02\n",
      "iteration: 20390 loss: 0.0083 lr: 0.02\n",
      "iteration: 20400 loss: 0.0084 lr: 0.02\n",
      "iteration: 20410 loss: 0.0066 lr: 0.02\n",
      "iteration: 20420 loss: 0.0073 lr: 0.02\n",
      "iteration: 20430 loss: 0.0066 lr: 0.02\n",
      "iteration: 20440 loss: 0.0066 lr: 0.02\n",
      "iteration: 20450 loss: 0.0064 lr: 0.02\n",
      "iteration: 20460 loss: 0.0084 lr: 0.02\n",
      "iteration: 20470 loss: 0.0080 lr: 0.02\n",
      "iteration: 20480 loss: 0.0085 lr: 0.02\n",
      "iteration: 20490 loss: 0.0078 lr: 0.02\n",
      "iteration: 20500 loss: 0.0065 lr: 0.02\n",
      "iteration: 20510 loss: 0.0104 lr: 0.02\n",
      "iteration: 20520 loss: 0.0089 lr: 0.02\n",
      "iteration: 20530 loss: 0.0076 lr: 0.02\n",
      "iteration: 20540 loss: 0.0076 lr: 0.02\n",
      "iteration: 20550 loss: 0.0083 lr: 0.02\n",
      "iteration: 20560 loss: 0.0065 lr: 0.02\n",
      "iteration: 20570 loss: 0.0074 lr: 0.02\n",
      "iteration: 20580 loss: 0.0070 lr: 0.02\n",
      "iteration: 20590 loss: 0.0076 lr: 0.02\n",
      "iteration: 20600 loss: 0.0087 lr: 0.02\n",
      "iteration: 20610 loss: 0.0069 lr: 0.02\n",
      "iteration: 20620 loss: 0.0082 lr: 0.02\n",
      "iteration: 20630 loss: 0.0084 lr: 0.02\n",
      "iteration: 20640 loss: 0.0056 lr: 0.02\n",
      "iteration: 20650 loss: 0.0077 lr: 0.02\n",
      "iteration: 20660 loss: 0.0076 lr: 0.02\n",
      "iteration: 20670 loss: 0.0063 lr: 0.02\n",
      "iteration: 20680 loss: 0.0062 lr: 0.02\n",
      "iteration: 20690 loss: 0.0066 lr: 0.02\n",
      "iteration: 20700 loss: 0.0084 lr: 0.02\n",
      "iteration: 20710 loss: 0.0097 lr: 0.02\n",
      "iteration: 20720 loss: 0.0072 lr: 0.02\n",
      "iteration: 20730 loss: 0.0072 lr: 0.02\n",
      "iteration: 20740 loss: 0.0095 lr: 0.02\n",
      "iteration: 20750 loss: 0.0062 lr: 0.02\n",
      "iteration: 20760 loss: 0.0080 lr: 0.02\n",
      "iteration: 20770 loss: 0.0081 lr: 0.02\n",
      "iteration: 20780 loss: 0.0094 lr: 0.02\n",
      "iteration: 20790 loss: 0.0086 lr: 0.02\n",
      "iteration: 20800 loss: 0.0079 lr: 0.02\n",
      "iteration: 20810 loss: 0.0079 lr: 0.02\n",
      "iteration: 20820 loss: 0.0095 lr: 0.02\n",
      "iteration: 20830 loss: 0.0086 lr: 0.02\n",
      "iteration: 20840 loss: 0.0087 lr: 0.02\n",
      "iteration: 20850 loss: 0.0069 lr: 0.02\n",
      "iteration: 20860 loss: 0.0084 lr: 0.02\n",
      "iteration: 20870 loss: 0.0082 lr: 0.02\n",
      "iteration: 20880 loss: 0.0062 lr: 0.02\n",
      "iteration: 20890 loss: 0.0075 lr: 0.02\n",
      "iteration: 20900 loss: 0.0080 lr: 0.02\n",
      "iteration: 20910 loss: 0.0057 lr: 0.02\n",
      "iteration: 20920 loss: 0.0077 lr: 0.02\n",
      "iteration: 20930 loss: 0.0081 lr: 0.02\n",
      "iteration: 20940 loss: 0.0057 lr: 0.02\n",
      "iteration: 20950 loss: 0.0055 lr: 0.02\n",
      "iteration: 20960 loss: 0.0073 lr: 0.02\n",
      "iteration: 20970 loss: 0.0085 lr: 0.02\n",
      "iteration: 20980 loss: 0.0049 lr: 0.02\n",
      "iteration: 20990 loss: 0.0077 lr: 0.02\n",
      "iteration: 21000 loss: 0.0068 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 21010 loss: 0.0063 lr: 0.02\n",
      "iteration: 21020 loss: 0.0068 lr: 0.02\n",
      "iteration: 21030 loss: 0.0085 lr: 0.02\n",
      "iteration: 21040 loss: 0.0064 lr: 0.02\n",
      "iteration: 21050 loss: 0.0071 lr: 0.02\n",
      "iteration: 21060 loss: 0.0058 lr: 0.02\n",
      "iteration: 21070 loss: 0.0062 lr: 0.02\n",
      "iteration: 21080 loss: 0.0087 lr: 0.02\n",
      "iteration: 21090 loss: 0.0076 lr: 0.02\n",
      "iteration: 21100 loss: 0.0072 lr: 0.02\n",
      "iteration: 21110 loss: 0.0071 lr: 0.02\n",
      "iteration: 21120 loss: 0.0072 lr: 0.02\n",
      "iteration: 21130 loss: 0.0056 lr: 0.02\n",
      "iteration: 21140 loss: 0.0070 lr: 0.02\n",
      "iteration: 21150 loss: 0.0088 lr: 0.02\n",
      "iteration: 21160 loss: 0.0094 lr: 0.02\n",
      "iteration: 21170 loss: 0.0089 lr: 0.02\n",
      "iteration: 21180 loss: 0.0076 lr: 0.02\n",
      "iteration: 21190 loss: 0.0079 lr: 0.02\n",
      "iteration: 21200 loss: 0.0079 lr: 0.02\n",
      "iteration: 21210 loss: 0.0082 lr: 0.02\n",
      "iteration: 21220 loss: 0.0066 lr: 0.02\n",
      "iteration: 21230 loss: 0.0077 lr: 0.02\n",
      "iteration: 21240 loss: 0.0106 lr: 0.02\n",
      "iteration: 21250 loss: 0.0076 lr: 0.02\n",
      "iteration: 21260 loss: 0.0068 lr: 0.02\n",
      "iteration: 21270 loss: 0.0075 lr: 0.02\n",
      "iteration: 21280 loss: 0.0069 lr: 0.02\n",
      "iteration: 21290 loss: 0.0064 lr: 0.02\n",
      "iteration: 21300 loss: 0.0091 lr: 0.02\n",
      "iteration: 21310 loss: 0.0094 lr: 0.02\n",
      "iteration: 21320 loss: 0.0071 lr: 0.02\n",
      "iteration: 21330 loss: 0.0088 lr: 0.02\n",
      "iteration: 21340 loss: 0.0074 lr: 0.02\n",
      "iteration: 21350 loss: 0.0074 lr: 0.02\n",
      "iteration: 21360 loss: 0.0067 lr: 0.02\n",
      "iteration: 21370 loss: 0.0061 lr: 0.02\n",
      "iteration: 21380 loss: 0.0069 lr: 0.02\n",
      "iteration: 21390 loss: 0.0061 lr: 0.02\n",
      "iteration: 21400 loss: 0.0067 lr: 0.02\n",
      "iteration: 21410 loss: 0.0069 lr: 0.02\n",
      "iteration: 21420 loss: 0.0077 lr: 0.02\n",
      "iteration: 21430 loss: 0.0069 lr: 0.02\n",
      "iteration: 21440 loss: 0.0104 lr: 0.02\n",
      "iteration: 21450 loss: 0.0091 lr: 0.02\n",
      "iteration: 21460 loss: 0.0063 lr: 0.02\n",
      "iteration: 21470 loss: 0.0067 lr: 0.02\n",
      "iteration: 21480 loss: 0.0077 lr: 0.02\n",
      "iteration: 21490 loss: 0.0067 lr: 0.02\n",
      "iteration: 21500 loss: 0.0090 lr: 0.02\n",
      "iteration: 21510 loss: 0.0078 lr: 0.02\n",
      "iteration: 21520 loss: 0.0071 lr: 0.02\n",
      "iteration: 21530 loss: 0.0081 lr: 0.02\n",
      "iteration: 21540 loss: 0.0077 lr: 0.02\n",
      "iteration: 21550 loss: 0.0059 lr: 0.02\n",
      "iteration: 21560 loss: 0.0071 lr: 0.02\n",
      "iteration: 21570 loss: 0.0072 lr: 0.02\n",
      "iteration: 21580 loss: 0.0067 lr: 0.02\n",
      "iteration: 21590 loss: 0.0071 lr: 0.02\n",
      "iteration: 21600 loss: 0.0070 lr: 0.02\n",
      "iteration: 21610 loss: 0.0060 lr: 0.02\n",
      "iteration: 21620 loss: 0.0084 lr: 0.02\n",
      "iteration: 21630 loss: 0.0066 lr: 0.02\n",
      "iteration: 21640 loss: 0.0093 lr: 0.02\n",
      "iteration: 21650 loss: 0.0077 lr: 0.02\n",
      "iteration: 21660 loss: 0.0086 lr: 0.02\n",
      "iteration: 21670 loss: 0.0075 lr: 0.02\n",
      "iteration: 21680 loss: 0.0071 lr: 0.02\n",
      "iteration: 21690 loss: 0.0088 lr: 0.02\n",
      "iteration: 21700 loss: 0.0083 lr: 0.02\n",
      "iteration: 21710 loss: 0.0084 lr: 0.02\n",
      "iteration: 21720 loss: 0.0072 lr: 0.02\n",
      "iteration: 21730 loss: 0.0066 lr: 0.02\n",
      "iteration: 21740 loss: 0.0064 lr: 0.02\n",
      "iteration: 21750 loss: 0.0072 lr: 0.02\n",
      "iteration: 21760 loss: 0.0073 lr: 0.02\n",
      "iteration: 21770 loss: 0.0058 lr: 0.02\n",
      "iteration: 21780 loss: 0.0066 lr: 0.02\n",
      "iteration: 21790 loss: 0.0071 lr: 0.02\n",
      "iteration: 21800 loss: 0.0070 lr: 0.02\n",
      "iteration: 21810 loss: 0.0075 lr: 0.02\n",
      "iteration: 21820 loss: 0.0086 lr: 0.02\n",
      "iteration: 21830 loss: 0.0081 lr: 0.02\n",
      "iteration: 21840 loss: 0.0074 lr: 0.02\n",
      "iteration: 21850 loss: 0.0088 lr: 0.02\n",
      "iteration: 21860 loss: 0.0074 lr: 0.02\n",
      "iteration: 21870 loss: 0.0087 lr: 0.02\n",
      "iteration: 21880 loss: 0.0068 lr: 0.02\n",
      "iteration: 21890 loss: 0.0074 lr: 0.02\n",
      "iteration: 21900 loss: 0.0073 lr: 0.02\n",
      "iteration: 21910 loss: 0.0064 lr: 0.02\n",
      "iteration: 21920 loss: 0.0061 lr: 0.02\n",
      "iteration: 21930 loss: 0.0070 lr: 0.02\n",
      "iteration: 21940 loss: 0.0062 lr: 0.02\n",
      "iteration: 21950 loss: 0.0063 lr: 0.02\n",
      "iteration: 21960 loss: 0.0083 lr: 0.02\n",
      "iteration: 21970 loss: 0.0079 lr: 0.02\n",
      "iteration: 21980 loss: 0.0087 lr: 0.02\n",
      "iteration: 21990 loss: 0.0060 lr: 0.02\n",
      "iteration: 22000 loss: 0.0081 lr: 0.02\n",
      "iteration: 22010 loss: 0.0068 lr: 0.02\n",
      "iteration: 22020 loss: 0.0059 lr: 0.02\n",
      "iteration: 22030 loss: 0.0064 lr: 0.02\n",
      "iteration: 22040 loss: 0.0085 lr: 0.02\n",
      "iteration: 22050 loss: 0.0076 lr: 0.02\n",
      "iteration: 22060 loss: 0.0071 lr: 0.02\n",
      "iteration: 22070 loss: 0.0072 lr: 0.02\n",
      "iteration: 22080 loss: 0.0055 lr: 0.02\n",
      "iteration: 22090 loss: 0.0073 lr: 0.02\n",
      "iteration: 22100 loss: 0.0083 lr: 0.02\n",
      "iteration: 22110 loss: 0.0075 lr: 0.02\n",
      "iteration: 22120 loss: 0.0073 lr: 0.02\n",
      "iteration: 22130 loss: 0.0056 lr: 0.02\n",
      "iteration: 22140 loss: 0.0066 lr: 0.02\n",
      "iteration: 22150 loss: 0.0070 lr: 0.02\n",
      "iteration: 22160 loss: 0.0075 lr: 0.02\n",
      "iteration: 22170 loss: 0.0075 lr: 0.02\n",
      "iteration: 22180 loss: 0.0072 lr: 0.02\n",
      "iteration: 22190 loss: 0.0075 lr: 0.02\n",
      "iteration: 22200 loss: 0.0076 lr: 0.02\n",
      "iteration: 22210 loss: 0.0070 lr: 0.02\n",
      "iteration: 22220 loss: 0.0071 lr: 0.02\n",
      "iteration: 22230 loss: 0.0075 lr: 0.02\n",
      "iteration: 22240 loss: 0.0057 lr: 0.02\n",
      "iteration: 22250 loss: 0.0050 lr: 0.02\n",
      "iteration: 22260 loss: 0.0068 lr: 0.02\n",
      "iteration: 22270 loss: 0.0070 lr: 0.02\n",
      "iteration: 22280 loss: 0.0068 lr: 0.02\n",
      "iteration: 22290 loss: 0.0079 lr: 0.02\n",
      "iteration: 22300 loss: 0.0061 lr: 0.02\n",
      "iteration: 22310 loss: 0.0074 lr: 0.02\n",
      "iteration: 22320 loss: 0.0068 lr: 0.02\n",
      "iteration: 22330 loss: 0.0080 lr: 0.02\n",
      "iteration: 22340 loss: 0.0073 lr: 0.02\n",
      "iteration: 22350 loss: 0.0079 lr: 0.02\n",
      "iteration: 22360 loss: 0.0059 lr: 0.02\n",
      "iteration: 22370 loss: 0.0076 lr: 0.02\n",
      "iteration: 22380 loss: 0.0070 lr: 0.02\n",
      "iteration: 22390 loss: 0.0063 lr: 0.02\n",
      "iteration: 22400 loss: 0.0071 lr: 0.02\n",
      "iteration: 22410 loss: 0.0059 lr: 0.02\n",
      "iteration: 22420 loss: 0.0076 lr: 0.02\n",
      "iteration: 22430 loss: 0.0071 lr: 0.02\n",
      "iteration: 22440 loss: 0.0089 lr: 0.02\n",
      "iteration: 22450 loss: 0.0071 lr: 0.02\n",
      "iteration: 22460 loss: 0.0070 lr: 0.02\n",
      "iteration: 22470 loss: 0.0058 lr: 0.02\n",
      "iteration: 22480 loss: 0.0079 lr: 0.02\n",
      "iteration: 22490 loss: 0.0076 lr: 0.02\n",
      "iteration: 22500 loss: 0.0070 lr: 0.02\n",
      "iteration: 22510 loss: 0.0089 lr: 0.02\n",
      "iteration: 22520 loss: 0.0083 lr: 0.02\n",
      "iteration: 22530 loss: 0.0071 lr: 0.02\n",
      "iteration: 22540 loss: 0.0074 lr: 0.02\n",
      "iteration: 22550 loss: 0.0059 lr: 0.02\n",
      "iteration: 22560 loss: 0.0080 lr: 0.02\n",
      "iteration: 22570 loss: 0.0057 lr: 0.02\n",
      "iteration: 22580 loss: 0.0077 lr: 0.02\n",
      "iteration: 22590 loss: 0.0054 lr: 0.02\n",
      "iteration: 22600 loss: 0.0077 lr: 0.02\n",
      "iteration: 22610 loss: 0.0063 lr: 0.02\n",
      "iteration: 22620 loss: 0.0063 lr: 0.02\n",
      "iteration: 22630 loss: 0.0084 lr: 0.02\n",
      "iteration: 22640 loss: 0.0070 lr: 0.02\n",
      "iteration: 22650 loss: 0.0072 lr: 0.02\n",
      "iteration: 22660 loss: 0.0085 lr: 0.02\n",
      "iteration: 22670 loss: 0.0089 lr: 0.02\n",
      "iteration: 22680 loss: 0.0092 lr: 0.02\n",
      "iteration: 22690 loss: 0.0069 lr: 0.02\n",
      "iteration: 22700 loss: 0.0076 lr: 0.02\n",
      "iteration: 22710 loss: 0.0091 lr: 0.02\n",
      "iteration: 22720 loss: 0.0100 lr: 0.02\n",
      "iteration: 22730 loss: 0.0084 lr: 0.02\n",
      "iteration: 22740 loss: 0.0064 lr: 0.02\n",
      "iteration: 22750 loss: 0.0070 lr: 0.02\n",
      "iteration: 22760 loss: 0.0071 lr: 0.02\n",
      "iteration: 22770 loss: 0.0081 lr: 0.02\n",
      "iteration: 22780 loss: 0.0054 lr: 0.02\n",
      "iteration: 22790 loss: 0.0079 lr: 0.02\n",
      "iteration: 22800 loss: 0.0064 lr: 0.02\n",
      "iteration: 22810 loss: 0.0068 lr: 0.02\n",
      "iteration: 22820 loss: 0.0099 lr: 0.02\n",
      "iteration: 22830 loss: 0.0069 lr: 0.02\n",
      "iteration: 22840 loss: 0.0083 lr: 0.02\n",
      "iteration: 22850 loss: 0.0086 lr: 0.02\n",
      "iteration: 22860 loss: 0.0059 lr: 0.02\n",
      "iteration: 22870 loss: 0.0073 lr: 0.02\n",
      "iteration: 22880 loss: 0.0079 lr: 0.02\n",
      "iteration: 22890 loss: 0.0069 lr: 0.02\n",
      "iteration: 22900 loss: 0.0073 lr: 0.02\n",
      "iteration: 22910 loss: 0.0073 lr: 0.02\n",
      "iteration: 22920 loss: 0.0077 lr: 0.02\n",
      "iteration: 22930 loss: 0.0074 lr: 0.02\n",
      "iteration: 22940 loss: 0.0074 lr: 0.02\n",
      "iteration: 22950 loss: 0.0081 lr: 0.02\n",
      "iteration: 22960 loss: 0.0066 lr: 0.02\n",
      "iteration: 22970 loss: 0.0068 lr: 0.02\n",
      "iteration: 22980 loss: 0.0063 lr: 0.02\n",
      "iteration: 22990 loss: 0.0073 lr: 0.02\n",
      "iteration: 23000 loss: 0.0059 lr: 0.02\n",
      "iteration: 23010 loss: 0.0071 lr: 0.02\n",
      "iteration: 23020 loss: 0.0072 lr: 0.02\n",
      "iteration: 23030 loss: 0.0062 lr: 0.02\n",
      "iteration: 23040 loss: 0.0069 lr: 0.02\n",
      "iteration: 23050 loss: 0.0065 lr: 0.02\n",
      "iteration: 23060 loss: 0.0093 lr: 0.02\n",
      "iteration: 23070 loss: 0.0099 lr: 0.02\n",
      "iteration: 23080 loss: 0.0066 lr: 0.02\n",
      "iteration: 23090 loss: 0.0091 lr: 0.02\n",
      "iteration: 23100 loss: 0.0052 lr: 0.02\n",
      "iteration: 23110 loss: 0.0077 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 23120 loss: 0.0074 lr: 0.02\n",
      "iteration: 23130 loss: 0.0070 lr: 0.02\n",
      "iteration: 23140 loss: 0.0087 lr: 0.02\n",
      "iteration: 23150 loss: 0.0093 lr: 0.02\n",
      "iteration: 23160 loss: 0.0082 lr: 0.02\n",
      "iteration: 23170 loss: 0.0080 lr: 0.02\n",
      "iteration: 23180 loss: 0.0078 lr: 0.02\n",
      "iteration: 23190 loss: 0.0070 lr: 0.02\n",
      "iteration: 23200 loss: 0.0079 lr: 0.02\n",
      "iteration: 23210 loss: 0.0070 lr: 0.02\n",
      "iteration: 23220 loss: 0.0083 lr: 0.02\n",
      "iteration: 23230 loss: 0.0069 lr: 0.02\n",
      "iteration: 23240 loss: 0.0058 lr: 0.02\n",
      "iteration: 23250 loss: 0.0070 lr: 0.02\n",
      "iteration: 23260 loss: 0.0068 lr: 0.02\n",
      "iteration: 23270 loss: 0.0105 lr: 0.02\n",
      "iteration: 23280 loss: 0.0057 lr: 0.02\n",
      "iteration: 23290 loss: 0.0070 lr: 0.02\n",
      "iteration: 23300 loss: 0.0064 lr: 0.02\n",
      "iteration: 23310 loss: 0.0069 lr: 0.02\n",
      "iteration: 23320 loss: 0.0065 lr: 0.02\n",
      "iteration: 23330 loss: 0.0075 lr: 0.02\n",
      "iteration: 23340 loss: 0.0064 lr: 0.02\n",
      "iteration: 23350 loss: 0.0066 lr: 0.02\n",
      "iteration: 23360 loss: 0.0078 lr: 0.02\n",
      "iteration: 23370 loss: 0.0066 lr: 0.02\n",
      "iteration: 23380 loss: 0.0084 lr: 0.02\n",
      "iteration: 23390 loss: 0.0065 lr: 0.02\n",
      "iteration: 23400 loss: 0.0084 lr: 0.02\n",
      "iteration: 23410 loss: 0.0076 lr: 0.02\n",
      "iteration: 23420 loss: 0.0081 lr: 0.02\n",
      "iteration: 23430 loss: 0.0069 lr: 0.02\n",
      "iteration: 23440 loss: 0.0059 lr: 0.02\n",
      "iteration: 23450 loss: 0.0067 lr: 0.02\n",
      "iteration: 23460 loss: 0.0085 lr: 0.02\n",
      "iteration: 23470 loss: 0.0067 lr: 0.02\n",
      "iteration: 23480 loss: 0.0064 lr: 0.02\n",
      "iteration: 23490 loss: 0.0073 lr: 0.02\n",
      "iteration: 23500 loss: 0.0076 lr: 0.02\n",
      "iteration: 23510 loss: 0.0080 lr: 0.02\n",
      "iteration: 23520 loss: 0.0087 lr: 0.02\n",
      "iteration: 23530 loss: 0.0072 lr: 0.02\n",
      "iteration: 23540 loss: 0.0061 lr: 0.02\n",
      "iteration: 23550 loss: 0.0074 lr: 0.02\n",
      "iteration: 23560 loss: 0.0065 lr: 0.02\n",
      "iteration: 23570 loss: 0.0074 lr: 0.02\n",
      "iteration: 23580 loss: 0.0060 lr: 0.02\n",
      "iteration: 23590 loss: 0.0061 lr: 0.02\n",
      "iteration: 23600 loss: 0.0067 lr: 0.02\n",
      "iteration: 23610 loss: 0.0074 lr: 0.02\n",
      "iteration: 23620 loss: 0.0071 lr: 0.02\n",
      "iteration: 23630 loss: 0.0070 lr: 0.02\n",
      "iteration: 23640 loss: 0.0066 lr: 0.02\n",
      "iteration: 23650 loss: 0.0080 lr: 0.02\n",
      "iteration: 23660 loss: 0.0065 lr: 0.02\n",
      "iteration: 23670 loss: 0.0066 lr: 0.02\n",
      "iteration: 23680 loss: 0.0078 lr: 0.02\n",
      "iteration: 23690 loss: 0.0081 lr: 0.02\n",
      "iteration: 23700 loss: 0.0061 lr: 0.02\n",
      "iteration: 23710 loss: 0.0082 lr: 0.02\n",
      "iteration: 23720 loss: 0.0087 lr: 0.02\n",
      "iteration: 23730 loss: 0.0055 lr: 0.02\n",
      "iteration: 23740 loss: 0.0063 lr: 0.02\n",
      "iteration: 23750 loss: 0.0064 lr: 0.02\n",
      "iteration: 23760 loss: 0.0073 lr: 0.02\n",
      "iteration: 23770 loss: 0.0078 lr: 0.02\n",
      "iteration: 23780 loss: 0.0069 lr: 0.02\n",
      "iteration: 23790 loss: 0.0076 lr: 0.02\n",
      "iteration: 23800 loss: 0.0068 lr: 0.02\n",
      "iteration: 23810 loss: 0.0075 lr: 0.02\n",
      "iteration: 23820 loss: 0.0054 lr: 0.02\n",
      "iteration: 23830 loss: 0.0076 lr: 0.02\n",
      "iteration: 23840 loss: 0.0086 lr: 0.02\n",
      "iteration: 23850 loss: 0.0071 lr: 0.02\n",
      "iteration: 23860 loss: 0.0076 lr: 0.02\n",
      "iteration: 23870 loss: 0.0070 lr: 0.02\n",
      "iteration: 23880 loss: 0.0087 lr: 0.02\n",
      "iteration: 23890 loss: 0.0056 lr: 0.02\n",
      "iteration: 23900 loss: 0.0072 lr: 0.02\n",
      "iteration: 23910 loss: 0.0074 lr: 0.02\n",
      "iteration: 23920 loss: 0.0073 lr: 0.02\n",
      "iteration: 23930 loss: 0.0090 lr: 0.02\n",
      "iteration: 23940 loss: 0.0066 lr: 0.02\n",
      "iteration: 23950 loss: 0.0051 lr: 0.02\n",
      "iteration: 23960 loss: 0.0091 lr: 0.02\n",
      "iteration: 23970 loss: 0.0061 lr: 0.02\n",
      "iteration: 23980 loss: 0.0064 lr: 0.02\n",
      "iteration: 23990 loss: 0.0067 lr: 0.02\n",
      "iteration: 24000 loss: 0.0080 lr: 0.02\n",
      "iteration: 24010 loss: 0.0066 lr: 0.02\n",
      "iteration: 24020 loss: 0.0073 lr: 0.02\n",
      "iteration: 24030 loss: 0.0065 lr: 0.02\n",
      "iteration: 24040 loss: 0.0058 lr: 0.02\n",
      "iteration: 24050 loss: 0.0070 lr: 0.02\n",
      "iteration: 24060 loss: 0.0058 lr: 0.02\n",
      "iteration: 24070 loss: 0.0051 lr: 0.02\n",
      "iteration: 24080 loss: 0.0081 lr: 0.02\n",
      "iteration: 24090 loss: 0.0071 lr: 0.02\n",
      "iteration: 24100 loss: 0.0062 lr: 0.02\n",
      "iteration: 24110 loss: 0.0061 lr: 0.02\n",
      "iteration: 24120 loss: 0.0056 lr: 0.02\n",
      "iteration: 24130 loss: 0.0073 lr: 0.02\n",
      "iteration: 24140 loss: 0.0071 lr: 0.02\n",
      "iteration: 24150 loss: 0.0055 lr: 0.02\n",
      "iteration: 24160 loss: 0.0069 lr: 0.02\n",
      "iteration: 24170 loss: 0.0070 lr: 0.02\n",
      "iteration: 24180 loss: 0.0083 lr: 0.02\n",
      "iteration: 24190 loss: 0.0073 lr: 0.02\n",
      "iteration: 24200 loss: 0.0064 lr: 0.02\n",
      "iteration: 24210 loss: 0.0079 lr: 0.02\n",
      "iteration: 24220 loss: 0.0093 lr: 0.02\n",
      "iteration: 24230 loss: 0.0067 lr: 0.02\n",
      "iteration: 24240 loss: 0.0096 lr: 0.02\n",
      "iteration: 24250 loss: 0.0083 lr: 0.02\n",
      "iteration: 24260 loss: 0.0067 lr: 0.02\n",
      "iteration: 24270 loss: 0.0067 lr: 0.02\n",
      "iteration: 24280 loss: 0.0060 lr: 0.02\n",
      "iteration: 24290 loss: 0.0058 lr: 0.02\n",
      "iteration: 24300 loss: 0.0067 lr: 0.02\n",
      "iteration: 24310 loss: 0.0072 lr: 0.02\n",
      "iteration: 24320 loss: 0.0070 lr: 0.02\n",
      "iteration: 24330 loss: 0.0057 lr: 0.02\n",
      "iteration: 24340 loss: 0.0071 lr: 0.02\n",
      "iteration: 24350 loss: 0.0074 lr: 0.02\n",
      "iteration: 24360 loss: 0.0061 lr: 0.02\n",
      "iteration: 24370 loss: 0.0072 lr: 0.02\n",
      "iteration: 24380 loss: 0.0063 lr: 0.02\n",
      "iteration: 24390 loss: 0.0077 lr: 0.02\n",
      "iteration: 24400 loss: 0.0081 lr: 0.02\n",
      "iteration: 24410 loss: 0.0071 lr: 0.02\n",
      "iteration: 24420 loss: 0.0056 lr: 0.02\n",
      "iteration: 24430 loss: 0.0071 lr: 0.02\n",
      "iteration: 24440 loss: 0.0072 lr: 0.02\n",
      "iteration: 24450 loss: 0.0056 lr: 0.02\n",
      "iteration: 24460 loss: 0.0069 lr: 0.02\n",
      "iteration: 24470 loss: 0.0061 lr: 0.02\n",
      "iteration: 24480 loss: 0.0058 lr: 0.02\n",
      "iteration: 24490 loss: 0.0075 lr: 0.02\n",
      "iteration: 24500 loss: 0.0076 lr: 0.02\n",
      "iteration: 24510 loss: 0.0085 lr: 0.02\n",
      "iteration: 24520 loss: 0.0076 lr: 0.02\n",
      "iteration: 24530 loss: 0.0068 lr: 0.02\n",
      "iteration: 24540 loss: 0.0072 lr: 0.02\n",
      "iteration: 24550 loss: 0.0067 lr: 0.02\n",
      "iteration: 24560 loss: 0.0064 lr: 0.02\n",
      "iteration: 24570 loss: 0.0084 lr: 0.02\n",
      "iteration: 24580 loss: 0.0071 lr: 0.02\n",
      "iteration: 24590 loss: 0.0061 lr: 0.02\n",
      "iteration: 24600 loss: 0.0067 lr: 0.02\n",
      "iteration: 24610 loss: 0.0073 lr: 0.02\n",
      "iteration: 24620 loss: 0.0069 lr: 0.02\n",
      "iteration: 24630 loss: 0.0061 lr: 0.02\n",
      "iteration: 24640 loss: 0.0080 lr: 0.02\n",
      "iteration: 24650 loss: 0.0064 lr: 0.02\n",
      "iteration: 24660 loss: 0.0073 lr: 0.02\n",
      "iteration: 24670 loss: 0.0065 lr: 0.02\n",
      "iteration: 24680 loss: 0.0072 lr: 0.02\n",
      "iteration: 24690 loss: 0.0067 lr: 0.02\n",
      "iteration: 24700 loss: 0.0055 lr: 0.02\n",
      "iteration: 24710 loss: 0.0072 lr: 0.02\n",
      "iteration: 24720 loss: 0.0072 lr: 0.02\n",
      "iteration: 24730 loss: 0.0060 lr: 0.02\n",
      "iteration: 24740 loss: 0.0061 lr: 0.02\n",
      "iteration: 24750 loss: 0.0064 lr: 0.02\n",
      "iteration: 24760 loss: 0.0065 lr: 0.02\n",
      "iteration: 24770 loss: 0.0072 lr: 0.02\n",
      "iteration: 24780 loss: 0.0060 lr: 0.02\n",
      "iteration: 24790 loss: 0.0063 lr: 0.02\n",
      "iteration: 24800 loss: 0.0056 lr: 0.02\n",
      "iteration: 24810 loss: 0.0078 lr: 0.02\n",
      "iteration: 24820 loss: 0.0059 lr: 0.02\n",
      "iteration: 24830 loss: 0.0084 lr: 0.02\n",
      "iteration: 24840 loss: 0.0074 lr: 0.02\n",
      "iteration: 24850 loss: 0.0067 lr: 0.02\n",
      "iteration: 24860 loss: 0.0084 lr: 0.02\n",
      "iteration: 24870 loss: 0.0066 lr: 0.02\n",
      "iteration: 24880 loss: 0.0068 lr: 0.02\n",
      "iteration: 24890 loss: 0.0065 lr: 0.02\n",
      "iteration: 24900 loss: 0.0064 lr: 0.02\n",
      "iteration: 24910 loss: 0.0064 lr: 0.02\n",
      "iteration: 24920 loss: 0.0058 lr: 0.02\n",
      "iteration: 24930 loss: 0.0063 lr: 0.02\n",
      "iteration: 24940 loss: 0.0059 lr: 0.02\n",
      "iteration: 24950 loss: 0.0066 lr: 0.02\n",
      "iteration: 24960 loss: 0.0069 lr: 0.02\n",
      "iteration: 24970 loss: 0.0066 lr: 0.02\n",
      "iteration: 24980 loss: 0.0066 lr: 0.02\n",
      "iteration: 24990 loss: 0.0068 lr: 0.02\n",
      "iteration: 25000 loss: 0.0058 lr: 0.02\n",
      "iteration: 25010 loss: 0.0050 lr: 0.02\n",
      "iteration: 25020 loss: 0.0069 lr: 0.02\n",
      "iteration: 25030 loss: 0.0052 lr: 0.02\n",
      "iteration: 25040 loss: 0.0068 lr: 0.02\n",
      "iteration: 25050 loss: 0.0070 lr: 0.02\n",
      "iteration: 25060 loss: 0.0061 lr: 0.02\n",
      "iteration: 25070 loss: 0.0082 lr: 0.02\n",
      "iteration: 25080 loss: 0.0066 lr: 0.02\n",
      "iteration: 25090 loss: 0.0078 lr: 0.02\n",
      "iteration: 25100 loss: 0.0064 lr: 0.02\n",
      "iteration: 25110 loss: 0.0068 lr: 0.02\n",
      "iteration: 25120 loss: 0.0050 lr: 0.02\n",
      "iteration: 25130 loss: 0.0066 lr: 0.02\n",
      "iteration: 25140 loss: 0.0058 lr: 0.02\n",
      "iteration: 25150 loss: 0.0069 lr: 0.02\n",
      "iteration: 25160 loss: 0.0053 lr: 0.02\n",
      "iteration: 25170 loss: 0.0051 lr: 0.02\n",
      "iteration: 25180 loss: 0.0056 lr: 0.02\n",
      "iteration: 25190 loss: 0.0075 lr: 0.02\n",
      "iteration: 25200 loss: 0.0061 lr: 0.02\n",
      "iteration: 25210 loss: 0.0066 lr: 0.02\n",
      "iteration: 25220 loss: 0.0058 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 25230 loss: 0.0065 lr: 0.02\n",
      "iteration: 25240 loss: 0.0066 lr: 0.02\n",
      "iteration: 25250 loss: 0.0062 lr: 0.02\n",
      "iteration: 25260 loss: 0.0064 lr: 0.02\n",
      "iteration: 25270 loss: 0.0115 lr: 0.02\n",
      "iteration: 25280 loss: 0.0064 lr: 0.02\n",
      "iteration: 25290 loss: 0.0069 lr: 0.02\n",
      "iteration: 25300 loss: 0.0060 lr: 0.02\n",
      "iteration: 25310 loss: 0.0060 lr: 0.02\n",
      "iteration: 25320 loss: 0.0061 lr: 0.02\n",
      "iteration: 25330 loss: 0.0075 lr: 0.02\n",
      "iteration: 25340 loss: 0.0085 lr: 0.02\n",
      "iteration: 25350 loss: 0.0065 lr: 0.02\n",
      "iteration: 25360 loss: 0.0051 lr: 0.02\n",
      "iteration: 25370 loss: 0.0058 lr: 0.02\n",
      "iteration: 25380 loss: 0.0078 lr: 0.02\n",
      "iteration: 25390 loss: 0.0058 lr: 0.02\n",
      "iteration: 25400 loss: 0.0076 lr: 0.02\n",
      "iteration: 25410 loss: 0.0065 lr: 0.02\n",
      "iteration: 25420 loss: 0.0061 lr: 0.02\n",
      "iteration: 25430 loss: 0.0076 lr: 0.02\n",
      "iteration: 25440 loss: 0.0062 lr: 0.02\n",
      "iteration: 25450 loss: 0.0061 lr: 0.02\n",
      "iteration: 25460 loss: 0.0069 lr: 0.02\n",
      "iteration: 25470 loss: 0.0062 lr: 0.02\n",
      "iteration: 25480 loss: 0.0060 lr: 0.02\n",
      "iteration: 25490 loss: 0.0073 lr: 0.02\n",
      "iteration: 25500 loss: 0.0060 lr: 0.02\n",
      "iteration: 25510 loss: 0.0063 lr: 0.02\n",
      "iteration: 25520 loss: 0.0060 lr: 0.02\n",
      "iteration: 25530 loss: 0.0059 lr: 0.02\n",
      "iteration: 25540 loss: 0.0069 lr: 0.02\n",
      "iteration: 25550 loss: 0.0063 lr: 0.02\n",
      "iteration: 25560 loss: 0.0060 lr: 0.02\n",
      "iteration: 25570 loss: 0.0068 lr: 0.02\n",
      "iteration: 25580 loss: 0.0077 lr: 0.02\n",
      "iteration: 25590 loss: 0.0070 lr: 0.02\n",
      "iteration: 25600 loss: 0.0063 lr: 0.02\n",
      "iteration: 25610 loss: 0.0078 lr: 0.02\n",
      "iteration: 25620 loss: 0.0062 lr: 0.02\n",
      "iteration: 25630 loss: 0.0058 lr: 0.02\n",
      "iteration: 25640 loss: 0.0062 lr: 0.02\n",
      "iteration: 25650 loss: 0.0065 lr: 0.02\n",
      "iteration: 25660 loss: 0.0077 lr: 0.02\n",
      "iteration: 25670 loss: 0.0059 lr: 0.02\n",
      "iteration: 25680 loss: 0.0064 lr: 0.02\n",
      "iteration: 25690 loss: 0.0075 lr: 0.02\n",
      "iteration: 25700 loss: 0.0070 lr: 0.02\n",
      "iteration: 25710 loss: 0.0059 lr: 0.02\n",
      "iteration: 25720 loss: 0.0075 lr: 0.02\n",
      "iteration: 25730 loss: 0.0066 lr: 0.02\n",
      "iteration: 25740 loss: 0.0081 lr: 0.02\n",
      "iteration: 25750 loss: 0.0077 lr: 0.02\n",
      "iteration: 25760 loss: 0.0070 lr: 0.02\n",
      "iteration: 25770 loss: 0.0065 lr: 0.02\n",
      "iteration: 25780 loss: 0.0068 lr: 0.02\n",
      "iteration: 25790 loss: 0.0057 lr: 0.02\n",
      "iteration: 25800 loss: 0.0064 lr: 0.02\n",
      "iteration: 25810 loss: 0.0058 lr: 0.02\n",
      "iteration: 25820 loss: 0.0085 lr: 0.02\n",
      "iteration: 25830 loss: 0.0072 lr: 0.02\n",
      "iteration: 25840 loss: 0.0066 lr: 0.02\n",
      "iteration: 25850 loss: 0.0057 lr: 0.02\n",
      "iteration: 25860 loss: 0.0055 lr: 0.02\n",
      "iteration: 25870 loss: 0.0054 lr: 0.02\n",
      "iteration: 25880 loss: 0.0060 lr: 0.02\n",
      "iteration: 25890 loss: 0.0079 lr: 0.02\n",
      "iteration: 25900 loss: 0.0056 lr: 0.02\n",
      "iteration: 25910 loss: 0.0063 lr: 0.02\n",
      "iteration: 25920 loss: 0.0067 lr: 0.02\n",
      "iteration: 25930 loss: 0.0070 lr: 0.02\n",
      "iteration: 25940 loss: 0.0059 lr: 0.02\n",
      "iteration: 25950 loss: 0.0060 lr: 0.02\n",
      "iteration: 25960 loss: 0.0059 lr: 0.02\n",
      "iteration: 25970 loss: 0.0051 lr: 0.02\n",
      "iteration: 25980 loss: 0.0058 lr: 0.02\n",
      "iteration: 25990 loss: 0.0081 lr: 0.02\n",
      "iteration: 26000 loss: 0.0065 lr: 0.02\n",
      "iteration: 26010 loss: 0.0070 lr: 0.02\n",
      "iteration: 26020 loss: 0.0064 lr: 0.02\n",
      "iteration: 26030 loss: 0.0049 lr: 0.02\n",
      "iteration: 26040 loss: 0.0052 lr: 0.02\n",
      "iteration: 26050 loss: 0.0073 lr: 0.02\n",
      "iteration: 26060 loss: 0.0081 lr: 0.02\n",
      "iteration: 26070 loss: 0.0066 lr: 0.02\n",
      "iteration: 26080 loss: 0.0067 lr: 0.02\n",
      "iteration: 26090 loss: 0.0082 lr: 0.02\n",
      "iteration: 26100 loss: 0.0063 lr: 0.02\n",
      "iteration: 26110 loss: 0.0065 lr: 0.02\n",
      "iteration: 26120 loss: 0.0055 lr: 0.02\n",
      "iteration: 26130 loss: 0.0076 lr: 0.02\n",
      "iteration: 26140 loss: 0.0062 lr: 0.02\n",
      "iteration: 26150 loss: 0.0059 lr: 0.02\n",
      "iteration: 26160 loss: 0.0061 lr: 0.02\n",
      "iteration: 26170 loss: 0.0071 lr: 0.02\n",
      "iteration: 26180 loss: 0.0073 lr: 0.02\n",
      "iteration: 26190 loss: 0.0064 lr: 0.02\n",
      "iteration: 26200 loss: 0.0065 lr: 0.02\n",
      "iteration: 26210 loss: 0.0063 lr: 0.02\n",
      "iteration: 26220 loss: 0.0050 lr: 0.02\n",
      "iteration: 26230 loss: 0.0078 lr: 0.02\n",
      "iteration: 26240 loss: 0.0061 lr: 0.02\n",
      "iteration: 26250 loss: 0.0062 lr: 0.02\n",
      "iteration: 26260 loss: 0.0060 lr: 0.02\n",
      "iteration: 26270 loss: 0.0058 lr: 0.02\n",
      "iteration: 26280 loss: 0.0093 lr: 0.02\n",
      "iteration: 26290 loss: 0.0060 lr: 0.02\n",
      "iteration: 26300 loss: 0.0052 lr: 0.02\n",
      "iteration: 26310 loss: 0.0055 lr: 0.02\n",
      "iteration: 26320 loss: 0.0067 lr: 0.02\n",
      "iteration: 26330 loss: 0.0060 lr: 0.02\n",
      "iteration: 26340 loss: 0.0049 lr: 0.02\n",
      "iteration: 26350 loss: 0.0060 lr: 0.02\n",
      "iteration: 26360 loss: 0.0050 lr: 0.02\n",
      "iteration: 26370 loss: 0.0077 lr: 0.02\n",
      "iteration: 26380 loss: 0.0087 lr: 0.02\n",
      "iteration: 26390 loss: 0.0060 lr: 0.02\n",
      "iteration: 26400 loss: 0.0060 lr: 0.02\n",
      "iteration: 26410 loss: 0.0058 lr: 0.02\n",
      "iteration: 26420 loss: 0.0064 lr: 0.02\n",
      "iteration: 26430 loss: 0.0072 lr: 0.02\n",
      "iteration: 26440 loss: 0.0051 lr: 0.02\n",
      "iteration: 26450 loss: 0.0062 lr: 0.02\n",
      "iteration: 26460 loss: 0.0062 lr: 0.02\n",
      "iteration: 26470 loss: 0.0066 lr: 0.02\n",
      "iteration: 26480 loss: 0.0063 lr: 0.02\n",
      "iteration: 26490 loss: 0.0063 lr: 0.02\n",
      "iteration: 26500 loss: 0.0052 lr: 0.02\n",
      "iteration: 26510 loss: 0.0061 lr: 0.02\n",
      "iteration: 26520 loss: 0.0058 lr: 0.02\n",
      "iteration: 26530 loss: 0.0066 lr: 0.02\n",
      "iteration: 26540 loss: 0.0073 lr: 0.02\n",
      "iteration: 26550 loss: 0.0061 lr: 0.02\n",
      "iteration: 26560 loss: 0.0067 lr: 0.02\n",
      "iteration: 26570 loss: 0.0059 lr: 0.02\n",
      "iteration: 26580 loss: 0.0069 lr: 0.02\n",
      "iteration: 26590 loss: 0.0056 lr: 0.02\n",
      "iteration: 26600 loss: 0.0066 lr: 0.02\n",
      "iteration: 26610 loss: 0.0054 lr: 0.02\n",
      "iteration: 26620 loss: 0.0063 lr: 0.02\n",
      "iteration: 26630 loss: 0.0060 lr: 0.02\n",
      "iteration: 26640 loss: 0.0062 lr: 0.02\n",
      "iteration: 26650 loss: 0.0073 lr: 0.02\n",
      "iteration: 26660 loss: 0.0059 lr: 0.02\n",
      "iteration: 26670 loss: 0.0063 lr: 0.02\n",
      "iteration: 26680 loss: 0.0059 lr: 0.02\n",
      "iteration: 26690 loss: 0.0068 lr: 0.02\n",
      "iteration: 26700 loss: 0.0050 lr: 0.02\n",
      "iteration: 26710 loss: 0.0068 lr: 0.02\n",
      "iteration: 26720 loss: 0.0060 lr: 0.02\n",
      "iteration: 26730 loss: 0.0064 lr: 0.02\n",
      "iteration: 26740 loss: 0.0062 lr: 0.02\n",
      "iteration: 26750 loss: 0.0053 lr: 0.02\n",
      "iteration: 26760 loss: 0.0056 lr: 0.02\n",
      "iteration: 26770 loss: 0.0054 lr: 0.02\n",
      "iteration: 26780 loss: 0.0066 lr: 0.02\n",
      "iteration: 26790 loss: 0.0069 lr: 0.02\n",
      "iteration: 26800 loss: 0.0067 lr: 0.02\n",
      "iteration: 26810 loss: 0.0072 lr: 0.02\n",
      "iteration: 26820 loss: 0.0064 lr: 0.02\n",
      "iteration: 26830 loss: 0.0045 lr: 0.02\n",
      "iteration: 26840 loss: 0.0058 lr: 0.02\n",
      "iteration: 26850 loss: 0.0075 lr: 0.02\n",
      "iteration: 26860 loss: 0.0075 lr: 0.02\n",
      "iteration: 26870 loss: 0.0073 lr: 0.02\n",
      "iteration: 26880 loss: 0.0071 lr: 0.02\n",
      "iteration: 26890 loss: 0.0058 lr: 0.02\n",
      "iteration: 26900 loss: 0.0058 lr: 0.02\n",
      "iteration: 26910 loss: 0.0059 lr: 0.02\n",
      "iteration: 26920 loss: 0.0074 lr: 0.02\n",
      "iteration: 26930 loss: 0.0074 lr: 0.02\n",
      "iteration: 26940 loss: 0.0057 lr: 0.02\n",
      "iteration: 26950 loss: 0.0045 lr: 0.02\n",
      "iteration: 26960 loss: 0.0063 lr: 0.02\n",
      "iteration: 26970 loss: 0.0065 lr: 0.02\n",
      "iteration: 26980 loss: 0.0060 lr: 0.02\n",
      "iteration: 26990 loss: 0.0058 lr: 0.02\n",
      "iteration: 27000 loss: 0.0076 lr: 0.02\n",
      "iteration: 27010 loss: 0.0054 lr: 0.02\n",
      "iteration: 27020 loss: 0.0062 lr: 0.02\n",
      "iteration: 27030 loss: 0.0070 lr: 0.02\n",
      "iteration: 27040 loss: 0.0049 lr: 0.02\n",
      "iteration: 27050 loss: 0.0072 lr: 0.02\n",
      "iteration: 27060 loss: 0.0079 lr: 0.02\n",
      "iteration: 27070 loss: 0.0064 lr: 0.02\n",
      "iteration: 27080 loss: 0.0070 lr: 0.02\n",
      "iteration: 27090 loss: 0.0048 lr: 0.02\n",
      "iteration: 27100 loss: 0.0059 lr: 0.02\n",
      "iteration: 27110 loss: 0.0066 lr: 0.02\n",
      "iteration: 27120 loss: 0.0056 lr: 0.02\n",
      "iteration: 27130 loss: 0.0071 lr: 0.02\n",
      "iteration: 27140 loss: 0.0050 lr: 0.02\n",
      "iteration: 27150 loss: 0.0076 lr: 0.02\n",
      "iteration: 27160 loss: 0.0066 lr: 0.02\n",
      "iteration: 27170 loss: 0.0080 lr: 0.02\n",
      "iteration: 27180 loss: 0.0053 lr: 0.02\n",
      "iteration: 27190 loss: 0.0064 lr: 0.02\n",
      "iteration: 27200 loss: 0.0063 lr: 0.02\n",
      "iteration: 27210 loss: 0.0067 lr: 0.02\n",
      "iteration: 27220 loss: 0.0074 lr: 0.02\n",
      "iteration: 27230 loss: 0.0064 lr: 0.02\n",
      "iteration: 27240 loss: 0.0082 lr: 0.02\n",
      "iteration: 27250 loss: 0.0065 lr: 0.02\n",
      "iteration: 27260 loss: 0.0071 lr: 0.02\n",
      "iteration: 27270 loss: 0.0060 lr: 0.02\n",
      "iteration: 27280 loss: 0.0053 lr: 0.02\n",
      "iteration: 27290 loss: 0.0071 lr: 0.02\n",
      "iteration: 27300 loss: 0.0060 lr: 0.02\n",
      "iteration: 27310 loss: 0.0063 lr: 0.02\n",
      "iteration: 27320 loss: 0.0067 lr: 0.02\n",
      "iteration: 27330 loss: 0.0064 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 27340 loss: 0.0062 lr: 0.02\n",
      "iteration: 27350 loss: 0.0063 lr: 0.02\n",
      "iteration: 27360 loss: 0.0075 lr: 0.02\n",
      "iteration: 27370 loss: 0.0060 lr: 0.02\n",
      "iteration: 27380 loss: 0.0068 lr: 0.02\n",
      "iteration: 27390 loss: 0.0066 lr: 0.02\n",
      "iteration: 27400 loss: 0.0062 lr: 0.02\n",
      "iteration: 27410 loss: 0.0055 lr: 0.02\n",
      "iteration: 27420 loss: 0.0076 lr: 0.02\n",
      "iteration: 27430 loss: 0.0056 lr: 0.02\n",
      "iteration: 27440 loss: 0.0048 lr: 0.02\n",
      "iteration: 27450 loss: 0.0062 lr: 0.02\n",
      "iteration: 27460 loss: 0.0044 lr: 0.02\n",
      "iteration: 27470 loss: 0.0053 lr: 0.02\n",
      "iteration: 27480 loss: 0.0058 lr: 0.02\n",
      "iteration: 27490 loss: 0.0047 lr: 0.02\n",
      "iteration: 27500 loss: 0.0058 lr: 0.02\n",
      "iteration: 27510 loss: 0.0071 lr: 0.02\n",
      "iteration: 27520 loss: 0.0054 lr: 0.02\n",
      "iteration: 27530 loss: 0.0074 lr: 0.02\n",
      "iteration: 27540 loss: 0.0066 lr: 0.02\n",
      "iteration: 27550 loss: 0.0062 lr: 0.02\n",
      "iteration: 27560 loss: 0.0063 lr: 0.02\n",
      "iteration: 27570 loss: 0.0061 lr: 0.02\n",
      "iteration: 27580 loss: 0.0048 lr: 0.02\n",
      "iteration: 27590 loss: 0.0076 lr: 0.02\n",
      "iteration: 27600 loss: 0.0071 lr: 0.02\n",
      "iteration: 27610 loss: 0.0068 lr: 0.02\n",
      "iteration: 27620 loss: 0.0071 lr: 0.02\n",
      "iteration: 27630 loss: 0.0056 lr: 0.02\n",
      "iteration: 27640 loss: 0.0062 lr: 0.02\n",
      "iteration: 27650 loss: 0.0052 lr: 0.02\n",
      "iteration: 27660 loss: 0.0073 lr: 0.02\n",
      "iteration: 27670 loss: 0.0058 lr: 0.02\n",
      "iteration: 27680 loss: 0.0070 lr: 0.02\n",
      "iteration: 27690 loss: 0.0078 lr: 0.02\n",
      "iteration: 27700 loss: 0.0058 lr: 0.02\n",
      "iteration: 27710 loss: 0.0064 lr: 0.02\n",
      "iteration: 27720 loss: 0.0060 lr: 0.02\n",
      "iteration: 27730 loss: 0.0076 lr: 0.02\n",
      "iteration: 27740 loss: 0.0059 lr: 0.02\n",
      "iteration: 27750 loss: 0.0075 lr: 0.02\n",
      "iteration: 27760 loss: 0.0063 lr: 0.02\n",
      "iteration: 27770 loss: 0.0053 lr: 0.02\n",
      "iteration: 27780 loss: 0.0066 lr: 0.02\n",
      "iteration: 27790 loss: 0.0058 lr: 0.02\n",
      "iteration: 27800 loss: 0.0050 lr: 0.02\n",
      "iteration: 27810 loss: 0.0058 lr: 0.02\n",
      "iteration: 27820 loss: 0.0062 lr: 0.02\n",
      "iteration: 27830 loss: 0.0085 lr: 0.02\n",
      "iteration: 27840 loss: 0.0079 lr: 0.02\n",
      "iteration: 27850 loss: 0.0055 lr: 0.02\n",
      "iteration: 27860 loss: 0.0054 lr: 0.02\n",
      "iteration: 27870 loss: 0.0057 lr: 0.02\n",
      "iteration: 27880 loss: 0.0054 lr: 0.02\n",
      "iteration: 27890 loss: 0.0060 lr: 0.02\n",
      "iteration: 27900 loss: 0.0054 lr: 0.02\n",
      "iteration: 27910 loss: 0.0063 lr: 0.02\n",
      "iteration: 27920 loss: 0.0065 lr: 0.02\n",
      "iteration: 27930 loss: 0.0061 lr: 0.02\n",
      "iteration: 27940 loss: 0.0066 lr: 0.02\n",
      "iteration: 27950 loss: 0.0042 lr: 0.02\n",
      "iteration: 27960 loss: 0.0071 lr: 0.02\n",
      "iteration: 27970 loss: 0.0074 lr: 0.02\n",
      "iteration: 27980 loss: 0.0049 lr: 0.02\n",
      "iteration: 27990 loss: 0.0059 lr: 0.02\n",
      "iteration: 28000 loss: 0.0054 lr: 0.02\n",
      "iteration: 28010 loss: 0.0060 lr: 0.02\n",
      "iteration: 28020 loss: 0.0054 lr: 0.02\n",
      "iteration: 28030 loss: 0.0055 lr: 0.02\n",
      "iteration: 28040 loss: 0.0044 lr: 0.02\n",
      "iteration: 28050 loss: 0.0066 lr: 0.02\n",
      "iteration: 28060 loss: 0.0058 lr: 0.02\n",
      "iteration: 28070 loss: 0.0071 lr: 0.02\n",
      "iteration: 28080 loss: 0.0048 lr: 0.02\n",
      "iteration: 28090 loss: 0.0056 lr: 0.02\n",
      "iteration: 28100 loss: 0.0066 lr: 0.02\n",
      "iteration: 28110 loss: 0.0087 lr: 0.02\n",
      "iteration: 28120 loss: 0.0057 lr: 0.02\n",
      "iteration: 28130 loss: 0.0061 lr: 0.02\n",
      "iteration: 28140 loss: 0.0070 lr: 0.02\n",
      "iteration: 28150 loss: 0.0075 lr: 0.02\n",
      "iteration: 28160 loss: 0.0082 lr: 0.02\n",
      "iteration: 28170 loss: 0.0053 lr: 0.02\n",
      "iteration: 28180 loss: 0.0068 lr: 0.02\n",
      "iteration: 28190 loss: 0.0072 lr: 0.02\n",
      "iteration: 28200 loss: 0.0056 lr: 0.02\n",
      "iteration: 28210 loss: 0.0062 lr: 0.02\n",
      "iteration: 28220 loss: 0.0050 lr: 0.02\n",
      "iteration: 28230 loss: 0.0063 lr: 0.02\n",
      "iteration: 28240 loss: 0.0047 lr: 0.02\n",
      "iteration: 28250 loss: 0.0071 lr: 0.02\n",
      "iteration: 28260 loss: 0.0059 lr: 0.02\n",
      "iteration: 28270 loss: 0.0055 lr: 0.02\n",
      "iteration: 28280 loss: 0.0061 lr: 0.02\n",
      "iteration: 28290 loss: 0.0062 lr: 0.02\n",
      "iteration: 28300 loss: 0.0067 lr: 0.02\n",
      "iteration: 28310 loss: 0.0071 lr: 0.02\n",
      "iteration: 28320 loss: 0.0055 lr: 0.02\n",
      "iteration: 28330 loss: 0.0074 lr: 0.02\n",
      "iteration: 28340 loss: 0.0071 lr: 0.02\n",
      "iteration: 28350 loss: 0.0059 lr: 0.02\n",
      "iteration: 28360 loss: 0.0068 lr: 0.02\n",
      "iteration: 28370 loss: 0.0070 lr: 0.02\n",
      "iteration: 28380 loss: 0.0078 lr: 0.02\n",
      "iteration: 28390 loss: 0.0063 lr: 0.02\n",
      "iteration: 28400 loss: 0.0060 lr: 0.02\n",
      "iteration: 28410 loss: 0.0061 lr: 0.02\n",
      "iteration: 28420 loss: 0.0061 lr: 0.02\n",
      "iteration: 28430 loss: 0.0050 lr: 0.02\n",
      "iteration: 28440 loss: 0.0063 lr: 0.02\n",
      "iteration: 28450 loss: 0.0075 lr: 0.02\n",
      "iteration: 28460 loss: 0.0056 lr: 0.02\n",
      "iteration: 28470 loss: 0.0053 lr: 0.02\n",
      "iteration: 28480 loss: 0.0063 lr: 0.02\n",
      "iteration: 28490 loss: 0.0067 lr: 0.02\n",
      "iteration: 28500 loss: 0.0064 lr: 0.02\n",
      "iteration: 28510 loss: 0.0056 lr: 0.02\n",
      "iteration: 28520 loss: 0.0053 lr: 0.02\n",
      "iteration: 28530 loss: 0.0048 lr: 0.02\n",
      "iteration: 28540 loss: 0.0055 lr: 0.02\n",
      "iteration: 28550 loss: 0.0067 lr: 0.02\n",
      "iteration: 28560 loss: 0.0061 lr: 0.02\n",
      "iteration: 28570 loss: 0.0060 lr: 0.02\n",
      "iteration: 28580 loss: 0.0038 lr: 0.02\n",
      "iteration: 28590 loss: 0.0073 lr: 0.02\n",
      "iteration: 28600 loss: 0.0058 lr: 0.02\n",
      "iteration: 28610 loss: 0.0061 lr: 0.02\n",
      "iteration: 28620 loss: 0.0066 lr: 0.02\n",
      "iteration: 28630 loss: 0.0059 lr: 0.02\n",
      "iteration: 28640 loss: 0.0060 lr: 0.02\n",
      "iteration: 28650 loss: 0.0071 lr: 0.02\n",
      "iteration: 28660 loss: 0.0061 lr: 0.02\n",
      "iteration: 28670 loss: 0.0076 lr: 0.02\n",
      "iteration: 28680 loss: 0.0061 lr: 0.02\n",
      "iteration: 28690 loss: 0.0059 lr: 0.02\n",
      "iteration: 28700 loss: 0.0053 lr: 0.02\n",
      "iteration: 28710 loss: 0.0066 lr: 0.02\n",
      "iteration: 28720 loss: 0.0066 lr: 0.02\n",
      "iteration: 28730 loss: 0.0078 lr: 0.02\n",
      "iteration: 28740 loss: 0.0059 lr: 0.02\n",
      "iteration: 28750 loss: 0.0073 lr: 0.02\n",
      "iteration: 28760 loss: 0.0069 lr: 0.02\n",
      "iteration: 28770 loss: 0.0076 lr: 0.02\n",
      "iteration: 28780 loss: 0.0061 lr: 0.02\n",
      "iteration: 28790 loss: 0.0062 lr: 0.02\n",
      "iteration: 28800 loss: 0.0053 lr: 0.02\n",
      "iteration: 28810 loss: 0.0079 lr: 0.02\n",
      "iteration: 28820 loss: 0.0054 lr: 0.02\n",
      "iteration: 28830 loss: 0.0052 lr: 0.02\n",
      "iteration: 28840 loss: 0.0068 lr: 0.02\n",
      "iteration: 28850 loss: 0.0063 lr: 0.02\n",
      "iteration: 28860 loss: 0.0055 lr: 0.02\n",
      "iteration: 28870 loss: 0.0060 lr: 0.02\n",
      "iteration: 28880 loss: 0.0054 lr: 0.02\n",
      "iteration: 28890 loss: 0.0054 lr: 0.02\n",
      "iteration: 28900 loss: 0.0073 lr: 0.02\n",
      "iteration: 28910 loss: 0.0050 lr: 0.02\n",
      "iteration: 28920 loss: 0.0048 lr: 0.02\n",
      "iteration: 28930 loss: 0.0062 lr: 0.02\n",
      "iteration: 28940 loss: 0.0069 lr: 0.02\n",
      "iteration: 28950 loss: 0.0059 lr: 0.02\n",
      "iteration: 28960 loss: 0.0064 lr: 0.02\n",
      "iteration: 28970 loss: 0.0049 lr: 0.02\n",
      "iteration: 28980 loss: 0.0087 lr: 0.02\n",
      "iteration: 28990 loss: 0.0056 lr: 0.02\n",
      "iteration: 29000 loss: 0.0053 lr: 0.02\n",
      "iteration: 29010 loss: 0.0062 lr: 0.02\n",
      "iteration: 29020 loss: 0.0057 lr: 0.02\n",
      "iteration: 29030 loss: 0.0063 lr: 0.02\n",
      "iteration: 29040 loss: 0.0073 lr: 0.02\n",
      "iteration: 29050 loss: 0.0053 lr: 0.02\n",
      "iteration: 29060 loss: 0.0064 lr: 0.02\n",
      "iteration: 29070 loss: 0.0047 lr: 0.02\n",
      "iteration: 29080 loss: 0.0054 lr: 0.02\n",
      "iteration: 29090 loss: 0.0055 lr: 0.02\n",
      "iteration: 29100 loss: 0.0051 lr: 0.02\n",
      "iteration: 29110 loss: 0.0056 lr: 0.02\n",
      "iteration: 29120 loss: 0.0074 lr: 0.02\n",
      "iteration: 29130 loss: 0.0058 lr: 0.02\n",
      "iteration: 29140 loss: 0.0040 lr: 0.02\n",
      "iteration: 29150 loss: 0.0065 lr: 0.02\n",
      "iteration: 29160 loss: 0.0053 lr: 0.02\n",
      "iteration: 29170 loss: 0.0064 lr: 0.02\n",
      "iteration: 29180 loss: 0.0059 lr: 0.02\n",
      "iteration: 29190 loss: 0.0068 lr: 0.02\n",
      "iteration: 29200 loss: 0.0067 lr: 0.02\n",
      "iteration: 29210 loss: 0.0069 lr: 0.02\n",
      "iteration: 29220 loss: 0.0064 lr: 0.02\n",
      "iteration: 29230 loss: 0.0055 lr: 0.02\n",
      "iteration: 29240 loss: 0.0047 lr: 0.02\n",
      "iteration: 29250 loss: 0.0048 lr: 0.02\n",
      "iteration: 29260 loss: 0.0065 lr: 0.02\n",
      "iteration: 29270 loss: 0.0051 lr: 0.02\n",
      "iteration: 29280 loss: 0.0061 lr: 0.02\n",
      "iteration: 29290 loss: 0.0054 lr: 0.02\n",
      "iteration: 29300 loss: 0.0068 lr: 0.02\n",
      "iteration: 29310 loss: 0.0070 lr: 0.02\n",
      "iteration: 29320 loss: 0.0051 lr: 0.02\n",
      "iteration: 29330 loss: 0.0060 lr: 0.02\n",
      "iteration: 29340 loss: 0.0057 lr: 0.02\n",
      "iteration: 29350 loss: 0.0067 lr: 0.02\n",
      "iteration: 29360 loss: 0.0066 lr: 0.02\n",
      "iteration: 29370 loss: 0.0056 lr: 0.02\n",
      "iteration: 29380 loss: 0.0060 lr: 0.02\n",
      "iteration: 29390 loss: 0.0054 lr: 0.02\n",
      "iteration: 29400 loss: 0.0077 lr: 0.02\n",
      "iteration: 29410 loss: 0.0052 lr: 0.02\n",
      "iteration: 29420 loss: 0.0061 lr: 0.02\n",
      "iteration: 29430 loss: 0.0070 lr: 0.02\n",
      "iteration: 29440 loss: 0.0047 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 29450 loss: 0.0057 lr: 0.02\n",
      "iteration: 29460 loss: 0.0051 lr: 0.02\n",
      "iteration: 29470 loss: 0.0069 lr: 0.02\n",
      "iteration: 29480 loss: 0.0051 lr: 0.02\n",
      "iteration: 29490 loss: 0.0066 lr: 0.02\n",
      "iteration: 29500 loss: 0.0055 lr: 0.02\n",
      "iteration: 29510 loss: 0.0065 lr: 0.02\n",
      "iteration: 29520 loss: 0.0069 lr: 0.02\n",
      "iteration: 29530 loss: 0.0065 lr: 0.02\n",
      "iteration: 29540 loss: 0.0069 lr: 0.02\n",
      "iteration: 29550 loss: 0.0057 lr: 0.02\n",
      "iteration: 29560 loss: 0.0053 lr: 0.02\n",
      "iteration: 29570 loss: 0.0060 lr: 0.02\n",
      "iteration: 29580 loss: 0.0059 lr: 0.02\n",
      "iteration: 29590 loss: 0.0064 lr: 0.02\n",
      "iteration: 29600 loss: 0.0051 lr: 0.02\n",
      "iteration: 29610 loss: 0.0056 lr: 0.02\n",
      "iteration: 29620 loss: 0.0052 lr: 0.02\n",
      "iteration: 29630 loss: 0.0073 lr: 0.02\n",
      "iteration: 29640 loss: 0.0050 lr: 0.02\n",
      "iteration: 29650 loss: 0.0050 lr: 0.02\n",
      "iteration: 29660 loss: 0.0061 lr: 0.02\n",
      "iteration: 29670 loss: 0.0074 lr: 0.02\n",
      "iteration: 29680 loss: 0.0058 lr: 0.02\n",
      "iteration: 29690 loss: 0.0057 lr: 0.02\n",
      "iteration: 29700 loss: 0.0062 lr: 0.02\n",
      "iteration: 29710 loss: 0.0054 lr: 0.02\n",
      "iteration: 29720 loss: 0.0064 lr: 0.02\n",
      "iteration: 29730 loss: 0.0043 lr: 0.02\n",
      "iteration: 29740 loss: 0.0063 lr: 0.02\n",
      "iteration: 29750 loss: 0.0064 lr: 0.02\n",
      "iteration: 29760 loss: 0.0055 lr: 0.02\n",
      "iteration: 29770 loss: 0.0063 lr: 0.02\n",
      "iteration: 29780 loss: 0.0059 lr: 0.02\n",
      "iteration: 29790 loss: 0.0067 lr: 0.02\n",
      "iteration: 29800 loss: 0.0053 lr: 0.02\n",
      "iteration: 29810 loss: 0.0065 lr: 0.02\n",
      "iteration: 29820 loss: 0.0070 lr: 0.02\n",
      "iteration: 29830 loss: 0.0065 lr: 0.02\n",
      "iteration: 29840 loss: 0.0063 lr: 0.02\n",
      "iteration: 29850 loss: 0.0084 lr: 0.02\n",
      "iteration: 29860 loss: 0.0061 lr: 0.02\n",
      "iteration: 29870 loss: 0.0057 lr: 0.02\n",
      "iteration: 29880 loss: 0.0065 lr: 0.02\n",
      "iteration: 29890 loss: 0.0061 lr: 0.02\n",
      "iteration: 29900 loss: 0.0068 lr: 0.02\n",
      "iteration: 29910 loss: 0.0060 lr: 0.02\n",
      "iteration: 29920 loss: 0.0065 lr: 0.02\n",
      "iteration: 29930 loss: 0.0051 lr: 0.02\n",
      "iteration: 29940 loss: 0.0057 lr: 0.02\n",
      "iteration: 29950 loss: 0.0062 lr: 0.02\n",
      "iteration: 29960 loss: 0.0072 lr: 0.02\n",
      "iteration: 29970 loss: 0.0069 lr: 0.02\n",
      "iteration: 29980 loss: 0.0060 lr: 0.02\n",
      "iteration: 29990 loss: 0.0058 lr: 0.02\n",
      "iteration: 30000 loss: 0.0054 lr: 0.02\n",
      "iteration: 30010 loss: 0.0058 lr: 0.02\n",
      "iteration: 30020 loss: 0.0054 lr: 0.02\n",
      "iteration: 30030 loss: 0.0078 lr: 0.02\n",
      "iteration: 30040 loss: 0.0062 lr: 0.02\n",
      "iteration: 30050 loss: 0.0059 lr: 0.02\n",
      "iteration: 30060 loss: 0.0051 lr: 0.02\n",
      "iteration: 30070 loss: 0.0060 lr: 0.02\n",
      "iteration: 30080 loss: 0.0053 lr: 0.02\n",
      "iteration: 30090 loss: 0.0058 lr: 0.02\n",
      "iteration: 30100 loss: 0.0047 lr: 0.02\n",
      "iteration: 30110 loss: 0.0061 lr: 0.02\n",
      "iteration: 30120 loss: 0.0064 lr: 0.02\n",
      "iteration: 30130 loss: 0.0055 lr: 0.02\n",
      "iteration: 30140 loss: 0.0066 lr: 0.02\n",
      "iteration: 30150 loss: 0.0074 lr: 0.02\n",
      "iteration: 30160 loss: 0.0054 lr: 0.02\n",
      "iteration: 30170 loss: 0.0073 lr: 0.02\n",
      "iteration: 30180 loss: 0.0064 lr: 0.02\n",
      "iteration: 30190 loss: 0.0078 lr: 0.02\n",
      "iteration: 30200 loss: 0.0064 lr: 0.02\n",
      "iteration: 30210 loss: 0.0057 lr: 0.02\n",
      "iteration: 30220 loss: 0.0047 lr: 0.02\n",
      "iteration: 30230 loss: 0.0068 lr: 0.02\n",
      "iteration: 30240 loss: 0.0054 lr: 0.02\n",
      "iteration: 30250 loss: 0.0061 lr: 0.02\n",
      "iteration: 30260 loss: 0.0048 lr: 0.02\n",
      "iteration: 30270 loss: 0.0060 lr: 0.02\n",
      "iteration: 30280 loss: 0.0059 lr: 0.02\n",
      "iteration: 30290 loss: 0.0057 lr: 0.02\n",
      "iteration: 30300 loss: 0.0064 lr: 0.02\n",
      "iteration: 30310 loss: 0.0047 lr: 0.02\n",
      "iteration: 30320 loss: 0.0067 lr: 0.02\n",
      "iteration: 30330 loss: 0.0068 lr: 0.02\n",
      "iteration: 30340 loss: 0.0053 lr: 0.02\n",
      "iteration: 30350 loss: 0.0049 lr: 0.02\n",
      "iteration: 30360 loss: 0.0072 lr: 0.02\n",
      "iteration: 30370 loss: 0.0047 lr: 0.02\n",
      "iteration: 30380 loss: 0.0057 lr: 0.02\n",
      "iteration: 30390 loss: 0.0069 lr: 0.02\n",
      "iteration: 30400 loss: 0.0048 lr: 0.02\n",
      "iteration: 30410 loss: 0.0070 lr: 0.02\n",
      "iteration: 30420 loss: 0.0074 lr: 0.02\n",
      "iteration: 30430 loss: 0.0056 lr: 0.02\n",
      "iteration: 30440 loss: 0.0067 lr: 0.02\n",
      "iteration: 30450 loss: 0.0079 lr: 0.02\n",
      "iteration: 30460 loss: 0.0068 lr: 0.02\n",
      "iteration: 30470 loss: 0.0047 lr: 0.02\n",
      "iteration: 30480 loss: 0.0053 lr: 0.02\n",
      "iteration: 30490 loss: 0.0057 lr: 0.02\n",
      "iteration: 30500 loss: 0.0063 lr: 0.02\n",
      "iteration: 30510 loss: 0.0064 lr: 0.02\n",
      "iteration: 30520 loss: 0.0073 lr: 0.02\n",
      "iteration: 30530 loss: 0.0055 lr: 0.02\n",
      "iteration: 30540 loss: 0.0069 lr: 0.02\n",
      "iteration: 30550 loss: 0.0051 lr: 0.02\n",
      "iteration: 30560 loss: 0.0064 lr: 0.02\n",
      "iteration: 30570 loss: 0.0059 lr: 0.02\n",
      "iteration: 30580 loss: 0.0062 lr: 0.02\n",
      "iteration: 30590 loss: 0.0056 lr: 0.02\n",
      "iteration: 30600 loss: 0.0046 lr: 0.02\n",
      "iteration: 30610 loss: 0.0059 lr: 0.02\n",
      "iteration: 30620 loss: 0.0046 lr: 0.02\n",
      "iteration: 30630 loss: 0.0067 lr: 0.02\n",
      "iteration: 30640 loss: 0.0072 lr: 0.02\n",
      "iteration: 30650 loss: 0.0061 lr: 0.02\n",
      "iteration: 30660 loss: 0.0056 lr: 0.02\n",
      "iteration: 30670 loss: 0.0059 lr: 0.02\n",
      "iteration: 30680 loss: 0.0054 lr: 0.02\n",
      "iteration: 30690 loss: 0.0058 lr: 0.02\n",
      "iteration: 30700 loss: 0.0055 lr: 0.02\n",
      "iteration: 30710 loss: 0.0062 lr: 0.02\n",
      "iteration: 30720 loss: 0.0055 lr: 0.02\n",
      "iteration: 30730 loss: 0.0051 lr: 0.02\n",
      "iteration: 30740 loss: 0.0064 lr: 0.02\n",
      "iteration: 30750 loss: 0.0068 lr: 0.02\n",
      "iteration: 30760 loss: 0.0059 lr: 0.02\n",
      "iteration: 30770 loss: 0.0047 lr: 0.02\n",
      "iteration: 30780 loss: 0.0068 lr: 0.02\n",
      "iteration: 30790 loss: 0.0076 lr: 0.02\n",
      "iteration: 30800 loss: 0.0059 lr: 0.02\n",
      "iteration: 30810 loss: 0.0053 lr: 0.02\n",
      "iteration: 30820 loss: 0.0059 lr: 0.02\n",
      "iteration: 30830 loss: 0.0056 lr: 0.02\n",
      "iteration: 30840 loss: 0.0069 lr: 0.02\n",
      "iteration: 30850 loss: 0.0050 lr: 0.02\n",
      "iteration: 30860 loss: 0.0051 lr: 0.02\n",
      "iteration: 30870 loss: 0.0073 lr: 0.02\n",
      "iteration: 30880 loss: 0.0062 lr: 0.02\n",
      "iteration: 30890 loss: 0.0048 lr: 0.02\n",
      "iteration: 30900 loss: 0.0054 lr: 0.02\n",
      "iteration: 30910 loss: 0.0051 lr: 0.02\n",
      "iteration: 30920 loss: 0.0064 lr: 0.02\n",
      "iteration: 30930 loss: 0.0069 lr: 0.02\n",
      "iteration: 30940 loss: 0.0071 lr: 0.02\n",
      "iteration: 30950 loss: 0.0056 lr: 0.02\n",
      "iteration: 30960 loss: 0.0061 lr: 0.02\n",
      "iteration: 30970 loss: 0.0050 lr: 0.02\n",
      "iteration: 30980 loss: 0.0049 lr: 0.02\n",
      "iteration: 30990 loss: 0.0056 lr: 0.02\n",
      "iteration: 31000 loss: 0.0057 lr: 0.02\n",
      "iteration: 31010 loss: 0.0049 lr: 0.02\n",
      "iteration: 31020 loss: 0.0064 lr: 0.02\n",
      "iteration: 31030 loss: 0.0050 lr: 0.02\n",
      "iteration: 31040 loss: 0.0053 lr: 0.02\n",
      "iteration: 31050 loss: 0.0060 lr: 0.02\n",
      "iteration: 31060 loss: 0.0061 lr: 0.02\n",
      "iteration: 31070 loss: 0.0060 lr: 0.02\n",
      "iteration: 31080 loss: 0.0057 lr: 0.02\n",
      "iteration: 31090 loss: 0.0058 lr: 0.02\n",
      "iteration: 31100 loss: 0.0058 lr: 0.02\n",
      "iteration: 31110 loss: 0.0060 lr: 0.02\n",
      "iteration: 31120 loss: 0.0066 lr: 0.02\n",
      "iteration: 31130 loss: 0.0040 lr: 0.02\n",
      "iteration: 31140 loss: 0.0082 lr: 0.02\n",
      "iteration: 31150 loss: 0.0051 lr: 0.02\n",
      "iteration: 31160 loss: 0.0063 lr: 0.02\n",
      "iteration: 31170 loss: 0.0053 lr: 0.02\n",
      "iteration: 31180 loss: 0.0056 lr: 0.02\n",
      "iteration: 31190 loss: 0.0059 lr: 0.02\n",
      "iteration: 31200 loss: 0.0058 lr: 0.02\n",
      "iteration: 31210 loss: 0.0060 lr: 0.02\n",
      "iteration: 31220 loss: 0.0080 lr: 0.02\n",
      "iteration: 31230 loss: 0.0061 lr: 0.02\n",
      "iteration: 31240 loss: 0.0072 lr: 0.02\n",
      "iteration: 31250 loss: 0.0064 lr: 0.02\n",
      "iteration: 31260 loss: 0.0058 lr: 0.02\n",
      "iteration: 31270 loss: 0.0067 lr: 0.02\n",
      "iteration: 31280 loss: 0.0050 lr: 0.02\n",
      "iteration: 31290 loss: 0.0051 lr: 0.02\n",
      "iteration: 31300 loss: 0.0061 lr: 0.02\n",
      "iteration: 31310 loss: 0.0061 lr: 0.02\n",
      "iteration: 31320 loss: 0.0049 lr: 0.02\n",
      "iteration: 31330 loss: 0.0058 lr: 0.02\n",
      "iteration: 31340 loss: 0.0062 lr: 0.02\n",
      "iteration: 31350 loss: 0.0063 lr: 0.02\n",
      "iteration: 31360 loss: 0.0052 lr: 0.02\n",
      "iteration: 31370 loss: 0.0064 lr: 0.02\n",
      "iteration: 31380 loss: 0.0058 lr: 0.02\n",
      "iteration: 31390 loss: 0.0052 lr: 0.02\n",
      "iteration: 31400 loss: 0.0070 lr: 0.02\n",
      "iteration: 31410 loss: 0.0052 lr: 0.02\n",
      "iteration: 31420 loss: 0.0070 lr: 0.02\n",
      "iteration: 31430 loss: 0.0049 lr: 0.02\n",
      "iteration: 31440 loss: 0.0064 lr: 0.02\n",
      "iteration: 31450 loss: 0.0069 lr: 0.02\n",
      "iteration: 31460 loss: 0.0058 lr: 0.02\n",
      "iteration: 31470 loss: 0.0058 lr: 0.02\n",
      "iteration: 31480 loss: 0.0059 lr: 0.02\n",
      "iteration: 31490 loss: 0.0069 lr: 0.02\n",
      "iteration: 31500 loss: 0.0063 lr: 0.02\n",
      "iteration: 31510 loss: 0.0057 lr: 0.02\n",
      "iteration: 31520 loss: 0.0060 lr: 0.02\n",
      "iteration: 31530 loss: 0.0063 lr: 0.02\n",
      "iteration: 31540 loss: 0.0058 lr: 0.02\n",
      "iteration: 31550 loss: 0.0055 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 31560 loss: 0.0056 lr: 0.02\n",
      "iteration: 31570 loss: 0.0058 lr: 0.02\n",
      "iteration: 31580 loss: 0.0054 lr: 0.02\n",
      "iteration: 31590 loss: 0.0081 lr: 0.02\n",
      "iteration: 31600 loss: 0.0061 lr: 0.02\n",
      "iteration: 31610 loss: 0.0052 lr: 0.02\n",
      "iteration: 31620 loss: 0.0059 lr: 0.02\n",
      "iteration: 31630 loss: 0.0052 lr: 0.02\n",
      "iteration: 31640 loss: 0.0060 lr: 0.02\n",
      "iteration: 31650 loss: 0.0070 lr: 0.02\n",
      "iteration: 31660 loss: 0.0072 lr: 0.02\n",
      "iteration: 31670 loss: 0.0050 lr: 0.02\n",
      "iteration: 31680 loss: 0.0047 lr: 0.02\n",
      "iteration: 31690 loss: 0.0060 lr: 0.02\n",
      "iteration: 31700 loss: 0.0062 lr: 0.02\n",
      "iteration: 31710 loss: 0.0077 lr: 0.02\n",
      "iteration: 31720 loss: 0.0057 lr: 0.02\n",
      "iteration: 31730 loss: 0.0062 lr: 0.02\n",
      "iteration: 31740 loss: 0.0055 lr: 0.02\n",
      "iteration: 31750 loss: 0.0049 lr: 0.02\n",
      "iteration: 31760 loss: 0.0055 lr: 0.02\n",
      "iteration: 31770 loss: 0.0070 lr: 0.02\n",
      "iteration: 31780 loss: 0.0057 lr: 0.02\n",
      "iteration: 31790 loss: 0.0066 lr: 0.02\n",
      "iteration: 31800 loss: 0.0061 lr: 0.02\n",
      "iteration: 31810 loss: 0.0057 lr: 0.02\n",
      "iteration: 31820 loss: 0.0082 lr: 0.02\n",
      "iteration: 31830 loss: 0.0062 lr: 0.02\n",
      "iteration: 31840 loss: 0.0047 lr: 0.02\n",
      "iteration: 31850 loss: 0.0058 lr: 0.02\n",
      "iteration: 31860 loss: 0.0061 lr: 0.02\n",
      "iteration: 31870 loss: 0.0057 lr: 0.02\n",
      "iteration: 31880 loss: 0.0059 lr: 0.02\n",
      "iteration: 31890 loss: 0.0057 lr: 0.02\n",
      "iteration: 31900 loss: 0.0055 lr: 0.02\n",
      "iteration: 31910 loss: 0.0044 lr: 0.02\n",
      "iteration: 31920 loss: 0.0052 lr: 0.02\n",
      "iteration: 31930 loss: 0.0055 lr: 0.02\n",
      "iteration: 31940 loss: 0.0054 lr: 0.02\n",
      "iteration: 31950 loss: 0.0055 lr: 0.02\n",
      "iteration: 31960 loss: 0.0067 lr: 0.02\n",
      "iteration: 31970 loss: 0.0046 lr: 0.02\n",
      "iteration: 31980 loss: 0.0055 lr: 0.02\n",
      "iteration: 31990 loss: 0.0064 lr: 0.02\n",
      "iteration: 32000 loss: 0.0057 lr: 0.02\n",
      "iteration: 32010 loss: 0.0064 lr: 0.02\n",
      "iteration: 32020 loss: 0.0064 lr: 0.02\n",
      "iteration: 32030 loss: 0.0045 lr: 0.02\n",
      "iteration: 32040 loss: 0.0060 lr: 0.02\n",
      "iteration: 32050 loss: 0.0062 lr: 0.02\n",
      "iteration: 32060 loss: 0.0059 lr: 0.02\n",
      "iteration: 32070 loss: 0.0060 lr: 0.02\n",
      "iteration: 32080 loss: 0.0048 lr: 0.02\n",
      "iteration: 32090 loss: 0.0070 lr: 0.02\n",
      "iteration: 32100 loss: 0.0046 lr: 0.02\n",
      "iteration: 32110 loss: 0.0068 lr: 0.02\n",
      "iteration: 32120 loss: 0.0063 lr: 0.02\n",
      "iteration: 32130 loss: 0.0057 lr: 0.02\n",
      "iteration: 32140 loss: 0.0054 lr: 0.02\n",
      "iteration: 32150 loss: 0.0064 lr: 0.02\n",
      "iteration: 32160 loss: 0.0056 lr: 0.02\n",
      "iteration: 32170 loss: 0.0055 lr: 0.02\n",
      "iteration: 32180 loss: 0.0050 lr: 0.02\n",
      "iteration: 32190 loss: 0.0066 lr: 0.02\n",
      "iteration: 32200 loss: 0.0048 lr: 0.02\n",
      "iteration: 32210 loss: 0.0057 lr: 0.02\n",
      "iteration: 32220 loss: 0.0049 lr: 0.02\n",
      "iteration: 32230 loss: 0.0058 lr: 0.02\n",
      "iteration: 32240 loss: 0.0060 lr: 0.02\n",
      "iteration: 32250 loss: 0.0050 lr: 0.02\n",
      "iteration: 32260 loss: 0.0058 lr: 0.02\n",
      "iteration: 32270 loss: 0.0055 lr: 0.02\n",
      "iteration: 32280 loss: 0.0057 lr: 0.02\n",
      "iteration: 32290 loss: 0.0063 lr: 0.02\n",
      "iteration: 32300 loss: 0.0055 lr: 0.02\n",
      "iteration: 32310 loss: 0.0059 lr: 0.02\n",
      "iteration: 32320 loss: 0.0047 lr: 0.02\n",
      "iteration: 32330 loss: 0.0043 lr: 0.02\n",
      "iteration: 32340 loss: 0.0055 lr: 0.02\n",
      "iteration: 32350 loss: 0.0041 lr: 0.02\n",
      "iteration: 32360 loss: 0.0046 lr: 0.02\n",
      "iteration: 32370 loss: 0.0056 lr: 0.02\n",
      "iteration: 32380 loss: 0.0049 lr: 0.02\n",
      "iteration: 32390 loss: 0.0061 lr: 0.02\n",
      "iteration: 32400 loss: 0.0058 lr: 0.02\n",
      "iteration: 32410 loss: 0.0054 lr: 0.02\n",
      "iteration: 32420 loss: 0.0053 lr: 0.02\n",
      "iteration: 32430 loss: 0.0052 lr: 0.02\n",
      "iteration: 32440 loss: 0.0064 lr: 0.02\n",
      "iteration: 32450 loss: 0.0059 lr: 0.02\n",
      "iteration: 32460 loss: 0.0047 lr: 0.02\n",
      "iteration: 32470 loss: 0.0052 lr: 0.02\n",
      "iteration: 32480 loss: 0.0065 lr: 0.02\n",
      "iteration: 32490 loss: 0.0050 lr: 0.02\n",
      "iteration: 32500 loss: 0.0058 lr: 0.02\n",
      "iteration: 32510 loss: 0.0062 lr: 0.02\n",
      "iteration: 32520 loss: 0.0046 lr: 0.02\n",
      "iteration: 32530 loss: 0.0061 lr: 0.02\n",
      "iteration: 32540 loss: 0.0065 lr: 0.02\n",
      "iteration: 32550 loss: 0.0048 lr: 0.02\n",
      "iteration: 32560 loss: 0.0052 lr: 0.02\n",
      "iteration: 32570 loss: 0.0070 lr: 0.02\n",
      "iteration: 32580 loss: 0.0053 lr: 0.02\n",
      "iteration: 32590 loss: 0.0057 lr: 0.02\n",
      "iteration: 32600 loss: 0.0065 lr: 0.02\n",
      "iteration: 32610 loss: 0.0060 lr: 0.02\n",
      "iteration: 32620 loss: 0.0068 lr: 0.02\n",
      "iteration: 32630 loss: 0.0062 lr: 0.02\n",
      "iteration: 32640 loss: 0.0060 lr: 0.02\n",
      "iteration: 32650 loss: 0.0045 lr: 0.02\n",
      "iteration: 32660 loss: 0.0055 lr: 0.02\n",
      "iteration: 32670 loss: 0.0053 lr: 0.02\n",
      "iteration: 32680 loss: 0.0056 lr: 0.02\n",
      "iteration: 32690 loss: 0.0050 lr: 0.02\n",
      "iteration: 32700 loss: 0.0061 lr: 0.02\n",
      "iteration: 32710 loss: 0.0065 lr: 0.02\n",
      "iteration: 32720 loss: 0.0069 lr: 0.02\n",
      "iteration: 32730 loss: 0.0052 lr: 0.02\n",
      "iteration: 32740 loss: 0.0064 lr: 0.02\n",
      "iteration: 32750 loss: 0.0067 lr: 0.02\n",
      "iteration: 32760 loss: 0.0046 lr: 0.02\n",
      "iteration: 32770 loss: 0.0052 lr: 0.02\n",
      "iteration: 32780 loss: 0.0061 lr: 0.02\n",
      "iteration: 32790 loss: 0.0048 lr: 0.02\n",
      "iteration: 32800 loss: 0.0049 lr: 0.02\n",
      "iteration: 32810 loss: 0.0056 lr: 0.02\n",
      "iteration: 32820 loss: 0.0056 lr: 0.02\n",
      "iteration: 32830 loss: 0.0054 lr: 0.02\n",
      "iteration: 32840 loss: 0.0060 lr: 0.02\n",
      "iteration: 32850 loss: 0.0063 lr: 0.02\n",
      "iteration: 32860 loss: 0.0069 lr: 0.02\n",
      "iteration: 32870 loss: 0.0057 lr: 0.02\n",
      "iteration: 32880 loss: 0.0064 lr: 0.02\n",
      "iteration: 32890 loss: 0.0047 lr: 0.02\n",
      "iteration: 32900 loss: 0.0054 lr: 0.02\n",
      "iteration: 32910 loss: 0.0052 lr: 0.02\n",
      "iteration: 32920 loss: 0.0068 lr: 0.02\n",
      "iteration: 32930 loss: 0.0061 lr: 0.02\n",
      "iteration: 32940 loss: 0.0045 lr: 0.02\n",
      "iteration: 32950 loss: 0.0068 lr: 0.02\n",
      "iteration: 32960 loss: 0.0047 lr: 0.02\n",
      "iteration: 32970 loss: 0.0055 lr: 0.02\n",
      "iteration: 32980 loss: 0.0047 lr: 0.02\n",
      "iteration: 32990 loss: 0.0056 lr: 0.02\n",
      "iteration: 33000 loss: 0.0071 lr: 0.02\n",
      "iteration: 33010 loss: 0.0059 lr: 0.02\n",
      "iteration: 33020 loss: 0.0065 lr: 0.02\n",
      "iteration: 33030 loss: 0.0057 lr: 0.02\n",
      "iteration: 33040 loss: 0.0047 lr: 0.02\n",
      "iteration: 33050 loss: 0.0046 lr: 0.02\n",
      "iteration: 33060 loss: 0.0057 lr: 0.02\n",
      "iteration: 33070 loss: 0.0053 lr: 0.02\n",
      "iteration: 33080 loss: 0.0055 lr: 0.02\n",
      "iteration: 33090 loss: 0.0057 lr: 0.02\n",
      "iteration: 33100 loss: 0.0063 lr: 0.02\n",
      "iteration: 33110 loss: 0.0054 lr: 0.02\n",
      "iteration: 33120 loss: 0.0057 lr: 0.02\n",
      "iteration: 33130 loss: 0.0046 lr: 0.02\n",
      "iteration: 33140 loss: 0.0050 lr: 0.02\n",
      "iteration: 33150 loss: 0.0072 lr: 0.02\n",
      "iteration: 33160 loss: 0.0062 lr: 0.02\n",
      "iteration: 33170 loss: 0.0049 lr: 0.02\n",
      "iteration: 33180 loss: 0.0062 lr: 0.02\n",
      "iteration: 33190 loss: 0.0059 lr: 0.02\n",
      "iteration: 33200 loss: 0.0059 lr: 0.02\n",
      "iteration: 33210 loss: 0.0065 lr: 0.02\n",
      "iteration: 33220 loss: 0.0050 lr: 0.02\n",
      "iteration: 33230 loss: 0.0063 lr: 0.02\n",
      "iteration: 33240 loss: 0.0076 lr: 0.02\n",
      "iteration: 33250 loss: 0.0055 lr: 0.02\n",
      "iteration: 33260 loss: 0.0066 lr: 0.02\n",
      "iteration: 33270 loss: 0.0052 lr: 0.02\n",
      "iteration: 33280 loss: 0.0051 lr: 0.02\n",
      "iteration: 33290 loss: 0.0054 lr: 0.02\n",
      "iteration: 33300 loss: 0.0050 lr: 0.02\n",
      "iteration: 33310 loss: 0.0070 lr: 0.02\n",
      "iteration: 33320 loss: 0.0054 lr: 0.02\n",
      "iteration: 33330 loss: 0.0065 lr: 0.02\n",
      "iteration: 33340 loss: 0.0060 lr: 0.02\n",
      "iteration: 33350 loss: 0.0062 lr: 0.02\n",
      "iteration: 33360 loss: 0.0042 lr: 0.02\n",
      "iteration: 33370 loss: 0.0056 lr: 0.02\n",
      "iteration: 33380 loss: 0.0054 lr: 0.02\n",
      "iteration: 33390 loss: 0.0047 lr: 0.02\n",
      "iteration: 33400 loss: 0.0058 lr: 0.02\n",
      "iteration: 33410 loss: 0.0056 lr: 0.02\n",
      "iteration: 33420 loss: 0.0049 lr: 0.02\n",
      "iteration: 33430 loss: 0.0055 lr: 0.02\n",
      "iteration: 33440 loss: 0.0044 lr: 0.02\n",
      "iteration: 33450 loss: 0.0051 lr: 0.02\n",
      "iteration: 33460 loss: 0.0063 lr: 0.02\n",
      "iteration: 33470 loss: 0.0047 lr: 0.02\n",
      "iteration: 33480 loss: 0.0054 lr: 0.02\n",
      "iteration: 33490 loss: 0.0050 lr: 0.02\n",
      "iteration: 33500 loss: 0.0049 lr: 0.02\n",
      "iteration: 33510 loss: 0.0046 lr: 0.02\n",
      "iteration: 33520 loss: 0.0057 lr: 0.02\n",
      "iteration: 33530 loss: 0.0070 lr: 0.02\n",
      "iteration: 33540 loss: 0.0047 lr: 0.02\n",
      "iteration: 33550 loss: 0.0055 lr: 0.02\n",
      "iteration: 33560 loss: 0.0064 lr: 0.02\n",
      "iteration: 33570 loss: 0.0049 lr: 0.02\n",
      "iteration: 33580 loss: 0.0050 lr: 0.02\n",
      "iteration: 33590 loss: 0.0062 lr: 0.02\n",
      "iteration: 33600 loss: 0.0051 lr: 0.02\n",
      "iteration: 33610 loss: 0.0042 lr: 0.02\n",
      "iteration: 33620 loss: 0.0040 lr: 0.02\n",
      "iteration: 33630 loss: 0.0072 lr: 0.02\n",
      "iteration: 33640 loss: 0.0051 lr: 0.02\n",
      "iteration: 33650 loss: 0.0057 lr: 0.02\n",
      "iteration: 33660 loss: 0.0070 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 33670 loss: 0.0048 lr: 0.02\n",
      "iteration: 33680 loss: 0.0047 lr: 0.02\n",
      "iteration: 33690 loss: 0.0054 lr: 0.02\n",
      "iteration: 33700 loss: 0.0066 lr: 0.02\n",
      "iteration: 33710 loss: 0.0051 lr: 0.02\n",
      "iteration: 33720 loss: 0.0051 lr: 0.02\n",
      "iteration: 33730 loss: 0.0064 lr: 0.02\n",
      "iteration: 33740 loss: 0.0059 lr: 0.02\n",
      "iteration: 33750 loss: 0.0052 lr: 0.02\n",
      "iteration: 33760 loss: 0.0049 lr: 0.02\n",
      "iteration: 33770 loss: 0.0064 lr: 0.02\n",
      "iteration: 33780 loss: 0.0063 lr: 0.02\n",
      "iteration: 33790 loss: 0.0051 lr: 0.02\n",
      "iteration: 33800 loss: 0.0046 lr: 0.02\n",
      "iteration: 33810 loss: 0.0044 lr: 0.02\n",
      "iteration: 33820 loss: 0.0049 lr: 0.02\n",
      "iteration: 33830 loss: 0.0051 lr: 0.02\n",
      "iteration: 33840 loss: 0.0055 lr: 0.02\n",
      "iteration: 33850 loss: 0.0057 lr: 0.02\n",
      "iteration: 33860 loss: 0.0056 lr: 0.02\n",
      "iteration: 33870 loss: 0.0041 lr: 0.02\n",
      "iteration: 33880 loss: 0.0052 lr: 0.02\n",
      "iteration: 33890 loss: 0.0046 lr: 0.02\n",
      "iteration: 33900 loss: 0.0040 lr: 0.02\n",
      "iteration: 33910 loss: 0.0050 lr: 0.02\n",
      "iteration: 33920 loss: 0.0056 lr: 0.02\n",
      "iteration: 33930 loss: 0.0051 lr: 0.02\n",
      "iteration: 33940 loss: 0.0072 lr: 0.02\n",
      "iteration: 33950 loss: 0.0053 lr: 0.02\n",
      "iteration: 33960 loss: 0.0048 lr: 0.02\n",
      "iteration: 33970 loss: 0.0044 lr: 0.02\n",
      "iteration: 33980 loss: 0.0048 lr: 0.02\n",
      "iteration: 33990 loss: 0.0054 lr: 0.02\n",
      "iteration: 34000 loss: 0.0054 lr: 0.02\n",
      "iteration: 34010 loss: 0.0050 lr: 0.02\n",
      "iteration: 34020 loss: 0.0061 lr: 0.02\n",
      "iteration: 34030 loss: 0.0070 lr: 0.02\n",
      "iteration: 34040 loss: 0.0061 lr: 0.02\n",
      "iteration: 34050 loss: 0.0065 lr: 0.02\n",
      "iteration: 34060 loss: 0.0060 lr: 0.02\n",
      "iteration: 34070 loss: 0.0055 lr: 0.02\n",
      "iteration: 34080 loss: 0.0057 lr: 0.02\n",
      "iteration: 34090 loss: 0.0053 lr: 0.02\n",
      "iteration: 34100 loss: 0.0054 lr: 0.02\n",
      "iteration: 34110 loss: 0.0057 lr: 0.02\n",
      "iteration: 34120 loss: 0.0053 lr: 0.02\n",
      "iteration: 34130 loss: 0.0067 lr: 0.02\n",
      "iteration: 34140 loss: 0.0062 lr: 0.02\n",
      "iteration: 34150 loss: 0.0059 lr: 0.02\n",
      "iteration: 34160 loss: 0.0053 lr: 0.02\n",
      "iteration: 34170 loss: 0.0049 lr: 0.02\n",
      "iteration: 34180 loss: 0.0046 lr: 0.02\n",
      "iteration: 34190 loss: 0.0069 lr: 0.02\n",
      "iteration: 34200 loss: 0.0054 lr: 0.02\n",
      "iteration: 34210 loss: 0.0054 lr: 0.02\n",
      "iteration: 34220 loss: 0.0054 lr: 0.02\n",
      "iteration: 34230 loss: 0.0070 lr: 0.02\n",
      "iteration: 34240 loss: 0.0042 lr: 0.02\n",
      "iteration: 34250 loss: 0.0055 lr: 0.02\n",
      "iteration: 34260 loss: 0.0044 lr: 0.02\n",
      "iteration: 34270 loss: 0.0057 lr: 0.02\n",
      "iteration: 34280 loss: 0.0053 lr: 0.02\n",
      "iteration: 34290 loss: 0.0053 lr: 0.02\n",
      "iteration: 34300 loss: 0.0044 lr: 0.02\n",
      "iteration: 34310 loss: 0.0073 lr: 0.02\n",
      "iteration: 34320 loss: 0.0049 lr: 0.02\n",
      "iteration: 34330 loss: 0.0065 lr: 0.02\n",
      "iteration: 34340 loss: 0.0050 lr: 0.02\n",
      "iteration: 34350 loss: 0.0055 lr: 0.02\n",
      "iteration: 34360 loss: 0.0049 lr: 0.02\n",
      "iteration: 34370 loss: 0.0048 lr: 0.02\n",
      "iteration: 34380 loss: 0.0080 lr: 0.02\n",
      "iteration: 34390 loss: 0.0063 lr: 0.02\n",
      "iteration: 34400 loss: 0.0052 lr: 0.02\n",
      "iteration: 34410 loss: 0.0052 lr: 0.02\n",
      "iteration: 34420 loss: 0.0056 lr: 0.02\n",
      "iteration: 34430 loss: 0.0048 lr: 0.02\n",
      "iteration: 34440 loss: 0.0048 lr: 0.02\n",
      "iteration: 34450 loss: 0.0051 lr: 0.02\n",
      "iteration: 34460 loss: 0.0057 lr: 0.02\n",
      "iteration: 34470 loss: 0.0061 lr: 0.02\n",
      "iteration: 34480 loss: 0.0049 lr: 0.02\n",
      "iteration: 34490 loss: 0.0060 lr: 0.02\n",
      "iteration: 34500 loss: 0.0051 lr: 0.02\n",
      "iteration: 34510 loss: 0.0058 lr: 0.02\n",
      "iteration: 34520 loss: 0.0056 lr: 0.02\n",
      "iteration: 34530 loss: 0.0055 lr: 0.02\n",
      "iteration: 34540 loss: 0.0061 lr: 0.02\n",
      "iteration: 34550 loss: 0.0044 lr: 0.02\n",
      "iteration: 34560 loss: 0.0045 lr: 0.02\n",
      "iteration: 34570 loss: 0.0052 lr: 0.02\n",
      "iteration: 34580 loss: 0.0055 lr: 0.02\n",
      "iteration: 34590 loss: 0.0063 lr: 0.02\n",
      "iteration: 34600 loss: 0.0061 lr: 0.02\n",
      "iteration: 34610 loss: 0.0056 lr: 0.02\n",
      "iteration: 34620 loss: 0.0050 lr: 0.02\n",
      "iteration: 34630 loss: 0.0065 lr: 0.02\n",
      "iteration: 34640 loss: 0.0040 lr: 0.02\n",
      "iteration: 34650 loss: 0.0050 lr: 0.02\n",
      "iteration: 34660 loss: 0.0048 lr: 0.02\n",
      "iteration: 34670 loss: 0.0063 lr: 0.02\n",
      "iteration: 34680 loss: 0.0062 lr: 0.02\n",
      "iteration: 34690 loss: 0.0070 lr: 0.02\n",
      "iteration: 34700 loss: 0.0059 lr: 0.02\n",
      "iteration: 34710 loss: 0.0061 lr: 0.02\n",
      "iteration: 34720 loss: 0.0059 lr: 0.02\n",
      "iteration: 34730 loss: 0.0050 lr: 0.02\n",
      "iteration: 34740 loss: 0.0067 lr: 0.02\n",
      "iteration: 34750 loss: 0.0051 lr: 0.02\n",
      "iteration: 34760 loss: 0.0051 lr: 0.02\n",
      "iteration: 34770 loss: 0.0054 lr: 0.02\n",
      "iteration: 34780 loss: 0.0063 lr: 0.02\n",
      "iteration: 34790 loss: 0.0061 lr: 0.02\n",
      "iteration: 34800 loss: 0.0063 lr: 0.02\n",
      "iteration: 34810 loss: 0.0049 lr: 0.02\n",
      "iteration: 34820 loss: 0.0049 lr: 0.02\n",
      "iteration: 34830 loss: 0.0062 lr: 0.02\n",
      "iteration: 34840 loss: 0.0046 lr: 0.02\n",
      "iteration: 34850 loss: 0.0045 lr: 0.02\n",
      "iteration: 34860 loss: 0.0043 lr: 0.02\n",
      "iteration: 34870 loss: 0.0060 lr: 0.02\n",
      "iteration: 34880 loss: 0.0048 lr: 0.02\n",
      "iteration: 34890 loss: 0.0054 lr: 0.02\n",
      "iteration: 34900 loss: 0.0059 lr: 0.02\n",
      "iteration: 34910 loss: 0.0056 lr: 0.02\n",
      "iteration: 34920 loss: 0.0047 lr: 0.02\n",
      "iteration: 34930 loss: 0.0050 lr: 0.02\n",
      "iteration: 34940 loss: 0.0041 lr: 0.02\n",
      "iteration: 34950 loss: 0.0074 lr: 0.02\n",
      "iteration: 34960 loss: 0.0055 lr: 0.02\n",
      "iteration: 34970 loss: 0.0047 lr: 0.02\n",
      "iteration: 34980 loss: 0.0045 lr: 0.02\n",
      "iteration: 34990 loss: 0.0055 lr: 0.02\n",
      "iteration: 35000 loss: 0.0058 lr: 0.02\n",
      "iteration: 35010 loss: 0.0046 lr: 0.02\n",
      "iteration: 35020 loss: 0.0048 lr: 0.02\n",
      "iteration: 35030 loss: 0.0050 lr: 0.02\n",
      "iteration: 35040 loss: 0.0064 lr: 0.02\n",
      "iteration: 35050 loss: 0.0058 lr: 0.02\n",
      "iteration: 35060 loss: 0.0048 lr: 0.02\n",
      "iteration: 35070 loss: 0.0048 lr: 0.02\n",
      "iteration: 35080 loss: 0.0056 lr: 0.02\n",
      "iteration: 35090 loss: 0.0064 lr: 0.02\n",
      "iteration: 35100 loss: 0.0053 lr: 0.02\n",
      "iteration: 35110 loss: 0.0047 lr: 0.02\n",
      "iteration: 35120 loss: 0.0066 lr: 0.02\n",
      "iteration: 35130 loss: 0.0053 lr: 0.02\n",
      "iteration: 35140 loss: 0.0071 lr: 0.02\n",
      "iteration: 35150 loss: 0.0053 lr: 0.02\n",
      "iteration: 35160 loss: 0.0060 lr: 0.02\n",
      "iteration: 35170 loss: 0.0063 lr: 0.02\n",
      "iteration: 35180 loss: 0.0055 lr: 0.02\n",
      "iteration: 35190 loss: 0.0055 lr: 0.02\n",
      "iteration: 35200 loss: 0.0064 lr: 0.02\n",
      "iteration: 35210 loss: 0.0072 lr: 0.02\n",
      "iteration: 35220 loss: 0.0048 lr: 0.02\n",
      "iteration: 35230 loss: 0.0053 lr: 0.02\n",
      "iteration: 35240 loss: 0.0062 lr: 0.02\n",
      "iteration: 35250 loss: 0.0065 lr: 0.02\n",
      "iteration: 35260 loss: 0.0052 lr: 0.02\n",
      "iteration: 35270 loss: 0.0048 lr: 0.02\n",
      "iteration: 35280 loss: 0.0045 lr: 0.02\n",
      "iteration: 35290 loss: 0.0057 lr: 0.02\n",
      "iteration: 35300 loss: 0.0051 lr: 0.02\n",
      "iteration: 35310 loss: 0.0048 lr: 0.02\n",
      "iteration: 35320 loss: 0.0052 lr: 0.02\n",
      "iteration: 35330 loss: 0.0053 lr: 0.02\n",
      "iteration: 35340 loss: 0.0054 lr: 0.02\n",
      "iteration: 35350 loss: 0.0057 lr: 0.02\n",
      "iteration: 35360 loss: 0.0055 lr: 0.02\n",
      "iteration: 35370 loss: 0.0057 lr: 0.02\n",
      "iteration: 35380 loss: 0.0045 lr: 0.02\n",
      "iteration: 35390 loss: 0.0056 lr: 0.02\n",
      "iteration: 35400 loss: 0.0046 lr: 0.02\n",
      "iteration: 35410 loss: 0.0048 lr: 0.02\n",
      "iteration: 35420 loss: 0.0055 lr: 0.02\n",
      "iteration: 35430 loss: 0.0056 lr: 0.02\n",
      "iteration: 35440 loss: 0.0057 lr: 0.02\n",
      "iteration: 35450 loss: 0.0043 lr: 0.02\n",
      "iteration: 35460 loss: 0.0050 lr: 0.02\n",
      "iteration: 35470 loss: 0.0055 lr: 0.02\n",
      "iteration: 35480 loss: 0.0048 lr: 0.02\n",
      "iteration: 35490 loss: 0.0047 lr: 0.02\n",
      "iteration: 35500 loss: 0.0033 lr: 0.02\n",
      "iteration: 35510 loss: 0.0054 lr: 0.02\n",
      "iteration: 35520 loss: 0.0067 lr: 0.02\n",
      "iteration: 35530 loss: 0.0053 lr: 0.02\n",
      "iteration: 35540 loss: 0.0041 lr: 0.02\n",
      "iteration: 35550 loss: 0.0053 lr: 0.02\n",
      "iteration: 35560 loss: 0.0063 lr: 0.02\n",
      "iteration: 35570 loss: 0.0053 lr: 0.02\n",
      "iteration: 35580 loss: 0.0063 lr: 0.02\n",
      "iteration: 35590 loss: 0.0070 lr: 0.02\n",
      "iteration: 35600 loss: 0.0048 lr: 0.02\n",
      "iteration: 35610 loss: 0.0053 lr: 0.02\n",
      "iteration: 35620 loss: 0.0064 lr: 0.02\n",
      "iteration: 35630 loss: 0.0052 lr: 0.02\n",
      "iteration: 35640 loss: 0.0065 lr: 0.02\n",
      "iteration: 35650 loss: 0.0050 lr: 0.02\n",
      "iteration: 35660 loss: 0.0049 lr: 0.02\n",
      "iteration: 35670 loss: 0.0049 lr: 0.02\n",
      "iteration: 35680 loss: 0.0056 lr: 0.02\n",
      "iteration: 35690 loss: 0.0055 lr: 0.02\n",
      "iteration: 35700 loss: 0.0074 lr: 0.02\n",
      "iteration: 35710 loss: 0.0055 lr: 0.02\n",
      "iteration: 35720 loss: 0.0055 lr: 0.02\n",
      "iteration: 35730 loss: 0.0059 lr: 0.02\n",
      "iteration: 35740 loss: 0.0051 lr: 0.02\n",
      "iteration: 35750 loss: 0.0060 lr: 0.02\n",
      "iteration: 35760 loss: 0.0056 lr: 0.02\n",
      "iteration: 35770 loss: 0.0045 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 35780 loss: 0.0060 lr: 0.02\n",
      "iteration: 35790 loss: 0.0073 lr: 0.02\n",
      "iteration: 35800 loss: 0.0052 lr: 0.02\n",
      "iteration: 35810 loss: 0.0060 lr: 0.02\n",
      "iteration: 35820 loss: 0.0055 lr: 0.02\n",
      "iteration: 35830 loss: 0.0049 lr: 0.02\n",
      "iteration: 35840 loss: 0.0054 lr: 0.02\n",
      "iteration: 35850 loss: 0.0064 lr: 0.02\n",
      "iteration: 35860 loss: 0.0055 lr: 0.02\n",
      "iteration: 35870 loss: 0.0043 lr: 0.02\n",
      "iteration: 35880 loss: 0.0047 lr: 0.02\n",
      "iteration: 35890 loss: 0.0063 lr: 0.02\n",
      "iteration: 35900 loss: 0.0062 lr: 0.02\n",
      "iteration: 35910 loss: 0.0053 lr: 0.02\n",
      "iteration: 35920 loss: 0.0051 lr: 0.02\n",
      "iteration: 35930 loss: 0.0058 lr: 0.02\n",
      "iteration: 35940 loss: 0.0042 lr: 0.02\n",
      "iteration: 35950 loss: 0.0056 lr: 0.02\n",
      "iteration: 35960 loss: 0.0054 lr: 0.02\n",
      "iteration: 35970 loss: 0.0047 lr: 0.02\n",
      "iteration: 35980 loss: 0.0052 lr: 0.02\n",
      "iteration: 35990 loss: 0.0054 lr: 0.02\n",
      "iteration: 36000 loss: 0.0043 lr: 0.02\n",
      "iteration: 36010 loss: 0.0051 lr: 0.02\n",
      "iteration: 36020 loss: 0.0060 lr: 0.02\n",
      "iteration: 36030 loss: 0.0047 lr: 0.02\n",
      "iteration: 36040 loss: 0.0049 lr: 0.02\n",
      "iteration: 36050 loss: 0.0054 lr: 0.02\n",
      "iteration: 36060 loss: 0.0049 lr: 0.02\n",
      "iteration: 36070 loss: 0.0060 lr: 0.02\n",
      "iteration: 36080 loss: 0.0056 lr: 0.02\n",
      "iteration: 36090 loss: 0.0046 lr: 0.02\n",
      "iteration: 36100 loss: 0.0057 lr: 0.02\n",
      "iteration: 36110 loss: 0.0050 lr: 0.02\n",
      "iteration: 36120 loss: 0.0052 lr: 0.02\n",
      "iteration: 36130 loss: 0.0052 lr: 0.02\n",
      "iteration: 36140 loss: 0.0054 lr: 0.02\n",
      "iteration: 36150 loss: 0.0053 lr: 0.02\n",
      "iteration: 36160 loss: 0.0056 lr: 0.02\n",
      "iteration: 36170 loss: 0.0048 lr: 0.02\n",
      "iteration: 36180 loss: 0.0046 lr: 0.02\n",
      "iteration: 36190 loss: 0.0060 lr: 0.02\n",
      "iteration: 36200 loss: 0.0060 lr: 0.02\n",
      "iteration: 36210 loss: 0.0052 lr: 0.02\n",
      "iteration: 36220 loss: 0.0050 lr: 0.02\n",
      "iteration: 36230 loss: 0.0053 lr: 0.02\n",
      "iteration: 36240 loss: 0.0045 lr: 0.02\n",
      "iteration: 36250 loss: 0.0044 lr: 0.02\n",
      "iteration: 36260 loss: 0.0051 lr: 0.02\n",
      "iteration: 36270 loss: 0.0041 lr: 0.02\n",
      "iteration: 36280 loss: 0.0052 lr: 0.02\n",
      "iteration: 36290 loss: 0.0040 lr: 0.02\n",
      "iteration: 36300 loss: 0.0056 lr: 0.02\n",
      "iteration: 36310 loss: 0.0055 lr: 0.02\n",
      "iteration: 36320 loss: 0.0051 lr: 0.02\n",
      "iteration: 36330 loss: 0.0048 lr: 0.02\n",
      "iteration: 36340 loss: 0.0045 lr: 0.02\n",
      "iteration: 36350 loss: 0.0047 lr: 0.02\n",
      "iteration: 36360 loss: 0.0055 lr: 0.02\n",
      "iteration: 36370 loss: 0.0052 lr: 0.02\n",
      "iteration: 36380 loss: 0.0057 lr: 0.02\n",
      "iteration: 36390 loss: 0.0055 lr: 0.02\n",
      "iteration: 36400 loss: 0.0051 lr: 0.02\n",
      "iteration: 36410 loss: 0.0058 lr: 0.02\n",
      "iteration: 36420 loss: 0.0060 lr: 0.02\n",
      "iteration: 36430 loss: 0.0058 lr: 0.02\n",
      "iteration: 36440 loss: 0.0052 lr: 0.02\n",
      "iteration: 36450 loss: 0.0050 lr: 0.02\n",
      "iteration: 36460 loss: 0.0048 lr: 0.02\n",
      "iteration: 36470 loss: 0.0050 lr: 0.02\n",
      "iteration: 36480 loss: 0.0053 lr: 0.02\n",
      "iteration: 36490 loss: 0.0065 lr: 0.02\n",
      "iteration: 36500 loss: 0.0048 lr: 0.02\n",
      "iteration: 36510 loss: 0.0052 lr: 0.02\n",
      "iteration: 36520 loss: 0.0051 lr: 0.02\n",
      "iteration: 36530 loss: 0.0060 lr: 0.02\n",
      "iteration: 36540 loss: 0.0061 lr: 0.02\n",
      "iteration: 36550 loss: 0.0044 lr: 0.02\n",
      "iteration: 36560 loss: 0.0052 lr: 0.02\n",
      "iteration: 36570 loss: 0.0053 lr: 0.02\n",
      "iteration: 36580 loss: 0.0055 lr: 0.02\n",
      "iteration: 36590 loss: 0.0050 lr: 0.02\n",
      "iteration: 36600 loss: 0.0054 lr: 0.02\n",
      "iteration: 36610 loss: 0.0056 lr: 0.02\n",
      "iteration: 36620 loss: 0.0042 lr: 0.02\n",
      "iteration: 36630 loss: 0.0059 lr: 0.02\n",
      "iteration: 36640 loss: 0.0066 lr: 0.02\n",
      "iteration: 36650 loss: 0.0050 lr: 0.02\n",
      "iteration: 36660 loss: 0.0043 lr: 0.02\n",
      "iteration: 36670 loss: 0.0043 lr: 0.02\n",
      "iteration: 36680 loss: 0.0071 lr: 0.02\n",
      "iteration: 36690 loss: 0.0062 lr: 0.02\n",
      "iteration: 36700 loss: 0.0048 lr: 0.02\n",
      "iteration: 36710 loss: 0.0052 lr: 0.02\n",
      "iteration: 36720 loss: 0.0051 lr: 0.02\n",
      "iteration: 36730 loss: 0.0054 lr: 0.02\n",
      "iteration: 36740 loss: 0.0051 lr: 0.02\n",
      "iteration: 36750 loss: 0.0044 lr: 0.02\n",
      "iteration: 36760 loss: 0.0053 lr: 0.02\n",
      "iteration: 36770 loss: 0.0060 lr: 0.02\n",
      "iteration: 36780 loss: 0.0051 lr: 0.02\n",
      "iteration: 36790 loss: 0.0052 lr: 0.02\n",
      "iteration: 36800 loss: 0.0042 lr: 0.02\n",
      "iteration: 36810 loss: 0.0047 lr: 0.02\n",
      "iteration: 36820 loss: 0.0044 lr: 0.02\n",
      "iteration: 36830 loss: 0.0046 lr: 0.02\n",
      "iteration: 36840 loss: 0.0046 lr: 0.02\n",
      "iteration: 36850 loss: 0.0037 lr: 0.02\n",
      "iteration: 36860 loss: 0.0051 lr: 0.02\n",
      "iteration: 36870 loss: 0.0053 lr: 0.02\n",
      "iteration: 36880 loss: 0.0064 lr: 0.02\n",
      "iteration: 36890 loss: 0.0057 lr: 0.02\n",
      "iteration: 36900 loss: 0.0061 lr: 0.02\n",
      "iteration: 36910 loss: 0.0047 lr: 0.02\n",
      "iteration: 36920 loss: 0.0050 lr: 0.02\n",
      "iteration: 36930 loss: 0.0050 lr: 0.02\n",
      "iteration: 36940 loss: 0.0046 lr: 0.02\n",
      "iteration: 36950 loss: 0.0050 lr: 0.02\n",
      "iteration: 36960 loss: 0.0076 lr: 0.02\n",
      "iteration: 36970 loss: 0.0069 lr: 0.02\n",
      "iteration: 36980 loss: 0.0047 lr: 0.02\n",
      "iteration: 36990 loss: 0.0049 lr: 0.02\n",
      "iteration: 37000 loss: 0.0051 lr: 0.02\n",
      "iteration: 37010 loss: 0.0044 lr: 0.02\n",
      "iteration: 37020 loss: 0.0054 lr: 0.02\n",
      "iteration: 37030 loss: 0.0039 lr: 0.02\n",
      "iteration: 37040 loss: 0.0054 lr: 0.02\n",
      "iteration: 37050 loss: 0.0054 lr: 0.02\n",
      "iteration: 37060 loss: 0.0047 lr: 0.02\n",
      "iteration: 37070 loss: 0.0056 lr: 0.02\n",
      "iteration: 37080 loss: 0.0062 lr: 0.02\n",
      "iteration: 37090 loss: 0.0045 lr: 0.02\n",
      "iteration: 37100 loss: 0.0058 lr: 0.02\n",
      "iteration: 37110 loss: 0.0048 lr: 0.02\n",
      "iteration: 37120 loss: 0.0056 lr: 0.02\n",
      "iteration: 37130 loss: 0.0056 lr: 0.02\n",
      "iteration: 37140 loss: 0.0055 lr: 0.02\n",
      "iteration: 37150 loss: 0.0038 lr: 0.02\n",
      "iteration: 37160 loss: 0.0053 lr: 0.02\n",
      "iteration: 37170 loss: 0.0058 lr: 0.02\n",
      "iteration: 37180 loss: 0.0055 lr: 0.02\n",
      "iteration: 37190 loss: 0.0048 lr: 0.02\n",
      "iteration: 37200 loss: 0.0056 lr: 0.02\n",
      "iteration: 37210 loss: 0.0052 lr: 0.02\n",
      "iteration: 37220 loss: 0.0069 lr: 0.02\n",
      "iteration: 37230 loss: 0.0042 lr: 0.02\n",
      "iteration: 37240 loss: 0.0063 lr: 0.02\n",
      "iteration: 37250 loss: 0.0050 lr: 0.02\n",
      "iteration: 37260 loss: 0.0051 lr: 0.02\n",
      "iteration: 37270 loss: 0.0052 lr: 0.02\n",
      "iteration: 37280 loss: 0.0044 lr: 0.02\n",
      "iteration: 37290 loss: 0.0060 lr: 0.02\n",
      "iteration: 37300 loss: 0.0056 lr: 0.02\n",
      "iteration: 37310 loss: 0.0051 lr: 0.02\n",
      "iteration: 37320 loss: 0.0061 lr: 0.02\n",
      "iteration: 37330 loss: 0.0050 lr: 0.02\n",
      "iteration: 37340 loss: 0.0055 lr: 0.02\n",
      "iteration: 37350 loss: 0.0052 lr: 0.02\n",
      "iteration: 37360 loss: 0.0052 lr: 0.02\n",
      "iteration: 37370 loss: 0.0048 lr: 0.02\n",
      "iteration: 37380 loss: 0.0055 lr: 0.02\n",
      "iteration: 37390 loss: 0.0039 lr: 0.02\n",
      "iteration: 37400 loss: 0.0059 lr: 0.02\n",
      "iteration: 37410 loss: 0.0056 lr: 0.02\n",
      "iteration: 37420 loss: 0.0064 lr: 0.02\n",
      "iteration: 37430 loss: 0.0046 lr: 0.02\n",
      "iteration: 37440 loss: 0.0058 lr: 0.02\n",
      "iteration: 37450 loss: 0.0052 lr: 0.02\n",
      "iteration: 37460 loss: 0.0057 lr: 0.02\n",
      "iteration: 37470 loss: 0.0061 lr: 0.02\n",
      "iteration: 37480 loss: 0.0047 lr: 0.02\n",
      "iteration: 37490 loss: 0.0063 lr: 0.02\n",
      "iteration: 37500 loss: 0.0050 lr: 0.02\n",
      "iteration: 37510 loss: 0.0059 lr: 0.02\n",
      "iteration: 37520 loss: 0.0059 lr: 0.02\n",
      "iteration: 37530 loss: 0.0048 lr: 0.02\n",
      "iteration: 37540 loss: 0.0046 lr: 0.02\n",
      "iteration: 37550 loss: 0.0064 lr: 0.02\n",
      "iteration: 37560 loss: 0.0059 lr: 0.02\n",
      "iteration: 37570 loss: 0.0054 lr: 0.02\n",
      "iteration: 37580 loss: 0.0047 lr: 0.02\n",
      "iteration: 37590 loss: 0.0044 lr: 0.02\n",
      "iteration: 37600 loss: 0.0057 lr: 0.02\n",
      "iteration: 37610 loss: 0.0054 lr: 0.02\n",
      "iteration: 37620 loss: 0.0043 lr: 0.02\n",
      "iteration: 37630 loss: 0.0050 lr: 0.02\n",
      "iteration: 37640 loss: 0.0055 lr: 0.02\n",
      "iteration: 37650 loss: 0.0057 lr: 0.02\n",
      "iteration: 37660 loss: 0.0061 lr: 0.02\n",
      "iteration: 37670 loss: 0.0055 lr: 0.02\n",
      "iteration: 37680 loss: 0.0051 lr: 0.02\n",
      "iteration: 37690 loss: 0.0058 lr: 0.02\n",
      "iteration: 37700 loss: 0.0054 lr: 0.02\n",
      "iteration: 37710 loss: 0.0046 lr: 0.02\n",
      "iteration: 37720 loss: 0.0047 lr: 0.02\n",
      "iteration: 37730 loss: 0.0044 lr: 0.02\n",
      "iteration: 37740 loss: 0.0043 lr: 0.02\n",
      "iteration: 37750 loss: 0.0053 lr: 0.02\n",
      "iteration: 37760 loss: 0.0058 lr: 0.02\n",
      "iteration: 37770 loss: 0.0048 lr: 0.02\n",
      "iteration: 37780 loss: 0.0049 lr: 0.02\n",
      "iteration: 37790 loss: 0.0050 lr: 0.02\n",
      "iteration: 37800 loss: 0.0057 lr: 0.02\n",
      "iteration: 37810 loss: 0.0049 lr: 0.02\n",
      "iteration: 37820 loss: 0.0050 lr: 0.02\n",
      "iteration: 37830 loss: 0.0050 lr: 0.02\n",
      "iteration: 37840 loss: 0.0050 lr: 0.02\n",
      "iteration: 37850 loss: 0.0054 lr: 0.02\n",
      "iteration: 37860 loss: 0.0036 lr: 0.02\n",
      "iteration: 37870 loss: 0.0062 lr: 0.02\n",
      "iteration: 37880 loss: 0.0048 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 37890 loss: 0.0049 lr: 0.02\n",
      "iteration: 37900 loss: 0.0040 lr: 0.02\n",
      "iteration: 37910 loss: 0.0059 lr: 0.02\n",
      "iteration: 37920 loss: 0.0064 lr: 0.02\n",
      "iteration: 37930 loss: 0.0048 lr: 0.02\n",
      "iteration: 37940 loss: 0.0061 lr: 0.02\n",
      "iteration: 37950 loss: 0.0056 lr: 0.02\n",
      "iteration: 37960 loss: 0.0047 lr: 0.02\n",
      "iteration: 37970 loss: 0.0049 lr: 0.02\n",
      "iteration: 37980 loss: 0.0046 lr: 0.02\n",
      "iteration: 37990 loss: 0.0043 lr: 0.02\n",
      "iteration: 38000 loss: 0.0046 lr: 0.02\n",
      "iteration: 38010 loss: 0.0040 lr: 0.02\n",
      "iteration: 38020 loss: 0.0048 lr: 0.02\n",
      "iteration: 38030 loss: 0.0061 lr: 0.02\n",
      "iteration: 38040 loss: 0.0062 lr: 0.02\n",
      "iteration: 38050 loss: 0.0048 lr: 0.02\n",
      "iteration: 38060 loss: 0.0056 lr: 0.02\n",
      "iteration: 38070 loss: 0.0047 lr: 0.02\n",
      "iteration: 38080 loss: 0.0048 lr: 0.02\n",
      "iteration: 38090 loss: 0.0057 lr: 0.02\n",
      "iteration: 38100 loss: 0.0045 lr: 0.02\n",
      "iteration: 38110 loss: 0.0054 lr: 0.02\n",
      "iteration: 38120 loss: 0.0054 lr: 0.02\n",
      "iteration: 38130 loss: 0.0059 lr: 0.02\n",
      "iteration: 38140 loss: 0.0058 lr: 0.02\n",
      "iteration: 38150 loss: 0.0049 lr: 0.02\n",
      "iteration: 38160 loss: 0.0051 lr: 0.02\n",
      "iteration: 38170 loss: 0.0042 lr: 0.02\n",
      "iteration: 38180 loss: 0.0057 lr: 0.02\n",
      "iteration: 38190 loss: 0.0041 lr: 0.02\n",
      "iteration: 38200 loss: 0.0061 lr: 0.02\n",
      "iteration: 38210 loss: 0.0056 lr: 0.02\n",
      "iteration: 38220 loss: 0.0044 lr: 0.02\n",
      "iteration: 38230 loss: 0.0049 lr: 0.02\n",
      "iteration: 38240 loss: 0.0049 lr: 0.02\n",
      "iteration: 38250 loss: 0.0055 lr: 0.02\n",
      "iteration: 38260 loss: 0.0056 lr: 0.02\n",
      "iteration: 38270 loss: 0.0044 lr: 0.02\n",
      "iteration: 38280 loss: 0.0045 lr: 0.02\n",
      "iteration: 38290 loss: 0.0054 lr: 0.02\n",
      "iteration: 38300 loss: 0.0047 lr: 0.02\n",
      "iteration: 38310 loss: 0.0069 lr: 0.02\n",
      "iteration: 38320 loss: 0.0052 lr: 0.02\n",
      "iteration: 38330 loss: 0.0058 lr: 0.02\n",
      "iteration: 38340 loss: 0.0056 lr: 0.02\n",
      "iteration: 38350 loss: 0.0045 lr: 0.02\n",
      "iteration: 38360 loss: 0.0052 lr: 0.02\n",
      "iteration: 38370 loss: 0.0065 lr: 0.02\n",
      "iteration: 38380 loss: 0.0054 lr: 0.02\n",
      "iteration: 38390 loss: 0.0051 lr: 0.02\n",
      "iteration: 38400 loss: 0.0042 lr: 0.02\n",
      "iteration: 38410 loss: 0.0057 lr: 0.02\n",
      "iteration: 38420 loss: 0.0049 lr: 0.02\n",
      "iteration: 38430 loss: 0.0053 lr: 0.02\n",
      "iteration: 38440 loss: 0.0055 lr: 0.02\n",
      "iteration: 38450 loss: 0.0047 lr: 0.02\n",
      "iteration: 38460 loss: 0.0051 lr: 0.02\n",
      "iteration: 38470 loss: 0.0050 lr: 0.02\n",
      "iteration: 38480 loss: 0.0067 lr: 0.02\n",
      "iteration: 38490 loss: 0.0048 lr: 0.02\n",
      "iteration: 38500 loss: 0.0058 lr: 0.02\n",
      "iteration: 38510 loss: 0.0043 lr: 0.02\n",
      "iteration: 38520 loss: 0.0046 lr: 0.02\n",
      "iteration: 38530 loss: 0.0047 lr: 0.02\n",
      "iteration: 38540 loss: 0.0054 lr: 0.02\n",
      "iteration: 38550 loss: 0.0051 lr: 0.02\n",
      "iteration: 38560 loss: 0.0062 lr: 0.02\n",
      "iteration: 38570 loss: 0.0060 lr: 0.02\n",
      "iteration: 38580 loss: 0.0055 lr: 0.02\n",
      "iteration: 38590 loss: 0.0066 lr: 0.02\n",
      "iteration: 38600 loss: 0.0052 lr: 0.02\n",
      "iteration: 38610 loss: 0.0058 lr: 0.02\n",
      "iteration: 38620 loss: 0.0064 lr: 0.02\n",
      "iteration: 38630 loss: 0.0050 lr: 0.02\n",
      "iteration: 38640 loss: 0.0049 lr: 0.02\n",
      "iteration: 38650 loss: 0.0055 lr: 0.02\n",
      "iteration: 38660 loss: 0.0061 lr: 0.02\n",
      "iteration: 38670 loss: 0.0061 lr: 0.02\n",
      "iteration: 38680 loss: 0.0050 lr: 0.02\n",
      "iteration: 38690 loss: 0.0066 lr: 0.02\n",
      "iteration: 38700 loss: 0.0054 lr: 0.02\n",
      "iteration: 38710 loss: 0.0058 lr: 0.02\n",
      "iteration: 38720 loss: 0.0059 lr: 0.02\n",
      "iteration: 38730 loss: 0.0049 lr: 0.02\n",
      "iteration: 38740 loss: 0.0049 lr: 0.02\n",
      "iteration: 38750 loss: 0.0050 lr: 0.02\n",
      "iteration: 38760 loss: 0.0050 lr: 0.02\n",
      "iteration: 38770 loss: 0.0051 lr: 0.02\n",
      "iteration: 38780 loss: 0.0057 lr: 0.02\n",
      "iteration: 38790 loss: 0.0054 lr: 0.02\n",
      "iteration: 38800 loss: 0.0066 lr: 0.02\n",
      "iteration: 38810 loss: 0.0058 lr: 0.02\n",
      "iteration: 38820 loss: 0.0050 lr: 0.02\n",
      "iteration: 38830 loss: 0.0067 lr: 0.02\n",
      "iteration: 38840 loss: 0.0046 lr: 0.02\n",
      "iteration: 38850 loss: 0.0067 lr: 0.02\n",
      "iteration: 38860 loss: 0.0056 lr: 0.02\n",
      "iteration: 38870 loss: 0.0045 lr: 0.02\n",
      "iteration: 38880 loss: 0.0057 lr: 0.02\n",
      "iteration: 38890 loss: 0.0064 lr: 0.02\n",
      "iteration: 38900 loss: 0.0048 lr: 0.02\n",
      "iteration: 38910 loss: 0.0044 lr: 0.02\n",
      "iteration: 38920 loss: 0.0043 lr: 0.02\n",
      "iteration: 38930 loss: 0.0059 lr: 0.02\n",
      "iteration: 38940 loss: 0.0066 lr: 0.02\n",
      "iteration: 38950 loss: 0.0043 lr: 0.02\n",
      "iteration: 38960 loss: 0.0064 lr: 0.02\n",
      "iteration: 38970 loss: 0.0049 lr: 0.02\n",
      "iteration: 38980 loss: 0.0051 lr: 0.02\n",
      "iteration: 38990 loss: 0.0042 lr: 0.02\n",
      "iteration: 39000 loss: 0.0051 lr: 0.02\n",
      "iteration: 39010 loss: 0.0046 lr: 0.02\n",
      "iteration: 39020 loss: 0.0051 lr: 0.02\n",
      "iteration: 39030 loss: 0.0062 lr: 0.02\n",
      "iteration: 39040 loss: 0.0060 lr: 0.02\n",
      "iteration: 39050 loss: 0.0059 lr: 0.02\n",
      "iteration: 39060 loss: 0.0045 lr: 0.02\n",
      "iteration: 39070 loss: 0.0063 lr: 0.02\n",
      "iteration: 39080 loss: 0.0058 lr: 0.02\n",
      "iteration: 39090 loss: 0.0047 lr: 0.02\n",
      "iteration: 39100 loss: 0.0043 lr: 0.02\n",
      "iteration: 39110 loss: 0.0064 lr: 0.02\n",
      "iteration: 39120 loss: 0.0048 lr: 0.02\n",
      "iteration: 39130 loss: 0.0044 lr: 0.02\n",
      "iteration: 39140 loss: 0.0071 lr: 0.02\n",
      "iteration: 39150 loss: 0.0058 lr: 0.02\n",
      "iteration: 39160 loss: 0.0054 lr: 0.02\n",
      "iteration: 39170 loss: 0.0054 lr: 0.02\n",
      "iteration: 39180 loss: 0.0056 lr: 0.02\n",
      "iteration: 39190 loss: 0.0056 lr: 0.02\n",
      "iteration: 39200 loss: 0.0059 lr: 0.02\n",
      "iteration: 39210 loss: 0.0055 lr: 0.02\n",
      "iteration: 39220 loss: 0.0056 lr: 0.02\n",
      "iteration: 39230 loss: 0.0049 lr: 0.02\n",
      "iteration: 39240 loss: 0.0048 lr: 0.02\n",
      "iteration: 39250 loss: 0.0050 lr: 0.02\n",
      "iteration: 39260 loss: 0.0050 lr: 0.02\n",
      "iteration: 39270 loss: 0.0061 lr: 0.02\n",
      "iteration: 39280 loss: 0.0069 lr: 0.02\n",
      "iteration: 39290 loss: 0.0053 lr: 0.02\n",
      "iteration: 39300 loss: 0.0048 lr: 0.02\n",
      "iteration: 39310 loss: 0.0052 lr: 0.02\n",
      "iteration: 39320 loss: 0.0045 lr: 0.02\n",
      "iteration: 39330 loss: 0.0044 lr: 0.02\n",
      "iteration: 39340 loss: 0.0050 lr: 0.02\n",
      "iteration: 39350 loss: 0.0048 lr: 0.02\n",
      "iteration: 39360 loss: 0.0051 lr: 0.02\n",
      "iteration: 39370 loss: 0.0044 lr: 0.02\n",
      "iteration: 39380 loss: 0.0042 lr: 0.02\n",
      "iteration: 39390 loss: 0.0050 lr: 0.02\n",
      "iteration: 39400 loss: 0.0047 lr: 0.02\n",
      "iteration: 39410 loss: 0.0058 lr: 0.02\n",
      "iteration: 39420 loss: 0.0055 lr: 0.02\n",
      "iteration: 39430 loss: 0.0048 lr: 0.02\n",
      "iteration: 39440 loss: 0.0052 lr: 0.02\n",
      "iteration: 39450 loss: 0.0049 lr: 0.02\n",
      "iteration: 39460 loss: 0.0060 lr: 0.02\n",
      "iteration: 39470 loss: 0.0069 lr: 0.02\n",
      "iteration: 39480 loss: 0.0053 lr: 0.02\n",
      "iteration: 39490 loss: 0.0049 lr: 0.02\n",
      "iteration: 39500 loss: 0.0045 lr: 0.02\n",
      "iteration: 39510 loss: 0.0056 lr: 0.02\n",
      "iteration: 39520 loss: 0.0041 lr: 0.02\n",
      "iteration: 39530 loss: 0.0057 lr: 0.02\n",
      "iteration: 39540 loss: 0.0052 lr: 0.02\n",
      "iteration: 39550 loss: 0.0041 lr: 0.02\n",
      "iteration: 39560 loss: 0.0057 lr: 0.02\n",
      "iteration: 39570 loss: 0.0055 lr: 0.02\n",
      "iteration: 39580 loss: 0.0054 lr: 0.02\n",
      "iteration: 39590 loss: 0.0042 lr: 0.02\n",
      "iteration: 39600 loss: 0.0047 lr: 0.02\n",
      "iteration: 39610 loss: 0.0044 lr: 0.02\n",
      "iteration: 39620 loss: 0.0042 lr: 0.02\n",
      "iteration: 39630 loss: 0.0054 lr: 0.02\n",
      "iteration: 39640 loss: 0.0053 lr: 0.02\n",
      "iteration: 39650 loss: 0.0057 lr: 0.02\n",
      "iteration: 39660 loss: 0.0048 lr: 0.02\n",
      "iteration: 39670 loss: 0.0049 lr: 0.02\n",
      "iteration: 39680 loss: 0.0040 lr: 0.02\n",
      "iteration: 39690 loss: 0.0051 lr: 0.02\n",
      "iteration: 39700 loss: 0.0068 lr: 0.02\n",
      "iteration: 39710 loss: 0.0054 lr: 0.02\n",
      "iteration: 39720 loss: 0.0053 lr: 0.02\n",
      "iteration: 39730 loss: 0.0043 lr: 0.02\n",
      "iteration: 39740 loss: 0.0043 lr: 0.02\n",
      "iteration: 39750 loss: 0.0049 lr: 0.02\n",
      "iteration: 39760 loss: 0.0061 lr: 0.02\n",
      "iteration: 39770 loss: 0.0043 lr: 0.02\n",
      "iteration: 39780 loss: 0.0047 lr: 0.02\n",
      "iteration: 39790 loss: 0.0061 lr: 0.02\n",
      "iteration: 39800 loss: 0.0056 lr: 0.02\n",
      "iteration: 39810 loss: 0.0057 lr: 0.02\n",
      "iteration: 39820 loss: 0.0045 lr: 0.02\n",
      "iteration: 39830 loss: 0.0054 lr: 0.02\n",
      "iteration: 39840 loss: 0.0050 lr: 0.02\n",
      "iteration: 39850 loss: 0.0051 lr: 0.02\n",
      "iteration: 39860 loss: 0.0057 lr: 0.02\n",
      "iteration: 39870 loss: 0.0063 lr: 0.02\n",
      "iteration: 39880 loss: 0.0051 lr: 0.02\n",
      "iteration: 39890 loss: 0.0044 lr: 0.02\n",
      "iteration: 39900 loss: 0.0052 lr: 0.02\n",
      "iteration: 39910 loss: 0.0054 lr: 0.02\n",
      "iteration: 39920 loss: 0.0051 lr: 0.02\n",
      "iteration: 39930 loss: 0.0048 lr: 0.02\n",
      "iteration: 39940 loss: 0.0052 lr: 0.02\n",
      "iteration: 39950 loss: 0.0049 lr: 0.02\n",
      "iteration: 39960 loss: 0.0050 lr: 0.02\n",
      "iteration: 39970 loss: 0.0048 lr: 0.02\n",
      "iteration: 39980 loss: 0.0054 lr: 0.02\n",
      "iteration: 39990 loss: 0.0058 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 40000 loss: 0.0056 lr: 0.02\n",
      "iteration: 40010 loss: 0.0045 lr: 0.02\n",
      "iteration: 40020 loss: 0.0048 lr: 0.02\n",
      "iteration: 40030 loss: 0.0050 lr: 0.02\n",
      "iteration: 40040 loss: 0.0038 lr: 0.02\n",
      "iteration: 40050 loss: 0.0055 lr: 0.02\n",
      "iteration: 40060 loss: 0.0053 lr: 0.02\n",
      "iteration: 40070 loss: 0.0051 lr: 0.02\n",
      "iteration: 40080 loss: 0.0059 lr: 0.02\n",
      "iteration: 40090 loss: 0.0037 lr: 0.02\n",
      "iteration: 40100 loss: 0.0045 lr: 0.02\n",
      "iteration: 40110 loss: 0.0047 lr: 0.02\n",
      "iteration: 40120 loss: 0.0051 lr: 0.02\n",
      "iteration: 40130 loss: 0.0035 lr: 0.02\n",
      "iteration: 40140 loss: 0.0041 lr: 0.02\n",
      "iteration: 40150 loss: 0.0063 lr: 0.02\n",
      "iteration: 40160 loss: 0.0047 lr: 0.02\n",
      "iteration: 40170 loss: 0.0048 lr: 0.02\n",
      "iteration: 40180 loss: 0.0044 lr: 0.02\n",
      "iteration: 40190 loss: 0.0047 lr: 0.02\n",
      "iteration: 40200 loss: 0.0057 lr: 0.02\n",
      "iteration: 40210 loss: 0.0041 lr: 0.02\n",
      "iteration: 40220 loss: 0.0046 lr: 0.02\n",
      "iteration: 40230 loss: 0.0046 lr: 0.02\n",
      "iteration: 40240 loss: 0.0049 lr: 0.02\n",
      "iteration: 40250 loss: 0.0057 lr: 0.02\n",
      "iteration: 40260 loss: 0.0054 lr: 0.02\n",
      "iteration: 40270 loss: 0.0046 lr: 0.02\n",
      "iteration: 40280 loss: 0.0049 lr: 0.02\n",
      "iteration: 40290 loss: 0.0048 lr: 0.02\n",
      "iteration: 40300 loss: 0.0049 lr: 0.02\n",
      "iteration: 40310 loss: 0.0045 lr: 0.02\n",
      "iteration: 40320 loss: 0.0040 lr: 0.02\n",
      "iteration: 40330 loss: 0.0045 lr: 0.02\n",
      "iteration: 40340 loss: 0.0034 lr: 0.02\n",
      "iteration: 40350 loss: 0.0051 lr: 0.02\n",
      "iteration: 40360 loss: 0.0049 lr: 0.02\n",
      "iteration: 40370 loss: 0.0045 lr: 0.02\n",
      "iteration: 40380 loss: 0.0053 lr: 0.02\n",
      "iteration: 40390 loss: 0.0057 lr: 0.02\n",
      "iteration: 40400 loss: 0.0049 lr: 0.02\n",
      "iteration: 40410 loss: 0.0054 lr: 0.02\n",
      "iteration: 40420 loss: 0.0048 lr: 0.02\n",
      "iteration: 40430 loss: 0.0046 lr: 0.02\n",
      "iteration: 40440 loss: 0.0047 lr: 0.02\n",
      "iteration: 40450 loss: 0.0049 lr: 0.02\n",
      "iteration: 40460 loss: 0.0057 lr: 0.02\n",
      "iteration: 40470 loss: 0.0056 lr: 0.02\n",
      "iteration: 40480 loss: 0.0058 lr: 0.02\n",
      "iteration: 40490 loss: 0.0053 lr: 0.02\n",
      "iteration: 40500 loss: 0.0055 lr: 0.02\n",
      "iteration: 40510 loss: 0.0054 lr: 0.02\n",
      "iteration: 40520 loss: 0.0044 lr: 0.02\n",
      "iteration: 40530 loss: 0.0047 lr: 0.02\n",
      "iteration: 40540 loss: 0.0048 lr: 0.02\n",
      "iteration: 40550 loss: 0.0044 lr: 0.02\n",
      "iteration: 40560 loss: 0.0047 lr: 0.02\n",
      "iteration: 40570 loss: 0.0052 lr: 0.02\n",
      "iteration: 40580 loss: 0.0046 lr: 0.02\n",
      "iteration: 40590 loss: 0.0038 lr: 0.02\n",
      "iteration: 40600 loss: 0.0050 lr: 0.02\n",
      "iteration: 40610 loss: 0.0065 lr: 0.02\n",
      "iteration: 40620 loss: 0.0056 lr: 0.02\n",
      "iteration: 40630 loss: 0.0048 lr: 0.02\n",
      "iteration: 40640 loss: 0.0038 lr: 0.02\n",
      "iteration: 40650 loss: 0.0055 lr: 0.02\n",
      "iteration: 40660 loss: 0.0047 lr: 0.02\n",
      "iteration: 40670 loss: 0.0052 lr: 0.02\n",
      "iteration: 40680 loss: 0.0054 lr: 0.02\n",
      "iteration: 40690 loss: 0.0056 lr: 0.02\n",
      "iteration: 40700 loss: 0.0051 lr: 0.02\n",
      "iteration: 40710 loss: 0.0048 lr: 0.02\n",
      "iteration: 40720 loss: 0.0052 lr: 0.02\n",
      "iteration: 40730 loss: 0.0047 lr: 0.02\n",
      "iteration: 40740 loss: 0.0058 lr: 0.02\n",
      "iteration: 40750 loss: 0.0039 lr: 0.02\n",
      "iteration: 40760 loss: 0.0053 lr: 0.02\n",
      "iteration: 40770 loss: 0.0048 lr: 0.02\n",
      "iteration: 40780 loss: 0.0050 lr: 0.02\n",
      "iteration: 40790 loss: 0.0047 lr: 0.02\n",
      "iteration: 40800 loss: 0.0052 lr: 0.02\n",
      "iteration: 40810 loss: 0.0048 lr: 0.02\n",
      "iteration: 40820 loss: 0.0044 lr: 0.02\n",
      "iteration: 40830 loss: 0.0043 lr: 0.02\n",
      "iteration: 40840 loss: 0.0054 lr: 0.02\n",
      "iteration: 40850 loss: 0.0050 lr: 0.02\n",
      "iteration: 40860 loss: 0.0060 lr: 0.02\n",
      "iteration: 40870 loss: 0.0051 lr: 0.02\n",
      "iteration: 40880 loss: 0.0055 lr: 0.02\n",
      "iteration: 40890 loss: 0.0060 lr: 0.02\n",
      "iteration: 40900 loss: 0.0054 lr: 0.02\n",
      "iteration: 40910 loss: 0.0045 lr: 0.02\n",
      "iteration: 40920 loss: 0.0045 lr: 0.02\n",
      "iteration: 40930 loss: 0.0044 lr: 0.02\n",
      "iteration: 40940 loss: 0.0061 lr: 0.02\n",
      "iteration: 40950 loss: 0.0053 lr: 0.02\n",
      "iteration: 40960 loss: 0.0042 lr: 0.02\n",
      "iteration: 40970 loss: 0.0038 lr: 0.02\n",
      "iteration: 40980 loss: 0.0063 lr: 0.02\n",
      "iteration: 40990 loss: 0.0043 lr: 0.02\n",
      "iteration: 41000 loss: 0.0044 lr: 0.02\n",
      "iteration: 41010 loss: 0.0039 lr: 0.02\n",
      "iteration: 41020 loss: 0.0043 lr: 0.02\n",
      "iteration: 41030 loss: 0.0047 lr: 0.02\n",
      "iteration: 41040 loss: 0.0054 lr: 0.02\n",
      "iteration: 41050 loss: 0.0042 lr: 0.02\n",
      "iteration: 41060 loss: 0.0039 lr: 0.02\n",
      "iteration: 41070 loss: 0.0053 lr: 0.02\n",
      "iteration: 41080 loss: 0.0042 lr: 0.02\n",
      "iteration: 41090 loss: 0.0043 lr: 0.02\n",
      "iteration: 41100 loss: 0.0041 lr: 0.02\n",
      "iteration: 41110 loss: 0.0051 lr: 0.02\n",
      "iteration: 41120 loss: 0.0046 lr: 0.02\n",
      "iteration: 41130 loss: 0.0058 lr: 0.02\n",
      "iteration: 41140 loss: 0.0044 lr: 0.02\n",
      "iteration: 41150 loss: 0.0044 lr: 0.02\n",
      "iteration: 41160 loss: 0.0047 lr: 0.02\n",
      "iteration: 41170 loss: 0.0050 lr: 0.02\n",
      "iteration: 41180 loss: 0.0051 lr: 0.02\n",
      "iteration: 41190 loss: 0.0049 lr: 0.02\n",
      "iteration: 41200 loss: 0.0053 lr: 0.02\n",
      "iteration: 41210 loss: 0.0065 lr: 0.02\n",
      "iteration: 41220 loss: 0.0050 lr: 0.02\n",
      "iteration: 41230 loss: 0.0048 lr: 0.02\n",
      "iteration: 41240 loss: 0.0044 lr: 0.02\n",
      "iteration: 41250 loss: 0.0046 lr: 0.02\n",
      "iteration: 41260 loss: 0.0048 lr: 0.02\n",
      "iteration: 41270 loss: 0.0069 lr: 0.02\n",
      "iteration: 41280 loss: 0.0048 lr: 0.02\n",
      "iteration: 41290 loss: 0.0053 lr: 0.02\n",
      "iteration: 41300 loss: 0.0050 lr: 0.02\n",
      "iteration: 41310 loss: 0.0044 lr: 0.02\n",
      "iteration: 41320 loss: 0.0049 lr: 0.02\n",
      "iteration: 41330 loss: 0.0043 lr: 0.02\n",
      "iteration: 41340 loss: 0.0058 lr: 0.02\n",
      "iteration: 41350 loss: 0.0049 lr: 0.02\n",
      "iteration: 41360 loss: 0.0040 lr: 0.02\n",
      "iteration: 41370 loss: 0.0053 lr: 0.02\n",
      "iteration: 41380 loss: 0.0053 lr: 0.02\n",
      "iteration: 41390 loss: 0.0047 lr: 0.02\n",
      "iteration: 41400 loss: 0.0040 lr: 0.02\n",
      "iteration: 41410 loss: 0.0054 lr: 0.02\n",
      "iteration: 41420 loss: 0.0050 lr: 0.02\n",
      "iteration: 41430 loss: 0.0046 lr: 0.02\n",
      "iteration: 41440 loss: 0.0047 lr: 0.02\n",
      "iteration: 41450 loss: 0.0048 lr: 0.02\n",
      "iteration: 41460 loss: 0.0054 lr: 0.02\n",
      "iteration: 41470 loss: 0.0047 lr: 0.02\n",
      "iteration: 41480 loss: 0.0062 lr: 0.02\n",
      "iteration: 41490 loss: 0.0047 lr: 0.02\n",
      "iteration: 41500 loss: 0.0050 lr: 0.02\n",
      "iteration: 41510 loss: 0.0048 lr: 0.02\n",
      "iteration: 41520 loss: 0.0042 lr: 0.02\n",
      "iteration: 41530 loss: 0.0033 lr: 0.02\n",
      "iteration: 41540 loss: 0.0054 lr: 0.02\n",
      "iteration: 41550 loss: 0.0063 lr: 0.02\n",
      "iteration: 41560 loss: 0.0057 lr: 0.02\n",
      "iteration: 41570 loss: 0.0050 lr: 0.02\n",
      "iteration: 41580 loss: 0.0047 lr: 0.02\n",
      "iteration: 41590 loss: 0.0062 lr: 0.02\n",
      "iteration: 41600 loss: 0.0054 lr: 0.02\n",
      "iteration: 41610 loss: 0.0056 lr: 0.02\n",
      "iteration: 41620 loss: 0.0048 lr: 0.02\n",
      "iteration: 41630 loss: 0.0050 lr: 0.02\n",
      "iteration: 41640 loss: 0.0053 lr: 0.02\n",
      "iteration: 41650 loss: 0.0048 lr: 0.02\n",
      "iteration: 41660 loss: 0.0046 lr: 0.02\n",
      "iteration: 41670 loss: 0.0056 lr: 0.02\n",
      "iteration: 41680 loss: 0.0045 lr: 0.02\n",
      "iteration: 41690 loss: 0.0054 lr: 0.02\n",
      "iteration: 41700 loss: 0.0046 lr: 0.02\n",
      "iteration: 41710 loss: 0.0040 lr: 0.02\n",
      "iteration: 41720 loss: 0.0043 lr: 0.02\n",
      "iteration: 41730 loss: 0.0046 lr: 0.02\n",
      "iteration: 41740 loss: 0.0044 lr: 0.02\n",
      "iteration: 41750 loss: 0.0049 lr: 0.02\n",
      "iteration: 41760 loss: 0.0047 lr: 0.02\n",
      "iteration: 41770 loss: 0.0039 lr: 0.02\n",
      "iteration: 41780 loss: 0.0053 lr: 0.02\n",
      "iteration: 41790 loss: 0.0045 lr: 0.02\n",
      "iteration: 41800 loss: 0.0041 lr: 0.02\n",
      "iteration: 41810 loss: 0.0063 lr: 0.02\n",
      "iteration: 41820 loss: 0.0060 lr: 0.02\n",
      "iteration: 41830 loss: 0.0048 lr: 0.02\n",
      "iteration: 41840 loss: 0.0047 lr: 0.02\n",
      "iteration: 41850 loss: 0.0049 lr: 0.02\n",
      "iteration: 41860 loss: 0.0044 lr: 0.02\n",
      "iteration: 41870 loss: 0.0046 lr: 0.02\n",
      "iteration: 41880 loss: 0.0043 lr: 0.02\n",
      "iteration: 41890 loss: 0.0044 lr: 0.02\n",
      "iteration: 41900 loss: 0.0038 lr: 0.02\n",
      "iteration: 41910 loss: 0.0046 lr: 0.02\n",
      "iteration: 41920 loss: 0.0048 lr: 0.02\n",
      "iteration: 41930 loss: 0.0050 lr: 0.02\n",
      "iteration: 41940 loss: 0.0049 lr: 0.02\n",
      "iteration: 41950 loss: 0.0041 lr: 0.02\n",
      "iteration: 41960 loss: 0.0066 lr: 0.02\n",
      "iteration: 41970 loss: 0.0044 lr: 0.02\n",
      "iteration: 41980 loss: 0.0038 lr: 0.02\n",
      "iteration: 41990 loss: 0.0046 lr: 0.02\n",
      "iteration: 42000 loss: 0.0054 lr: 0.02\n",
      "iteration: 42010 loss: 0.0040 lr: 0.02\n",
      "iteration: 42020 loss: 0.0047 lr: 0.02\n",
      "iteration: 42030 loss: 0.0047 lr: 0.02\n",
      "iteration: 42040 loss: 0.0042 lr: 0.02\n",
      "iteration: 42050 loss: 0.0037 lr: 0.02\n",
      "iteration: 42060 loss: 0.0039 lr: 0.02\n",
      "iteration: 42070 loss: 0.0057 lr: 0.02\n",
      "iteration: 42080 loss: 0.0048 lr: 0.02\n",
      "iteration: 42090 loss: 0.0041 lr: 0.02\n",
      "iteration: 42100 loss: 0.0042 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 42110 loss: 0.0048 lr: 0.02\n",
      "iteration: 42120 loss: 0.0044 lr: 0.02\n",
      "iteration: 42130 loss: 0.0050 lr: 0.02\n",
      "iteration: 42140 loss: 0.0052 lr: 0.02\n",
      "iteration: 42150 loss: 0.0051 lr: 0.02\n",
      "iteration: 42160 loss: 0.0058 lr: 0.02\n",
      "iteration: 42170 loss: 0.0050 lr: 0.02\n",
      "iteration: 42180 loss: 0.0034 lr: 0.02\n",
      "iteration: 42190 loss: 0.0050 lr: 0.02\n",
      "iteration: 42200 loss: 0.0048 lr: 0.02\n",
      "iteration: 42210 loss: 0.0048 lr: 0.02\n",
      "iteration: 42220 loss: 0.0058 lr: 0.02\n",
      "iteration: 42230 loss: 0.0044 lr: 0.02\n",
      "iteration: 42240 loss: 0.0050 lr: 0.02\n",
      "iteration: 42250 loss: 0.0049 lr: 0.02\n",
      "iteration: 42260 loss: 0.0048 lr: 0.02\n",
      "iteration: 42270 loss: 0.0042 lr: 0.02\n",
      "iteration: 42280 loss: 0.0045 lr: 0.02\n",
      "iteration: 42290 loss: 0.0043 lr: 0.02\n",
      "iteration: 42300 loss: 0.0053 lr: 0.02\n",
      "iteration: 42310 loss: 0.0045 lr: 0.02\n",
      "iteration: 42320 loss: 0.0061 lr: 0.02\n",
      "iteration: 42330 loss: 0.0052 lr: 0.02\n",
      "iteration: 42340 loss: 0.0044 lr: 0.02\n",
      "iteration: 42350 loss: 0.0047 lr: 0.02\n",
      "iteration: 42360 loss: 0.0043 lr: 0.02\n",
      "iteration: 42370 loss: 0.0045 lr: 0.02\n",
      "iteration: 42380 loss: 0.0051 lr: 0.02\n",
      "iteration: 42390 loss: 0.0084 lr: 0.02\n",
      "iteration: 42400 loss: 0.0063 lr: 0.02\n",
      "iteration: 42410 loss: 0.0050 lr: 0.02\n",
      "iteration: 42420 loss: 0.0056 lr: 0.02\n",
      "iteration: 42430 loss: 0.0057 lr: 0.02\n",
      "iteration: 42440 loss: 0.0051 lr: 0.02\n",
      "iteration: 42450 loss: 0.0053 lr: 0.02\n",
      "iteration: 42460 loss: 0.0065 lr: 0.02\n",
      "iteration: 42470 loss: 0.0051 lr: 0.02\n",
      "iteration: 42480 loss: 0.0051 lr: 0.02\n",
      "iteration: 42490 loss: 0.0059 lr: 0.02\n",
      "iteration: 42500 loss: 0.0041 lr: 0.02\n",
      "iteration: 42510 loss: 0.0043 lr: 0.02\n",
      "iteration: 42520 loss: 0.0045 lr: 0.02\n",
      "iteration: 42530 loss: 0.0042 lr: 0.02\n",
      "iteration: 42540 loss: 0.0062 lr: 0.02\n",
      "iteration: 42550 loss: 0.0049 lr: 0.02\n",
      "iteration: 42560 loss: 0.0050 lr: 0.02\n",
      "iteration: 42570 loss: 0.0052 lr: 0.02\n",
      "iteration: 42580 loss: 0.0052 lr: 0.02\n",
      "iteration: 42590 loss: 0.0041 lr: 0.02\n",
      "iteration: 42600 loss: 0.0058 lr: 0.02\n",
      "iteration: 42610 loss: 0.0046 lr: 0.02\n",
      "iteration: 42620 loss: 0.0057 lr: 0.02\n",
      "iteration: 42630 loss: 0.0058 lr: 0.02\n",
      "iteration: 42640 loss: 0.0058 lr: 0.02\n",
      "iteration: 42650 loss: 0.0050 lr: 0.02\n",
      "iteration: 42660 loss: 0.0047 lr: 0.02\n",
      "iteration: 42670 loss: 0.0065 lr: 0.02\n",
      "iteration: 42680 loss: 0.0041 lr: 0.02\n",
      "iteration: 42690 loss: 0.0040 lr: 0.02\n",
      "iteration: 42700 loss: 0.0047 lr: 0.02\n",
      "iteration: 42710 loss: 0.0045 lr: 0.02\n",
      "iteration: 42720 loss: 0.0057 lr: 0.02\n",
      "iteration: 42730 loss: 0.0043 lr: 0.02\n",
      "iteration: 42740 loss: 0.0048 lr: 0.02\n",
      "iteration: 42750 loss: 0.0056 lr: 0.02\n",
      "iteration: 42760 loss: 0.0053 lr: 0.02\n",
      "iteration: 42770 loss: 0.0045 lr: 0.02\n",
      "iteration: 42780 loss: 0.0042 lr: 0.02\n",
      "iteration: 42790 loss: 0.0051 lr: 0.02\n",
      "iteration: 42800 loss: 0.0041 lr: 0.02\n",
      "iteration: 42810 loss: 0.0045 lr: 0.02\n",
      "iteration: 42820 loss: 0.0040 lr: 0.02\n",
      "iteration: 42830 loss: 0.0043 lr: 0.02\n",
      "iteration: 42840 loss: 0.0046 lr: 0.02\n",
      "iteration: 42850 loss: 0.0039 lr: 0.02\n",
      "iteration: 42860 loss: 0.0044 lr: 0.02\n",
      "iteration: 42870 loss: 0.0039 lr: 0.02\n",
      "iteration: 42880 loss: 0.0054 lr: 0.02\n",
      "iteration: 42890 loss: 0.0041 lr: 0.02\n",
      "iteration: 42900 loss: 0.0050 lr: 0.02\n",
      "iteration: 42910 loss: 0.0042 lr: 0.02\n",
      "iteration: 42920 loss: 0.0040 lr: 0.02\n",
      "iteration: 42930 loss: 0.0054 lr: 0.02\n",
      "iteration: 42940 loss: 0.0043 lr: 0.02\n",
      "iteration: 42950 loss: 0.0047 lr: 0.02\n",
      "iteration: 42960 loss: 0.0048 lr: 0.02\n",
      "iteration: 42970 loss: 0.0048 lr: 0.02\n",
      "iteration: 42980 loss: 0.0047 lr: 0.02\n",
      "iteration: 42990 loss: 0.0055 lr: 0.02\n",
      "iteration: 43000 loss: 0.0048 lr: 0.02\n",
      "iteration: 43010 loss: 0.0048 lr: 0.02\n",
      "iteration: 43020 loss: 0.0055 lr: 0.02\n",
      "iteration: 43030 loss: 0.0053 lr: 0.02\n",
      "iteration: 43040 loss: 0.0051 lr: 0.02\n",
      "iteration: 43050 loss: 0.0058 lr: 0.02\n",
      "iteration: 43060 loss: 0.0041 lr: 0.02\n",
      "iteration: 43070 loss: 0.0056 lr: 0.02\n",
      "iteration: 43080 loss: 0.0037 lr: 0.02\n",
      "iteration: 43090 loss: 0.0049 lr: 0.02\n",
      "iteration: 43100 loss: 0.0047 lr: 0.02\n",
      "iteration: 43110 loss: 0.0054 lr: 0.02\n",
      "iteration: 43120 loss: 0.0057 lr: 0.02\n",
      "iteration: 43130 loss: 0.0038 lr: 0.02\n",
      "iteration: 43140 loss: 0.0046 lr: 0.02\n",
      "iteration: 43150 loss: 0.0060 lr: 0.02\n",
      "iteration: 43160 loss: 0.0049 lr: 0.02\n",
      "iteration: 43170 loss: 0.0042 lr: 0.02\n",
      "iteration: 43180 loss: 0.0043 lr: 0.02\n",
      "iteration: 43190 loss: 0.0048 lr: 0.02\n",
      "iteration: 43200 loss: 0.0035 lr: 0.02\n",
      "iteration: 43210 loss: 0.0039 lr: 0.02\n",
      "iteration: 43220 loss: 0.0043 lr: 0.02\n",
      "iteration: 43230 loss: 0.0043 lr: 0.02\n",
      "iteration: 43240 loss: 0.0043 lr: 0.02\n",
      "iteration: 43250 loss: 0.0042 lr: 0.02\n",
      "iteration: 43260 loss: 0.0050 lr: 0.02\n",
      "iteration: 43270 loss: 0.0045 lr: 0.02\n",
      "iteration: 43280 loss: 0.0051 lr: 0.02\n",
      "iteration: 43290 loss: 0.0062 lr: 0.02\n",
      "iteration: 43300 loss: 0.0045 lr: 0.02\n",
      "iteration: 43310 loss: 0.0040 lr: 0.02\n",
      "iteration: 43320 loss: 0.0039 lr: 0.02\n",
      "iteration: 43330 loss: 0.0052 lr: 0.02\n",
      "iteration: 43340 loss: 0.0053 lr: 0.02\n",
      "iteration: 43350 loss: 0.0046 lr: 0.02\n",
      "iteration: 43360 loss: 0.0051 lr: 0.02\n",
      "iteration: 43370 loss: 0.0053 lr: 0.02\n",
      "iteration: 43380 loss: 0.0037 lr: 0.02\n",
      "iteration: 43390 loss: 0.0043 lr: 0.02\n",
      "iteration: 43400 loss: 0.0044 lr: 0.02\n",
      "iteration: 43410 loss: 0.0043 lr: 0.02\n",
      "iteration: 43420 loss: 0.0050 lr: 0.02\n",
      "iteration: 43430 loss: 0.0050 lr: 0.02\n",
      "iteration: 43440 loss: 0.0062 lr: 0.02\n",
      "iteration: 43450 loss: 0.0055 lr: 0.02\n",
      "iteration: 43460 loss: 0.0046 lr: 0.02\n",
      "iteration: 43470 loss: 0.0049 lr: 0.02\n",
      "iteration: 43480 loss: 0.0045 lr: 0.02\n",
      "iteration: 43490 loss: 0.0052 lr: 0.02\n",
      "iteration: 43500 loss: 0.0051 lr: 0.02\n",
      "iteration: 43510 loss: 0.0039 lr: 0.02\n",
      "iteration: 43520 loss: 0.0052 lr: 0.02\n",
      "iteration: 43530 loss: 0.0045 lr: 0.02\n",
      "iteration: 43540 loss: 0.0046 lr: 0.02\n",
      "iteration: 43550 loss: 0.0047 lr: 0.02\n",
      "iteration: 43560 loss: 0.0046 lr: 0.02\n",
      "iteration: 43570 loss: 0.0044 lr: 0.02\n",
      "iteration: 43580 loss: 0.0044 lr: 0.02\n",
      "iteration: 43590 loss: 0.0048 lr: 0.02\n",
      "iteration: 43600 loss: 0.0038 lr: 0.02\n",
      "iteration: 43610 loss: 0.0040 lr: 0.02\n",
      "iteration: 43620 loss: 0.0034 lr: 0.02\n",
      "iteration: 43630 loss: 0.0043 lr: 0.02\n",
      "iteration: 43640 loss: 0.0057 lr: 0.02\n",
      "iteration: 43650 loss: 0.0051 lr: 0.02\n",
      "iteration: 43660 loss: 0.0050 lr: 0.02\n",
      "iteration: 43670 loss: 0.0049 lr: 0.02\n",
      "iteration: 43680 loss: 0.0045 lr: 0.02\n",
      "iteration: 43690 loss: 0.0055 lr: 0.02\n",
      "iteration: 43700 loss: 0.0044 lr: 0.02\n",
      "iteration: 43710 loss: 0.0051 lr: 0.02\n",
      "iteration: 43720 loss: 0.0053 lr: 0.02\n",
      "iteration: 43730 loss: 0.0064 lr: 0.02\n",
      "iteration: 43740 loss: 0.0046 lr: 0.02\n",
      "iteration: 43750 loss: 0.0049 lr: 0.02\n",
      "iteration: 43760 loss: 0.0058 lr: 0.02\n",
      "iteration: 43770 loss: 0.0044 lr: 0.02\n",
      "iteration: 43780 loss: 0.0045 lr: 0.02\n",
      "iteration: 43790 loss: 0.0043 lr: 0.02\n",
      "iteration: 43800 loss: 0.0041 lr: 0.02\n",
      "iteration: 43810 loss: 0.0064 lr: 0.02\n",
      "iteration: 43820 loss: 0.0058 lr: 0.02\n",
      "iteration: 43830 loss: 0.0045 lr: 0.02\n",
      "iteration: 43840 loss: 0.0035 lr: 0.02\n",
      "iteration: 43850 loss: 0.0049 lr: 0.02\n",
      "iteration: 43860 loss: 0.0045 lr: 0.02\n",
      "iteration: 43870 loss: 0.0056 lr: 0.02\n",
      "iteration: 43880 loss: 0.0048 lr: 0.02\n",
      "iteration: 43890 loss: 0.0047 lr: 0.02\n",
      "iteration: 43900 loss: 0.0041 lr: 0.02\n",
      "iteration: 43910 loss: 0.0047 lr: 0.02\n",
      "iteration: 43920 loss: 0.0047 lr: 0.02\n",
      "iteration: 43930 loss: 0.0042 lr: 0.02\n",
      "iteration: 43940 loss: 0.0047 lr: 0.02\n",
      "iteration: 43950 loss: 0.0042 lr: 0.02\n",
      "iteration: 43960 loss: 0.0051 lr: 0.02\n",
      "iteration: 43970 loss: 0.0043 lr: 0.02\n",
      "iteration: 43980 loss: 0.0062 lr: 0.02\n",
      "iteration: 43990 loss: 0.0057 lr: 0.02\n",
      "iteration: 44000 loss: 0.0049 lr: 0.02\n",
      "iteration: 44010 loss: 0.0039 lr: 0.02\n",
      "iteration: 44020 loss: 0.0055 lr: 0.02\n",
      "iteration: 44030 loss: 0.0041 lr: 0.02\n",
      "iteration: 44040 loss: 0.0061 lr: 0.02\n",
      "iteration: 44050 loss: 0.0050 lr: 0.02\n",
      "iteration: 44060 loss: 0.0047 lr: 0.02\n",
      "iteration: 44070 loss: 0.0058 lr: 0.02\n",
      "iteration: 44080 loss: 0.0053 lr: 0.02\n",
      "iteration: 44090 loss: 0.0050 lr: 0.02\n",
      "iteration: 44100 loss: 0.0050 lr: 0.02\n",
      "iteration: 44110 loss: 0.0060 lr: 0.02\n",
      "iteration: 44120 loss: 0.0058 lr: 0.02\n",
      "iteration: 44130 loss: 0.0054 lr: 0.02\n",
      "iteration: 44140 loss: 0.0065 lr: 0.02\n",
      "iteration: 44150 loss: 0.0043 lr: 0.02\n",
      "iteration: 44160 loss: 0.0045 lr: 0.02\n",
      "iteration: 44170 loss: 0.0045 lr: 0.02\n",
      "iteration: 44180 loss: 0.0060 lr: 0.02\n",
      "iteration: 44190 loss: 0.0049 lr: 0.02\n",
      "iteration: 44200 loss: 0.0047 lr: 0.02\n",
      "iteration: 44210 loss: 0.0056 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 44220 loss: 0.0044 lr: 0.02\n",
      "iteration: 44230 loss: 0.0058 lr: 0.02\n",
      "iteration: 44240 loss: 0.0044 lr: 0.02\n",
      "iteration: 44250 loss: 0.0053 lr: 0.02\n",
      "iteration: 44260 loss: 0.0048 lr: 0.02\n",
      "iteration: 44270 loss: 0.0052 lr: 0.02\n",
      "iteration: 44280 loss: 0.0065 lr: 0.02\n",
      "iteration: 44290 loss: 0.0061 lr: 0.02\n",
      "iteration: 44300 loss: 0.0042 lr: 0.02\n",
      "iteration: 44310 loss: 0.0050 lr: 0.02\n",
      "iteration: 44320 loss: 0.0052 lr: 0.02\n",
      "iteration: 44330 loss: 0.0036 lr: 0.02\n",
      "iteration: 44340 loss: 0.0058 lr: 0.02\n",
      "iteration: 44350 loss: 0.0048 lr: 0.02\n",
      "iteration: 44360 loss: 0.0040 lr: 0.02\n",
      "iteration: 44370 loss: 0.0055 lr: 0.02\n",
      "iteration: 44380 loss: 0.0050 lr: 0.02\n",
      "iteration: 44390 loss: 0.0043 lr: 0.02\n",
      "iteration: 44400 loss: 0.0050 lr: 0.02\n",
      "iteration: 44410 loss: 0.0049 lr: 0.02\n",
      "iteration: 44420 loss: 0.0038 lr: 0.02\n",
      "iteration: 44430 loss: 0.0036 lr: 0.02\n",
      "iteration: 44440 loss: 0.0059 lr: 0.02\n",
      "iteration: 44450 loss: 0.0045 lr: 0.02\n",
      "iteration: 44460 loss: 0.0032 lr: 0.02\n",
      "iteration: 44470 loss: 0.0049 lr: 0.02\n",
      "iteration: 44480 loss: 0.0047 lr: 0.02\n",
      "iteration: 44490 loss: 0.0045 lr: 0.02\n",
      "iteration: 44500 loss: 0.0043 lr: 0.02\n",
      "iteration: 44510 loss: 0.0047 lr: 0.02\n",
      "iteration: 44520 loss: 0.0049 lr: 0.02\n",
      "iteration: 44530 loss: 0.0049 lr: 0.02\n",
      "iteration: 44540 loss: 0.0046 lr: 0.02\n",
      "iteration: 44550 loss: 0.0054 lr: 0.02\n",
      "iteration: 44560 loss: 0.0034 lr: 0.02\n",
      "iteration: 44570 loss: 0.0050 lr: 0.02\n",
      "iteration: 44580 loss: 0.0056 lr: 0.02\n",
      "iteration: 44590 loss: 0.0056 lr: 0.02\n",
      "iteration: 44600 loss: 0.0055 lr: 0.02\n",
      "iteration: 44610 loss: 0.0055 lr: 0.02\n",
      "iteration: 44620 loss: 0.0055 lr: 0.02\n",
      "iteration: 44630 loss: 0.0062 lr: 0.02\n",
      "iteration: 44640 loss: 0.0054 lr: 0.02\n",
      "iteration: 44650 loss: 0.0046 lr: 0.02\n",
      "iteration: 44660 loss: 0.0041 lr: 0.02\n",
      "iteration: 44670 loss: 0.0048 lr: 0.02\n",
      "iteration: 44680 loss: 0.0041 lr: 0.02\n",
      "iteration: 44690 loss: 0.0043 lr: 0.02\n",
      "iteration: 44700 loss: 0.0034 lr: 0.02\n",
      "iteration: 44710 loss: 0.0037 lr: 0.02\n",
      "iteration: 44720 loss: 0.0061 lr: 0.02\n",
      "iteration: 44730 loss: 0.0061 lr: 0.02\n",
      "iteration: 44740 loss: 0.0047 lr: 0.02\n",
      "iteration: 44750 loss: 0.0040 lr: 0.02\n",
      "iteration: 44760 loss: 0.0036 lr: 0.02\n",
      "iteration: 44770 loss: 0.0046 lr: 0.02\n",
      "iteration: 44780 loss: 0.0039 lr: 0.02\n",
      "iteration: 44790 loss: 0.0042 lr: 0.02\n",
      "iteration: 44800 loss: 0.0040 lr: 0.02\n",
      "iteration: 44810 loss: 0.0041 lr: 0.02\n",
      "iteration: 44820 loss: 0.0048 lr: 0.02\n",
      "iteration: 44830 loss: 0.0041 lr: 0.02\n",
      "iteration: 44840 loss: 0.0050 lr: 0.02\n",
      "iteration: 44850 loss: 0.0059 lr: 0.02\n",
      "iteration: 44860 loss: 0.0040 lr: 0.02\n",
      "iteration: 44870 loss: 0.0048 lr: 0.02\n",
      "iteration: 44880 loss: 0.0055 lr: 0.02\n",
      "iteration: 44890 loss: 0.0051 lr: 0.02\n",
      "iteration: 44900 loss: 0.0053 lr: 0.02\n",
      "iteration: 44910 loss: 0.0034 lr: 0.02\n",
      "iteration: 44920 loss: 0.0049 lr: 0.02\n",
      "iteration: 44930 loss: 0.0041 lr: 0.02\n",
      "iteration: 44940 loss: 0.0047 lr: 0.02\n",
      "iteration: 44950 loss: 0.0047 lr: 0.02\n",
      "iteration: 44960 loss: 0.0048 lr: 0.02\n",
      "iteration: 44970 loss: 0.0046 lr: 0.02\n",
      "iteration: 44980 loss: 0.0047 lr: 0.02\n",
      "iteration: 44990 loss: 0.0048 lr: 0.02\n",
      "iteration: 45000 loss: 0.0052 lr: 0.02\n",
      "iteration: 45010 loss: 0.0048 lr: 0.02\n",
      "iteration: 45020 loss: 0.0038 lr: 0.02\n",
      "iteration: 45030 loss: 0.0055 lr: 0.02\n",
      "iteration: 45040 loss: 0.0042 lr: 0.02\n",
      "iteration: 45050 loss: 0.0034 lr: 0.02\n",
      "iteration: 45060 loss: 0.0046 lr: 0.02\n",
      "iteration: 45070 loss: 0.0048 lr: 0.02\n",
      "iteration: 45080 loss: 0.0039 lr: 0.02\n",
      "iteration: 45090 loss: 0.0041 lr: 0.02\n",
      "iteration: 45100 loss: 0.0052 lr: 0.02\n",
      "iteration: 45110 loss: 0.0046 lr: 0.02\n",
      "iteration: 45120 loss: 0.0041 lr: 0.02\n",
      "iteration: 45130 loss: 0.0049 lr: 0.02\n",
      "iteration: 45140 loss: 0.0051 lr: 0.02\n",
      "iteration: 45150 loss: 0.0047 lr: 0.02\n",
      "iteration: 45160 loss: 0.0046 lr: 0.02\n",
      "iteration: 45170 loss: 0.0029 lr: 0.02\n",
      "iteration: 45180 loss: 0.0045 lr: 0.02\n",
      "iteration: 45190 loss: 0.0049 lr: 0.02\n",
      "iteration: 45200 loss: 0.0045 lr: 0.02\n",
      "iteration: 45210 loss: 0.0047 lr: 0.02\n",
      "iteration: 45220 loss: 0.0042 lr: 0.02\n",
      "iteration: 45230 loss: 0.0036 lr: 0.02\n",
      "iteration: 45240 loss: 0.0055 lr: 0.02\n",
      "iteration: 45250 loss: 0.0049 lr: 0.02\n",
      "iteration: 45260 loss: 0.0054 lr: 0.02\n",
      "iteration: 45270 loss: 0.0041 lr: 0.02\n",
      "iteration: 45280 loss: 0.0033 lr: 0.02\n",
      "iteration: 45290 loss: 0.0030 lr: 0.02\n",
      "iteration: 45300 loss: 0.0045 lr: 0.02\n",
      "iteration: 45310 loss: 0.0042 lr: 0.02\n",
      "iteration: 45320 loss: 0.0052 lr: 0.02\n",
      "iteration: 45330 loss: 0.0041 lr: 0.02\n",
      "iteration: 45340 loss: 0.0052 lr: 0.02\n",
      "iteration: 45350 loss: 0.0055 lr: 0.02\n",
      "iteration: 45360 loss: 0.0040 lr: 0.02\n",
      "iteration: 45370 loss: 0.0037 lr: 0.02\n",
      "iteration: 45380 loss: 0.0048 lr: 0.02\n",
      "iteration: 45390 loss: 0.0046 lr: 0.02\n",
      "iteration: 45400 loss: 0.0045 lr: 0.02\n",
      "iteration: 45410 loss: 0.0045 lr: 0.02\n",
      "iteration: 45420 loss: 0.0043 lr: 0.02\n",
      "iteration: 45430 loss: 0.0051 lr: 0.02\n",
      "iteration: 45440 loss: 0.0050 lr: 0.02\n",
      "iteration: 45450 loss: 0.0048 lr: 0.02\n",
      "iteration: 45460 loss: 0.0042 lr: 0.02\n",
      "iteration: 45470 loss: 0.0049 lr: 0.02\n",
      "iteration: 45480 loss: 0.0046 lr: 0.02\n",
      "iteration: 45490 loss: 0.0047 lr: 0.02\n",
      "iteration: 45500 loss: 0.0038 lr: 0.02\n",
      "iteration: 45510 loss: 0.0047 lr: 0.02\n",
      "iteration: 45520 loss: 0.0053 lr: 0.02\n",
      "iteration: 45530 loss: 0.0041 lr: 0.02\n",
      "iteration: 45540 loss: 0.0047 lr: 0.02\n",
      "iteration: 45550 loss: 0.0071 lr: 0.02\n",
      "iteration: 45560 loss: 0.0068 lr: 0.02\n",
      "iteration: 45570 loss: 0.0058 lr: 0.02\n",
      "iteration: 45580 loss: 0.0045 lr: 0.02\n",
      "iteration: 45590 loss: 0.0056 lr: 0.02\n",
      "iteration: 45600 loss: 0.0053 lr: 0.02\n",
      "iteration: 45610 loss: 0.0054 lr: 0.02\n",
      "iteration: 45620 loss: 0.0048 lr: 0.02\n",
      "iteration: 45630 loss: 0.0043 lr: 0.02\n",
      "iteration: 45640 loss: 0.0052 lr: 0.02\n",
      "iteration: 45650 loss: 0.0041 lr: 0.02\n",
      "iteration: 45660 loss: 0.0039 lr: 0.02\n",
      "iteration: 45670 loss: 0.0046 lr: 0.02\n",
      "iteration: 45680 loss: 0.0035 lr: 0.02\n",
      "iteration: 45690 loss: 0.0044 lr: 0.02\n",
      "iteration: 45700 loss: 0.0039 lr: 0.02\n",
      "iteration: 45710 loss: 0.0055 lr: 0.02\n",
      "iteration: 45720 loss: 0.0039 lr: 0.02\n",
      "iteration: 45730 loss: 0.0047 lr: 0.02\n",
      "iteration: 45740 loss: 0.0051 lr: 0.02\n",
      "iteration: 45750 loss: 0.0043 lr: 0.02\n",
      "iteration: 45760 loss: 0.0048 lr: 0.02\n",
      "iteration: 45770 loss: 0.0037 lr: 0.02\n",
      "iteration: 45780 loss: 0.0041 lr: 0.02\n",
      "iteration: 45790 loss: 0.0066 lr: 0.02\n",
      "iteration: 45800 loss: 0.0041 lr: 0.02\n",
      "iteration: 45810 loss: 0.0050 lr: 0.02\n",
      "iteration: 45820 loss: 0.0043 lr: 0.02\n",
      "iteration: 45830 loss: 0.0043 lr: 0.02\n",
      "iteration: 45840 loss: 0.0051 lr: 0.02\n",
      "iteration: 45850 loss: 0.0038 lr: 0.02\n",
      "iteration: 45860 loss: 0.0041 lr: 0.02\n",
      "iteration: 45870 loss: 0.0055 lr: 0.02\n",
      "iteration: 45880 loss: 0.0042 lr: 0.02\n",
      "iteration: 45890 loss: 0.0047 lr: 0.02\n",
      "iteration: 45900 loss: 0.0066 lr: 0.02\n",
      "iteration: 45910 loss: 0.0045 lr: 0.02\n",
      "iteration: 45920 loss: 0.0046 lr: 0.02\n",
      "iteration: 45930 loss: 0.0048 lr: 0.02\n",
      "iteration: 45940 loss: 0.0043 lr: 0.02\n",
      "iteration: 45950 loss: 0.0040 lr: 0.02\n",
      "iteration: 45960 loss: 0.0043 lr: 0.02\n",
      "iteration: 45970 loss: 0.0047 lr: 0.02\n",
      "iteration: 45980 loss: 0.0044 lr: 0.02\n",
      "iteration: 45990 loss: 0.0044 lr: 0.02\n",
      "iteration: 46000 loss: 0.0042 lr: 0.02\n",
      "iteration: 46010 loss: 0.0046 lr: 0.02\n",
      "iteration: 46020 loss: 0.0051 lr: 0.02\n",
      "iteration: 46030 loss: 0.0043 lr: 0.02\n",
      "iteration: 46040 loss: 0.0045 lr: 0.02\n",
      "iteration: 46050 loss: 0.0048 lr: 0.02\n",
      "iteration: 46060 loss: 0.0044 lr: 0.02\n",
      "iteration: 46070 loss: 0.0038 lr: 0.02\n",
      "iteration: 46080 loss: 0.0042 lr: 0.02\n",
      "iteration: 46090 loss: 0.0034 lr: 0.02\n",
      "iteration: 46100 loss: 0.0039 lr: 0.02\n",
      "iteration: 46110 loss: 0.0046 lr: 0.02\n",
      "iteration: 46120 loss: 0.0046 lr: 0.02\n",
      "iteration: 46130 loss: 0.0043 lr: 0.02\n",
      "iteration: 46140 loss: 0.0041 lr: 0.02\n",
      "iteration: 46150 loss: 0.0052 lr: 0.02\n",
      "iteration: 46160 loss: 0.0045 lr: 0.02\n",
      "iteration: 46170 loss: 0.0035 lr: 0.02\n",
      "iteration: 46180 loss: 0.0042 lr: 0.02\n",
      "iteration: 46190 loss: 0.0048 lr: 0.02\n",
      "iteration: 46200 loss: 0.0034 lr: 0.02\n",
      "iteration: 46210 loss: 0.0046 lr: 0.02\n",
      "iteration: 46220 loss: 0.0044 lr: 0.02\n",
      "iteration: 46230 loss: 0.0044 lr: 0.02\n",
      "iteration: 46240 loss: 0.0051 lr: 0.02\n",
      "iteration: 46250 loss: 0.0044 lr: 0.02\n",
      "iteration: 46260 loss: 0.0039 lr: 0.02\n",
      "iteration: 46270 loss: 0.0049 lr: 0.02\n",
      "iteration: 46280 loss: 0.0040 lr: 0.02\n",
      "iteration: 46290 loss: 0.0041 lr: 0.02\n",
      "iteration: 46300 loss: 0.0048 lr: 0.02\n",
      "iteration: 46310 loss: 0.0042 lr: 0.02\n",
      "iteration: 46320 loss: 0.0042 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 46330 loss: 0.0050 lr: 0.02\n",
      "iteration: 46340 loss: 0.0059 lr: 0.02\n",
      "iteration: 46350 loss: 0.0045 lr: 0.02\n",
      "iteration: 46360 loss: 0.0036 lr: 0.02\n",
      "iteration: 46370 loss: 0.0046 lr: 0.02\n",
      "iteration: 46380 loss: 0.0049 lr: 0.02\n",
      "iteration: 46390 loss: 0.0059 lr: 0.02\n",
      "iteration: 46400 loss: 0.0064 lr: 0.02\n",
      "iteration: 46410 loss: 0.0051 lr: 0.02\n",
      "iteration: 46420 loss: 0.0058 lr: 0.02\n",
      "iteration: 46430 loss: 0.0048 lr: 0.02\n",
      "iteration: 46440 loss: 0.0065 lr: 0.02\n",
      "iteration: 46450 loss: 0.0049 lr: 0.02\n",
      "iteration: 46460 loss: 0.0069 lr: 0.02\n",
      "iteration: 46470 loss: 0.0049 lr: 0.02\n",
      "iteration: 46480 loss: 0.0044 lr: 0.02\n",
      "iteration: 46490 loss: 0.0047 lr: 0.02\n",
      "iteration: 46500 loss: 0.0046 lr: 0.02\n",
      "iteration: 46510 loss: 0.0046 lr: 0.02\n",
      "iteration: 46520 loss: 0.0044 lr: 0.02\n",
      "iteration: 46530 loss: 0.0036 lr: 0.02\n",
      "iteration: 46540 loss: 0.0042 lr: 0.02\n",
      "iteration: 46550 loss: 0.0041 lr: 0.02\n",
      "iteration: 46560 loss: 0.0044 lr: 0.02\n",
      "iteration: 46570 loss: 0.0038 lr: 0.02\n",
      "iteration: 46580 loss: 0.0038 lr: 0.02\n",
      "iteration: 46590 loss: 0.0047 lr: 0.02\n",
      "iteration: 46600 loss: 0.0040 lr: 0.02\n",
      "iteration: 46610 loss: 0.0056 lr: 0.02\n",
      "iteration: 46620 loss: 0.0069 lr: 0.02\n",
      "iteration: 46630 loss: 0.0048 lr: 0.02\n",
      "iteration: 46640 loss: 0.0039 lr: 0.02\n",
      "iteration: 46650 loss: 0.0050 lr: 0.02\n",
      "iteration: 46660 loss: 0.0055 lr: 0.02\n",
      "iteration: 46670 loss: 0.0045 lr: 0.02\n",
      "iteration: 46680 loss: 0.0048 lr: 0.02\n",
      "iteration: 46690 loss: 0.0050 lr: 0.02\n",
      "iteration: 46700 loss: 0.0046 lr: 0.02\n",
      "iteration: 46710 loss: 0.0044 lr: 0.02\n",
      "iteration: 46720 loss: 0.0048 lr: 0.02\n",
      "iteration: 46730 loss: 0.0037 lr: 0.02\n",
      "iteration: 46740 loss: 0.0047 lr: 0.02\n",
      "iteration: 46750 loss: 0.0055 lr: 0.02\n",
      "iteration: 46760 loss: 0.0046 lr: 0.02\n",
      "iteration: 46770 loss: 0.0048 lr: 0.02\n",
      "iteration: 46780 loss: 0.0046 lr: 0.02\n",
      "iteration: 46790 loss: 0.0046 lr: 0.02\n",
      "iteration: 46800 loss: 0.0042 lr: 0.02\n",
      "iteration: 46810 loss: 0.0038 lr: 0.02\n",
      "iteration: 46820 loss: 0.0045 lr: 0.02\n",
      "iteration: 46830 loss: 0.0038 lr: 0.02\n",
      "iteration: 46840 loss: 0.0036 lr: 0.02\n",
      "iteration: 46850 loss: 0.0044 lr: 0.02\n",
      "iteration: 46860 loss: 0.0048 lr: 0.02\n",
      "iteration: 46870 loss: 0.0048 lr: 0.02\n",
      "iteration: 46880 loss: 0.0047 lr: 0.02\n",
      "iteration: 46890 loss: 0.0040 lr: 0.02\n",
      "iteration: 46900 loss: 0.0047 lr: 0.02\n",
      "iteration: 46910 loss: 0.0039 lr: 0.02\n",
      "iteration: 46920 loss: 0.0046 lr: 0.02\n",
      "iteration: 46930 loss: 0.0048 lr: 0.02\n",
      "iteration: 46940 loss: 0.0044 lr: 0.02\n",
      "iteration: 46950 loss: 0.0045 lr: 0.02\n",
      "iteration: 46960 loss: 0.0040 lr: 0.02\n",
      "iteration: 46970 loss: 0.0047 lr: 0.02\n",
      "iteration: 46980 loss: 0.0042 lr: 0.02\n",
      "iteration: 46990 loss: 0.0056 lr: 0.02\n",
      "iteration: 47000 loss: 0.0045 lr: 0.02\n",
      "iteration: 47010 loss: 0.0044 lr: 0.02\n",
      "iteration: 47020 loss: 0.0058 lr: 0.02\n",
      "iteration: 47030 loss: 0.0045 lr: 0.02\n",
      "iteration: 47040 loss: 0.0041 lr: 0.02\n",
      "iteration: 47050 loss: 0.0049 lr: 0.02\n",
      "iteration: 47060 loss: 0.0043 lr: 0.02\n",
      "iteration: 47070 loss: 0.0059 lr: 0.02\n",
      "iteration: 47080 loss: 0.0042 lr: 0.02\n",
      "iteration: 47090 loss: 0.0041 lr: 0.02\n",
      "iteration: 47100 loss: 0.0041 lr: 0.02\n",
      "iteration: 47110 loss: 0.0046 lr: 0.02\n",
      "iteration: 47120 loss: 0.0039 lr: 0.02\n",
      "iteration: 47130 loss: 0.0035 lr: 0.02\n",
      "iteration: 47140 loss: 0.0046 lr: 0.02\n",
      "iteration: 47150 loss: 0.0038 lr: 0.02\n",
      "iteration: 47160 loss: 0.0057 lr: 0.02\n",
      "iteration: 47170 loss: 0.0047 lr: 0.02\n",
      "iteration: 47180 loss: 0.0042 lr: 0.02\n",
      "iteration: 47190 loss: 0.0042 lr: 0.02\n",
      "iteration: 47200 loss: 0.0044 lr: 0.02\n",
      "iteration: 47210 loss: 0.0053 lr: 0.02\n",
      "iteration: 47220 loss: 0.0041 lr: 0.02\n",
      "iteration: 47230 loss: 0.0041 lr: 0.02\n",
      "iteration: 47240 loss: 0.0061 lr: 0.02\n",
      "iteration: 47250 loss: 0.0033 lr: 0.02\n",
      "iteration: 47260 loss: 0.0034 lr: 0.02\n",
      "iteration: 47270 loss: 0.0042 lr: 0.02\n",
      "iteration: 47280 loss: 0.0045 lr: 0.02\n",
      "iteration: 47290 loss: 0.0042 lr: 0.02\n",
      "iteration: 47300 loss: 0.0046 lr: 0.02\n",
      "iteration: 47310 loss: 0.0048 lr: 0.02\n",
      "iteration: 47320 loss: 0.0052 lr: 0.02\n",
      "iteration: 47330 loss: 0.0046 lr: 0.02\n",
      "iteration: 47340 loss: 0.0051 lr: 0.02\n",
      "iteration: 47350 loss: 0.0047 lr: 0.02\n",
      "iteration: 47360 loss: 0.0041 lr: 0.02\n",
      "iteration: 47370 loss: 0.0064 lr: 0.02\n",
      "iteration: 47380 loss: 0.0039 lr: 0.02\n",
      "iteration: 47390 loss: 0.0041 lr: 0.02\n",
      "iteration: 47400 loss: 0.0046 lr: 0.02\n",
      "iteration: 47410 loss: 0.0049 lr: 0.02\n",
      "iteration: 47420 loss: 0.0038 lr: 0.02\n",
      "iteration: 47430 loss: 0.0051 lr: 0.02\n",
      "iteration: 47440 loss: 0.0043 lr: 0.02\n",
      "iteration: 47450 loss: 0.0040 lr: 0.02\n",
      "iteration: 47460 loss: 0.0059 lr: 0.02\n",
      "iteration: 47470 loss: 0.0049 lr: 0.02\n",
      "iteration: 47480 loss: 0.0037 lr: 0.02\n",
      "iteration: 47490 loss: 0.0053 lr: 0.02\n",
      "iteration: 47500 loss: 0.0040 lr: 0.02\n",
      "iteration: 47510 loss: 0.0046 lr: 0.02\n",
      "iteration: 47520 loss: 0.0040 lr: 0.02\n",
      "iteration: 47530 loss: 0.0047 lr: 0.02\n",
      "iteration: 47540 loss: 0.0038 lr: 0.02\n",
      "iteration: 47550 loss: 0.0046 lr: 0.02\n",
      "iteration: 47560 loss: 0.0039 lr: 0.02\n",
      "iteration: 47570 loss: 0.0049 lr: 0.02\n",
      "iteration: 47580 loss: 0.0058 lr: 0.02\n",
      "iteration: 47590 loss: 0.0039 lr: 0.02\n",
      "iteration: 47600 loss: 0.0049 lr: 0.02\n",
      "iteration: 47610 loss: 0.0049 lr: 0.02\n",
      "iteration: 47620 loss: 0.0042 lr: 0.02\n",
      "iteration: 47630 loss: 0.0049 lr: 0.02\n",
      "iteration: 47640 loss: 0.0046 lr: 0.02\n",
      "iteration: 47650 loss: 0.0032 lr: 0.02\n",
      "iteration: 47660 loss: 0.0044 lr: 0.02\n",
      "iteration: 47670 loss: 0.0043 lr: 0.02\n",
      "iteration: 47680 loss: 0.0052 lr: 0.02\n",
      "iteration: 47690 loss: 0.0037 lr: 0.02\n",
      "iteration: 47700 loss: 0.0042 lr: 0.02\n",
      "iteration: 47710 loss: 0.0045 lr: 0.02\n",
      "iteration: 47720 loss: 0.0042 lr: 0.02\n",
      "iteration: 47730 loss: 0.0051 lr: 0.02\n",
      "iteration: 47740 loss: 0.0042 lr: 0.02\n",
      "iteration: 47750 loss: 0.0053 lr: 0.02\n",
      "iteration: 47760 loss: 0.0044 lr: 0.02\n",
      "iteration: 47770 loss: 0.0056 lr: 0.02\n",
      "iteration: 47780 loss: 0.0040 lr: 0.02\n",
      "iteration: 47790 loss: 0.0048 lr: 0.02\n",
      "iteration: 47800 loss: 0.0046 lr: 0.02\n",
      "iteration: 47810 loss: 0.0045 lr: 0.02\n",
      "iteration: 47820 loss: 0.0043 lr: 0.02\n",
      "iteration: 47830 loss: 0.0043 lr: 0.02\n",
      "iteration: 47840 loss: 0.0035 lr: 0.02\n",
      "iteration: 47850 loss: 0.0043 lr: 0.02\n",
      "iteration: 47860 loss: 0.0043 lr: 0.02\n",
      "iteration: 47870 loss: 0.0036 lr: 0.02\n",
      "iteration: 47880 loss: 0.0038 lr: 0.02\n",
      "iteration: 47890 loss: 0.0045 lr: 0.02\n",
      "iteration: 47900 loss: 0.0047 lr: 0.02\n",
      "iteration: 47910 loss: 0.0053 lr: 0.02\n",
      "iteration: 47920 loss: 0.0052 lr: 0.02\n",
      "iteration: 47930 loss: 0.0044 lr: 0.02\n",
      "iteration: 47940 loss: 0.0037 lr: 0.02\n",
      "iteration: 47950 loss: 0.0044 lr: 0.02\n",
      "iteration: 47960 loss: 0.0042 lr: 0.02\n",
      "iteration: 47970 loss: 0.0054 lr: 0.02\n",
      "iteration: 47980 loss: 0.0041 lr: 0.02\n",
      "iteration: 47990 loss: 0.0047 lr: 0.02\n",
      "iteration: 48000 loss: 0.0038 lr: 0.02\n",
      "iteration: 48010 loss: 0.0035 lr: 0.02\n",
      "iteration: 48020 loss: 0.0051 lr: 0.02\n",
      "iteration: 48030 loss: 0.0045 lr: 0.02\n",
      "iteration: 48040 loss: 0.0039 lr: 0.02\n",
      "iteration: 48050 loss: 0.0040 lr: 0.02\n",
      "iteration: 48060 loss: 0.0040 lr: 0.02\n",
      "iteration: 48070 loss: 0.0046 lr: 0.02\n",
      "iteration: 48080 loss: 0.0044 lr: 0.02\n",
      "iteration: 48090 loss: 0.0041 lr: 0.02\n",
      "iteration: 48100 loss: 0.0043 lr: 0.02\n",
      "iteration: 48110 loss: 0.0055 lr: 0.02\n",
      "iteration: 48120 loss: 0.0044 lr: 0.02\n",
      "iteration: 48130 loss: 0.0054 lr: 0.02\n",
      "iteration: 48140 loss: 0.0040 lr: 0.02\n",
      "iteration: 48150 loss: 0.0040 lr: 0.02\n",
      "iteration: 48160 loss: 0.0038 lr: 0.02\n",
      "iteration: 48170 loss: 0.0052 lr: 0.02\n",
      "iteration: 48180 loss: 0.0052 lr: 0.02\n",
      "iteration: 48190 loss: 0.0044 lr: 0.02\n",
      "iteration: 48200 loss: 0.0051 lr: 0.02\n",
      "iteration: 48210 loss: 0.0042 lr: 0.02\n",
      "iteration: 48220 loss: 0.0047 lr: 0.02\n",
      "iteration: 48230 loss: 0.0039 lr: 0.02\n",
      "iteration: 48240 loss: 0.0039 lr: 0.02\n",
      "iteration: 48250 loss: 0.0041 lr: 0.02\n",
      "iteration: 48260 loss: 0.0047 lr: 0.02\n",
      "iteration: 48270 loss: 0.0044 lr: 0.02\n",
      "iteration: 48280 loss: 0.0044 lr: 0.02\n",
      "iteration: 48290 loss: 0.0038 lr: 0.02\n",
      "iteration: 48300 loss: 0.0043 lr: 0.02\n",
      "iteration: 48310 loss: 0.0038 lr: 0.02\n",
      "iteration: 48320 loss: 0.0056 lr: 0.02\n",
      "iteration: 48330 loss: 0.0035 lr: 0.02\n",
      "iteration: 48340 loss: 0.0047 lr: 0.02\n",
      "iteration: 48350 loss: 0.0041 lr: 0.02\n",
      "iteration: 48360 loss: 0.0057 lr: 0.02\n",
      "iteration: 48370 loss: 0.0045 lr: 0.02\n",
      "iteration: 48380 loss: 0.0052 lr: 0.02\n",
      "iteration: 48390 loss: 0.0051 lr: 0.02\n",
      "iteration: 48400 loss: 0.0050 lr: 0.02\n",
      "iteration: 48410 loss: 0.0048 lr: 0.02\n",
      "iteration: 48420 loss: 0.0041 lr: 0.02\n",
      "iteration: 48430 loss: 0.0038 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 48440 loss: 0.0060 lr: 0.02\n",
      "iteration: 48450 loss: 0.0052 lr: 0.02\n",
      "iteration: 48460 loss: 0.0041 lr: 0.02\n",
      "iteration: 48470 loss: 0.0038 lr: 0.02\n",
      "iteration: 48480 loss: 0.0038 lr: 0.02\n",
      "iteration: 48490 loss: 0.0036 lr: 0.02\n",
      "iteration: 48500 loss: 0.0043 lr: 0.02\n",
      "iteration: 48510 loss: 0.0050 lr: 0.02\n",
      "iteration: 48520 loss: 0.0052 lr: 0.02\n",
      "iteration: 48530 loss: 0.0049 lr: 0.02\n",
      "iteration: 48540 loss: 0.0040 lr: 0.02\n",
      "iteration: 48550 loss: 0.0049 lr: 0.02\n",
      "iteration: 48560 loss: 0.0043 lr: 0.02\n",
      "iteration: 48570 loss: 0.0040 lr: 0.02\n",
      "iteration: 48580 loss: 0.0041 lr: 0.02\n",
      "iteration: 48590 loss: 0.0051 lr: 0.02\n",
      "iteration: 48600 loss: 0.0037 lr: 0.02\n",
      "iteration: 48610 loss: 0.0035 lr: 0.02\n",
      "iteration: 48620 loss: 0.0047 lr: 0.02\n",
      "iteration: 48630 loss: 0.0040 lr: 0.02\n",
      "iteration: 48640 loss: 0.0037 lr: 0.02\n",
      "iteration: 48650 loss: 0.0048 lr: 0.02\n",
      "iteration: 48660 loss: 0.0040 lr: 0.02\n",
      "iteration: 48670 loss: 0.0052 lr: 0.02\n",
      "iteration: 48680 loss: 0.0039 lr: 0.02\n",
      "iteration: 48690 loss: 0.0047 lr: 0.02\n",
      "iteration: 48700 loss: 0.0034 lr: 0.02\n",
      "iteration: 48710 loss: 0.0054 lr: 0.02\n",
      "iteration: 48720 loss: 0.0040 lr: 0.02\n",
      "iteration: 48730 loss: 0.0045 lr: 0.02\n",
      "iteration: 48740 loss: 0.0049 lr: 0.02\n",
      "iteration: 48750 loss: 0.0043 lr: 0.02\n",
      "iteration: 48760 loss: 0.0041 lr: 0.02\n",
      "iteration: 48770 loss: 0.0050 lr: 0.02\n",
      "iteration: 48780 loss: 0.0034 lr: 0.02\n",
      "iteration: 48790 loss: 0.0046 lr: 0.02\n",
      "iteration: 48800 loss: 0.0057 lr: 0.02\n",
      "iteration: 48810 loss: 0.0043 lr: 0.02\n",
      "iteration: 48820 loss: 0.0039 lr: 0.02\n",
      "iteration: 48830 loss: 0.0054 lr: 0.02\n",
      "iteration: 48840 loss: 0.0046 lr: 0.02\n",
      "iteration: 48850 loss: 0.0034 lr: 0.02\n",
      "iteration: 48860 loss: 0.0053 lr: 0.02\n",
      "iteration: 48870 loss: 0.0058 lr: 0.02\n",
      "iteration: 48880 loss: 0.0042 lr: 0.02\n",
      "iteration: 48890 loss: 0.0041 lr: 0.02\n",
      "iteration: 48900 loss: 0.0039 lr: 0.02\n",
      "iteration: 48910 loss: 0.0042 lr: 0.02\n",
      "iteration: 48920 loss: 0.0038 lr: 0.02\n",
      "iteration: 48930 loss: 0.0038 lr: 0.02\n",
      "iteration: 48940 loss: 0.0050 lr: 0.02\n",
      "iteration: 48950 loss: 0.0045 lr: 0.02\n",
      "iteration: 48960 loss: 0.0036 lr: 0.02\n",
      "iteration: 48970 loss: 0.0041 lr: 0.02\n",
      "iteration: 48980 loss: 0.0040 lr: 0.02\n",
      "iteration: 48990 loss: 0.0035 lr: 0.02\n",
      "iteration: 49000 loss: 0.0047 lr: 0.02\n",
      "iteration: 49010 loss: 0.0044 lr: 0.02\n",
      "iteration: 49020 loss: 0.0041 lr: 0.02\n",
      "iteration: 49030 loss: 0.0046 lr: 0.02\n",
      "iteration: 49040 loss: 0.0039 lr: 0.02\n",
      "iteration: 49050 loss: 0.0041 lr: 0.02\n",
      "iteration: 49060 loss: 0.0051 lr: 0.02\n",
      "iteration: 49070 loss: 0.0046 lr: 0.02\n",
      "iteration: 49080 loss: 0.0039 lr: 0.02\n",
      "iteration: 49090 loss: 0.0039 lr: 0.02\n",
      "iteration: 49100 loss: 0.0035 lr: 0.02\n",
      "iteration: 49110 loss: 0.0043 lr: 0.02\n",
      "iteration: 49120 loss: 0.0046 lr: 0.02\n",
      "iteration: 49130 loss: 0.0041 lr: 0.02\n",
      "iteration: 49140 loss: 0.0037 lr: 0.02\n",
      "iteration: 49150 loss: 0.0038 lr: 0.02\n",
      "iteration: 49160 loss: 0.0040 lr: 0.02\n",
      "iteration: 49170 loss: 0.0052 lr: 0.02\n",
      "iteration: 49180 loss: 0.0039 lr: 0.02\n",
      "iteration: 49190 loss: 0.0039 lr: 0.02\n",
      "iteration: 49200 loss: 0.0042 lr: 0.02\n",
      "iteration: 49210 loss: 0.0054 lr: 0.02\n",
      "iteration: 49220 loss: 0.0045 lr: 0.02\n",
      "iteration: 49230 loss: 0.0044 lr: 0.02\n",
      "iteration: 49240 loss: 0.0037 lr: 0.02\n",
      "iteration: 49250 loss: 0.0044 lr: 0.02\n",
      "iteration: 49260 loss: 0.0051 lr: 0.02\n",
      "iteration: 49270 loss: 0.0051 lr: 0.02\n",
      "iteration: 49280 loss: 0.0040 lr: 0.02\n",
      "iteration: 49290 loss: 0.0046 lr: 0.02\n",
      "iteration: 49300 loss: 0.0046 lr: 0.02\n",
      "iteration: 49310 loss: 0.0049 lr: 0.02\n",
      "iteration: 49320 loss: 0.0049 lr: 0.02\n",
      "iteration: 49330 loss: 0.0039 lr: 0.02\n",
      "iteration: 49340 loss: 0.0035 lr: 0.02\n",
      "iteration: 49350 loss: 0.0045 lr: 0.02\n",
      "iteration: 49360 loss: 0.0042 lr: 0.02\n",
      "iteration: 49370 loss: 0.0040 lr: 0.02\n",
      "iteration: 49380 loss: 0.0039 lr: 0.02\n",
      "iteration: 49390 loss: 0.0042 lr: 0.02\n",
      "iteration: 49400 loss: 0.0044 lr: 0.02\n",
      "iteration: 49410 loss: 0.0043 lr: 0.02\n",
      "iteration: 49420 loss: 0.0049 lr: 0.02\n",
      "iteration: 49430 loss: 0.0038 lr: 0.02\n",
      "iteration: 49440 loss: 0.0041 lr: 0.02\n",
      "iteration: 49450 loss: 0.0033 lr: 0.02\n",
      "iteration: 49460 loss: 0.0038 lr: 0.02\n",
      "iteration: 49470 loss: 0.0035 lr: 0.02\n",
      "iteration: 49480 loss: 0.0040 lr: 0.02\n",
      "iteration: 49490 loss: 0.0042 lr: 0.02\n",
      "iteration: 49500 loss: 0.0048 lr: 0.02\n",
      "iteration: 49510 loss: 0.0042 lr: 0.02\n",
      "iteration: 49520 loss: 0.0042 lr: 0.02\n",
      "iteration: 49530 loss: 0.0035 lr: 0.02\n",
      "iteration: 49540 loss: 0.0041 lr: 0.02\n",
      "iteration: 49550 loss: 0.0045 lr: 0.02\n",
      "iteration: 49560 loss: 0.0055 lr: 0.02\n",
      "iteration: 49570 loss: 0.0037 lr: 0.02\n",
      "iteration: 49580 loss: 0.0039 lr: 0.02\n",
      "iteration: 49590 loss: 0.0053 lr: 0.02\n",
      "iteration: 49600 loss: 0.0044 lr: 0.02\n",
      "iteration: 49610 loss: 0.0049 lr: 0.02\n",
      "iteration: 49620 loss: 0.0047 lr: 0.02\n",
      "iteration: 49630 loss: 0.0036 lr: 0.02\n",
      "iteration: 49640 loss: 0.0058 lr: 0.02\n",
      "iteration: 49650 loss: 0.0045 lr: 0.02\n",
      "iteration: 49660 loss: 0.0040 lr: 0.02\n",
      "iteration: 49670 loss: 0.0044 lr: 0.02\n",
      "iteration: 49680 loss: 0.0045 lr: 0.02\n",
      "iteration: 49690 loss: 0.0030 lr: 0.02\n",
      "iteration: 49700 loss: 0.0048 lr: 0.02\n",
      "iteration: 49710 loss: 0.0035 lr: 0.02\n",
      "iteration: 49720 loss: 0.0034 lr: 0.02\n",
      "iteration: 49730 loss: 0.0043 lr: 0.02\n",
      "iteration: 49740 loss: 0.0045 lr: 0.02\n",
      "iteration: 49750 loss: 0.0040 lr: 0.02\n",
      "iteration: 49760 loss: 0.0035 lr: 0.02\n",
      "iteration: 49770 loss: 0.0041 lr: 0.02\n",
      "iteration: 49780 loss: 0.0048 lr: 0.02\n",
      "iteration: 49790 loss: 0.0052 lr: 0.02\n",
      "iteration: 49800 loss: 0.0041 lr: 0.02\n",
      "iteration: 49810 loss: 0.0035 lr: 0.02\n",
      "iteration: 49820 loss: 0.0036 lr: 0.02\n",
      "iteration: 49830 loss: 0.0044 lr: 0.02\n",
      "iteration: 49840 loss: 0.0038 lr: 0.02\n",
      "iteration: 49850 loss: 0.0046 lr: 0.02\n",
      "iteration: 49860 loss: 0.0040 lr: 0.02\n",
      "iteration: 49870 loss: 0.0041 lr: 0.02\n",
      "iteration: 49880 loss: 0.0034 lr: 0.02\n",
      "iteration: 49890 loss: 0.0050 lr: 0.02\n",
      "iteration: 49900 loss: 0.0040 lr: 0.02\n",
      "iteration: 49910 loss: 0.0035 lr: 0.02\n",
      "iteration: 49920 loss: 0.0041 lr: 0.02\n",
      "iteration: 49930 loss: 0.0040 lr: 0.02\n",
      "iteration: 49940 loss: 0.0044 lr: 0.02\n",
      "iteration: 49950 loss: 0.0039 lr: 0.02\n",
      "iteration: 49960 loss: 0.0041 lr: 0.02\n",
      "iteration: 49970 loss: 0.0043 lr: 0.02\n",
      "iteration: 49980 loss: 0.0040 lr: 0.02\n",
      "iteration: 49990 loss: 0.0034 lr: 0.02\n",
      "iteration: 50000 loss: 0.0047 lr: 0.02\n",
      "iteration: 50010 loss: 0.0048 lr: 0.02\n",
      "iteration: 50020 loss: 0.0056 lr: 0.02\n",
      "iteration: 50030 loss: 0.0043 lr: 0.02\n",
      "iteration: 50040 loss: 0.0041 lr: 0.02\n",
      "iteration: 50050 loss: 0.0051 lr: 0.02\n",
      "iteration: 50060 loss: 0.0047 lr: 0.02\n",
      "iteration: 50070 loss: 0.0055 lr: 0.02\n",
      "iteration: 50080 loss: 0.0034 lr: 0.02\n",
      "iteration: 50090 loss: 0.0039 lr: 0.02\n",
      "iteration: 50100 loss: 0.0028 lr: 0.02\n",
      "iteration: 50110 loss: 0.0037 lr: 0.02\n",
      "iteration: 50120 loss: 0.0042 lr: 0.02\n",
      "iteration: 50130 loss: 0.0040 lr: 0.02\n",
      "iteration: 50140 loss: 0.0041 lr: 0.02\n",
      "iteration: 50150 loss: 0.0040 lr: 0.02\n",
      "iteration: 50160 loss: 0.0043 lr: 0.02\n",
      "iteration: 50170 loss: 0.0043 lr: 0.02\n",
      "iteration: 50180 loss: 0.0042 lr: 0.02\n",
      "iteration: 50190 loss: 0.0047 lr: 0.02\n",
      "iteration: 50200 loss: 0.0045 lr: 0.02\n",
      "iteration: 50210 loss: 0.0048 lr: 0.02\n",
      "iteration: 50220 loss: 0.0045 lr: 0.02\n",
      "iteration: 50230 loss: 0.0044 lr: 0.02\n",
      "iteration: 50240 loss: 0.0051 lr: 0.02\n",
      "iteration: 50250 loss: 0.0036 lr: 0.02\n",
      "iteration: 50260 loss: 0.0041 lr: 0.02\n",
      "iteration: 50270 loss: 0.0054 lr: 0.02\n",
      "iteration: 50280 loss: 0.0036 lr: 0.02\n",
      "iteration: 50290 loss: 0.0044 lr: 0.02\n",
      "iteration: 50300 loss: 0.0047 lr: 0.02\n",
      "iteration: 50310 loss: 0.0048 lr: 0.02\n",
      "iteration: 50320 loss: 0.0052 lr: 0.02\n",
      "iteration: 50330 loss: 0.0042 lr: 0.02\n",
      "iteration: 50340 loss: 0.0042 lr: 0.02\n",
      "iteration: 50350 loss: 0.0047 lr: 0.02\n",
      "iteration: 50360 loss: 0.0046 lr: 0.02\n",
      "iteration: 50370 loss: 0.0038 lr: 0.02\n",
      "iteration: 50380 loss: 0.0049 lr: 0.02\n",
      "iteration: 50390 loss: 0.0042 lr: 0.02\n",
      "iteration: 50400 loss: 0.0043 lr: 0.02\n",
      "iteration: 50410 loss: 0.0038 lr: 0.02\n",
      "iteration: 50420 loss: 0.0042 lr: 0.02\n",
      "iteration: 50430 loss: 0.0047 lr: 0.02\n",
      "iteration: 50440 loss: 0.0043 lr: 0.02\n",
      "iteration: 50450 loss: 0.0043 lr: 0.02\n",
      "iteration: 50460 loss: 0.0045 lr: 0.02\n",
      "iteration: 50470 loss: 0.0042 lr: 0.02\n",
      "iteration: 50480 loss: 0.0046 lr: 0.02\n",
      "iteration: 50490 loss: 0.0041 lr: 0.02\n",
      "iteration: 50500 loss: 0.0042 lr: 0.02\n",
      "iteration: 50510 loss: 0.0044 lr: 0.02\n",
      "iteration: 50520 loss: 0.0048 lr: 0.02\n",
      "iteration: 50530 loss: 0.0041 lr: 0.02\n",
      "iteration: 50540 loss: 0.0043 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 50550 loss: 0.0041 lr: 0.02\n",
      "iteration: 50560 loss: 0.0041 lr: 0.02\n",
      "iteration: 50570 loss: 0.0046 lr: 0.02\n",
      "iteration: 50580 loss: 0.0044 lr: 0.02\n",
      "iteration: 50590 loss: 0.0039 lr: 0.02\n",
      "iteration: 50600 loss: 0.0046 lr: 0.02\n",
      "iteration: 50610 loss: 0.0038 lr: 0.02\n",
      "iteration: 50620 loss: 0.0049 lr: 0.02\n",
      "iteration: 50630 loss: 0.0046 lr: 0.02\n",
      "iteration: 50640 loss: 0.0046 lr: 0.02\n",
      "iteration: 50650 loss: 0.0043 lr: 0.02\n",
      "iteration: 50660 loss: 0.0044 lr: 0.02\n",
      "iteration: 50670 loss: 0.0034 lr: 0.02\n",
      "iteration: 50680 loss: 0.0039 lr: 0.02\n",
      "iteration: 50690 loss: 0.0039 lr: 0.02\n",
      "iteration: 50700 loss: 0.0042 lr: 0.02\n",
      "iteration: 50710 loss: 0.0036 lr: 0.02\n",
      "iteration: 50720 loss: 0.0050 lr: 0.02\n",
      "iteration: 50730 loss: 0.0048 lr: 0.02\n",
      "iteration: 50740 loss: 0.0044 lr: 0.02\n",
      "iteration: 50750 loss: 0.0043 lr: 0.02\n",
      "iteration: 50760 loss: 0.0044 lr: 0.02\n",
      "iteration: 50770 loss: 0.0050 lr: 0.02\n",
      "iteration: 50780 loss: 0.0038 lr: 0.02\n",
      "iteration: 50790 loss: 0.0042 lr: 0.02\n",
      "iteration: 50800 loss: 0.0038 lr: 0.02\n",
      "iteration: 50810 loss: 0.0045 lr: 0.02\n",
      "iteration: 50820 loss: 0.0038 lr: 0.02\n",
      "iteration: 50830 loss: 0.0048 lr: 0.02\n",
      "iteration: 50840 loss: 0.0044 lr: 0.02\n",
      "iteration: 50850 loss: 0.0037 lr: 0.02\n",
      "iteration: 50860 loss: 0.0045 lr: 0.02\n",
      "iteration: 50870 loss: 0.0037 lr: 0.02\n",
      "iteration: 50880 loss: 0.0040 lr: 0.02\n",
      "iteration: 50890 loss: 0.0043 lr: 0.02\n",
      "iteration: 50900 loss: 0.0046 lr: 0.02\n",
      "iteration: 50910 loss: 0.0049 lr: 0.02\n",
      "iteration: 50920 loss: 0.0040 lr: 0.02\n",
      "iteration: 50930 loss: 0.0047 lr: 0.02\n",
      "iteration: 50940 loss: 0.0045 lr: 0.02\n",
      "iteration: 50950 loss: 0.0036 lr: 0.02\n",
      "iteration: 50960 loss: 0.0047 lr: 0.02\n",
      "iteration: 50970 loss: 0.0059 lr: 0.02\n",
      "iteration: 50980 loss: 0.0044 lr: 0.02\n",
      "iteration: 50990 loss: 0.0039 lr: 0.02\n",
      "iteration: 51000 loss: 0.0035 lr: 0.02\n",
      "iteration: 51010 loss: 0.0038 lr: 0.02\n",
      "iteration: 51020 loss: 0.0036 lr: 0.02\n",
      "iteration: 51030 loss: 0.0038 lr: 0.02\n",
      "iteration: 51040 loss: 0.0037 lr: 0.02\n",
      "iteration: 51050 loss: 0.0046 lr: 0.02\n",
      "iteration: 51060 loss: 0.0046 lr: 0.02\n",
      "iteration: 51070 loss: 0.0045 lr: 0.02\n",
      "iteration: 51080 loss: 0.0048 lr: 0.02\n",
      "iteration: 51090 loss: 0.0039 lr: 0.02\n",
      "iteration: 51100 loss: 0.0058 lr: 0.02\n",
      "iteration: 51110 loss: 0.0038 lr: 0.02\n",
      "iteration: 51120 loss: 0.0047 lr: 0.02\n",
      "iteration: 51130 loss: 0.0038 lr: 0.02\n",
      "iteration: 51140 loss: 0.0047 lr: 0.02\n",
      "iteration: 51150 loss: 0.0038 lr: 0.02\n",
      "iteration: 51160 loss: 0.0039 lr: 0.02\n",
      "iteration: 51170 loss: 0.0046 lr: 0.02\n",
      "iteration: 51180 loss: 0.0040 lr: 0.02\n",
      "iteration: 51190 loss: 0.0040 lr: 0.02\n",
      "iteration: 51200 loss: 0.0041 lr: 0.02\n",
      "iteration: 51210 loss: 0.0037 lr: 0.02\n",
      "iteration: 51220 loss: 0.0039 lr: 0.02\n",
      "iteration: 51230 loss: 0.0039 lr: 0.02\n",
      "iteration: 51240 loss: 0.0029 lr: 0.02\n",
      "iteration: 51250 loss: 0.0048 lr: 0.02\n",
      "iteration: 51260 loss: 0.0039 lr: 0.02\n",
      "iteration: 51270 loss: 0.0054 lr: 0.02\n",
      "iteration: 51280 loss: 0.0048 lr: 0.02\n",
      "iteration: 51290 loss: 0.0051 lr: 0.02\n",
      "iteration: 51300 loss: 0.0047 lr: 0.02\n",
      "iteration: 51310 loss: 0.0052 lr: 0.02\n",
      "iteration: 51320 loss: 0.0045 lr: 0.02\n",
      "iteration: 51330 loss: 0.0044 lr: 0.02\n",
      "iteration: 51340 loss: 0.0026 lr: 0.02\n",
      "iteration: 51350 loss: 0.0040 lr: 0.02\n",
      "iteration: 51360 loss: 0.0052 lr: 0.02\n",
      "iteration: 51370 loss: 0.0037 lr: 0.02\n",
      "iteration: 51380 loss: 0.0047 lr: 0.02\n",
      "iteration: 51390 loss: 0.0036 lr: 0.02\n",
      "iteration: 51400 loss: 0.0052 lr: 0.02\n",
      "iteration: 51410 loss: 0.0039 lr: 0.02\n",
      "iteration: 51420 loss: 0.0040 lr: 0.02\n",
      "iteration: 51430 loss: 0.0054 lr: 0.02\n",
      "iteration: 51440 loss: 0.0043 lr: 0.02\n",
      "iteration: 51450 loss: 0.0038 lr: 0.02\n",
      "iteration: 51460 loss: 0.0046 lr: 0.02\n",
      "iteration: 51470 loss: 0.0032 lr: 0.02\n",
      "iteration: 51480 loss: 0.0040 lr: 0.02\n",
      "iteration: 51490 loss: 0.0047 lr: 0.02\n",
      "iteration: 51500 loss: 0.0038 lr: 0.02\n",
      "iteration: 51510 loss: 0.0046 lr: 0.02\n",
      "iteration: 51520 loss: 0.0044 lr: 0.02\n",
      "iteration: 51530 loss: 0.0046 lr: 0.02\n",
      "iteration: 51540 loss: 0.0042 lr: 0.02\n",
      "iteration: 51550 loss: 0.0046 lr: 0.02\n",
      "iteration: 51560 loss: 0.0051 lr: 0.02\n",
      "iteration: 51570 loss: 0.0049 lr: 0.02\n",
      "iteration: 51580 loss: 0.0042 lr: 0.02\n",
      "iteration: 51590 loss: 0.0035 lr: 0.02\n",
      "iteration: 51600 loss: 0.0045 lr: 0.02\n",
      "iteration: 51610 loss: 0.0040 lr: 0.02\n",
      "iteration: 51620 loss: 0.0047 lr: 0.02\n",
      "iteration: 51630 loss: 0.0042 lr: 0.02\n",
      "iteration: 51640 loss: 0.0034 lr: 0.02\n",
      "iteration: 51650 loss: 0.0047 lr: 0.02\n",
      "iteration: 51660 loss: 0.0040 lr: 0.02\n",
      "iteration: 51670 loss: 0.0051 lr: 0.02\n",
      "iteration: 51680 loss: 0.0047 lr: 0.02\n",
      "iteration: 51690 loss: 0.0050 lr: 0.02\n",
      "iteration: 51700 loss: 0.0050 lr: 0.02\n",
      "iteration: 51710 loss: 0.0048 lr: 0.02\n",
      "iteration: 51720 loss: 0.0051 lr: 0.02\n",
      "iteration: 51730 loss: 0.0037 lr: 0.02\n",
      "iteration: 51740 loss: 0.0040 lr: 0.02\n",
      "iteration: 51750 loss: 0.0056 lr: 0.02\n",
      "iteration: 51760 loss: 0.0038 lr: 0.02\n",
      "iteration: 51770 loss: 0.0040 lr: 0.02\n",
      "iteration: 51780 loss: 0.0035 lr: 0.02\n",
      "iteration: 51790 loss: 0.0040 lr: 0.02\n",
      "iteration: 51800 loss: 0.0043 lr: 0.02\n",
      "iteration: 51810 loss: 0.0048 lr: 0.02\n",
      "iteration: 51820 loss: 0.0043 lr: 0.02\n",
      "iteration: 51830 loss: 0.0028 lr: 0.02\n",
      "iteration: 51840 loss: 0.0042 lr: 0.02\n",
      "iteration: 51850 loss: 0.0034 lr: 0.02\n",
      "iteration: 51860 loss: 0.0054 lr: 0.02\n",
      "iteration: 51870 loss: 0.0041 lr: 0.02\n",
      "iteration: 51880 loss: 0.0045 lr: 0.02\n",
      "iteration: 51890 loss: 0.0051 lr: 0.02\n",
      "iteration: 51900 loss: 0.0047 lr: 0.02\n",
      "iteration: 51910 loss: 0.0045 lr: 0.02\n",
      "iteration: 51920 loss: 0.0046 lr: 0.02\n",
      "iteration: 51930 loss: 0.0043 lr: 0.02\n",
      "iteration: 51940 loss: 0.0036 lr: 0.02\n",
      "iteration: 51950 loss: 0.0044 lr: 0.02\n",
      "iteration: 51960 loss: 0.0034 lr: 0.02\n",
      "iteration: 51970 loss: 0.0040 lr: 0.02\n",
      "iteration: 51980 loss: 0.0049 lr: 0.02\n",
      "iteration: 51990 loss: 0.0043 lr: 0.02\n",
      "iteration: 52000 loss: 0.0037 lr: 0.02\n",
      "iteration: 52010 loss: 0.0043 lr: 0.02\n",
      "iteration: 52020 loss: 0.0039 lr: 0.02\n",
      "iteration: 52030 loss: 0.0056 lr: 0.02\n",
      "iteration: 52040 loss: 0.0050 lr: 0.02\n",
      "iteration: 52050 loss: 0.0056 lr: 0.02\n",
      "iteration: 52060 loss: 0.0047 lr: 0.02\n",
      "iteration: 52070 loss: 0.0054 lr: 0.02\n",
      "iteration: 52080 loss: 0.0045 lr: 0.02\n",
      "iteration: 52090 loss: 0.0049 lr: 0.02\n",
      "iteration: 52100 loss: 0.0052 lr: 0.02\n",
      "iteration: 52110 loss: 0.0048 lr: 0.02\n",
      "iteration: 52120 loss: 0.0042 lr: 0.02\n",
      "iteration: 52130 loss: 0.0041 lr: 0.02\n",
      "iteration: 52140 loss: 0.0028 lr: 0.02\n",
      "iteration: 52150 loss: 0.0050 lr: 0.02\n",
      "iteration: 52160 loss: 0.0043 lr: 0.02\n",
      "iteration: 52170 loss: 0.0035 lr: 0.02\n",
      "iteration: 52180 loss: 0.0050 lr: 0.02\n",
      "iteration: 52190 loss: 0.0031 lr: 0.02\n",
      "iteration: 52200 loss: 0.0038 lr: 0.02\n",
      "iteration: 52210 loss: 0.0057 lr: 0.02\n",
      "iteration: 52220 loss: 0.0042 lr: 0.02\n",
      "iteration: 52230 loss: 0.0048 lr: 0.02\n",
      "iteration: 52240 loss: 0.0035 lr: 0.02\n",
      "iteration: 52250 loss: 0.0043 lr: 0.02\n",
      "iteration: 52260 loss: 0.0038 lr: 0.02\n",
      "iteration: 52270 loss: 0.0047 lr: 0.02\n",
      "iteration: 52280 loss: 0.0034 lr: 0.02\n",
      "iteration: 52290 loss: 0.0038 lr: 0.02\n",
      "iteration: 52300 loss: 0.0046 lr: 0.02\n",
      "iteration: 52310 loss: 0.0045 lr: 0.02\n",
      "iteration: 52320 loss: 0.0033 lr: 0.02\n",
      "iteration: 52330 loss: 0.0037 lr: 0.02\n",
      "iteration: 52340 loss: 0.0034 lr: 0.02\n",
      "iteration: 52350 loss: 0.0050 lr: 0.02\n",
      "iteration: 52360 loss: 0.0039 lr: 0.02\n",
      "iteration: 52370 loss: 0.0039 lr: 0.02\n",
      "iteration: 52380 loss: 0.0057 lr: 0.02\n",
      "iteration: 52390 loss: 0.0041 lr: 0.02\n",
      "iteration: 52400 loss: 0.0041 lr: 0.02\n",
      "iteration: 52410 loss: 0.0053 lr: 0.02\n",
      "iteration: 52420 loss: 0.0048 lr: 0.02\n",
      "iteration: 52430 loss: 0.0050 lr: 0.02\n",
      "iteration: 52440 loss: 0.0036 lr: 0.02\n",
      "iteration: 52450 loss: 0.0051 lr: 0.02\n",
      "iteration: 52460 loss: 0.0050 lr: 0.02\n",
      "iteration: 52470 loss: 0.0051 lr: 0.02\n",
      "iteration: 52480 loss: 0.0037 lr: 0.02\n",
      "iteration: 52490 loss: 0.0052 lr: 0.02\n",
      "iteration: 52500 loss: 0.0047 lr: 0.02\n",
      "iteration: 52510 loss: 0.0039 lr: 0.02\n",
      "iteration: 52520 loss: 0.0053 lr: 0.02\n",
      "iteration: 52530 loss: 0.0046 lr: 0.02\n",
      "iteration: 52540 loss: 0.0048 lr: 0.02\n",
      "iteration: 52550 loss: 0.0044 lr: 0.02\n",
      "iteration: 52560 loss: 0.0038 lr: 0.02\n",
      "iteration: 52570 loss: 0.0042 lr: 0.02\n",
      "iteration: 52580 loss: 0.0039 lr: 0.02\n",
      "iteration: 52590 loss: 0.0041 lr: 0.02\n",
      "iteration: 52600 loss: 0.0033 lr: 0.02\n",
      "iteration: 52610 loss: 0.0047 lr: 0.02\n",
      "iteration: 52620 loss: 0.0034 lr: 0.02\n",
      "iteration: 52630 loss: 0.0045 lr: 0.02\n",
      "iteration: 52640 loss: 0.0043 lr: 0.02\n",
      "iteration: 52650 loss: 0.0050 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 52660 loss: 0.0047 lr: 0.02\n",
      "iteration: 52670 loss: 0.0041 lr: 0.02\n",
      "iteration: 52680 loss: 0.0047 lr: 0.02\n",
      "iteration: 52690 loss: 0.0042 lr: 0.02\n",
      "iteration: 52700 loss: 0.0031 lr: 0.02\n",
      "iteration: 52710 loss: 0.0047 lr: 0.02\n",
      "iteration: 52720 loss: 0.0049 lr: 0.02\n",
      "iteration: 52730 loss: 0.0034 lr: 0.02\n",
      "iteration: 52740 loss: 0.0036 lr: 0.02\n",
      "iteration: 52750 loss: 0.0036 lr: 0.02\n",
      "iteration: 52760 loss: 0.0057 lr: 0.02\n",
      "iteration: 52770 loss: 0.0045 lr: 0.02\n",
      "iteration: 52780 loss: 0.0042 lr: 0.02\n",
      "iteration: 52790 loss: 0.0041 lr: 0.02\n",
      "iteration: 52800 loss: 0.0037 lr: 0.02\n",
      "iteration: 52810 loss: 0.0046 lr: 0.02\n",
      "iteration: 52820 loss: 0.0044 lr: 0.02\n",
      "iteration: 52830 loss: 0.0048 lr: 0.02\n",
      "iteration: 52840 loss: 0.0043 lr: 0.02\n",
      "iteration: 52850 loss: 0.0038 lr: 0.02\n",
      "iteration: 52860 loss: 0.0047 lr: 0.02\n",
      "iteration: 52870 loss: 0.0047 lr: 0.02\n",
      "iteration: 52880 loss: 0.0040 lr: 0.02\n",
      "iteration: 52890 loss: 0.0043 lr: 0.02\n",
      "iteration: 52900 loss: 0.0043 lr: 0.02\n",
      "iteration: 52910 loss: 0.0042 lr: 0.02\n",
      "iteration: 52920 loss: 0.0049 lr: 0.02\n",
      "iteration: 52930 loss: 0.0047 lr: 0.02\n",
      "iteration: 52940 loss: 0.0046 lr: 0.02\n",
      "iteration: 52950 loss: 0.0038 lr: 0.02\n",
      "iteration: 52960 loss: 0.0042 lr: 0.02\n",
      "iteration: 52970 loss: 0.0043 lr: 0.02\n",
      "iteration: 52980 loss: 0.0037 lr: 0.02\n",
      "iteration: 52990 loss: 0.0040 lr: 0.02\n",
      "iteration: 53000 loss: 0.0045 lr: 0.02\n",
      "iteration: 53010 loss: 0.0040 lr: 0.02\n",
      "iteration: 53020 loss: 0.0052 lr: 0.02\n",
      "iteration: 53030 loss: 0.0051 lr: 0.02\n",
      "iteration: 53040 loss: 0.0038 lr: 0.02\n",
      "iteration: 53050 loss: 0.0040 lr: 0.02\n",
      "iteration: 53060 loss: 0.0049 lr: 0.02\n",
      "iteration: 53070 loss: 0.0052 lr: 0.02\n",
      "iteration: 53080 loss: 0.0049 lr: 0.02\n",
      "iteration: 53090 loss: 0.0039 lr: 0.02\n",
      "iteration: 53100 loss: 0.0044 lr: 0.02\n",
      "iteration: 53110 loss: 0.0038 lr: 0.02\n",
      "iteration: 53120 loss: 0.0047 lr: 0.02\n",
      "iteration: 53130 loss: 0.0041 lr: 0.02\n",
      "iteration: 53140 loss: 0.0040 lr: 0.02\n",
      "iteration: 53150 loss: 0.0044 lr: 0.02\n",
      "iteration: 53160 loss: 0.0049 lr: 0.02\n",
      "iteration: 53170 loss: 0.0056 lr: 0.02\n",
      "iteration: 53180 loss: 0.0049 lr: 0.02\n",
      "iteration: 53190 loss: 0.0039 lr: 0.02\n",
      "iteration: 53200 loss: 0.0040 lr: 0.02\n",
      "iteration: 53210 loss: 0.0047 lr: 0.02\n",
      "iteration: 53220 loss: 0.0037 lr: 0.02\n",
      "iteration: 53230 loss: 0.0044 lr: 0.02\n",
      "iteration: 53240 loss: 0.0040 lr: 0.02\n",
      "iteration: 53250 loss: 0.0055 lr: 0.02\n",
      "iteration: 53260 loss: 0.0041 lr: 0.02\n",
      "iteration: 53270 loss: 0.0045 lr: 0.02\n",
      "iteration: 53280 loss: 0.0035 lr: 0.02\n",
      "iteration: 53290 loss: 0.0048 lr: 0.02\n",
      "iteration: 53300 loss: 0.0043 lr: 0.02\n",
      "iteration: 53310 loss: 0.0062 lr: 0.02\n",
      "iteration: 53320 loss: 0.0040 lr: 0.02\n",
      "iteration: 53330 loss: 0.0038 lr: 0.02\n",
      "iteration: 53340 loss: 0.0033 lr: 0.02\n",
      "iteration: 53350 loss: 0.0038 lr: 0.02\n",
      "iteration: 53360 loss: 0.0033 lr: 0.02\n",
      "iteration: 53370 loss: 0.0033 lr: 0.02\n",
      "iteration: 53380 loss: 0.0047 lr: 0.02\n",
      "iteration: 53390 loss: 0.0060 lr: 0.02\n",
      "iteration: 53400 loss: 0.0048 lr: 0.02\n",
      "iteration: 53410 loss: 0.0038 lr: 0.02\n",
      "iteration: 53420 loss: 0.0032 lr: 0.02\n",
      "iteration: 53430 loss: 0.0035 lr: 0.02\n",
      "iteration: 53440 loss: 0.0035 lr: 0.02\n",
      "iteration: 53450 loss: 0.0044 lr: 0.02\n",
      "iteration: 53460 loss: 0.0038 lr: 0.02\n",
      "iteration: 53470 loss: 0.0034 lr: 0.02\n",
      "iteration: 53480 loss: 0.0053 lr: 0.02\n",
      "iteration: 53490 loss: 0.0041 lr: 0.02\n",
      "iteration: 53500 loss: 0.0044 lr: 0.02\n",
      "iteration: 53510 loss: 0.0057 lr: 0.02\n",
      "iteration: 53520 loss: 0.0046 lr: 0.02\n",
      "iteration: 53530 loss: 0.0032 lr: 0.02\n",
      "iteration: 53540 loss: 0.0050 lr: 0.02\n",
      "iteration: 53550 loss: 0.0040 lr: 0.02\n",
      "iteration: 53560 loss: 0.0042 lr: 0.02\n",
      "iteration: 53570 loss: 0.0043 lr: 0.02\n",
      "iteration: 53580 loss: 0.0062 lr: 0.02\n",
      "iteration: 53590 loss: 0.0047 lr: 0.02\n",
      "iteration: 53600 loss: 0.0039 lr: 0.02\n",
      "iteration: 53610 loss: 0.0038 lr: 0.02\n",
      "iteration: 53620 loss: 0.0044 lr: 0.02\n",
      "iteration: 53630 loss: 0.0039 lr: 0.02\n",
      "iteration: 53640 loss: 0.0038 lr: 0.02\n",
      "iteration: 53650 loss: 0.0045 lr: 0.02\n",
      "iteration: 53660 loss: 0.0055 lr: 0.02\n",
      "iteration: 53670 loss: 0.0047 lr: 0.02\n",
      "iteration: 53680 loss: 0.0036 lr: 0.02\n",
      "iteration: 53690 loss: 0.0039 lr: 0.02\n",
      "iteration: 53700 loss: 0.0054 lr: 0.02\n",
      "iteration: 53710 loss: 0.0043 lr: 0.02\n",
      "iteration: 53720 loss: 0.0038 lr: 0.02\n",
      "iteration: 53730 loss: 0.0038 lr: 0.02\n",
      "iteration: 53740 loss: 0.0046 lr: 0.02\n",
      "iteration: 53750 loss: 0.0046 lr: 0.02\n",
      "iteration: 53760 loss: 0.0041 lr: 0.02\n",
      "iteration: 53770 loss: 0.0053 lr: 0.02\n",
      "iteration: 53780 loss: 0.0038 lr: 0.02\n",
      "iteration: 53790 loss: 0.0040 lr: 0.02\n",
      "iteration: 53800 loss: 0.0038 lr: 0.02\n",
      "iteration: 53810 loss: 0.0038 lr: 0.02\n",
      "iteration: 53820 loss: 0.0041 lr: 0.02\n",
      "iteration: 53830 loss: 0.0041 lr: 0.02\n",
      "iteration: 53840 loss: 0.0041 lr: 0.02\n",
      "iteration: 53850 loss: 0.0053 lr: 0.02\n",
      "iteration: 53860 loss: 0.0039 lr: 0.02\n",
      "iteration: 53870 loss: 0.0037 lr: 0.02\n",
      "iteration: 53880 loss: 0.0040 lr: 0.02\n",
      "iteration: 53890 loss: 0.0031 lr: 0.02\n",
      "iteration: 53900 loss: 0.0038 lr: 0.02\n",
      "iteration: 53910 loss: 0.0037 lr: 0.02\n",
      "iteration: 53920 loss: 0.0043 lr: 0.02\n",
      "iteration: 53930 loss: 0.0046 lr: 0.02\n",
      "iteration: 53940 loss: 0.0031 lr: 0.02\n",
      "iteration: 53950 loss: 0.0041 lr: 0.02\n",
      "iteration: 53960 loss: 0.0039 lr: 0.02\n",
      "iteration: 53970 loss: 0.0032 lr: 0.02\n",
      "iteration: 53980 loss: 0.0062 lr: 0.02\n",
      "iteration: 53990 loss: 0.0049 lr: 0.02\n",
      "iteration: 54000 loss: 0.0051 lr: 0.02\n",
      "iteration: 54010 loss: 0.0045 lr: 0.02\n",
      "iteration: 54020 loss: 0.0045 lr: 0.02\n",
      "iteration: 54030 loss: 0.0034 lr: 0.02\n",
      "iteration: 54040 loss: 0.0040 lr: 0.02\n",
      "iteration: 54050 loss: 0.0043 lr: 0.02\n",
      "iteration: 54060 loss: 0.0048 lr: 0.02\n",
      "iteration: 54070 loss: 0.0053 lr: 0.02\n",
      "iteration: 54080 loss: 0.0046 lr: 0.02\n",
      "iteration: 54090 loss: 0.0045 lr: 0.02\n",
      "iteration: 54100 loss: 0.0046 lr: 0.02\n",
      "iteration: 54110 loss: 0.0049 lr: 0.02\n",
      "iteration: 54120 loss: 0.0043 lr: 0.02\n",
      "iteration: 54130 loss: 0.0041 lr: 0.02\n",
      "iteration: 54140 loss: 0.0049 lr: 0.02\n",
      "iteration: 54150 loss: 0.0038 lr: 0.02\n",
      "iteration: 54160 loss: 0.0046 lr: 0.02\n",
      "iteration: 54170 loss: 0.0028 lr: 0.02\n",
      "iteration: 54180 loss: 0.0039 lr: 0.02\n",
      "iteration: 54190 loss: 0.0036 lr: 0.02\n",
      "iteration: 54200 loss: 0.0043 lr: 0.02\n",
      "iteration: 54210 loss: 0.0035 lr: 0.02\n",
      "iteration: 54220 loss: 0.0054 lr: 0.02\n",
      "iteration: 54230 loss: 0.0044 lr: 0.02\n",
      "iteration: 54240 loss: 0.0046 lr: 0.02\n",
      "iteration: 54250 loss: 0.0038 lr: 0.02\n",
      "iteration: 54260 loss: 0.0036 lr: 0.02\n",
      "iteration: 54270 loss: 0.0038 lr: 0.02\n",
      "iteration: 54280 loss: 0.0035 lr: 0.02\n",
      "iteration: 54290 loss: 0.0055 lr: 0.02\n",
      "iteration: 54300 loss: 0.0044 lr: 0.02\n",
      "iteration: 54310 loss: 0.0033 lr: 0.02\n",
      "iteration: 54320 loss: 0.0040 lr: 0.02\n",
      "iteration: 54330 loss: 0.0040 lr: 0.02\n",
      "iteration: 54340 loss: 0.0039 lr: 0.02\n",
      "iteration: 54350 loss: 0.0032 lr: 0.02\n",
      "iteration: 54360 loss: 0.0034 lr: 0.02\n",
      "iteration: 54370 loss: 0.0053 lr: 0.02\n",
      "iteration: 54380 loss: 0.0038 lr: 0.02\n",
      "iteration: 54390 loss: 0.0040 lr: 0.02\n",
      "iteration: 54400 loss: 0.0043 lr: 0.02\n",
      "iteration: 54410 loss: 0.0049 lr: 0.02\n",
      "iteration: 54420 loss: 0.0054 lr: 0.02\n",
      "iteration: 54430 loss: 0.0042 lr: 0.02\n",
      "iteration: 54440 loss: 0.0045 lr: 0.02\n",
      "iteration: 54450 loss: 0.0037 lr: 0.02\n",
      "iteration: 54460 loss: 0.0042 lr: 0.02\n",
      "iteration: 54470 loss: 0.0034 lr: 0.02\n",
      "iteration: 54480 loss: 0.0041 lr: 0.02\n",
      "iteration: 54490 loss: 0.0037 lr: 0.02\n",
      "iteration: 54500 loss: 0.0038 lr: 0.02\n",
      "iteration: 54510 loss: 0.0039 lr: 0.02\n",
      "iteration: 54520 loss: 0.0043 lr: 0.02\n",
      "iteration: 54530 loss: 0.0044 lr: 0.02\n",
      "iteration: 54540 loss: 0.0035 lr: 0.02\n",
      "iteration: 54550 loss: 0.0051 lr: 0.02\n",
      "iteration: 54560 loss: 0.0039 lr: 0.02\n",
      "iteration: 54570 loss: 0.0041 lr: 0.02\n",
      "iteration: 54580 loss: 0.0054 lr: 0.02\n",
      "iteration: 54590 loss: 0.0042 lr: 0.02\n",
      "iteration: 54600 loss: 0.0041 lr: 0.02\n",
      "iteration: 54610 loss: 0.0029 lr: 0.02\n",
      "iteration: 54620 loss: 0.0044 lr: 0.02\n",
      "iteration: 54630 loss: 0.0032 lr: 0.02\n",
      "iteration: 54640 loss: 0.0044 lr: 0.02\n",
      "iteration: 54650 loss: 0.0036 lr: 0.02\n",
      "iteration: 54660 loss: 0.0042 lr: 0.02\n",
      "iteration: 54670 loss: 0.0048 lr: 0.02\n",
      "iteration: 54680 loss: 0.0038 lr: 0.02\n",
      "iteration: 54690 loss: 0.0034 lr: 0.02\n",
      "iteration: 54700 loss: 0.0038 lr: 0.02\n",
      "iteration: 54710 loss: 0.0037 lr: 0.02\n",
      "iteration: 54720 loss: 0.0046 lr: 0.02\n",
      "iteration: 54730 loss: 0.0039 lr: 0.02\n",
      "iteration: 54740 loss: 0.0053 lr: 0.02\n",
      "iteration: 54750 loss: 0.0041 lr: 0.02\n",
      "iteration: 54760 loss: 0.0043 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 54770 loss: 0.0039 lr: 0.02\n",
      "iteration: 54780 loss: 0.0043 lr: 0.02\n",
      "iteration: 54790 loss: 0.0047 lr: 0.02\n",
      "iteration: 54800 loss: 0.0036 lr: 0.02\n",
      "iteration: 54810 loss: 0.0047 lr: 0.02\n",
      "iteration: 54820 loss: 0.0035 lr: 0.02\n",
      "iteration: 54830 loss: 0.0042 lr: 0.02\n",
      "iteration: 54840 loss: 0.0036 lr: 0.02\n",
      "iteration: 54850 loss: 0.0043 lr: 0.02\n",
      "iteration: 54860 loss: 0.0039 lr: 0.02\n",
      "iteration: 54870 loss: 0.0041 lr: 0.02\n",
      "iteration: 54880 loss: 0.0050 lr: 0.02\n",
      "iteration: 54890 loss: 0.0048 lr: 0.02\n",
      "iteration: 54900 loss: 0.0039 lr: 0.02\n",
      "iteration: 54910 loss: 0.0048 lr: 0.02\n",
      "iteration: 54920 loss: 0.0036 lr: 0.02\n",
      "iteration: 54930 loss: 0.0049 lr: 0.02\n",
      "iteration: 54940 loss: 0.0046 lr: 0.02\n",
      "iteration: 54950 loss: 0.0045 lr: 0.02\n",
      "iteration: 54960 loss: 0.0037 lr: 0.02\n",
      "iteration: 54970 loss: 0.0043 lr: 0.02\n",
      "iteration: 54980 loss: 0.0045 lr: 0.02\n",
      "iteration: 54990 loss: 0.0034 lr: 0.02\n",
      "iteration: 55000 loss: 0.0046 lr: 0.02\n",
      "iteration: 55010 loss: 0.0042 lr: 0.02\n",
      "iteration: 55020 loss: 0.0034 lr: 0.02\n",
      "iteration: 55030 loss: 0.0043 lr: 0.02\n",
      "iteration: 55040 loss: 0.0040 lr: 0.02\n",
      "iteration: 55050 loss: 0.0031 lr: 0.02\n",
      "iteration: 55060 loss: 0.0047 lr: 0.02\n",
      "iteration: 55070 loss: 0.0052 lr: 0.02\n",
      "iteration: 55080 loss: 0.0051 lr: 0.02\n",
      "iteration: 55090 loss: 0.0043 lr: 0.02\n",
      "iteration: 55100 loss: 0.0042 lr: 0.02\n",
      "iteration: 55110 loss: 0.0041 lr: 0.02\n",
      "iteration: 55120 loss: 0.0056 lr: 0.02\n",
      "iteration: 55130 loss: 0.0035 lr: 0.02\n",
      "iteration: 55140 loss: 0.0044 lr: 0.02\n",
      "iteration: 55150 loss: 0.0041 lr: 0.02\n",
      "iteration: 55160 loss: 0.0038 lr: 0.02\n",
      "iteration: 55170 loss: 0.0040 lr: 0.02\n",
      "iteration: 55180 loss: 0.0057 lr: 0.02\n",
      "iteration: 55190 loss: 0.0042 lr: 0.02\n",
      "iteration: 55200 loss: 0.0046 lr: 0.02\n",
      "iteration: 55210 loss: 0.0031 lr: 0.02\n",
      "iteration: 55220 loss: 0.0046 lr: 0.02\n",
      "iteration: 55230 loss: 0.0038 lr: 0.02\n",
      "iteration: 55240 loss: 0.0042 lr: 0.02\n",
      "iteration: 55250 loss: 0.0050 lr: 0.02\n",
      "iteration: 55260 loss: 0.0056 lr: 0.02\n",
      "iteration: 55270 loss: 0.0041 lr: 0.02\n",
      "iteration: 55280 loss: 0.0041 lr: 0.02\n",
      "iteration: 55290 loss: 0.0041 lr: 0.02\n",
      "iteration: 55300 loss: 0.0040 lr: 0.02\n",
      "iteration: 55310 loss: 0.0034 lr: 0.02\n",
      "iteration: 55320 loss: 0.0039 lr: 0.02\n",
      "iteration: 55330 loss: 0.0042 lr: 0.02\n",
      "iteration: 55340 loss: 0.0041 lr: 0.02\n",
      "iteration: 55350 loss: 0.0045 lr: 0.02\n",
      "iteration: 55360 loss: 0.0039 lr: 0.02\n",
      "iteration: 55370 loss: 0.0040 lr: 0.02\n",
      "iteration: 55380 loss: 0.0050 lr: 0.02\n",
      "iteration: 55390 loss: 0.0042 lr: 0.02\n",
      "iteration: 55400 loss: 0.0037 lr: 0.02\n",
      "iteration: 55410 loss: 0.0041 lr: 0.02\n",
      "iteration: 55420 loss: 0.0035 lr: 0.02\n",
      "iteration: 55430 loss: 0.0040 lr: 0.02\n",
      "iteration: 55440 loss: 0.0036 lr: 0.02\n",
      "iteration: 55450 loss: 0.0050 lr: 0.02\n",
      "iteration: 55460 loss: 0.0052 lr: 0.02\n",
      "iteration: 55470 loss: 0.0041 lr: 0.02\n",
      "iteration: 55480 loss: 0.0039 lr: 0.02\n",
      "iteration: 55490 loss: 0.0038 lr: 0.02\n",
      "iteration: 55500 loss: 0.0035 lr: 0.02\n",
      "iteration: 55510 loss: 0.0039 lr: 0.02\n",
      "iteration: 55520 loss: 0.0039 lr: 0.02\n",
      "iteration: 55530 loss: 0.0030 lr: 0.02\n",
      "iteration: 55540 loss: 0.0034 lr: 0.02\n",
      "iteration: 55550 loss: 0.0034 lr: 0.02\n",
      "iteration: 55560 loss: 0.0044 lr: 0.02\n",
      "iteration: 55570 loss: 0.0032 lr: 0.02\n",
      "iteration: 55580 loss: 0.0039 lr: 0.02\n",
      "iteration: 55590 loss: 0.0048 lr: 0.02\n",
      "iteration: 55600 loss: 0.0034 lr: 0.02\n",
      "iteration: 55610 loss: 0.0048 lr: 0.02\n",
      "iteration: 55620 loss: 0.0039 lr: 0.02\n",
      "iteration: 55630 loss: 0.0046 lr: 0.02\n",
      "iteration: 55640 loss: 0.0042 lr: 0.02\n",
      "iteration: 55650 loss: 0.0039 lr: 0.02\n",
      "iteration: 55660 loss: 0.0035 lr: 0.02\n",
      "iteration: 55670 loss: 0.0037 lr: 0.02\n",
      "iteration: 55680 loss: 0.0035 lr: 0.02\n",
      "iteration: 55690 loss: 0.0032 lr: 0.02\n",
      "iteration: 55700 loss: 0.0053 lr: 0.02\n",
      "iteration: 55710 loss: 0.0038 lr: 0.02\n",
      "iteration: 55720 loss: 0.0032 lr: 0.02\n",
      "iteration: 55730 loss: 0.0045 lr: 0.02\n",
      "iteration: 55740 loss: 0.0037 lr: 0.02\n",
      "iteration: 55750 loss: 0.0040 lr: 0.02\n",
      "iteration: 55760 loss: 0.0046 lr: 0.02\n",
      "iteration: 55770 loss: 0.0048 lr: 0.02\n",
      "iteration: 55780 loss: 0.0039 lr: 0.02\n",
      "iteration: 55790 loss: 0.0045 lr: 0.02\n",
      "iteration: 55800 loss: 0.0038 lr: 0.02\n",
      "iteration: 55810 loss: 0.0036 lr: 0.02\n",
      "iteration: 55820 loss: 0.0045 lr: 0.02\n",
      "iteration: 55830 loss: 0.0038 lr: 0.02\n",
      "iteration: 55840 loss: 0.0038 lr: 0.02\n",
      "iteration: 55850 loss: 0.0044 lr: 0.02\n",
      "iteration: 55860 loss: 0.0045 lr: 0.02\n",
      "iteration: 55870 loss: 0.0057 lr: 0.02\n",
      "iteration: 55880 loss: 0.0052 lr: 0.02\n",
      "iteration: 55890 loss: 0.0046 lr: 0.02\n",
      "iteration: 55900 loss: 0.0045 lr: 0.02\n",
      "iteration: 55910 loss: 0.0053 lr: 0.02\n",
      "iteration: 55920 loss: 0.0047 lr: 0.02\n",
      "iteration: 55930 loss: 0.0039 lr: 0.02\n",
      "iteration: 55940 loss: 0.0044 lr: 0.02\n",
      "iteration: 55950 loss: 0.0037 lr: 0.02\n",
      "iteration: 55960 loss: 0.0033 lr: 0.02\n",
      "iteration: 55970 loss: 0.0039 lr: 0.02\n",
      "iteration: 55980 loss: 0.0035 lr: 0.02\n",
      "iteration: 55990 loss: 0.0044 lr: 0.02\n",
      "iteration: 56000 loss: 0.0047 lr: 0.02\n",
      "iteration: 56010 loss: 0.0036 lr: 0.02\n",
      "iteration: 56020 loss: 0.0043 lr: 0.02\n",
      "iteration: 56030 loss: 0.0045 lr: 0.02\n",
      "iteration: 56040 loss: 0.0044 lr: 0.02\n",
      "iteration: 56050 loss: 0.0042 lr: 0.02\n",
      "iteration: 56060 loss: 0.0035 lr: 0.02\n",
      "iteration: 56070 loss: 0.0044 lr: 0.02\n",
      "iteration: 56080 loss: 0.0038 lr: 0.02\n",
      "iteration: 56090 loss: 0.0038 lr: 0.02\n",
      "iteration: 56100 loss: 0.0038 lr: 0.02\n",
      "iteration: 56110 loss: 0.0031 lr: 0.02\n",
      "iteration: 56120 loss: 0.0056 lr: 0.02\n",
      "iteration: 56130 loss: 0.0034 lr: 0.02\n",
      "iteration: 56140 loss: 0.0050 lr: 0.02\n",
      "iteration: 56150 loss: 0.0056 lr: 0.02\n",
      "iteration: 56160 loss: 0.0033 lr: 0.02\n",
      "iteration: 56170 loss: 0.0048 lr: 0.02\n",
      "iteration: 56180 loss: 0.0046 lr: 0.02\n",
      "iteration: 56190 loss: 0.0049 lr: 0.02\n",
      "iteration: 56200 loss: 0.0041 lr: 0.02\n",
      "iteration: 56210 loss: 0.0042 lr: 0.02\n",
      "iteration: 56220 loss: 0.0041 lr: 0.02\n",
      "iteration: 56230 loss: 0.0042 lr: 0.02\n",
      "iteration: 56240 loss: 0.0044 lr: 0.02\n",
      "iteration: 56250 loss: 0.0049 lr: 0.02\n",
      "iteration: 56260 loss: 0.0042 lr: 0.02\n",
      "iteration: 56270 loss: 0.0047 lr: 0.02\n",
      "iteration: 56280 loss: 0.0045 lr: 0.02\n",
      "iteration: 56290 loss: 0.0043 lr: 0.02\n",
      "iteration: 56300 loss: 0.0047 lr: 0.02\n",
      "iteration: 56310 loss: 0.0037 lr: 0.02\n",
      "iteration: 56320 loss: 0.0040 lr: 0.02\n",
      "iteration: 56330 loss: 0.0033 lr: 0.02\n",
      "iteration: 56340 loss: 0.0037 lr: 0.02\n",
      "iteration: 56350 loss: 0.0046 lr: 0.02\n",
      "iteration: 56360 loss: 0.0045 lr: 0.02\n",
      "iteration: 56370 loss: 0.0047 lr: 0.02\n",
      "iteration: 56380 loss: 0.0047 lr: 0.02\n",
      "iteration: 56390 loss: 0.0048 lr: 0.02\n",
      "iteration: 56400 loss: 0.0041 lr: 0.02\n",
      "iteration: 56410 loss: 0.0036 lr: 0.02\n",
      "iteration: 56420 loss: 0.0052 lr: 0.02\n",
      "iteration: 56430 loss: 0.0049 lr: 0.02\n",
      "iteration: 56440 loss: 0.0051 lr: 0.02\n",
      "iteration: 56450 loss: 0.0044 lr: 0.02\n",
      "iteration: 56460 loss: 0.0052 lr: 0.02\n",
      "iteration: 56470 loss: 0.0036 lr: 0.02\n",
      "iteration: 56480 loss: 0.0047 lr: 0.02\n",
      "iteration: 56490 loss: 0.0050 lr: 0.02\n",
      "iteration: 56500 loss: 0.0044 lr: 0.02\n",
      "iteration: 56510 loss: 0.0044 lr: 0.02\n",
      "iteration: 56520 loss: 0.0032 lr: 0.02\n",
      "iteration: 56530 loss: 0.0050 lr: 0.02\n",
      "iteration: 56540 loss: 0.0063 lr: 0.02\n",
      "iteration: 56550 loss: 0.0044 lr: 0.02\n",
      "iteration: 56560 loss: 0.0046 lr: 0.02\n",
      "iteration: 56570 loss: 0.0043 lr: 0.02\n",
      "iteration: 56580 loss: 0.0042 lr: 0.02\n",
      "iteration: 56590 loss: 0.0031 lr: 0.02\n",
      "iteration: 56600 loss: 0.0050 lr: 0.02\n",
      "iteration: 56610 loss: 0.0041 lr: 0.02\n",
      "iteration: 56620 loss: 0.0046 lr: 0.02\n",
      "iteration: 56630 loss: 0.0036 lr: 0.02\n",
      "iteration: 56640 loss: 0.0039 lr: 0.02\n",
      "iteration: 56650 loss: 0.0042 lr: 0.02\n",
      "iteration: 56660 loss: 0.0039 lr: 0.02\n",
      "iteration: 56670 loss: 0.0040 lr: 0.02\n",
      "iteration: 56680 loss: 0.0045 lr: 0.02\n",
      "iteration: 56690 loss: 0.0038 lr: 0.02\n",
      "iteration: 56700 loss: 0.0036 lr: 0.02\n",
      "iteration: 56710 loss: 0.0035 lr: 0.02\n",
      "iteration: 56720 loss: 0.0028 lr: 0.02\n",
      "iteration: 56730 loss: 0.0044 lr: 0.02\n",
      "iteration: 56740 loss: 0.0043 lr: 0.02\n",
      "iteration: 56750 loss: 0.0040 lr: 0.02\n",
      "iteration: 56760 loss: 0.0044 lr: 0.02\n",
      "iteration: 56770 loss: 0.0040 lr: 0.02\n",
      "iteration: 56780 loss: 0.0054 lr: 0.02\n",
      "iteration: 56790 loss: 0.0053 lr: 0.02\n",
      "iteration: 56800 loss: 0.0040 lr: 0.02\n",
      "iteration: 56810 loss: 0.0032 lr: 0.02\n",
      "iteration: 56820 loss: 0.0041 lr: 0.02\n",
      "iteration: 56830 loss: 0.0038 lr: 0.02\n",
      "iteration: 56840 loss: 0.0037 lr: 0.02\n",
      "iteration: 56850 loss: 0.0044 lr: 0.02\n",
      "iteration: 56860 loss: 0.0040 lr: 0.02\n",
      "iteration: 56870 loss: 0.0038 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 56880 loss: 0.0036 lr: 0.02\n",
      "iteration: 56890 loss: 0.0050 lr: 0.02\n",
      "iteration: 56900 loss: 0.0044 lr: 0.02\n",
      "iteration: 56910 loss: 0.0030 lr: 0.02\n",
      "iteration: 56920 loss: 0.0045 lr: 0.02\n",
      "iteration: 56930 loss: 0.0033 lr: 0.02\n",
      "iteration: 56940 loss: 0.0041 lr: 0.02\n",
      "iteration: 56950 loss: 0.0042 lr: 0.02\n",
      "iteration: 56960 loss: 0.0047 lr: 0.02\n",
      "iteration: 56970 loss: 0.0039 lr: 0.02\n",
      "iteration: 56980 loss: 0.0046 lr: 0.02\n",
      "iteration: 56990 loss: 0.0040 lr: 0.02\n",
      "iteration: 57000 loss: 0.0034 lr: 0.02\n",
      "iteration: 57010 loss: 0.0034 lr: 0.02\n",
      "iteration: 57020 loss: 0.0043 lr: 0.02\n",
      "iteration: 57030 loss: 0.0033 lr: 0.02\n",
      "iteration: 57040 loss: 0.0049 lr: 0.02\n",
      "iteration: 57050 loss: 0.0038 lr: 0.02\n",
      "iteration: 57060 loss: 0.0037 lr: 0.02\n",
      "iteration: 57070 loss: 0.0043 lr: 0.02\n",
      "iteration: 57080 loss: 0.0034 lr: 0.02\n",
      "iteration: 57090 loss: 0.0056 lr: 0.02\n",
      "iteration: 57100 loss: 0.0036 lr: 0.02\n",
      "iteration: 57110 loss: 0.0044 lr: 0.02\n",
      "iteration: 57120 loss: 0.0038 lr: 0.02\n",
      "iteration: 57130 loss: 0.0035 lr: 0.02\n",
      "iteration: 57140 loss: 0.0041 lr: 0.02\n",
      "iteration: 57150 loss: 0.0032 lr: 0.02\n",
      "iteration: 57160 loss: 0.0036 lr: 0.02\n",
      "iteration: 57170 loss: 0.0043 lr: 0.02\n",
      "iteration: 57180 loss: 0.0043 lr: 0.02\n",
      "iteration: 57190 loss: 0.0045 lr: 0.02\n",
      "iteration: 57200 loss: 0.0041 lr: 0.02\n",
      "iteration: 57210 loss: 0.0039 lr: 0.02\n",
      "iteration: 57220 loss: 0.0038 lr: 0.02\n",
      "iteration: 57230 loss: 0.0037 lr: 0.02\n",
      "iteration: 57240 loss: 0.0042 lr: 0.02\n",
      "iteration: 57250 loss: 0.0034 lr: 0.02\n",
      "iteration: 57260 loss: 0.0040 lr: 0.02\n",
      "iteration: 57270 loss: 0.0040 lr: 0.02\n",
      "iteration: 57280 loss: 0.0034 lr: 0.02\n",
      "iteration: 57290 loss: 0.0041 lr: 0.02\n",
      "iteration: 57300 loss: 0.0048 lr: 0.02\n",
      "iteration: 57310 loss: 0.0042 lr: 0.02\n",
      "iteration: 57320 loss: 0.0036 lr: 0.02\n",
      "iteration: 57330 loss: 0.0036 lr: 0.02\n",
      "iteration: 57340 loss: 0.0037 lr: 0.02\n",
      "iteration: 57350 loss: 0.0038 lr: 0.02\n",
      "iteration: 57360 loss: 0.0035 lr: 0.02\n",
      "iteration: 57370 loss: 0.0046 lr: 0.02\n",
      "iteration: 57380 loss: 0.0045 lr: 0.02\n",
      "iteration: 57390 loss: 0.0037 lr: 0.02\n",
      "iteration: 57400 loss: 0.0041 lr: 0.02\n",
      "iteration: 57410 loss: 0.0039 lr: 0.02\n",
      "iteration: 57420 loss: 0.0042 lr: 0.02\n",
      "iteration: 57430 loss: 0.0044 lr: 0.02\n",
      "iteration: 57440 loss: 0.0044 lr: 0.02\n",
      "iteration: 57450 loss: 0.0041 lr: 0.02\n",
      "iteration: 57460 loss: 0.0033 lr: 0.02\n",
      "iteration: 57470 loss: 0.0042 lr: 0.02\n",
      "iteration: 57480 loss: 0.0047 lr: 0.02\n",
      "iteration: 57490 loss: 0.0033 lr: 0.02\n",
      "iteration: 57500 loss: 0.0041 lr: 0.02\n",
      "iteration: 57510 loss: 0.0044 lr: 0.02\n",
      "iteration: 57520 loss: 0.0037 lr: 0.02\n",
      "iteration: 57530 loss: 0.0039 lr: 0.02\n",
      "iteration: 57540 loss: 0.0043 lr: 0.02\n",
      "iteration: 57550 loss: 0.0032 lr: 0.02\n",
      "iteration: 57560 loss: 0.0040 lr: 0.02\n",
      "iteration: 57570 loss: 0.0045 lr: 0.02\n",
      "iteration: 57580 loss: 0.0035 lr: 0.02\n",
      "iteration: 57590 loss: 0.0036 lr: 0.02\n",
      "iteration: 57600 loss: 0.0039 lr: 0.02\n",
      "iteration: 57610 loss: 0.0036 lr: 0.02\n",
      "iteration: 57620 loss: 0.0029 lr: 0.02\n",
      "iteration: 57630 loss: 0.0036 lr: 0.02\n",
      "iteration: 57640 loss: 0.0045 lr: 0.02\n",
      "iteration: 57650 loss: 0.0037 lr: 0.02\n",
      "iteration: 57660 loss: 0.0044 lr: 0.02\n",
      "iteration: 57670 loss: 0.0034 lr: 0.02\n",
      "iteration: 57680 loss: 0.0038 lr: 0.02\n",
      "iteration: 57690 loss: 0.0035 lr: 0.02\n",
      "iteration: 57700 loss: 0.0040 lr: 0.02\n",
      "iteration: 57710 loss: 0.0045 lr: 0.02\n",
      "iteration: 57720 loss: 0.0044 lr: 0.02\n",
      "iteration: 57730 loss: 0.0051 lr: 0.02\n",
      "iteration: 57740 loss: 0.0039 lr: 0.02\n",
      "iteration: 57750 loss: 0.0034 lr: 0.02\n",
      "iteration: 57760 loss: 0.0040 lr: 0.02\n",
      "iteration: 57770 loss: 0.0037 lr: 0.02\n",
      "iteration: 57780 loss: 0.0044 lr: 0.02\n",
      "iteration: 57790 loss: 0.0042 lr: 0.02\n",
      "iteration: 57800 loss: 0.0035 lr: 0.02\n",
      "iteration: 57810 loss: 0.0030 lr: 0.02\n",
      "iteration: 57820 loss: 0.0041 lr: 0.02\n",
      "iteration: 57830 loss: 0.0038 lr: 0.02\n",
      "iteration: 57840 loss: 0.0042 lr: 0.02\n",
      "iteration: 57850 loss: 0.0038 lr: 0.02\n",
      "iteration: 57860 loss: 0.0042 lr: 0.02\n",
      "iteration: 57870 loss: 0.0038 lr: 0.02\n",
      "iteration: 57880 loss: 0.0034 lr: 0.02\n",
      "iteration: 57890 loss: 0.0040 lr: 0.02\n",
      "iteration: 57900 loss: 0.0034 lr: 0.02\n",
      "iteration: 57910 loss: 0.0038 lr: 0.02\n",
      "iteration: 57920 loss: 0.0041 lr: 0.02\n",
      "iteration: 57930 loss: 0.0033 lr: 0.02\n",
      "iteration: 57940 loss: 0.0038 lr: 0.02\n",
      "iteration: 57950 loss: 0.0042 lr: 0.02\n",
      "iteration: 57960 loss: 0.0038 lr: 0.02\n",
      "iteration: 57970 loss: 0.0062 lr: 0.02\n",
      "iteration: 57980 loss: 0.0038 lr: 0.02\n",
      "iteration: 57990 loss: 0.0034 lr: 0.02\n",
      "iteration: 58000 loss: 0.0046 lr: 0.02\n",
      "iteration: 58010 loss: 0.0036 lr: 0.02\n",
      "iteration: 58020 loss: 0.0042 lr: 0.02\n",
      "iteration: 58030 loss: 0.0045 lr: 0.02\n",
      "iteration: 58040 loss: 0.0033 lr: 0.02\n",
      "iteration: 58050 loss: 0.0043 lr: 0.02\n",
      "iteration: 58060 loss: 0.0042 lr: 0.02\n",
      "iteration: 58070 loss: 0.0042 lr: 0.02\n",
      "iteration: 58080 loss: 0.0047 lr: 0.02\n",
      "iteration: 58090 loss: 0.0039 lr: 0.02\n",
      "iteration: 58100 loss: 0.0037 lr: 0.02\n",
      "iteration: 58110 loss: 0.0032 lr: 0.02\n",
      "iteration: 58120 loss: 0.0033 lr: 0.02\n",
      "iteration: 58130 loss: 0.0037 lr: 0.02\n",
      "iteration: 58140 loss: 0.0036 lr: 0.02\n",
      "iteration: 58150 loss: 0.0037 lr: 0.02\n",
      "iteration: 58160 loss: 0.0039 lr: 0.02\n",
      "iteration: 58170 loss: 0.0050 lr: 0.02\n",
      "iteration: 58180 loss: 0.0043 lr: 0.02\n",
      "iteration: 58190 loss: 0.0035 lr: 0.02\n",
      "iteration: 58200 loss: 0.0044 lr: 0.02\n",
      "iteration: 58210 loss: 0.0045 lr: 0.02\n",
      "iteration: 58220 loss: 0.0034 lr: 0.02\n",
      "iteration: 58230 loss: 0.0041 lr: 0.02\n",
      "iteration: 58240 loss: 0.0035 lr: 0.02\n",
      "iteration: 58250 loss: 0.0036 lr: 0.02\n",
      "iteration: 58260 loss: 0.0037 lr: 0.02\n",
      "iteration: 58270 loss: 0.0046 lr: 0.02\n",
      "iteration: 58280 loss: 0.0038 lr: 0.02\n",
      "iteration: 58290 loss: 0.0045 lr: 0.02\n",
      "iteration: 58300 loss: 0.0045 lr: 0.02\n",
      "iteration: 58310 loss: 0.0046 lr: 0.02\n",
      "iteration: 58320 loss: 0.0036 lr: 0.02\n",
      "iteration: 58330 loss: 0.0040 lr: 0.02\n",
      "iteration: 58340 loss: 0.0037 lr: 0.02\n",
      "iteration: 58350 loss: 0.0039 lr: 0.02\n",
      "iteration: 58360 loss: 0.0043 lr: 0.02\n",
      "iteration: 58370 loss: 0.0045 lr: 0.02\n",
      "iteration: 58380 loss: 0.0033 lr: 0.02\n",
      "iteration: 58390 loss: 0.0035 lr: 0.02\n",
      "iteration: 58400 loss: 0.0032 lr: 0.02\n",
      "iteration: 58410 loss: 0.0044 lr: 0.02\n",
      "iteration: 58420 loss: 0.0039 lr: 0.02\n",
      "iteration: 58430 loss: 0.0046 lr: 0.02\n",
      "iteration: 58440 loss: 0.0038 lr: 0.02\n",
      "iteration: 58450 loss: 0.0034 lr: 0.02\n",
      "iteration: 58460 loss: 0.0047 lr: 0.02\n",
      "iteration: 58470 loss: 0.0036 lr: 0.02\n",
      "iteration: 58480 loss: 0.0037 lr: 0.02\n",
      "iteration: 58490 loss: 0.0047 lr: 0.02\n",
      "iteration: 58500 loss: 0.0048 lr: 0.02\n",
      "iteration: 58510 loss: 0.0046 lr: 0.02\n",
      "iteration: 58520 loss: 0.0036 lr: 0.02\n",
      "iteration: 58530 loss: 0.0035 lr: 0.02\n",
      "iteration: 58540 loss: 0.0042 lr: 0.02\n",
      "iteration: 58550 loss: 0.0032 lr: 0.02\n",
      "iteration: 58560 loss: 0.0040 lr: 0.02\n",
      "iteration: 58570 loss: 0.0049 lr: 0.02\n",
      "iteration: 58580 loss: 0.0034 lr: 0.02\n",
      "iteration: 58590 loss: 0.0035 lr: 0.02\n",
      "iteration: 58600 loss: 0.0032 lr: 0.02\n",
      "iteration: 58610 loss: 0.0038 lr: 0.02\n",
      "iteration: 58620 loss: 0.0044 lr: 0.02\n",
      "iteration: 58630 loss: 0.0031 lr: 0.02\n",
      "iteration: 58640 loss: 0.0045 lr: 0.02\n",
      "iteration: 58650 loss: 0.0044 lr: 0.02\n",
      "iteration: 58660 loss: 0.0035 lr: 0.02\n",
      "iteration: 58670 loss: 0.0038 lr: 0.02\n",
      "iteration: 58680 loss: 0.0033 lr: 0.02\n",
      "iteration: 58690 loss: 0.0029 lr: 0.02\n",
      "iteration: 58700 loss: 0.0037 lr: 0.02\n",
      "iteration: 58710 loss: 0.0041 lr: 0.02\n",
      "iteration: 58720 loss: 0.0044 lr: 0.02\n",
      "iteration: 58730 loss: 0.0037 lr: 0.02\n",
      "iteration: 58740 loss: 0.0037 lr: 0.02\n",
      "iteration: 58750 loss: 0.0051 lr: 0.02\n",
      "iteration: 58760 loss: 0.0038 lr: 0.02\n",
      "iteration: 58770 loss: 0.0047 lr: 0.02\n",
      "iteration: 58780 loss: 0.0039 lr: 0.02\n",
      "iteration: 58790 loss: 0.0045 lr: 0.02\n",
      "iteration: 58800 loss: 0.0046 lr: 0.02\n",
      "iteration: 58810 loss: 0.0032 lr: 0.02\n",
      "iteration: 58820 loss: 0.0026 lr: 0.02\n",
      "iteration: 58830 loss: 0.0027 lr: 0.02\n",
      "iteration: 58840 loss: 0.0042 lr: 0.02\n",
      "iteration: 58850 loss: 0.0048 lr: 0.02\n",
      "iteration: 58860 loss: 0.0034 lr: 0.02\n",
      "iteration: 58870 loss: 0.0041 lr: 0.02\n",
      "iteration: 58880 loss: 0.0035 lr: 0.02\n",
      "iteration: 58890 loss: 0.0038 lr: 0.02\n",
      "iteration: 58900 loss: 0.0030 lr: 0.02\n",
      "iteration: 58910 loss: 0.0048 lr: 0.02\n",
      "iteration: 58920 loss: 0.0066 lr: 0.02\n",
      "iteration: 58930 loss: 0.0040 lr: 0.02\n",
      "iteration: 58940 loss: 0.0041 lr: 0.02\n",
      "iteration: 58950 loss: 0.0039 lr: 0.02\n",
      "iteration: 58960 loss: 0.0035 lr: 0.02\n",
      "iteration: 58970 loss: 0.0035 lr: 0.02\n",
      "iteration: 58980 loss: 0.0033 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 58990 loss: 0.0044 lr: 0.02\n",
      "iteration: 59000 loss: 0.0032 lr: 0.02\n",
      "iteration: 59010 loss: 0.0041 lr: 0.02\n",
      "iteration: 59020 loss: 0.0035 lr: 0.02\n",
      "iteration: 59030 loss: 0.0036 lr: 0.02\n",
      "iteration: 59040 loss: 0.0034 lr: 0.02\n",
      "iteration: 59050 loss: 0.0053 lr: 0.02\n",
      "iteration: 59060 loss: 0.0044 lr: 0.02\n",
      "iteration: 59070 loss: 0.0037 lr: 0.02\n",
      "iteration: 59080 loss: 0.0039 lr: 0.02\n",
      "iteration: 59090 loss: 0.0035 lr: 0.02\n",
      "iteration: 59100 loss: 0.0040 lr: 0.02\n",
      "iteration: 59110 loss: 0.0033 lr: 0.02\n",
      "iteration: 59120 loss: 0.0041 lr: 0.02\n",
      "iteration: 59130 loss: 0.0030 lr: 0.02\n",
      "iteration: 59140 loss: 0.0048 lr: 0.02\n",
      "iteration: 59150 loss: 0.0047 lr: 0.02\n",
      "iteration: 59160 loss: 0.0037 lr: 0.02\n",
      "iteration: 59170 loss: 0.0034 lr: 0.02\n",
      "iteration: 59180 loss: 0.0052 lr: 0.02\n",
      "iteration: 59190 loss: 0.0035 lr: 0.02\n",
      "iteration: 59200 loss: 0.0042 lr: 0.02\n",
      "iteration: 59210 loss: 0.0036 lr: 0.02\n",
      "iteration: 59220 loss: 0.0045 lr: 0.02\n",
      "iteration: 59230 loss: 0.0032 lr: 0.02\n",
      "iteration: 59240 loss: 0.0034 lr: 0.02\n",
      "iteration: 59250 loss: 0.0045 lr: 0.02\n",
      "iteration: 59260 loss: 0.0047 lr: 0.02\n",
      "iteration: 59270 loss: 0.0041 lr: 0.02\n",
      "iteration: 59280 loss: 0.0031 lr: 0.02\n",
      "iteration: 59290 loss: 0.0042 lr: 0.02\n",
      "iteration: 59300 loss: 0.0047 lr: 0.02\n",
      "iteration: 59310 loss: 0.0040 lr: 0.02\n",
      "iteration: 59320 loss: 0.0039 lr: 0.02\n",
      "iteration: 59330 loss: 0.0037 lr: 0.02\n",
      "iteration: 59340 loss: 0.0035 lr: 0.02\n",
      "iteration: 59350 loss: 0.0039 lr: 0.02\n",
      "iteration: 59360 loss: 0.0052 lr: 0.02\n",
      "iteration: 59370 loss: 0.0043 lr: 0.02\n",
      "iteration: 59380 loss: 0.0038 lr: 0.02\n",
      "iteration: 59390 loss: 0.0038 lr: 0.02\n",
      "iteration: 59400 loss: 0.0039 lr: 0.02\n",
      "iteration: 59410 loss: 0.0043 lr: 0.02\n",
      "iteration: 59420 loss: 0.0046 lr: 0.02\n",
      "iteration: 59430 loss: 0.0061 lr: 0.02\n",
      "iteration: 59440 loss: 0.0049 lr: 0.02\n",
      "iteration: 59450 loss: 0.0033 lr: 0.02\n",
      "iteration: 59460 loss: 0.0049 lr: 0.02\n",
      "iteration: 59470 loss: 0.0035 lr: 0.02\n",
      "iteration: 59480 loss: 0.0049 lr: 0.02\n",
      "iteration: 59490 loss: 0.0042 lr: 0.02\n",
      "iteration: 59500 loss: 0.0047 lr: 0.02\n",
      "iteration: 59510 loss: 0.0040 lr: 0.02\n",
      "iteration: 59520 loss: 0.0032 lr: 0.02\n",
      "iteration: 59530 loss: 0.0041 lr: 0.02\n",
      "iteration: 59540 loss: 0.0037 lr: 0.02\n",
      "iteration: 59550 loss: 0.0041 lr: 0.02\n",
      "iteration: 59560 loss: 0.0041 lr: 0.02\n",
      "iteration: 59570 loss: 0.0033 lr: 0.02\n",
      "iteration: 59580 loss: 0.0041 lr: 0.02\n",
      "iteration: 59590 loss: 0.0042 lr: 0.02\n",
      "iteration: 59600 loss: 0.0041 lr: 0.02\n",
      "iteration: 59610 loss: 0.0037 lr: 0.02\n",
      "iteration: 59620 loss: 0.0045 lr: 0.02\n",
      "iteration: 59630 loss: 0.0030 lr: 0.02\n",
      "iteration: 59640 loss: 0.0038 lr: 0.02\n",
      "iteration: 59650 loss: 0.0035 lr: 0.02\n",
      "iteration: 59660 loss: 0.0042 lr: 0.02\n",
      "iteration: 59670 loss: 0.0058 lr: 0.02\n",
      "iteration: 59680 loss: 0.0047 lr: 0.02\n",
      "iteration: 59690 loss: 0.0063 lr: 0.02\n",
      "iteration: 59700 loss: 0.0034 lr: 0.02\n",
      "iteration: 59710 loss: 0.0041 lr: 0.02\n",
      "iteration: 59720 loss: 0.0035 lr: 0.02\n",
      "iteration: 59730 loss: 0.0030 lr: 0.02\n",
      "iteration: 59740 loss: 0.0043 lr: 0.02\n",
      "iteration: 59750 loss: 0.0040 lr: 0.02\n",
      "iteration: 59760 loss: 0.0038 lr: 0.02\n",
      "iteration: 59770 loss: 0.0040 lr: 0.02\n",
      "iteration: 59780 loss: 0.0041 lr: 0.02\n",
      "iteration: 59790 loss: 0.0046 lr: 0.02\n",
      "iteration: 59800 loss: 0.0043 lr: 0.02\n",
      "iteration: 59810 loss: 0.0042 lr: 0.02\n",
      "iteration: 59820 loss: 0.0037 lr: 0.02\n",
      "iteration: 59830 loss: 0.0048 lr: 0.02\n",
      "iteration: 59840 loss: 0.0031 lr: 0.02\n",
      "iteration: 59850 loss: 0.0035 lr: 0.02\n",
      "iteration: 59860 loss: 0.0036 lr: 0.02\n",
      "iteration: 59870 loss: 0.0041 lr: 0.02\n",
      "iteration: 59880 loss: 0.0040 lr: 0.02\n",
      "iteration: 59890 loss: 0.0047 lr: 0.02\n",
      "iteration: 59900 loss: 0.0042 lr: 0.02\n",
      "iteration: 59910 loss: 0.0041 lr: 0.02\n",
      "iteration: 59920 loss: 0.0047 lr: 0.02\n",
      "iteration: 59930 loss: 0.0034 lr: 0.02\n",
      "iteration: 59940 loss: 0.0041 lr: 0.02\n",
      "iteration: 59950 loss: 0.0035 lr: 0.02\n",
      "iteration: 59960 loss: 0.0058 lr: 0.02\n",
      "iteration: 59970 loss: 0.0045 lr: 0.02\n",
      "iteration: 59980 loss: 0.0042 lr: 0.02\n",
      "iteration: 59990 loss: 0.0033 lr: 0.02\n",
      "iteration: 60000 loss: 0.0034 lr: 0.02\n",
      "iteration: 60010 loss: 0.0038 lr: 0.02\n",
      "iteration: 60020 loss: 0.0044 lr: 0.02\n",
      "iteration: 60030 loss: 0.0038 lr: 0.02\n",
      "iteration: 60040 loss: 0.0043 lr: 0.02\n",
      "iteration: 60050 loss: 0.0033 lr: 0.02\n",
      "iteration: 60060 loss: 0.0053 lr: 0.02\n",
      "iteration: 60070 loss: 0.0031 lr: 0.02\n",
      "iteration: 60080 loss: 0.0033 lr: 0.02\n",
      "iteration: 60090 loss: 0.0040 lr: 0.02\n",
      "iteration: 60100 loss: 0.0040 lr: 0.02\n",
      "iteration: 60110 loss: 0.0031 lr: 0.02\n",
      "iteration: 60120 loss: 0.0053 lr: 0.02\n",
      "iteration: 60130 loss: 0.0039 lr: 0.02\n",
      "iteration: 60140 loss: 0.0042 lr: 0.02\n",
      "iteration: 60150 loss: 0.0043 lr: 0.02\n",
      "iteration: 60160 loss: 0.0034 lr: 0.02\n",
      "iteration: 60170 loss: 0.0039 lr: 0.02\n",
      "iteration: 60180 loss: 0.0038 lr: 0.02\n",
      "iteration: 60190 loss: 0.0038 lr: 0.02\n",
      "iteration: 60200 loss: 0.0038 lr: 0.02\n",
      "iteration: 60210 loss: 0.0043 lr: 0.02\n",
      "iteration: 60220 loss: 0.0043 lr: 0.02\n",
      "iteration: 60230 loss: 0.0035 lr: 0.02\n",
      "iteration: 60240 loss: 0.0038 lr: 0.02\n",
      "iteration: 60250 loss: 0.0037 lr: 0.02\n",
      "iteration: 60260 loss: 0.0034 lr: 0.02\n",
      "iteration: 60270 loss: 0.0045 lr: 0.02\n",
      "iteration: 60280 loss: 0.0036 lr: 0.02\n",
      "iteration: 60290 loss: 0.0039 lr: 0.02\n",
      "iteration: 60300 loss: 0.0027 lr: 0.02\n",
      "iteration: 60310 loss: 0.0046 lr: 0.02\n",
      "iteration: 60320 loss: 0.0039 lr: 0.02\n",
      "iteration: 60330 loss: 0.0028 lr: 0.02\n",
      "iteration: 60340 loss: 0.0037 lr: 0.02\n",
      "iteration: 60350 loss: 0.0041 lr: 0.02\n",
      "iteration: 60360 loss: 0.0043 lr: 0.02\n",
      "iteration: 60370 loss: 0.0034 lr: 0.02\n",
      "iteration: 60380 loss: 0.0032 lr: 0.02\n",
      "iteration: 60390 loss: 0.0039 lr: 0.02\n",
      "iteration: 60400 loss: 0.0046 lr: 0.02\n",
      "iteration: 60410 loss: 0.0048 lr: 0.02\n",
      "iteration: 60420 loss: 0.0038 lr: 0.02\n",
      "iteration: 60430 loss: 0.0035 lr: 0.02\n",
      "iteration: 60440 loss: 0.0042 lr: 0.02\n",
      "iteration: 60450 loss: 0.0046 lr: 0.02\n",
      "iteration: 60460 loss: 0.0044 lr: 0.02\n",
      "iteration: 60470 loss: 0.0039 lr: 0.02\n",
      "iteration: 60480 loss: 0.0037 lr: 0.02\n",
      "iteration: 60490 loss: 0.0041 lr: 0.02\n",
      "iteration: 60500 loss: 0.0044 lr: 0.02\n",
      "iteration: 60510 loss: 0.0049 lr: 0.02\n",
      "iteration: 60520 loss: 0.0045 lr: 0.02\n",
      "iteration: 60530 loss: 0.0044 lr: 0.02\n",
      "iteration: 60540 loss: 0.0047 lr: 0.02\n",
      "iteration: 60550 loss: 0.0036 lr: 0.02\n",
      "iteration: 60560 loss: 0.0051 lr: 0.02\n",
      "iteration: 60570 loss: 0.0036 lr: 0.02\n",
      "iteration: 60580 loss: 0.0048 lr: 0.02\n",
      "iteration: 60590 loss: 0.0044 lr: 0.02\n",
      "iteration: 60600 loss: 0.0038 lr: 0.02\n",
      "iteration: 60610 loss: 0.0040 lr: 0.02\n",
      "iteration: 60620 loss: 0.0033 lr: 0.02\n",
      "iteration: 60630 loss: 0.0032 lr: 0.02\n",
      "iteration: 60640 loss: 0.0033 lr: 0.02\n",
      "iteration: 60650 loss: 0.0046 lr: 0.02\n",
      "iteration: 60660 loss: 0.0044 lr: 0.02\n",
      "iteration: 60670 loss: 0.0034 lr: 0.02\n",
      "iteration: 60680 loss: 0.0040 lr: 0.02\n",
      "iteration: 60690 loss: 0.0031 lr: 0.02\n",
      "iteration: 60700 loss: 0.0039 lr: 0.02\n",
      "iteration: 60710 loss: 0.0039 lr: 0.02\n",
      "iteration: 60720 loss: 0.0031 lr: 0.02\n",
      "iteration: 60730 loss: 0.0038 lr: 0.02\n",
      "iteration: 60740 loss: 0.0035 lr: 0.02\n",
      "iteration: 60750 loss: 0.0040 lr: 0.02\n",
      "iteration: 60760 loss: 0.0044 lr: 0.02\n",
      "iteration: 60770 loss: 0.0035 lr: 0.02\n",
      "iteration: 60780 loss: 0.0030 lr: 0.02\n",
      "iteration: 60790 loss: 0.0032 lr: 0.02\n",
      "iteration: 60800 loss: 0.0033 lr: 0.02\n",
      "iteration: 60810 loss: 0.0041 lr: 0.02\n",
      "iteration: 60820 loss: 0.0039 lr: 0.02\n",
      "iteration: 60830 loss: 0.0027 lr: 0.02\n",
      "iteration: 60840 loss: 0.0044 lr: 0.02\n",
      "iteration: 60850 loss: 0.0033 lr: 0.02\n",
      "iteration: 60860 loss: 0.0041 lr: 0.02\n",
      "iteration: 60870 loss: 0.0042 lr: 0.02\n",
      "iteration: 60880 loss: 0.0039 lr: 0.02\n",
      "iteration: 60890 loss: 0.0039 lr: 0.02\n",
      "iteration: 60900 loss: 0.0043 lr: 0.02\n",
      "iteration: 60910 loss: 0.0044 lr: 0.02\n",
      "iteration: 60920 loss: 0.0043 lr: 0.02\n",
      "iteration: 60930 loss: 0.0038 lr: 0.02\n",
      "iteration: 60940 loss: 0.0037 lr: 0.02\n",
      "iteration: 60950 loss: 0.0039 lr: 0.02\n",
      "iteration: 60960 loss: 0.0032 lr: 0.02\n",
      "iteration: 60970 loss: 0.0034 lr: 0.02\n",
      "iteration: 60980 loss: 0.0037 lr: 0.02\n",
      "iteration: 60990 loss: 0.0036 lr: 0.02\n",
      "iteration: 61000 loss: 0.0049 lr: 0.02\n",
      "iteration: 61010 loss: 0.0031 lr: 0.02\n",
      "iteration: 61020 loss: 0.0048 lr: 0.02\n",
      "iteration: 61030 loss: 0.0038 lr: 0.02\n",
      "iteration: 61040 loss: 0.0045 lr: 0.02\n",
      "iteration: 61050 loss: 0.0060 lr: 0.02\n",
      "iteration: 61060 loss: 0.0038 lr: 0.02\n",
      "iteration: 61070 loss: 0.0040 lr: 0.02\n",
      "iteration: 61080 loss: 0.0040 lr: 0.02\n",
      "iteration: 61090 loss: 0.0031 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 61100 loss: 0.0038 lr: 0.02\n",
      "iteration: 61110 loss: 0.0053 lr: 0.02\n",
      "iteration: 61120 loss: 0.0034 lr: 0.02\n",
      "iteration: 61130 loss: 0.0044 lr: 0.02\n",
      "iteration: 61140 loss: 0.0037 lr: 0.02\n",
      "iteration: 61150 loss: 0.0036 lr: 0.02\n",
      "iteration: 61160 loss: 0.0043 lr: 0.02\n",
      "iteration: 61170 loss: 0.0037 lr: 0.02\n",
      "iteration: 61180 loss: 0.0036 lr: 0.02\n",
      "iteration: 61190 loss: 0.0030 lr: 0.02\n",
      "iteration: 61200 loss: 0.0032 lr: 0.02\n",
      "iteration: 61210 loss: 0.0033 lr: 0.02\n",
      "iteration: 61220 loss: 0.0039 lr: 0.02\n",
      "iteration: 61230 loss: 0.0048 lr: 0.02\n",
      "iteration: 61240 loss: 0.0035 lr: 0.02\n",
      "iteration: 61250 loss: 0.0062 lr: 0.02\n",
      "iteration: 61260 loss: 0.0043 lr: 0.02\n",
      "iteration: 61270 loss: 0.0041 lr: 0.02\n",
      "iteration: 61280 loss: 0.0037 lr: 0.02\n",
      "iteration: 61290 loss: 0.0032 lr: 0.02\n",
      "iteration: 61300 loss: 0.0041 lr: 0.02\n",
      "iteration: 61310 loss: 0.0041 lr: 0.02\n",
      "iteration: 61320 loss: 0.0032 lr: 0.02\n",
      "iteration: 61330 loss: 0.0034 lr: 0.02\n",
      "iteration: 61340 loss: 0.0034 lr: 0.02\n",
      "iteration: 61350 loss: 0.0036 lr: 0.02\n",
      "iteration: 61360 loss: 0.0037 lr: 0.02\n",
      "iteration: 61370 loss: 0.0041 lr: 0.02\n",
      "iteration: 61380 loss: 0.0038 lr: 0.02\n",
      "iteration: 61390 loss: 0.0041 lr: 0.02\n",
      "iteration: 61400 loss: 0.0032 lr: 0.02\n",
      "iteration: 61410 loss: 0.0037 lr: 0.02\n",
      "iteration: 61420 loss: 0.0035 lr: 0.02\n",
      "iteration: 61430 loss: 0.0032 lr: 0.02\n",
      "iteration: 61440 loss: 0.0032 lr: 0.02\n",
      "iteration: 61450 loss: 0.0037 lr: 0.02\n",
      "iteration: 61460 loss: 0.0033 lr: 0.02\n",
      "iteration: 61470 loss: 0.0045 lr: 0.02\n",
      "iteration: 61480 loss: 0.0039 lr: 0.02\n",
      "iteration: 61490 loss: 0.0033 lr: 0.02\n",
      "iteration: 61500 loss: 0.0032 lr: 0.02\n",
      "iteration: 61510 loss: 0.0036 lr: 0.02\n",
      "iteration: 61520 loss: 0.0039 lr: 0.02\n",
      "iteration: 61530 loss: 0.0039 lr: 0.02\n",
      "iteration: 61540 loss: 0.0033 lr: 0.02\n",
      "iteration: 61550 loss: 0.0042 lr: 0.02\n",
      "iteration: 61560 loss: 0.0037 lr: 0.02\n",
      "iteration: 61570 loss: 0.0036 lr: 0.02\n",
      "iteration: 61580 loss: 0.0035 lr: 0.02\n",
      "iteration: 61590 loss: 0.0032 lr: 0.02\n",
      "iteration: 61600 loss: 0.0033 lr: 0.02\n",
      "iteration: 61610 loss: 0.0036 lr: 0.02\n",
      "iteration: 61620 loss: 0.0041 lr: 0.02\n",
      "iteration: 61630 loss: 0.0035 lr: 0.02\n",
      "iteration: 61640 loss: 0.0033 lr: 0.02\n",
      "iteration: 61650 loss: 0.0032 lr: 0.02\n",
      "iteration: 61660 loss: 0.0040 lr: 0.02\n",
      "iteration: 61670 loss: 0.0033 lr: 0.02\n",
      "iteration: 61680 loss: 0.0036 lr: 0.02\n",
      "iteration: 61690 loss: 0.0029 lr: 0.02\n",
      "iteration: 61700 loss: 0.0042 lr: 0.02\n",
      "iteration: 61710 loss: 0.0040 lr: 0.02\n",
      "iteration: 61720 loss: 0.0034 lr: 0.02\n",
      "iteration: 61730 loss: 0.0047 lr: 0.02\n",
      "iteration: 61740 loss: 0.0036 lr: 0.02\n",
      "iteration: 61750 loss: 0.0032 lr: 0.02\n",
      "iteration: 61760 loss: 0.0040 lr: 0.02\n",
      "iteration: 61770 loss: 0.0043 lr: 0.02\n",
      "iteration: 61780 loss: 0.0046 lr: 0.02\n",
      "iteration: 61790 loss: 0.0035 lr: 0.02\n",
      "iteration: 61800 loss: 0.0038 lr: 0.02\n",
      "iteration: 61810 loss: 0.0031 lr: 0.02\n",
      "iteration: 61820 loss: 0.0038 lr: 0.02\n",
      "iteration: 61830 loss: 0.0039 lr: 0.02\n",
      "iteration: 61840 loss: 0.0042 lr: 0.02\n",
      "iteration: 61850 loss: 0.0041 lr: 0.02\n",
      "iteration: 61860 loss: 0.0051 lr: 0.02\n",
      "iteration: 61870 loss: 0.0044 lr: 0.02\n",
      "iteration: 61880 loss: 0.0043 lr: 0.02\n",
      "iteration: 61890 loss: 0.0049 lr: 0.02\n",
      "iteration: 61900 loss: 0.0035 lr: 0.02\n",
      "iteration: 61910 loss: 0.0045 lr: 0.02\n",
      "iteration: 61920 loss: 0.0040 lr: 0.02\n",
      "iteration: 61930 loss: 0.0034 lr: 0.02\n",
      "iteration: 61940 loss: 0.0032 lr: 0.02\n",
      "iteration: 61950 loss: 0.0044 lr: 0.02\n",
      "iteration: 61960 loss: 0.0037 lr: 0.02\n",
      "iteration: 61970 loss: 0.0050 lr: 0.02\n",
      "iteration: 61980 loss: 0.0048 lr: 0.02\n",
      "iteration: 61990 loss: 0.0042 lr: 0.02\n",
      "iteration: 62000 loss: 0.0055 lr: 0.02\n",
      "iteration: 62010 loss: 0.0037 lr: 0.02\n",
      "iteration: 62020 loss: 0.0047 lr: 0.02\n",
      "iteration: 62030 loss: 0.0047 lr: 0.02\n",
      "iteration: 62040 loss: 0.0041 lr: 0.02\n",
      "iteration: 62050 loss: 0.0035 lr: 0.02\n",
      "iteration: 62060 loss: 0.0033 lr: 0.02\n",
      "iteration: 62070 loss: 0.0045 lr: 0.02\n",
      "iteration: 62080 loss: 0.0037 lr: 0.02\n",
      "iteration: 62090 loss: 0.0034 lr: 0.02\n",
      "iteration: 62100 loss: 0.0050 lr: 0.02\n",
      "iteration: 62110 loss: 0.0036 lr: 0.02\n",
      "iteration: 62120 loss: 0.0056 lr: 0.02\n",
      "iteration: 62130 loss: 0.0030 lr: 0.02\n",
      "iteration: 62140 loss: 0.0041 lr: 0.02\n",
      "iteration: 62150 loss: 0.0037 lr: 0.02\n",
      "iteration: 62160 loss: 0.0037 lr: 0.02\n",
      "iteration: 62170 loss: 0.0040 lr: 0.02\n",
      "iteration: 62180 loss: 0.0034 lr: 0.02\n",
      "iteration: 62190 loss: 0.0043 lr: 0.02\n",
      "iteration: 62200 loss: 0.0033 lr: 0.02\n",
      "iteration: 62210 loss: 0.0048 lr: 0.02\n",
      "iteration: 62220 loss: 0.0041 lr: 0.02\n",
      "iteration: 62230 loss: 0.0045 lr: 0.02\n",
      "iteration: 62240 loss: 0.0030 lr: 0.02\n",
      "iteration: 62250 loss: 0.0033 lr: 0.02\n",
      "iteration: 62260 loss: 0.0037 lr: 0.02\n",
      "iteration: 62270 loss: 0.0036 lr: 0.02\n",
      "iteration: 62280 loss: 0.0039 lr: 0.02\n",
      "iteration: 62290 loss: 0.0035 lr: 0.02\n",
      "iteration: 62300 loss: 0.0038 lr: 0.02\n",
      "iteration: 62310 loss: 0.0040 lr: 0.02\n",
      "iteration: 62320 loss: 0.0045 lr: 0.02\n",
      "iteration: 62330 loss: 0.0038 lr: 0.02\n",
      "iteration: 62340 loss: 0.0038 lr: 0.02\n",
      "iteration: 62350 loss: 0.0038 lr: 0.02\n",
      "iteration: 62360 loss: 0.0034 lr: 0.02\n",
      "iteration: 62370 loss: 0.0033 lr: 0.02\n",
      "iteration: 62380 loss: 0.0044 lr: 0.02\n",
      "iteration: 62390 loss: 0.0045 lr: 0.02\n",
      "iteration: 62400 loss: 0.0043 lr: 0.02\n",
      "iteration: 62410 loss: 0.0038 lr: 0.02\n",
      "iteration: 62420 loss: 0.0041 lr: 0.02\n",
      "iteration: 62430 loss: 0.0040 lr: 0.02\n",
      "iteration: 62440 loss: 0.0041 lr: 0.02\n",
      "iteration: 62450 loss: 0.0032 lr: 0.02\n",
      "iteration: 62460 loss: 0.0039 lr: 0.02\n",
      "iteration: 62470 loss: 0.0047 lr: 0.02\n",
      "iteration: 62480 loss: 0.0033 lr: 0.02\n",
      "iteration: 62490 loss: 0.0041 lr: 0.02\n",
      "iteration: 62500 loss: 0.0055 lr: 0.02\n",
      "iteration: 62510 loss: 0.0045 lr: 0.02\n",
      "iteration: 62520 loss: 0.0032 lr: 0.02\n",
      "iteration: 62530 loss: 0.0027 lr: 0.02\n",
      "iteration: 62540 loss: 0.0045 lr: 0.02\n",
      "iteration: 62550 loss: 0.0041 lr: 0.02\n",
      "iteration: 62560 loss: 0.0052 lr: 0.02\n",
      "iteration: 62570 loss: 0.0058 lr: 0.02\n",
      "iteration: 62580 loss: 0.0035 lr: 0.02\n",
      "iteration: 62590 loss: 0.0038 lr: 0.02\n",
      "iteration: 62600 loss: 0.0049 lr: 0.02\n",
      "iteration: 62610 loss: 0.0050 lr: 0.02\n",
      "iteration: 62620 loss: 0.0047 lr: 0.02\n",
      "iteration: 62630 loss: 0.0047 lr: 0.02\n",
      "iteration: 62640 loss: 0.0055 lr: 0.02\n",
      "iteration: 62650 loss: 0.0044 lr: 0.02\n",
      "iteration: 62660 loss: 0.0043 lr: 0.02\n",
      "iteration: 62670 loss: 0.0034 lr: 0.02\n",
      "iteration: 62680 loss: 0.0041 lr: 0.02\n",
      "iteration: 62690 loss: 0.0045 lr: 0.02\n",
      "iteration: 62700 loss: 0.0036 lr: 0.02\n",
      "iteration: 62710 loss: 0.0029 lr: 0.02\n",
      "iteration: 62720 loss: 0.0044 lr: 0.02\n",
      "iteration: 62730 loss: 0.0038 lr: 0.02\n",
      "iteration: 62740 loss: 0.0041 lr: 0.02\n",
      "iteration: 62750 loss: 0.0045 lr: 0.02\n",
      "iteration: 62760 loss: 0.0051 lr: 0.02\n",
      "iteration: 62770 loss: 0.0040 lr: 0.02\n",
      "iteration: 62780 loss: 0.0035 lr: 0.02\n",
      "iteration: 62790 loss: 0.0034 lr: 0.02\n",
      "iteration: 62800 loss: 0.0042 lr: 0.02\n",
      "iteration: 62810 loss: 0.0034 lr: 0.02\n",
      "iteration: 62820 loss: 0.0038 lr: 0.02\n",
      "iteration: 62830 loss: 0.0050 lr: 0.02\n",
      "iteration: 62840 loss: 0.0038 lr: 0.02\n",
      "iteration: 62850 loss: 0.0035 lr: 0.02\n",
      "iteration: 62860 loss: 0.0038 lr: 0.02\n",
      "iteration: 62870 loss: 0.0036 lr: 0.02\n",
      "iteration: 62880 loss: 0.0034 lr: 0.02\n",
      "iteration: 62890 loss: 0.0044 lr: 0.02\n",
      "iteration: 62900 loss: 0.0055 lr: 0.02\n",
      "iteration: 62910 loss: 0.0047 lr: 0.02\n",
      "iteration: 62920 loss: 0.0038 lr: 0.02\n",
      "iteration: 62930 loss: 0.0045 lr: 0.02\n",
      "iteration: 62940 loss: 0.0033 lr: 0.02\n",
      "iteration: 62950 loss: 0.0036 lr: 0.02\n",
      "iteration: 62960 loss: 0.0031 lr: 0.02\n",
      "iteration: 62970 loss: 0.0041 lr: 0.02\n",
      "iteration: 62980 loss: 0.0064 lr: 0.02\n",
      "iteration: 62990 loss: 0.0039 lr: 0.02\n",
      "iteration: 63000 loss: 0.0034 lr: 0.02\n",
      "iteration: 63010 loss: 0.0032 lr: 0.02\n",
      "iteration: 63020 loss: 0.0038 lr: 0.02\n",
      "iteration: 63030 loss: 0.0040 lr: 0.02\n",
      "iteration: 63040 loss: 0.0038 lr: 0.02\n",
      "iteration: 63050 loss: 0.0039 lr: 0.02\n",
      "iteration: 63060 loss: 0.0040 lr: 0.02\n",
      "iteration: 63070 loss: 0.0036 lr: 0.02\n",
      "iteration: 63080 loss: 0.0034 lr: 0.02\n",
      "iteration: 63090 loss: 0.0034 lr: 0.02\n",
      "iteration: 63100 loss: 0.0041 lr: 0.02\n",
      "iteration: 63110 loss: 0.0044 lr: 0.02\n",
      "iteration: 63120 loss: 0.0046 lr: 0.02\n",
      "iteration: 63130 loss: 0.0036 lr: 0.02\n",
      "iteration: 63140 loss: 0.0050 lr: 0.02\n",
      "iteration: 63150 loss: 0.0037 lr: 0.02\n",
      "iteration: 63160 loss: 0.0033 lr: 0.02\n",
      "iteration: 63170 loss: 0.0036 lr: 0.02\n",
      "iteration: 63180 loss: 0.0045 lr: 0.02\n",
      "iteration: 63190 loss: 0.0037 lr: 0.02\n",
      "iteration: 63200 loss: 0.0031 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 63210 loss: 0.0047 lr: 0.02\n",
      "iteration: 63220 loss: 0.0039 lr: 0.02\n",
      "iteration: 63230 loss: 0.0035 lr: 0.02\n",
      "iteration: 63240 loss: 0.0040 lr: 0.02\n",
      "iteration: 63250 loss: 0.0049 lr: 0.02\n",
      "iteration: 63260 loss: 0.0036 lr: 0.02\n",
      "iteration: 63270 loss: 0.0034 lr: 0.02\n",
      "iteration: 63280 loss: 0.0035 lr: 0.02\n",
      "iteration: 63290 loss: 0.0033 lr: 0.02\n",
      "iteration: 63300 loss: 0.0036 lr: 0.02\n",
      "iteration: 63310 loss: 0.0036 lr: 0.02\n",
      "iteration: 63320 loss: 0.0040 lr: 0.02\n",
      "iteration: 63330 loss: 0.0030 lr: 0.02\n",
      "iteration: 63340 loss: 0.0038 lr: 0.02\n",
      "iteration: 63350 loss: 0.0033 lr: 0.02\n",
      "iteration: 63360 loss: 0.0051 lr: 0.02\n",
      "iteration: 63370 loss: 0.0041 lr: 0.02\n",
      "iteration: 63380 loss: 0.0046 lr: 0.02\n",
      "iteration: 63390 loss: 0.0039 lr: 0.02\n",
      "iteration: 63400 loss: 0.0033 lr: 0.02\n",
      "iteration: 63410 loss: 0.0036 lr: 0.02\n",
      "iteration: 63420 loss: 0.0032 lr: 0.02\n",
      "iteration: 63430 loss: 0.0033 lr: 0.02\n",
      "iteration: 63440 loss: 0.0039 lr: 0.02\n",
      "iteration: 63450 loss: 0.0033 lr: 0.02\n",
      "iteration: 63460 loss: 0.0033 lr: 0.02\n",
      "iteration: 63470 loss: 0.0046 lr: 0.02\n",
      "iteration: 63480 loss: 0.0039 lr: 0.02\n",
      "iteration: 63490 loss: 0.0039 lr: 0.02\n",
      "iteration: 63500 loss: 0.0040 lr: 0.02\n",
      "iteration: 63510 loss: 0.0044 lr: 0.02\n",
      "iteration: 63520 loss: 0.0036 lr: 0.02\n",
      "iteration: 63530 loss: 0.0040 lr: 0.02\n",
      "iteration: 63540 loss: 0.0038 lr: 0.02\n",
      "iteration: 63550 loss: 0.0036 lr: 0.02\n",
      "iteration: 63560 loss: 0.0035 lr: 0.02\n",
      "iteration: 63570 loss: 0.0046 lr: 0.02\n",
      "iteration: 63580 loss: 0.0027 lr: 0.02\n",
      "iteration: 63590 loss: 0.0032 lr: 0.02\n",
      "iteration: 63600 loss: 0.0046 lr: 0.02\n",
      "iteration: 63610 loss: 0.0031 lr: 0.02\n",
      "iteration: 63620 loss: 0.0040 lr: 0.02\n",
      "iteration: 63630 loss: 0.0039 lr: 0.02\n",
      "iteration: 63640 loss: 0.0037 lr: 0.02\n",
      "iteration: 63650 loss: 0.0043 lr: 0.02\n",
      "iteration: 63660 loss: 0.0037 lr: 0.02\n",
      "iteration: 63670 loss: 0.0039 lr: 0.02\n",
      "iteration: 63680 loss: 0.0049 lr: 0.02\n",
      "iteration: 63690 loss: 0.0042 lr: 0.02\n",
      "iteration: 63700 loss: 0.0050 lr: 0.02\n",
      "iteration: 63710 loss: 0.0036 lr: 0.02\n",
      "iteration: 63720 loss: 0.0039 lr: 0.02\n",
      "iteration: 63730 loss: 0.0037 lr: 0.02\n",
      "iteration: 63740 loss: 0.0029 lr: 0.02\n",
      "iteration: 63750 loss: 0.0035 lr: 0.02\n",
      "iteration: 63760 loss: 0.0045 lr: 0.02\n",
      "iteration: 63770 loss: 0.0046 lr: 0.02\n",
      "iteration: 63780 loss: 0.0032 lr: 0.02\n",
      "iteration: 63790 loss: 0.0038 lr: 0.02\n",
      "iteration: 63800 loss: 0.0034 lr: 0.02\n",
      "iteration: 63810 loss: 0.0032 lr: 0.02\n",
      "iteration: 63820 loss: 0.0046 lr: 0.02\n",
      "iteration: 63830 loss: 0.0039 lr: 0.02\n",
      "iteration: 63840 loss: 0.0033 lr: 0.02\n",
      "iteration: 63850 loss: 0.0037 lr: 0.02\n",
      "iteration: 63860 loss: 0.0045 lr: 0.02\n",
      "iteration: 63870 loss: 0.0034 lr: 0.02\n",
      "iteration: 63880 loss: 0.0035 lr: 0.02\n",
      "iteration: 63890 loss: 0.0038 lr: 0.02\n",
      "iteration: 63900 loss: 0.0045 lr: 0.02\n",
      "iteration: 63910 loss: 0.0034 lr: 0.02\n",
      "iteration: 63920 loss: 0.0033 lr: 0.02\n",
      "iteration: 63930 loss: 0.0034 lr: 0.02\n",
      "iteration: 63940 loss: 0.0039 lr: 0.02\n",
      "iteration: 63950 loss: 0.0026 lr: 0.02\n",
      "iteration: 63960 loss: 0.0034 lr: 0.02\n",
      "iteration: 63970 loss: 0.0070 lr: 0.02\n",
      "iteration: 63980 loss: 0.0041 lr: 0.02\n",
      "iteration: 63990 loss: 0.0036 lr: 0.02\n",
      "iteration: 64000 loss: 0.0050 lr: 0.02\n",
      "iteration: 64010 loss: 0.0045 lr: 0.02\n",
      "iteration: 64020 loss: 0.0039 lr: 0.02\n",
      "iteration: 64030 loss: 0.0054 lr: 0.02\n",
      "iteration: 64040 loss: 0.0046 lr: 0.02\n",
      "iteration: 64050 loss: 0.0036 lr: 0.02\n",
      "iteration: 64060 loss: 0.0044 lr: 0.02\n",
      "iteration: 64070 loss: 0.0038 lr: 0.02\n",
      "iteration: 64080 loss: 0.0044 lr: 0.02\n",
      "iteration: 64090 loss: 0.0029 lr: 0.02\n",
      "iteration: 64100 loss: 0.0042 lr: 0.02\n",
      "iteration: 64110 loss: 0.0026 lr: 0.02\n",
      "iteration: 64120 loss: 0.0038 lr: 0.02\n",
      "iteration: 64130 loss: 0.0056 lr: 0.02\n",
      "iteration: 64140 loss: 0.0041 lr: 0.02\n",
      "iteration: 64150 loss: 0.0049 lr: 0.02\n",
      "iteration: 64160 loss: 0.0035 lr: 0.02\n",
      "iteration: 64170 loss: 0.0044 lr: 0.02\n",
      "iteration: 64180 loss: 0.0033 lr: 0.02\n",
      "iteration: 64190 loss: 0.0048 lr: 0.02\n",
      "iteration: 64200 loss: 0.0043 lr: 0.02\n",
      "iteration: 64210 loss: 0.0043 lr: 0.02\n",
      "iteration: 64220 loss: 0.0043 lr: 0.02\n",
      "iteration: 64230 loss: 0.0036 lr: 0.02\n",
      "iteration: 64240 loss: 0.0040 lr: 0.02\n",
      "iteration: 64250 loss: 0.0037 lr: 0.02\n",
      "iteration: 64260 loss: 0.0034 lr: 0.02\n",
      "iteration: 64270 loss: 0.0037 lr: 0.02\n",
      "iteration: 64280 loss: 0.0043 lr: 0.02\n",
      "iteration: 64290 loss: 0.0047 lr: 0.02\n",
      "iteration: 64300 loss: 0.0037 lr: 0.02\n",
      "iteration: 64310 loss: 0.0034 lr: 0.02\n",
      "iteration: 64320 loss: 0.0036 lr: 0.02\n",
      "iteration: 64330 loss: 0.0030 lr: 0.02\n",
      "iteration: 64340 loss: 0.0039 lr: 0.02\n",
      "iteration: 64350 loss: 0.0033 lr: 0.02\n",
      "iteration: 64360 loss: 0.0038 lr: 0.02\n",
      "iteration: 64370 loss: 0.0038 lr: 0.02\n",
      "iteration: 64380 loss: 0.0035 lr: 0.02\n",
      "iteration: 64390 loss: 0.0043 lr: 0.02\n",
      "iteration: 64400 loss: 0.0033 lr: 0.02\n",
      "iteration: 64410 loss: 0.0033 lr: 0.02\n",
      "iteration: 64420 loss: 0.0048 lr: 0.02\n",
      "iteration: 64430 loss: 0.0038 lr: 0.02\n",
      "iteration: 64440 loss: 0.0038 lr: 0.02\n",
      "iteration: 64450 loss: 0.0030 lr: 0.02\n",
      "iteration: 64460 loss: 0.0049 lr: 0.02\n",
      "iteration: 64470 loss: 0.0049 lr: 0.02\n",
      "iteration: 64480 loss: 0.0040 lr: 0.02\n",
      "iteration: 64490 loss: 0.0039 lr: 0.02\n",
      "iteration: 64500 loss: 0.0037 lr: 0.02\n",
      "iteration: 64510 loss: 0.0034 lr: 0.02\n",
      "iteration: 64520 loss: 0.0029 lr: 0.02\n",
      "iteration: 64530 loss: 0.0037 lr: 0.02\n",
      "iteration: 64540 loss: 0.0036 lr: 0.02\n",
      "iteration: 64550 loss: 0.0040 lr: 0.02\n",
      "iteration: 64560 loss: 0.0031 lr: 0.02\n",
      "iteration: 64570 loss: 0.0034 lr: 0.02\n",
      "iteration: 64580 loss: 0.0031 lr: 0.02\n",
      "iteration: 64590 loss: 0.0037 lr: 0.02\n",
      "iteration: 64600 loss: 0.0033 lr: 0.02\n",
      "iteration: 64610 loss: 0.0037 lr: 0.02\n",
      "iteration: 64620 loss: 0.0036 lr: 0.02\n",
      "iteration: 64630 loss: 0.0045 lr: 0.02\n",
      "iteration: 64640 loss: 0.0043 lr: 0.02\n",
      "iteration: 64650 loss: 0.0041 lr: 0.02\n",
      "iteration: 64660 loss: 0.0044 lr: 0.02\n",
      "iteration: 64670 loss: 0.0034 lr: 0.02\n",
      "iteration: 64680 loss: 0.0040 lr: 0.02\n",
      "iteration: 64690 loss: 0.0032 lr: 0.02\n",
      "iteration: 64700 loss: 0.0042 lr: 0.02\n",
      "iteration: 64710 loss: 0.0035 lr: 0.02\n",
      "iteration: 64720 loss: 0.0036 lr: 0.02\n",
      "iteration: 64730 loss: 0.0046 lr: 0.02\n",
      "iteration: 64740 loss: 0.0034 lr: 0.02\n",
      "iteration: 64750 loss: 0.0037 lr: 0.02\n",
      "iteration: 64760 loss: 0.0031 lr: 0.02\n",
      "iteration: 64770 loss: 0.0034 lr: 0.02\n",
      "iteration: 64780 loss: 0.0044 lr: 0.02\n",
      "iteration: 64790 loss: 0.0032 lr: 0.02\n",
      "iteration: 64800 loss: 0.0042 lr: 0.02\n",
      "iteration: 64810 loss: 0.0040 lr: 0.02\n",
      "iteration: 64820 loss: 0.0040 lr: 0.02\n",
      "iteration: 64830 loss: 0.0041 lr: 0.02\n",
      "iteration: 64840 loss: 0.0036 lr: 0.02\n",
      "iteration: 64850 loss: 0.0036 lr: 0.02\n",
      "iteration: 64860 loss: 0.0038 lr: 0.02\n",
      "iteration: 64870 loss: 0.0040 lr: 0.02\n",
      "iteration: 64880 loss: 0.0049 lr: 0.02\n",
      "iteration: 64890 loss: 0.0031 lr: 0.02\n",
      "iteration: 64900 loss: 0.0032 lr: 0.02\n",
      "iteration: 64910 loss: 0.0046 lr: 0.02\n",
      "iteration: 64920 loss: 0.0038 lr: 0.02\n",
      "iteration: 64930 loss: 0.0044 lr: 0.02\n",
      "iteration: 64940 loss: 0.0030 lr: 0.02\n",
      "iteration: 64950 loss: 0.0037 lr: 0.02\n",
      "iteration: 64960 loss: 0.0032 lr: 0.02\n",
      "iteration: 64970 loss: 0.0038 lr: 0.02\n",
      "iteration: 64980 loss: 0.0040 lr: 0.02\n",
      "iteration: 64990 loss: 0.0031 lr: 0.02\n",
      "iteration: 65000 loss: 0.0029 lr: 0.02\n",
      "iteration: 65010 loss: 0.0050 lr: 0.02\n",
      "iteration: 65020 loss: 0.0041 lr: 0.02\n",
      "iteration: 65030 loss: 0.0034 lr: 0.02\n",
      "iteration: 65040 loss: 0.0038 lr: 0.02\n",
      "iteration: 65050 loss: 0.0030 lr: 0.02\n",
      "iteration: 65060 loss: 0.0039 lr: 0.02\n",
      "iteration: 65070 loss: 0.0043 lr: 0.02\n",
      "iteration: 65080 loss: 0.0034 lr: 0.02\n",
      "iteration: 65090 loss: 0.0037 lr: 0.02\n",
      "iteration: 65100 loss: 0.0047 lr: 0.02\n",
      "iteration: 65110 loss: 0.0038 lr: 0.02\n",
      "iteration: 65120 loss: 0.0033 lr: 0.02\n",
      "iteration: 65130 loss: 0.0037 lr: 0.02\n",
      "iteration: 65140 loss: 0.0044 lr: 0.02\n",
      "iteration: 65150 loss: 0.0041 lr: 0.02\n",
      "iteration: 65160 loss: 0.0039 lr: 0.02\n",
      "iteration: 65170 loss: 0.0038 lr: 0.02\n",
      "iteration: 65180 loss: 0.0034 lr: 0.02\n",
      "iteration: 65190 loss: 0.0032 lr: 0.02\n",
      "iteration: 65200 loss: 0.0045 lr: 0.02\n",
      "iteration: 65210 loss: 0.0034 lr: 0.02\n",
      "iteration: 65220 loss: 0.0047 lr: 0.02\n",
      "iteration: 65230 loss: 0.0043 lr: 0.02\n",
      "iteration: 65240 loss: 0.0033 lr: 0.02\n",
      "iteration: 65250 loss: 0.0034 lr: 0.02\n",
      "iteration: 65260 loss: 0.0043 lr: 0.02\n",
      "iteration: 65270 loss: 0.0034 lr: 0.02\n",
      "iteration: 65280 loss: 0.0042 lr: 0.02\n",
      "iteration: 65290 loss: 0.0029 lr: 0.02\n",
      "iteration: 65300 loss: 0.0040 lr: 0.02\n",
      "iteration: 65310 loss: 0.0028 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 65320 loss: 0.0035 lr: 0.02\n",
      "iteration: 65330 loss: 0.0034 lr: 0.02\n",
      "iteration: 65340 loss: 0.0039 lr: 0.02\n",
      "iteration: 65350 loss: 0.0031 lr: 0.02\n",
      "iteration: 65360 loss: 0.0028 lr: 0.02\n",
      "iteration: 65370 loss: 0.0040 lr: 0.02\n",
      "iteration: 65380 loss: 0.0039 lr: 0.02\n",
      "iteration: 65390 loss: 0.0039 lr: 0.02\n",
      "iteration: 65400 loss: 0.0036 lr: 0.02\n",
      "iteration: 65410 loss: 0.0041 lr: 0.02\n",
      "iteration: 65420 loss: 0.0041 lr: 0.02\n",
      "iteration: 65430 loss: 0.0033 lr: 0.02\n",
      "iteration: 65440 loss: 0.0028 lr: 0.02\n",
      "iteration: 65450 loss: 0.0036 lr: 0.02\n",
      "iteration: 65460 loss: 0.0039 lr: 0.02\n",
      "iteration: 65470 loss: 0.0049 lr: 0.02\n",
      "iteration: 65480 loss: 0.0052 lr: 0.02\n",
      "iteration: 65490 loss: 0.0037 lr: 0.02\n",
      "iteration: 65500 loss: 0.0038 lr: 0.02\n",
      "iteration: 65510 loss: 0.0035 lr: 0.02\n",
      "iteration: 65520 loss: 0.0032 lr: 0.02\n",
      "iteration: 65530 loss: 0.0032 lr: 0.02\n",
      "iteration: 65540 loss: 0.0042 lr: 0.02\n",
      "iteration: 65550 loss: 0.0032 lr: 0.02\n",
      "iteration: 65560 loss: 0.0037 lr: 0.02\n",
      "iteration: 65570 loss: 0.0042 lr: 0.02\n",
      "iteration: 65580 loss: 0.0031 lr: 0.02\n",
      "iteration: 65590 loss: 0.0041 lr: 0.02\n",
      "iteration: 65600 loss: 0.0038 lr: 0.02\n",
      "iteration: 65610 loss: 0.0037 lr: 0.02\n",
      "iteration: 65620 loss: 0.0042 lr: 0.02\n",
      "iteration: 65630 loss: 0.0029 lr: 0.02\n",
      "iteration: 65640 loss: 0.0032 lr: 0.02\n",
      "iteration: 65650 loss: 0.0035 lr: 0.02\n",
      "iteration: 65660 loss: 0.0037 lr: 0.02\n",
      "iteration: 65670 loss: 0.0044 lr: 0.02\n",
      "iteration: 65680 loss: 0.0036 lr: 0.02\n",
      "iteration: 65690 loss: 0.0038 lr: 0.02\n",
      "iteration: 65700 loss: 0.0031 lr: 0.02\n",
      "iteration: 65710 loss: 0.0040 lr: 0.02\n",
      "iteration: 65720 loss: 0.0044 lr: 0.02\n",
      "iteration: 65730 loss: 0.0036 lr: 0.02\n",
      "iteration: 65740 loss: 0.0033 lr: 0.02\n",
      "iteration: 65750 loss: 0.0038 lr: 0.02\n",
      "iteration: 65760 loss: 0.0030 lr: 0.02\n",
      "iteration: 65770 loss: 0.0032 lr: 0.02\n",
      "iteration: 65780 loss: 0.0039 lr: 0.02\n",
      "iteration: 65790 loss: 0.0049 lr: 0.02\n",
      "iteration: 65800 loss: 0.0035 lr: 0.02\n",
      "iteration: 65810 loss: 0.0039 lr: 0.02\n",
      "iteration: 65820 loss: 0.0042 lr: 0.02\n",
      "iteration: 65830 loss: 0.0031 lr: 0.02\n",
      "iteration: 65840 loss: 0.0037 lr: 0.02\n",
      "iteration: 65850 loss: 0.0050 lr: 0.02\n",
      "iteration: 65860 loss: 0.0044 lr: 0.02\n",
      "iteration: 65870 loss: 0.0033 lr: 0.02\n",
      "iteration: 65880 loss: 0.0031 lr: 0.02\n",
      "iteration: 65890 loss: 0.0042 lr: 0.02\n",
      "iteration: 65900 loss: 0.0036 lr: 0.02\n",
      "iteration: 65910 loss: 0.0037 lr: 0.02\n",
      "iteration: 65920 loss: 0.0035 lr: 0.02\n",
      "iteration: 65930 loss: 0.0036 lr: 0.02\n",
      "iteration: 65940 loss: 0.0037 lr: 0.02\n",
      "iteration: 65950 loss: 0.0036 lr: 0.02\n",
      "iteration: 65960 loss: 0.0043 lr: 0.02\n",
      "iteration: 65970 loss: 0.0036 lr: 0.02\n",
      "iteration: 65980 loss: 0.0039 lr: 0.02\n",
      "iteration: 65990 loss: 0.0034 lr: 0.02\n",
      "iteration: 66000 loss: 0.0034 lr: 0.02\n",
      "iteration: 66010 loss: 0.0039 lr: 0.02\n",
      "iteration: 66020 loss: 0.0033 lr: 0.02\n",
      "iteration: 66030 loss: 0.0034 lr: 0.02\n",
      "iteration: 66040 loss: 0.0035 lr: 0.02\n",
      "iteration: 66050 loss: 0.0041 lr: 0.02\n",
      "iteration: 66060 loss: 0.0045 lr: 0.02\n",
      "iteration: 66070 loss: 0.0037 lr: 0.02\n",
      "iteration: 66080 loss: 0.0027 lr: 0.02\n",
      "iteration: 66090 loss: 0.0042 lr: 0.02\n",
      "iteration: 66100 loss: 0.0035 lr: 0.02\n",
      "iteration: 66110 loss: 0.0036 lr: 0.02\n",
      "iteration: 66120 loss: 0.0037 lr: 0.02\n",
      "iteration: 66130 loss: 0.0038 lr: 0.02\n",
      "iteration: 66140 loss: 0.0033 lr: 0.02\n",
      "iteration: 66150 loss: 0.0029 lr: 0.02\n",
      "iteration: 66160 loss: 0.0040 lr: 0.02\n",
      "iteration: 66170 loss: 0.0039 lr: 0.02\n",
      "iteration: 66180 loss: 0.0051 lr: 0.02\n",
      "iteration: 66190 loss: 0.0040 lr: 0.02\n",
      "iteration: 66200 loss: 0.0038 lr: 0.02\n",
      "iteration: 66210 loss: 0.0034 lr: 0.02\n",
      "iteration: 66220 loss: 0.0034 lr: 0.02\n",
      "iteration: 66230 loss: 0.0039 lr: 0.02\n",
      "iteration: 66240 loss: 0.0053 lr: 0.02\n",
      "iteration: 66250 loss: 0.0032 lr: 0.02\n",
      "iteration: 66260 loss: 0.0046 lr: 0.02\n",
      "iteration: 66270 loss: 0.0038 lr: 0.02\n",
      "iteration: 66280 loss: 0.0045 lr: 0.02\n",
      "iteration: 66290 loss: 0.0052 lr: 0.02\n",
      "iteration: 66300 loss: 0.0039 lr: 0.02\n",
      "iteration: 66310 loss: 0.0035 lr: 0.02\n",
      "iteration: 66320 loss: 0.0039 lr: 0.02\n",
      "iteration: 66330 loss: 0.0029 lr: 0.02\n",
      "iteration: 66340 loss: 0.0038 lr: 0.02\n",
      "iteration: 66350 loss: 0.0043 lr: 0.02\n",
      "iteration: 66360 loss: 0.0035 lr: 0.02\n",
      "iteration: 66370 loss: 0.0039 lr: 0.02\n",
      "iteration: 66380 loss: 0.0034 lr: 0.02\n",
      "iteration: 66390 loss: 0.0030 lr: 0.02\n",
      "iteration: 66400 loss: 0.0031 lr: 0.02\n",
      "iteration: 66410 loss: 0.0037 lr: 0.02\n",
      "iteration: 66420 loss: 0.0033 lr: 0.02\n",
      "iteration: 66430 loss: 0.0034 lr: 0.02\n",
      "iteration: 66440 loss: 0.0031 lr: 0.02\n",
      "iteration: 66450 loss: 0.0033 lr: 0.02\n",
      "iteration: 66460 loss: 0.0028 lr: 0.02\n",
      "iteration: 66470 loss: 0.0041 lr: 0.02\n",
      "iteration: 66480 loss: 0.0029 lr: 0.02\n",
      "iteration: 66490 loss: 0.0036 lr: 0.02\n",
      "iteration: 66500 loss: 0.0035 lr: 0.02\n",
      "iteration: 66510 loss: 0.0040 lr: 0.02\n",
      "iteration: 66520 loss: 0.0027 lr: 0.02\n",
      "iteration: 66530 loss: 0.0029 lr: 0.02\n",
      "iteration: 66540 loss: 0.0044 lr: 0.02\n",
      "iteration: 66550 loss: 0.0037 lr: 0.02\n",
      "iteration: 66560 loss: 0.0039 lr: 0.02\n",
      "iteration: 66570 loss: 0.0041 lr: 0.02\n",
      "iteration: 66580 loss: 0.0033 lr: 0.02\n",
      "iteration: 66590 loss: 0.0035 lr: 0.02\n",
      "iteration: 66600 loss: 0.0035 lr: 0.02\n",
      "iteration: 66610 loss: 0.0036 lr: 0.02\n",
      "iteration: 66620 loss: 0.0036 lr: 0.02\n",
      "iteration: 66630 loss: 0.0043 lr: 0.02\n",
      "iteration: 66640 loss: 0.0050 lr: 0.02\n",
      "iteration: 66650 loss: 0.0041 lr: 0.02\n",
      "iteration: 66660 loss: 0.0033 lr: 0.02\n",
      "iteration: 66670 loss: 0.0034 lr: 0.02\n",
      "iteration: 66680 loss: 0.0047 lr: 0.02\n",
      "iteration: 66690 loss: 0.0033 lr: 0.02\n",
      "iteration: 66700 loss: 0.0030 lr: 0.02\n",
      "iteration: 66710 loss: 0.0042 lr: 0.02\n",
      "iteration: 66720 loss: 0.0046 lr: 0.02\n",
      "iteration: 66730 loss: 0.0034 lr: 0.02\n",
      "iteration: 66740 loss: 0.0035 lr: 0.02\n",
      "iteration: 66750 loss: 0.0046 lr: 0.02\n",
      "iteration: 66760 loss: 0.0032 lr: 0.02\n",
      "iteration: 66770 loss: 0.0047 lr: 0.02\n",
      "iteration: 66780 loss: 0.0036 lr: 0.02\n",
      "iteration: 66790 loss: 0.0032 lr: 0.02\n",
      "iteration: 66800 loss: 0.0036 lr: 0.02\n",
      "iteration: 66810 loss: 0.0046 lr: 0.02\n",
      "iteration: 66820 loss: 0.0038 lr: 0.02\n",
      "iteration: 66830 loss: 0.0031 lr: 0.02\n",
      "iteration: 66840 loss: 0.0033 lr: 0.02\n",
      "iteration: 66850 loss: 0.0033 lr: 0.02\n",
      "iteration: 66860 loss: 0.0027 lr: 0.02\n",
      "iteration: 66870 loss: 0.0059 lr: 0.02\n",
      "iteration: 66880 loss: 0.0037 lr: 0.02\n",
      "iteration: 66890 loss: 0.0037 lr: 0.02\n",
      "iteration: 66900 loss: 0.0032 lr: 0.02\n",
      "iteration: 66910 loss: 0.0032 lr: 0.02\n",
      "iteration: 66920 loss: 0.0037 lr: 0.02\n",
      "iteration: 66930 loss: 0.0028 lr: 0.02\n",
      "iteration: 66940 loss: 0.0036 lr: 0.02\n",
      "iteration: 66950 loss: 0.0043 lr: 0.02\n",
      "iteration: 66960 loss: 0.0041 lr: 0.02\n",
      "iteration: 66970 loss: 0.0046 lr: 0.02\n",
      "iteration: 66980 loss: 0.0037 lr: 0.02\n",
      "iteration: 66990 loss: 0.0033 lr: 0.02\n",
      "iteration: 67000 loss: 0.0036 lr: 0.02\n",
      "iteration: 67010 loss: 0.0031 lr: 0.02\n",
      "iteration: 67020 loss: 0.0042 lr: 0.02\n",
      "iteration: 67030 loss: 0.0043 lr: 0.02\n",
      "iteration: 67040 loss: 0.0039 lr: 0.02\n",
      "iteration: 67050 loss: 0.0040 lr: 0.02\n",
      "iteration: 67060 loss: 0.0032 lr: 0.02\n",
      "iteration: 67070 loss: 0.0034 lr: 0.02\n",
      "iteration: 67080 loss: 0.0044 lr: 0.02\n",
      "iteration: 67090 loss: 0.0040 lr: 0.02\n",
      "iteration: 67100 loss: 0.0034 lr: 0.02\n",
      "iteration: 67110 loss: 0.0045 lr: 0.02\n",
      "iteration: 67120 loss: 0.0030 lr: 0.02\n",
      "iteration: 67130 loss: 0.0033 lr: 0.02\n",
      "iteration: 67140 loss: 0.0034 lr: 0.02\n",
      "iteration: 67150 loss: 0.0034 lr: 0.02\n",
      "iteration: 67160 loss: 0.0040 lr: 0.02\n",
      "iteration: 67170 loss: 0.0054 lr: 0.02\n",
      "iteration: 67180 loss: 0.0034 lr: 0.02\n",
      "iteration: 67190 loss: 0.0034 lr: 0.02\n",
      "iteration: 67200 loss: 0.0035 lr: 0.02\n",
      "iteration: 67210 loss: 0.0034 lr: 0.02\n",
      "iteration: 67220 loss: 0.0041 lr: 0.02\n",
      "iteration: 67230 loss: 0.0035 lr: 0.02\n",
      "iteration: 67240 loss: 0.0039 lr: 0.02\n",
      "iteration: 67250 loss: 0.0041 lr: 0.02\n",
      "iteration: 67260 loss: 0.0036 lr: 0.02\n",
      "iteration: 67270 loss: 0.0044 lr: 0.02\n",
      "iteration: 67280 loss: 0.0035 lr: 0.02\n",
      "iteration: 67290 loss: 0.0031 lr: 0.02\n",
      "iteration: 67300 loss: 0.0036 lr: 0.02\n",
      "iteration: 67310 loss: 0.0039 lr: 0.02\n",
      "iteration: 67320 loss: 0.0042 lr: 0.02\n",
      "iteration: 67330 loss: 0.0037 lr: 0.02\n",
      "iteration: 67340 loss: 0.0033 lr: 0.02\n",
      "iteration: 67350 loss: 0.0039 lr: 0.02\n",
      "iteration: 67360 loss: 0.0043 lr: 0.02\n",
      "iteration: 67370 loss: 0.0039 lr: 0.02\n",
      "iteration: 67380 loss: 0.0037 lr: 0.02\n",
      "iteration: 67390 loss: 0.0039 lr: 0.02\n",
      "iteration: 67400 loss: 0.0026 lr: 0.02\n",
      "iteration: 67410 loss: 0.0039 lr: 0.02\n",
      "iteration: 67420 loss: 0.0036 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 67430 loss: 0.0030 lr: 0.02\n",
      "iteration: 67440 loss: 0.0028 lr: 0.02\n",
      "iteration: 67450 loss: 0.0024 lr: 0.02\n",
      "iteration: 67460 loss: 0.0029 lr: 0.02\n",
      "iteration: 67470 loss: 0.0035 lr: 0.02\n",
      "iteration: 67480 loss: 0.0040 lr: 0.02\n",
      "iteration: 67490 loss: 0.0041 lr: 0.02\n",
      "iteration: 67500 loss: 0.0039 lr: 0.02\n",
      "iteration: 67510 loss: 0.0040 lr: 0.02\n",
      "iteration: 67520 loss: 0.0034 lr: 0.02\n",
      "iteration: 67530 loss: 0.0031 lr: 0.02\n",
      "iteration: 67540 loss: 0.0038 lr: 0.02\n",
      "iteration: 67550 loss: 0.0030 lr: 0.02\n",
      "iteration: 67560 loss: 0.0037 lr: 0.02\n",
      "iteration: 67570 loss: 0.0031 lr: 0.02\n",
      "iteration: 67580 loss: 0.0032 lr: 0.02\n",
      "iteration: 67590 loss: 0.0046 lr: 0.02\n",
      "iteration: 67600 loss: 0.0033 lr: 0.02\n",
      "iteration: 67610 loss: 0.0030 lr: 0.02\n",
      "iteration: 67620 loss: 0.0034 lr: 0.02\n",
      "iteration: 67630 loss: 0.0030 lr: 0.02\n",
      "iteration: 67640 loss: 0.0035 lr: 0.02\n",
      "iteration: 67650 loss: 0.0034 lr: 0.02\n",
      "iteration: 67660 loss: 0.0042 lr: 0.02\n",
      "iteration: 67670 loss: 0.0042 lr: 0.02\n",
      "iteration: 67680 loss: 0.0040 lr: 0.02\n",
      "iteration: 67690 loss: 0.0046 lr: 0.02\n",
      "iteration: 67700 loss: 0.0036 lr: 0.02\n",
      "iteration: 67710 loss: 0.0039 lr: 0.02\n",
      "iteration: 67720 loss: 0.0036 lr: 0.02\n",
      "iteration: 67730 loss: 0.0045 lr: 0.02\n",
      "iteration: 67740 loss: 0.0045 lr: 0.02\n",
      "iteration: 67750 loss: 0.0036 lr: 0.02\n",
      "iteration: 67760 loss: 0.0047 lr: 0.02\n",
      "iteration: 67770 loss: 0.0045 lr: 0.02\n",
      "iteration: 67780 loss: 0.0042 lr: 0.02\n",
      "iteration: 67790 loss: 0.0033 lr: 0.02\n",
      "iteration: 67800 loss: 0.0032 lr: 0.02\n",
      "iteration: 67810 loss: 0.0037 lr: 0.02\n",
      "iteration: 67820 loss: 0.0046 lr: 0.02\n",
      "iteration: 67830 loss: 0.0036 lr: 0.02\n",
      "iteration: 67840 loss: 0.0042 lr: 0.02\n",
      "iteration: 67850 loss: 0.0040 lr: 0.02\n",
      "iteration: 67860 loss: 0.0041 lr: 0.02\n",
      "iteration: 67870 loss: 0.0039 lr: 0.02\n",
      "iteration: 67880 loss: 0.0034 lr: 0.02\n",
      "iteration: 67890 loss: 0.0043 lr: 0.02\n",
      "iteration: 67900 loss: 0.0041 lr: 0.02\n",
      "iteration: 67910 loss: 0.0033 lr: 0.02\n",
      "iteration: 67920 loss: 0.0039 lr: 0.02\n",
      "iteration: 67930 loss: 0.0031 lr: 0.02\n",
      "iteration: 67940 loss: 0.0032 lr: 0.02\n",
      "iteration: 67950 loss: 0.0036 lr: 0.02\n",
      "iteration: 67960 loss: 0.0036 lr: 0.02\n",
      "iteration: 67970 loss: 0.0036 lr: 0.02\n",
      "iteration: 67980 loss: 0.0042 lr: 0.02\n",
      "iteration: 67990 loss: 0.0040 lr: 0.02\n",
      "iteration: 68000 loss: 0.0032 lr: 0.02\n",
      "iteration: 68010 loss: 0.0038 lr: 0.02\n",
      "iteration: 68020 loss: 0.0037 lr: 0.02\n",
      "iteration: 68030 loss: 0.0034 lr: 0.02\n",
      "iteration: 68040 loss: 0.0035 lr: 0.02\n",
      "iteration: 68050 loss: 0.0032 lr: 0.02\n",
      "iteration: 68060 loss: 0.0034 lr: 0.02\n",
      "iteration: 68070 loss: 0.0031 lr: 0.02\n",
      "iteration: 68080 loss: 0.0035 lr: 0.02\n",
      "iteration: 68090 loss: 0.0035 lr: 0.02\n",
      "iteration: 68100 loss: 0.0028 lr: 0.02\n",
      "iteration: 68110 loss: 0.0048 lr: 0.02\n",
      "iteration: 68120 loss: 0.0033 lr: 0.02\n",
      "iteration: 68130 loss: 0.0029 lr: 0.02\n",
      "iteration: 68140 loss: 0.0026 lr: 0.02\n",
      "iteration: 68150 loss: 0.0030 lr: 0.02\n",
      "iteration: 68160 loss: 0.0034 lr: 0.02\n",
      "iteration: 68170 loss: 0.0032 lr: 0.02\n",
      "iteration: 68180 loss: 0.0039 lr: 0.02\n",
      "iteration: 68190 loss: 0.0035 lr: 0.02\n",
      "iteration: 68200 loss: 0.0039 lr: 0.02\n",
      "iteration: 68210 loss: 0.0028 lr: 0.02\n",
      "iteration: 68220 loss: 0.0041 lr: 0.02\n",
      "iteration: 68230 loss: 0.0038 lr: 0.02\n",
      "iteration: 68240 loss: 0.0038 lr: 0.02\n",
      "iteration: 68250 loss: 0.0040 lr: 0.02\n",
      "iteration: 68260 loss: 0.0037 lr: 0.02\n",
      "iteration: 68270 loss: 0.0034 lr: 0.02\n",
      "iteration: 68280 loss: 0.0030 lr: 0.02\n",
      "iteration: 68290 loss: 0.0033 lr: 0.02\n",
      "iteration: 68300 loss: 0.0032 lr: 0.02\n",
      "iteration: 68310 loss: 0.0042 lr: 0.02\n",
      "iteration: 68320 loss: 0.0044 lr: 0.02\n",
      "iteration: 68330 loss: 0.0041 lr: 0.02\n",
      "iteration: 68340 loss: 0.0049 lr: 0.02\n",
      "iteration: 68350 loss: 0.0038 lr: 0.02\n",
      "iteration: 68360 loss: 0.0038 lr: 0.02\n",
      "iteration: 68370 loss: 0.0033 lr: 0.02\n",
      "iteration: 68380 loss: 0.0035 lr: 0.02\n",
      "iteration: 68390 loss: 0.0028 lr: 0.02\n",
      "iteration: 68400 loss: 0.0042 lr: 0.02\n",
      "iteration: 68410 loss: 0.0036 lr: 0.02\n",
      "iteration: 68420 loss: 0.0027 lr: 0.02\n",
      "iteration: 68430 loss: 0.0036 lr: 0.02\n",
      "iteration: 68440 loss: 0.0032 lr: 0.02\n",
      "iteration: 68450 loss: 0.0033 lr: 0.02\n",
      "iteration: 68460 loss: 0.0036 lr: 0.02\n",
      "iteration: 68470 loss: 0.0042 lr: 0.02\n",
      "iteration: 68480 loss: 0.0033 lr: 0.02\n",
      "iteration: 68490 loss: 0.0036 lr: 0.02\n",
      "iteration: 68500 loss: 0.0044 lr: 0.02\n",
      "iteration: 68510 loss: 0.0029 lr: 0.02\n",
      "iteration: 68520 loss: 0.0047 lr: 0.02\n",
      "iteration: 68530 loss: 0.0040 lr: 0.02\n",
      "iteration: 68540 loss: 0.0040 lr: 0.02\n",
      "iteration: 68550 loss: 0.0034 lr: 0.02\n",
      "iteration: 68560 loss: 0.0045 lr: 0.02\n",
      "iteration: 68570 loss: 0.0038 lr: 0.02\n",
      "iteration: 68580 loss: 0.0044 lr: 0.02\n",
      "iteration: 68590 loss: 0.0030 lr: 0.02\n",
      "iteration: 68600 loss: 0.0038 lr: 0.02\n",
      "iteration: 68610 loss: 0.0047 lr: 0.02\n",
      "iteration: 68620 loss: 0.0047 lr: 0.02\n",
      "iteration: 68630 loss: 0.0044 lr: 0.02\n",
      "iteration: 68640 loss: 0.0032 lr: 0.02\n",
      "iteration: 68650 loss: 0.0029 lr: 0.02\n",
      "iteration: 68660 loss: 0.0036 lr: 0.02\n",
      "iteration: 68670 loss: 0.0039 lr: 0.02\n",
      "iteration: 68680 loss: 0.0040 lr: 0.02\n",
      "iteration: 68690 loss: 0.0029 lr: 0.02\n",
      "iteration: 68700 loss: 0.0038 lr: 0.02\n",
      "iteration: 68710 loss: 0.0039 lr: 0.02\n",
      "iteration: 68720 loss: 0.0034 lr: 0.02\n",
      "iteration: 68730 loss: 0.0041 lr: 0.02\n",
      "iteration: 68740 loss: 0.0042 lr: 0.02\n",
      "iteration: 68750 loss: 0.0030 lr: 0.02\n",
      "iteration: 68760 loss: 0.0037 lr: 0.02\n",
      "iteration: 68770 loss: 0.0042 lr: 0.02\n",
      "iteration: 68780 loss: 0.0031 lr: 0.02\n",
      "iteration: 68790 loss: 0.0035 lr: 0.02\n",
      "iteration: 68800 loss: 0.0029 lr: 0.02\n",
      "iteration: 68810 loss: 0.0036 lr: 0.02\n",
      "iteration: 68820 loss: 0.0040 lr: 0.02\n",
      "iteration: 68830 loss: 0.0038 lr: 0.02\n",
      "iteration: 68840 loss: 0.0051 lr: 0.02\n",
      "iteration: 68850 loss: 0.0035 lr: 0.02\n",
      "iteration: 68860 loss: 0.0037 lr: 0.02\n",
      "iteration: 68870 loss: 0.0041 lr: 0.02\n",
      "iteration: 68880 loss: 0.0034 lr: 0.02\n",
      "iteration: 68890 loss: 0.0036 lr: 0.02\n",
      "iteration: 68900 loss: 0.0031 lr: 0.02\n",
      "iteration: 68910 loss: 0.0030 lr: 0.02\n",
      "iteration: 68920 loss: 0.0033 lr: 0.02\n",
      "iteration: 68930 loss: 0.0045 lr: 0.02\n",
      "iteration: 68940 loss: 0.0034 lr: 0.02\n",
      "iteration: 68950 loss: 0.0028 lr: 0.02\n",
      "iteration: 68960 loss: 0.0032 lr: 0.02\n",
      "iteration: 68970 loss: 0.0035 lr: 0.02\n",
      "iteration: 68980 loss: 0.0035 lr: 0.02\n",
      "iteration: 68990 loss: 0.0033 lr: 0.02\n",
      "iteration: 69000 loss: 0.0027 lr: 0.02\n",
      "iteration: 69010 loss: 0.0031 lr: 0.02\n",
      "iteration: 69020 loss: 0.0044 lr: 0.02\n",
      "iteration: 69030 loss: 0.0039 lr: 0.02\n",
      "iteration: 69040 loss: 0.0033 lr: 0.02\n",
      "iteration: 69050 loss: 0.0040 lr: 0.02\n",
      "iteration: 69060 loss: 0.0041 lr: 0.02\n",
      "iteration: 69070 loss: 0.0039 lr: 0.02\n",
      "iteration: 69080 loss: 0.0036 lr: 0.02\n",
      "iteration: 69090 loss: 0.0040 lr: 0.02\n",
      "iteration: 69100 loss: 0.0045 lr: 0.02\n",
      "iteration: 69110 loss: 0.0028 lr: 0.02\n",
      "iteration: 69120 loss: 0.0042 lr: 0.02\n",
      "iteration: 69130 loss: 0.0039 lr: 0.02\n",
      "iteration: 69140 loss: 0.0045 lr: 0.02\n",
      "iteration: 69150 loss: 0.0039 lr: 0.02\n",
      "iteration: 69160 loss: 0.0032 lr: 0.02\n",
      "iteration: 69170 loss: 0.0038 lr: 0.02\n",
      "iteration: 69180 loss: 0.0035 lr: 0.02\n",
      "iteration: 69190 loss: 0.0032 lr: 0.02\n",
      "iteration: 69200 loss: 0.0034 lr: 0.02\n",
      "iteration: 69210 loss: 0.0041 lr: 0.02\n",
      "iteration: 69220 loss: 0.0054 lr: 0.02\n",
      "iteration: 69230 loss: 0.0041 lr: 0.02\n",
      "iteration: 69240 loss: 0.0035 lr: 0.02\n",
      "iteration: 69250 loss: 0.0038 lr: 0.02\n",
      "iteration: 69260 loss: 0.0035 lr: 0.02\n",
      "iteration: 69270 loss: 0.0036 lr: 0.02\n",
      "iteration: 69280 loss: 0.0034 lr: 0.02\n",
      "iteration: 69290 loss: 0.0030 lr: 0.02\n",
      "iteration: 69300 loss: 0.0042 lr: 0.02\n",
      "iteration: 69310 loss: 0.0043 lr: 0.02\n",
      "iteration: 69320 loss: 0.0035 lr: 0.02\n",
      "iteration: 69330 loss: 0.0035 lr: 0.02\n",
      "iteration: 69340 loss: 0.0036 lr: 0.02\n",
      "iteration: 69350 loss: 0.0032 lr: 0.02\n",
      "iteration: 69360 loss: 0.0026 lr: 0.02\n",
      "iteration: 69370 loss: 0.0032 lr: 0.02\n",
      "iteration: 69380 loss: 0.0041 lr: 0.02\n",
      "iteration: 69390 loss: 0.0042 lr: 0.02\n",
      "iteration: 69400 loss: 0.0032 lr: 0.02\n",
      "iteration: 69410 loss: 0.0033 lr: 0.02\n",
      "iteration: 69420 loss: 0.0037 lr: 0.02\n",
      "iteration: 69430 loss: 0.0028 lr: 0.02\n",
      "iteration: 69440 loss: 0.0032 lr: 0.02\n",
      "iteration: 69450 loss: 0.0041 lr: 0.02\n",
      "iteration: 69460 loss: 0.0032 lr: 0.02\n",
      "iteration: 69470 loss: 0.0048 lr: 0.02\n",
      "iteration: 69480 loss: 0.0037 lr: 0.02\n",
      "iteration: 69490 loss: 0.0035 lr: 0.02\n",
      "iteration: 69500 loss: 0.0027 lr: 0.02\n",
      "iteration: 69510 loss: 0.0032 lr: 0.02\n",
      "iteration: 69520 loss: 0.0034 lr: 0.02\n",
      "iteration: 69530 loss: 0.0023 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 69540 loss: 0.0038 lr: 0.02\n",
      "iteration: 69550 loss: 0.0032 lr: 0.02\n",
      "iteration: 69560 loss: 0.0037 lr: 0.02\n",
      "iteration: 69570 loss: 0.0031 lr: 0.02\n",
      "iteration: 69580 loss: 0.0036 lr: 0.02\n",
      "iteration: 69590 loss: 0.0040 lr: 0.02\n",
      "iteration: 69600 loss: 0.0032 lr: 0.02\n",
      "iteration: 69610 loss: 0.0036 lr: 0.02\n",
      "iteration: 69620 loss: 0.0033 lr: 0.02\n",
      "iteration: 69630 loss: 0.0029 lr: 0.02\n",
      "iteration: 69640 loss: 0.0039 lr: 0.02\n",
      "iteration: 69650 loss: 0.0039 lr: 0.02\n",
      "iteration: 69660 loss: 0.0025 lr: 0.02\n",
      "iteration: 69670 loss: 0.0029 lr: 0.02\n",
      "iteration: 69680 loss: 0.0033 lr: 0.02\n",
      "iteration: 69690 loss: 0.0039 lr: 0.02\n",
      "iteration: 69700 loss: 0.0023 lr: 0.02\n",
      "iteration: 69710 loss: 0.0033 lr: 0.02\n",
      "iteration: 69720 loss: 0.0034 lr: 0.02\n",
      "iteration: 69730 loss: 0.0034 lr: 0.02\n",
      "iteration: 69740 loss: 0.0032 lr: 0.02\n",
      "iteration: 69750 loss: 0.0042 lr: 0.02\n",
      "iteration: 69760 loss: 0.0029 lr: 0.02\n",
      "iteration: 69770 loss: 0.0029 lr: 0.02\n",
      "iteration: 69780 loss: 0.0038 lr: 0.02\n",
      "iteration: 69790 loss: 0.0028 lr: 0.02\n",
      "iteration: 69800 loss: 0.0029 lr: 0.02\n",
      "iteration: 69810 loss: 0.0032 lr: 0.02\n",
      "iteration: 69820 loss: 0.0039 lr: 0.02\n",
      "iteration: 69830 loss: 0.0038 lr: 0.02\n",
      "iteration: 69840 loss: 0.0036 lr: 0.02\n",
      "iteration: 69850 loss: 0.0028 lr: 0.02\n",
      "iteration: 69860 loss: 0.0051 lr: 0.02\n",
      "iteration: 69870 loss: 0.0037 lr: 0.02\n",
      "iteration: 69880 loss: 0.0035 lr: 0.02\n",
      "iteration: 69890 loss: 0.0027 lr: 0.02\n",
      "iteration: 69900 loss: 0.0028 lr: 0.02\n",
      "iteration: 69910 loss: 0.0040 lr: 0.02\n",
      "iteration: 69920 loss: 0.0036 lr: 0.02\n",
      "iteration: 69930 loss: 0.0039 lr: 0.02\n",
      "iteration: 69940 loss: 0.0038 lr: 0.02\n",
      "iteration: 69950 loss: 0.0034 lr: 0.02\n",
      "iteration: 69960 loss: 0.0034 lr: 0.02\n",
      "iteration: 69970 loss: 0.0038 lr: 0.02\n",
      "iteration: 69980 loss: 0.0026 lr: 0.02\n",
      "iteration: 69990 loss: 0.0037 lr: 0.02\n",
      "iteration: 70000 loss: 0.0037 lr: 0.02\n",
      "iteration: 70010 loss: 0.0044 lr: 0.02\n",
      "iteration: 70020 loss: 0.0048 lr: 0.02\n",
      "iteration: 70030 loss: 0.0026 lr: 0.02\n",
      "iteration: 70040 loss: 0.0035 lr: 0.02\n",
      "iteration: 70050 loss: 0.0039 lr: 0.02\n",
      "iteration: 70060 loss: 0.0032 lr: 0.02\n",
      "iteration: 70070 loss: 0.0033 lr: 0.02\n",
      "iteration: 70080 loss: 0.0034 lr: 0.02\n",
      "iteration: 70090 loss: 0.0027 lr: 0.02\n",
      "iteration: 70100 loss: 0.0025 lr: 0.02\n",
      "iteration: 70110 loss: 0.0036 lr: 0.02\n",
      "iteration: 70120 loss: 0.0030 lr: 0.02\n",
      "iteration: 70130 loss: 0.0040 lr: 0.02\n",
      "iteration: 70140 loss: 0.0029 lr: 0.02\n",
      "iteration: 70150 loss: 0.0031 lr: 0.02\n",
      "iteration: 70160 loss: 0.0046 lr: 0.02\n",
      "iteration: 70170 loss: 0.0032 lr: 0.02\n",
      "iteration: 70180 loss: 0.0035 lr: 0.02\n",
      "iteration: 70190 loss: 0.0030 lr: 0.02\n",
      "iteration: 70200 loss: 0.0031 lr: 0.02\n",
      "iteration: 70210 loss: 0.0040 lr: 0.02\n",
      "iteration: 70220 loss: 0.0045 lr: 0.02\n",
      "iteration: 70230 loss: 0.0024 lr: 0.02\n",
      "iteration: 70240 loss: 0.0035 lr: 0.02\n",
      "iteration: 70250 loss: 0.0039 lr: 0.02\n",
      "iteration: 70260 loss: 0.0040 lr: 0.02\n",
      "iteration: 70270 loss: 0.0031 lr: 0.02\n",
      "iteration: 70280 loss: 0.0031 lr: 0.02\n",
      "iteration: 70290 loss: 0.0035 lr: 0.02\n",
      "iteration: 70300 loss: 0.0036 lr: 0.02\n",
      "iteration: 70310 loss: 0.0034 lr: 0.02\n",
      "iteration: 70320 loss: 0.0035 lr: 0.02\n",
      "iteration: 70330 loss: 0.0027 lr: 0.02\n",
      "iteration: 70340 loss: 0.0033 lr: 0.02\n",
      "iteration: 70350 loss: 0.0029 lr: 0.02\n",
      "iteration: 70360 loss: 0.0050 lr: 0.02\n",
      "iteration: 70370 loss: 0.0037 lr: 0.02\n",
      "iteration: 70380 loss: 0.0039 lr: 0.02\n",
      "iteration: 70390 loss: 0.0034 lr: 0.02\n",
      "iteration: 70400 loss: 0.0045 lr: 0.02\n",
      "iteration: 70410 loss: 0.0030 lr: 0.02\n",
      "iteration: 70420 loss: 0.0035 lr: 0.02\n",
      "iteration: 70430 loss: 0.0034 lr: 0.02\n",
      "iteration: 70440 loss: 0.0038 lr: 0.02\n",
      "iteration: 70450 loss: 0.0035 lr: 0.02\n",
      "iteration: 70460 loss: 0.0036 lr: 0.02\n",
      "iteration: 70470 loss: 0.0030 lr: 0.02\n",
      "iteration: 70480 loss: 0.0032 lr: 0.02\n",
      "iteration: 70490 loss: 0.0037 lr: 0.02\n",
      "iteration: 70500 loss: 0.0027 lr: 0.02\n",
      "iteration: 70510 loss: 0.0035 lr: 0.02\n",
      "iteration: 70520 loss: 0.0032 lr: 0.02\n",
      "iteration: 70530 loss: 0.0042 lr: 0.02\n",
      "iteration: 70540 loss: 0.0028 lr: 0.02\n",
      "iteration: 70550 loss: 0.0033 lr: 0.02\n",
      "iteration: 70560 loss: 0.0025 lr: 0.02\n",
      "iteration: 70570 loss: 0.0041 lr: 0.02\n",
      "iteration: 70580 loss: 0.0026 lr: 0.02\n",
      "iteration: 70590 loss: 0.0031 lr: 0.02\n",
      "iteration: 70600 loss: 0.0027 lr: 0.02\n",
      "iteration: 70610 loss: 0.0036 lr: 0.02\n",
      "iteration: 70620 loss: 0.0027 lr: 0.02\n",
      "iteration: 70630 loss: 0.0037 lr: 0.02\n",
      "iteration: 70640 loss: 0.0035 lr: 0.02\n",
      "iteration: 70650 loss: 0.0041 lr: 0.02\n",
      "iteration: 70660 loss: 0.0030 lr: 0.02\n",
      "iteration: 70670 loss: 0.0037 lr: 0.02\n",
      "iteration: 70680 loss: 0.0039 lr: 0.02\n",
      "iteration: 70690 loss: 0.0041 lr: 0.02\n",
      "iteration: 70700 loss: 0.0035 lr: 0.02\n",
      "iteration: 70710 loss: 0.0030 lr: 0.02\n",
      "iteration: 70720 loss: 0.0047 lr: 0.02\n",
      "iteration: 70730 loss: 0.0029 lr: 0.02\n",
      "iteration: 70740 loss: 0.0041 lr: 0.02\n",
      "iteration: 70750 loss: 0.0040 lr: 0.02\n",
      "iteration: 70760 loss: 0.0029 lr: 0.02\n",
      "iteration: 70770 loss: 0.0035 lr: 0.02\n",
      "iteration: 70780 loss: 0.0040 lr: 0.02\n",
      "iteration: 70790 loss: 0.0030 lr: 0.02\n",
      "iteration: 70800 loss: 0.0035 lr: 0.02\n",
      "iteration: 70810 loss: 0.0032 lr: 0.02\n",
      "iteration: 70820 loss: 0.0041 lr: 0.02\n",
      "iteration: 70830 loss: 0.0028 lr: 0.02\n",
      "iteration: 70840 loss: 0.0036 lr: 0.02\n",
      "iteration: 70850 loss: 0.0030 lr: 0.02\n",
      "iteration: 70860 loss: 0.0035 lr: 0.02\n",
      "iteration: 70870 loss: 0.0032 lr: 0.02\n",
      "iteration: 70880 loss: 0.0037 lr: 0.02\n",
      "iteration: 70890 loss: 0.0033 lr: 0.02\n",
      "iteration: 70900 loss: 0.0035 lr: 0.02\n",
      "iteration: 70910 loss: 0.0031 lr: 0.02\n",
      "iteration: 70920 loss: 0.0037 lr: 0.02\n",
      "iteration: 70930 loss: 0.0038 lr: 0.02\n",
      "iteration: 70940 loss: 0.0033 lr: 0.02\n",
      "iteration: 70950 loss: 0.0037 lr: 0.02\n",
      "iteration: 70960 loss: 0.0036 lr: 0.02\n",
      "iteration: 70970 loss: 0.0041 lr: 0.02\n",
      "iteration: 70980 loss: 0.0038 lr: 0.02\n",
      "iteration: 70990 loss: 0.0045 lr: 0.02\n",
      "iteration: 71000 loss: 0.0035 lr: 0.02\n",
      "iteration: 71010 loss: 0.0036 lr: 0.02\n",
      "iteration: 71020 loss: 0.0039 lr: 0.02\n",
      "iteration: 71030 loss: 0.0029 lr: 0.02\n",
      "iteration: 71040 loss: 0.0049 lr: 0.02\n",
      "iteration: 71050 loss: 0.0044 lr: 0.02\n",
      "iteration: 71060 loss: 0.0030 lr: 0.02\n",
      "iteration: 71070 loss: 0.0038 lr: 0.02\n",
      "iteration: 71080 loss: 0.0035 lr: 0.02\n",
      "iteration: 71090 loss: 0.0040 lr: 0.02\n",
      "iteration: 71100 loss: 0.0035 lr: 0.02\n",
      "iteration: 71110 loss: 0.0032 lr: 0.02\n",
      "iteration: 71120 loss: 0.0038 lr: 0.02\n",
      "iteration: 71130 loss: 0.0036 lr: 0.02\n",
      "iteration: 71140 loss: 0.0037 lr: 0.02\n",
      "iteration: 71150 loss: 0.0043 lr: 0.02\n",
      "iteration: 71160 loss: 0.0047 lr: 0.02\n",
      "iteration: 71170 loss: 0.0044 lr: 0.02\n",
      "iteration: 71180 loss: 0.0038 lr: 0.02\n",
      "iteration: 71190 loss: 0.0032 lr: 0.02\n",
      "iteration: 71200 loss: 0.0042 lr: 0.02\n",
      "iteration: 71210 loss: 0.0036 lr: 0.02\n",
      "iteration: 71220 loss: 0.0034 lr: 0.02\n",
      "iteration: 71230 loss: 0.0035 lr: 0.02\n",
      "iteration: 71240 loss: 0.0029 lr: 0.02\n",
      "iteration: 71250 loss: 0.0036 lr: 0.02\n",
      "iteration: 71260 loss: 0.0042 lr: 0.02\n",
      "iteration: 71270 loss: 0.0036 lr: 0.02\n",
      "iteration: 71280 loss: 0.0033 lr: 0.02\n",
      "iteration: 71290 loss: 0.0030 lr: 0.02\n",
      "iteration: 71300 loss: 0.0036 lr: 0.02\n",
      "iteration: 71310 loss: 0.0036 lr: 0.02\n",
      "iteration: 71320 loss: 0.0030 lr: 0.02\n",
      "iteration: 71330 loss: 0.0040 lr: 0.02\n",
      "iteration: 71340 loss: 0.0040 lr: 0.02\n",
      "iteration: 71350 loss: 0.0032 lr: 0.02\n",
      "iteration: 71360 loss: 0.0033 lr: 0.02\n",
      "iteration: 71370 loss: 0.0043 lr: 0.02\n",
      "iteration: 71380 loss: 0.0030 lr: 0.02\n",
      "iteration: 71390 loss: 0.0030 lr: 0.02\n",
      "iteration: 71400 loss: 0.0030 lr: 0.02\n",
      "iteration: 71410 loss: 0.0029 lr: 0.02\n",
      "iteration: 71420 loss: 0.0035 lr: 0.02\n",
      "iteration: 71430 loss: 0.0025 lr: 0.02\n",
      "iteration: 71440 loss: 0.0031 lr: 0.02\n",
      "iteration: 71450 loss: 0.0030 lr: 0.02\n",
      "iteration: 71460 loss: 0.0028 lr: 0.02\n",
      "iteration: 71470 loss: 0.0030 lr: 0.02\n",
      "iteration: 71480 loss: 0.0042 lr: 0.02\n",
      "iteration: 71490 loss: 0.0035 lr: 0.02\n",
      "iteration: 71500 loss: 0.0029 lr: 0.02\n",
      "iteration: 71510 loss: 0.0037 lr: 0.02\n",
      "iteration: 71520 loss: 0.0038 lr: 0.02\n",
      "iteration: 71530 loss: 0.0036 lr: 0.02\n",
      "iteration: 71540 loss: 0.0034 lr: 0.02\n",
      "iteration: 71550 loss: 0.0046 lr: 0.02\n",
      "iteration: 71560 loss: 0.0032 lr: 0.02\n",
      "iteration: 71570 loss: 0.0038 lr: 0.02\n",
      "iteration: 71580 loss: 0.0027 lr: 0.02\n",
      "iteration: 71590 loss: 0.0038 lr: 0.02\n",
      "iteration: 71600 loss: 0.0029 lr: 0.02\n",
      "iteration: 71610 loss: 0.0037 lr: 0.02\n",
      "iteration: 71620 loss: 0.0034 lr: 0.02\n",
      "iteration: 71630 loss: 0.0028 lr: 0.02\n",
      "iteration: 71640 loss: 0.0028 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 71650 loss: 0.0038 lr: 0.02\n",
      "iteration: 71660 loss: 0.0040 lr: 0.02\n",
      "iteration: 71670 loss: 0.0029 lr: 0.02\n",
      "iteration: 71680 loss: 0.0038 lr: 0.02\n",
      "iteration: 71690 loss: 0.0033 lr: 0.02\n",
      "iteration: 71700 loss: 0.0039 lr: 0.02\n",
      "iteration: 71710 loss: 0.0039 lr: 0.02\n",
      "iteration: 71720 loss: 0.0033 lr: 0.02\n",
      "iteration: 71730 loss: 0.0030 lr: 0.02\n",
      "iteration: 71740 loss: 0.0040 lr: 0.02\n",
      "iteration: 71750 loss: 0.0036 lr: 0.02\n",
      "iteration: 71760 loss: 0.0028 lr: 0.02\n",
      "iteration: 71770 loss: 0.0036 lr: 0.02\n",
      "iteration: 71780 loss: 0.0042 lr: 0.02\n",
      "iteration: 71790 loss: 0.0044 lr: 0.02\n",
      "iteration: 71800 loss: 0.0031 lr: 0.02\n",
      "iteration: 71810 loss: 0.0033 lr: 0.02\n",
      "iteration: 71820 loss: 0.0038 lr: 0.02\n",
      "iteration: 71830 loss: 0.0028 lr: 0.02\n",
      "iteration: 71840 loss: 0.0033 lr: 0.02\n",
      "iteration: 71850 loss: 0.0028 lr: 0.02\n",
      "iteration: 71860 loss: 0.0036 lr: 0.02\n",
      "iteration: 71870 loss: 0.0036 lr: 0.02\n",
      "iteration: 71880 loss: 0.0035 lr: 0.02\n",
      "iteration: 71890 loss: 0.0045 lr: 0.02\n",
      "iteration: 71900 loss: 0.0039 lr: 0.02\n",
      "iteration: 71910 loss: 0.0033 lr: 0.02\n",
      "iteration: 71920 loss: 0.0027 lr: 0.02\n",
      "iteration: 71930 loss: 0.0039 lr: 0.02\n",
      "iteration: 71940 loss: 0.0051 lr: 0.02\n",
      "iteration: 71950 loss: 0.0028 lr: 0.02\n",
      "iteration: 71960 loss: 0.0040 lr: 0.02\n",
      "iteration: 71970 loss: 0.0042 lr: 0.02\n",
      "iteration: 71980 loss: 0.0039 lr: 0.02\n",
      "iteration: 71990 loss: 0.0043 lr: 0.02\n",
      "iteration: 72000 loss: 0.0047 lr: 0.02\n",
      "iteration: 72010 loss: 0.0029 lr: 0.02\n",
      "iteration: 72020 loss: 0.0040 lr: 0.02\n",
      "iteration: 72030 loss: 0.0034 lr: 0.02\n",
      "iteration: 72040 loss: 0.0033 lr: 0.02\n",
      "iteration: 72050 loss: 0.0033 lr: 0.02\n",
      "iteration: 72060 loss: 0.0037 lr: 0.02\n",
      "iteration: 72070 loss: 0.0036 lr: 0.02\n",
      "iteration: 72080 loss: 0.0035 lr: 0.02\n",
      "iteration: 72090 loss: 0.0038 lr: 0.02\n",
      "iteration: 72100 loss: 0.0048 lr: 0.02\n",
      "iteration: 72110 loss: 0.0027 lr: 0.02\n",
      "iteration: 72120 loss: 0.0043 lr: 0.02\n",
      "iteration: 72130 loss: 0.0038 lr: 0.02\n",
      "iteration: 72140 loss: 0.0038 lr: 0.02\n",
      "iteration: 72150 loss: 0.0047 lr: 0.02\n",
      "iteration: 72160 loss: 0.0041 lr: 0.02\n",
      "iteration: 72170 loss: 0.0045 lr: 0.02\n",
      "iteration: 72180 loss: 0.0044 lr: 0.02\n",
      "iteration: 72190 loss: 0.0028 lr: 0.02\n",
      "iteration: 72200 loss: 0.0034 lr: 0.02\n",
      "iteration: 72210 loss: 0.0035 lr: 0.02\n",
      "iteration: 72220 loss: 0.0031 lr: 0.02\n",
      "iteration: 72230 loss: 0.0034 lr: 0.02\n",
      "iteration: 72240 loss: 0.0023 lr: 0.02\n",
      "iteration: 72250 loss: 0.0035 lr: 0.02\n",
      "iteration: 72260 loss: 0.0029 lr: 0.02\n",
      "iteration: 72270 loss: 0.0041 lr: 0.02\n",
      "iteration: 72280 loss: 0.0041 lr: 0.02\n",
      "iteration: 72290 loss: 0.0028 lr: 0.02\n",
      "iteration: 72300 loss: 0.0030 lr: 0.02\n",
      "iteration: 72310 loss: 0.0031 lr: 0.02\n",
      "iteration: 72320 loss: 0.0040 lr: 0.02\n",
      "iteration: 72330 loss: 0.0035 lr: 0.02\n",
      "iteration: 72340 loss: 0.0040 lr: 0.02\n",
      "iteration: 72350 loss: 0.0032 lr: 0.02\n",
      "iteration: 72360 loss: 0.0032 lr: 0.02\n",
      "iteration: 72370 loss: 0.0033 lr: 0.02\n",
      "iteration: 72380 loss: 0.0032 lr: 0.02\n",
      "iteration: 72390 loss: 0.0039 lr: 0.02\n",
      "iteration: 72400 loss: 0.0033 lr: 0.02\n",
      "iteration: 72410 loss: 0.0028 lr: 0.02\n",
      "iteration: 72420 loss: 0.0033 lr: 0.02\n",
      "iteration: 72430 loss: 0.0031 lr: 0.02\n",
      "iteration: 72440 loss: 0.0036 lr: 0.02\n",
      "iteration: 72450 loss: 0.0031 lr: 0.02\n",
      "iteration: 72460 loss: 0.0037 lr: 0.02\n",
      "iteration: 72470 loss: 0.0051 lr: 0.02\n",
      "iteration: 72480 loss: 0.0031 lr: 0.02\n",
      "iteration: 72490 loss: 0.0035 lr: 0.02\n",
      "iteration: 72500 loss: 0.0032 lr: 0.02\n",
      "iteration: 72510 loss: 0.0029 lr: 0.02\n",
      "iteration: 72520 loss: 0.0027 lr: 0.02\n",
      "iteration: 72530 loss: 0.0030 lr: 0.02\n",
      "iteration: 72540 loss: 0.0035 lr: 0.02\n",
      "iteration: 72550 loss: 0.0024 lr: 0.02\n",
      "iteration: 72560 loss: 0.0031 lr: 0.02\n",
      "iteration: 72570 loss: 0.0033 lr: 0.02\n",
      "iteration: 72580 loss: 0.0033 lr: 0.02\n",
      "iteration: 72590 loss: 0.0036 lr: 0.02\n",
      "iteration: 72600 loss: 0.0035 lr: 0.02\n",
      "iteration: 72610 loss: 0.0039 lr: 0.02\n",
      "iteration: 72620 loss: 0.0041 lr: 0.02\n",
      "iteration: 72630 loss: 0.0039 lr: 0.02\n",
      "iteration: 72640 loss: 0.0026 lr: 0.02\n",
      "iteration: 72650 loss: 0.0031 lr: 0.02\n",
      "iteration: 72660 loss: 0.0038 lr: 0.02\n",
      "iteration: 72670 loss: 0.0040 lr: 0.02\n",
      "iteration: 72680 loss: 0.0041 lr: 0.02\n",
      "iteration: 72690 loss: 0.0039 lr: 0.02\n",
      "iteration: 72700 loss: 0.0037 lr: 0.02\n",
      "iteration: 72710 loss: 0.0032 lr: 0.02\n",
      "iteration: 72720 loss: 0.0030 lr: 0.02\n",
      "iteration: 72730 loss: 0.0036 lr: 0.02\n",
      "iteration: 72740 loss: 0.0031 lr: 0.02\n",
      "iteration: 72750 loss: 0.0033 lr: 0.02\n",
      "iteration: 72760 loss: 0.0031 lr: 0.02\n",
      "iteration: 72770 loss: 0.0029 lr: 0.02\n",
      "iteration: 72780 loss: 0.0031 lr: 0.02\n",
      "iteration: 72790 loss: 0.0031 lr: 0.02\n",
      "iteration: 72800 loss: 0.0042 lr: 0.02\n",
      "iteration: 72810 loss: 0.0038 lr: 0.02\n",
      "iteration: 72820 loss: 0.0040 lr: 0.02\n",
      "iteration: 72830 loss: 0.0042 lr: 0.02\n",
      "iteration: 72840 loss: 0.0032 lr: 0.02\n",
      "iteration: 72850 loss: 0.0040 lr: 0.02\n",
      "iteration: 72860 loss: 0.0038 lr: 0.02\n",
      "iteration: 72870 loss: 0.0038 lr: 0.02\n",
      "iteration: 72880 loss: 0.0034 lr: 0.02\n",
      "iteration: 72890 loss: 0.0043 lr: 0.02\n",
      "iteration: 72900 loss: 0.0035 lr: 0.02\n",
      "iteration: 72910 loss: 0.0036 lr: 0.02\n",
      "iteration: 72920 loss: 0.0042 lr: 0.02\n",
      "iteration: 72930 loss: 0.0037 lr: 0.02\n",
      "iteration: 72940 loss: 0.0031 lr: 0.02\n",
      "iteration: 72950 loss: 0.0037 lr: 0.02\n",
      "iteration: 72960 loss: 0.0042 lr: 0.02\n",
      "iteration: 72970 loss: 0.0033 lr: 0.02\n",
      "iteration: 72980 loss: 0.0044 lr: 0.02\n",
      "iteration: 72990 loss: 0.0039 lr: 0.02\n",
      "iteration: 73000 loss: 0.0036 lr: 0.02\n",
      "iteration: 73010 loss: 0.0036 lr: 0.02\n",
      "iteration: 73020 loss: 0.0028 lr: 0.02\n",
      "iteration: 73030 loss: 0.0032 lr: 0.02\n",
      "iteration: 73040 loss: 0.0034 lr: 0.02\n",
      "iteration: 73050 loss: 0.0029 lr: 0.02\n",
      "iteration: 73060 loss: 0.0035 lr: 0.02\n",
      "iteration: 73070 loss: 0.0034 lr: 0.02\n",
      "iteration: 73080 loss: 0.0030 lr: 0.02\n",
      "iteration: 73090 loss: 0.0033 lr: 0.02\n",
      "iteration: 73100 loss: 0.0032 lr: 0.02\n",
      "iteration: 73110 loss: 0.0033 lr: 0.02\n",
      "iteration: 73120 loss: 0.0030 lr: 0.02\n",
      "iteration: 73130 loss: 0.0036 lr: 0.02\n",
      "iteration: 73140 loss: 0.0035 lr: 0.02\n",
      "iteration: 73150 loss: 0.0032 lr: 0.02\n",
      "iteration: 73160 loss: 0.0055 lr: 0.02\n",
      "iteration: 73170 loss: 0.0037 lr: 0.02\n",
      "iteration: 73180 loss: 0.0039 lr: 0.02\n",
      "iteration: 73190 loss: 0.0035 lr: 0.02\n",
      "iteration: 73200 loss: 0.0030 lr: 0.02\n",
      "iteration: 73210 loss: 0.0036 lr: 0.02\n",
      "iteration: 73220 loss: 0.0041 lr: 0.02\n",
      "iteration: 73230 loss: 0.0031 lr: 0.02\n",
      "iteration: 73240 loss: 0.0054 lr: 0.02\n",
      "iteration: 73250 loss: 0.0024 lr: 0.02\n",
      "iteration: 73260 loss: 0.0038 lr: 0.02\n",
      "iteration: 73270 loss: 0.0031 lr: 0.02\n",
      "iteration: 73280 loss: 0.0025 lr: 0.02\n",
      "iteration: 73290 loss: 0.0030 lr: 0.02\n",
      "iteration: 73300 loss: 0.0031 lr: 0.02\n",
      "iteration: 73310 loss: 0.0032 lr: 0.02\n",
      "iteration: 73320 loss: 0.0037 lr: 0.02\n",
      "iteration: 73330 loss: 0.0035 lr: 0.02\n",
      "iteration: 73340 loss: 0.0045 lr: 0.02\n",
      "iteration: 73350 loss: 0.0030 lr: 0.02\n",
      "iteration: 73360 loss: 0.0027 lr: 0.02\n",
      "iteration: 73370 loss: 0.0037 lr: 0.02\n",
      "iteration: 73380 loss: 0.0025 lr: 0.02\n",
      "iteration: 73390 loss: 0.0039 lr: 0.02\n",
      "iteration: 73400 loss: 0.0035 lr: 0.02\n",
      "iteration: 73410 loss: 0.0043 lr: 0.02\n",
      "iteration: 73420 loss: 0.0033 lr: 0.02\n",
      "iteration: 73430 loss: 0.0035 lr: 0.02\n",
      "iteration: 73440 loss: 0.0037 lr: 0.02\n",
      "iteration: 73450 loss: 0.0036 lr: 0.02\n",
      "iteration: 73460 loss: 0.0031 lr: 0.02\n",
      "iteration: 73470 loss: 0.0035 lr: 0.02\n",
      "iteration: 73480 loss: 0.0029 lr: 0.02\n",
      "iteration: 73490 loss: 0.0028 lr: 0.02\n",
      "iteration: 73500 loss: 0.0035 lr: 0.02\n",
      "iteration: 73510 loss: 0.0045 lr: 0.02\n",
      "iteration: 73520 loss: 0.0036 lr: 0.02\n",
      "iteration: 73530 loss: 0.0033 lr: 0.02\n",
      "iteration: 73540 loss: 0.0028 lr: 0.02\n",
      "iteration: 73550 loss: 0.0042 lr: 0.02\n",
      "iteration: 73560 loss: 0.0045 lr: 0.02\n",
      "iteration: 73570 loss: 0.0032 lr: 0.02\n",
      "iteration: 73580 loss: 0.0034 lr: 0.02\n",
      "iteration: 73590 loss: 0.0037 lr: 0.02\n",
      "iteration: 73600 loss: 0.0037 lr: 0.02\n",
      "iteration: 73610 loss: 0.0024 lr: 0.02\n",
      "iteration: 73620 loss: 0.0040 lr: 0.02\n",
      "iteration: 73630 loss: 0.0035 lr: 0.02\n",
      "iteration: 73640 loss: 0.0027 lr: 0.02\n",
      "iteration: 73650 loss: 0.0033 lr: 0.02\n",
      "iteration: 73660 loss: 0.0042 lr: 0.02\n",
      "iteration: 73670 loss: 0.0028 lr: 0.02\n",
      "iteration: 73680 loss: 0.0029 lr: 0.02\n",
      "iteration: 73690 loss: 0.0030 lr: 0.02\n",
      "iteration: 73700 loss: 0.0035 lr: 0.02\n",
      "iteration: 73710 loss: 0.0033 lr: 0.02\n",
      "iteration: 73720 loss: 0.0034 lr: 0.02\n",
      "iteration: 73730 loss: 0.0033 lr: 0.02\n",
      "iteration: 73740 loss: 0.0036 lr: 0.02\n",
      "iteration: 73750 loss: 0.0029 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 73760 loss: 0.0034 lr: 0.02\n",
      "iteration: 73770 loss: 0.0033 lr: 0.02\n",
      "iteration: 73780 loss: 0.0030 lr: 0.02\n",
      "iteration: 73790 loss: 0.0040 lr: 0.02\n",
      "iteration: 73800 loss: 0.0040 lr: 0.02\n",
      "iteration: 73810 loss: 0.0032 lr: 0.02\n",
      "iteration: 73820 loss: 0.0028 lr: 0.02\n",
      "iteration: 73830 loss: 0.0038 lr: 0.02\n",
      "iteration: 73840 loss: 0.0037 lr: 0.02\n",
      "iteration: 73850 loss: 0.0032 lr: 0.02\n",
      "iteration: 73860 loss: 0.0040 lr: 0.02\n",
      "iteration: 73870 loss: 0.0035 lr: 0.02\n",
      "iteration: 73880 loss: 0.0031 lr: 0.02\n",
      "iteration: 73890 loss: 0.0035 lr: 0.02\n",
      "iteration: 73900 loss: 0.0029 lr: 0.02\n",
      "iteration: 73910 loss: 0.0034 lr: 0.02\n",
      "iteration: 73920 loss: 0.0038 lr: 0.02\n",
      "iteration: 73930 loss: 0.0037 lr: 0.02\n",
      "iteration: 73940 loss: 0.0034 lr: 0.02\n",
      "iteration: 73950 loss: 0.0040 lr: 0.02\n",
      "iteration: 73960 loss: 0.0033 lr: 0.02\n",
      "iteration: 73970 loss: 0.0033 lr: 0.02\n",
      "iteration: 73980 loss: 0.0037 lr: 0.02\n",
      "iteration: 73990 loss: 0.0038 lr: 0.02\n",
      "iteration: 74000 loss: 0.0031 lr: 0.02\n",
      "iteration: 74010 loss: 0.0042 lr: 0.02\n",
      "iteration: 74020 loss: 0.0034 lr: 0.02\n",
      "iteration: 74030 loss: 0.0026 lr: 0.02\n",
      "iteration: 74040 loss: 0.0039 lr: 0.02\n",
      "iteration: 74050 loss: 0.0039 lr: 0.02\n",
      "iteration: 74060 loss: 0.0031 lr: 0.02\n",
      "iteration: 74070 loss: 0.0041 lr: 0.02\n",
      "iteration: 74080 loss: 0.0029 lr: 0.02\n",
      "iteration: 74090 loss: 0.0036 lr: 0.02\n",
      "iteration: 74100 loss: 0.0034 lr: 0.02\n",
      "iteration: 74110 loss: 0.0028 lr: 0.02\n",
      "iteration: 74120 loss: 0.0042 lr: 0.02\n",
      "iteration: 74130 loss: 0.0038 lr: 0.02\n",
      "iteration: 74140 loss: 0.0031 lr: 0.02\n",
      "iteration: 74150 loss: 0.0033 lr: 0.02\n",
      "iteration: 74160 loss: 0.0026 lr: 0.02\n",
      "iteration: 74170 loss: 0.0035 lr: 0.02\n",
      "iteration: 74180 loss: 0.0036 lr: 0.02\n",
      "iteration: 74190 loss: 0.0049 lr: 0.02\n",
      "iteration: 74200 loss: 0.0041 lr: 0.02\n",
      "iteration: 74210 loss: 0.0040 lr: 0.02\n",
      "iteration: 74220 loss: 0.0045 lr: 0.02\n",
      "iteration: 74230 loss: 0.0035 lr: 0.02\n",
      "iteration: 74240 loss: 0.0037 lr: 0.02\n",
      "iteration: 74250 loss: 0.0038 lr: 0.02\n",
      "iteration: 74260 loss: 0.0037 lr: 0.02\n",
      "iteration: 74270 loss: 0.0031 lr: 0.02\n",
      "iteration: 74280 loss: 0.0032 lr: 0.02\n",
      "iteration: 74290 loss: 0.0030 lr: 0.02\n",
      "iteration: 74300 loss: 0.0038 lr: 0.02\n",
      "iteration: 74310 loss: 0.0031 lr: 0.02\n",
      "iteration: 74320 loss: 0.0035 lr: 0.02\n",
      "iteration: 74330 loss: 0.0026 lr: 0.02\n",
      "iteration: 74340 loss: 0.0035 lr: 0.02\n",
      "iteration: 74350 loss: 0.0048 lr: 0.02\n",
      "iteration: 74360 loss: 0.0032 lr: 0.02\n",
      "iteration: 74370 loss: 0.0037 lr: 0.02\n",
      "iteration: 74380 loss: 0.0038 lr: 0.02\n",
      "iteration: 74390 loss: 0.0039 lr: 0.02\n",
      "iteration: 74400 loss: 0.0038 lr: 0.02\n",
      "iteration: 74410 loss: 0.0032 lr: 0.02\n",
      "iteration: 74420 loss: 0.0024 lr: 0.02\n",
      "iteration: 74430 loss: 0.0033 lr: 0.02\n",
      "iteration: 74440 loss: 0.0036 lr: 0.02\n",
      "iteration: 74450 loss: 0.0029 lr: 0.02\n",
      "iteration: 74460 loss: 0.0029 lr: 0.02\n",
      "iteration: 74470 loss: 0.0032 lr: 0.02\n",
      "iteration: 74480 loss: 0.0038 lr: 0.02\n",
      "iteration: 74490 loss: 0.0038 lr: 0.02\n",
      "iteration: 74500 loss: 0.0034 lr: 0.02\n",
      "iteration: 74510 loss: 0.0040 lr: 0.02\n",
      "iteration: 74520 loss: 0.0029 lr: 0.02\n",
      "iteration: 74530 loss: 0.0028 lr: 0.02\n",
      "iteration: 74540 loss: 0.0044 lr: 0.02\n",
      "iteration: 74550 loss: 0.0025 lr: 0.02\n",
      "iteration: 74560 loss: 0.0028 lr: 0.02\n",
      "iteration: 74570 loss: 0.0029 lr: 0.02\n",
      "iteration: 74580 loss: 0.0032 lr: 0.02\n",
      "iteration: 74590 loss: 0.0029 lr: 0.02\n",
      "iteration: 74600 loss: 0.0032 lr: 0.02\n",
      "iteration: 74610 loss: 0.0029 lr: 0.02\n",
      "iteration: 74620 loss: 0.0033 lr: 0.02\n",
      "iteration: 74630 loss: 0.0032 lr: 0.02\n",
      "iteration: 74640 loss: 0.0029 lr: 0.02\n",
      "iteration: 74650 loss: 0.0027 lr: 0.02\n",
      "iteration: 74660 loss: 0.0027 lr: 0.02\n",
      "iteration: 74670 loss: 0.0031 lr: 0.02\n",
      "iteration: 74680 loss: 0.0036 lr: 0.02\n",
      "iteration: 74690 loss: 0.0032 lr: 0.02\n",
      "iteration: 74700 loss: 0.0043 lr: 0.02\n",
      "iteration: 74710 loss: 0.0048 lr: 0.02\n",
      "iteration: 74720 loss: 0.0031 lr: 0.02\n",
      "iteration: 74730 loss: 0.0035 lr: 0.02\n",
      "iteration: 74740 loss: 0.0030 lr: 0.02\n",
      "iteration: 74750 loss: 0.0038 lr: 0.02\n",
      "iteration: 74760 loss: 0.0035 lr: 0.02\n",
      "iteration: 74770 loss: 0.0039 lr: 0.02\n",
      "iteration: 74780 loss: 0.0038 lr: 0.02\n",
      "iteration: 74790 loss: 0.0033 lr: 0.02\n",
      "iteration: 74800 loss: 0.0040 lr: 0.02\n",
      "iteration: 74810 loss: 0.0032 lr: 0.02\n",
      "iteration: 74820 loss: 0.0026 lr: 0.02\n",
      "iteration: 74830 loss: 0.0035 lr: 0.02\n",
      "iteration: 74840 loss: 0.0029 lr: 0.02\n",
      "iteration: 74850 loss: 0.0036 lr: 0.02\n",
      "iteration: 74860 loss: 0.0037 lr: 0.02\n",
      "iteration: 74870 loss: 0.0039 lr: 0.02\n",
      "iteration: 74880 loss: 0.0028 lr: 0.02\n",
      "iteration: 74890 loss: 0.0034 lr: 0.02\n",
      "iteration: 74900 loss: 0.0034 lr: 0.02\n",
      "iteration: 74910 loss: 0.0029 lr: 0.02\n",
      "iteration: 74920 loss: 0.0034 lr: 0.02\n",
      "iteration: 74930 loss: 0.0030 lr: 0.02\n",
      "iteration: 74940 loss: 0.0025 lr: 0.02\n",
      "iteration: 74950 loss: 0.0031 lr: 0.02\n",
      "iteration: 74960 loss: 0.0033 lr: 0.02\n",
      "iteration: 74970 loss: 0.0032 lr: 0.02\n",
      "iteration: 74980 loss: 0.0030 lr: 0.02\n",
      "iteration: 74990 loss: 0.0035 lr: 0.02\n",
      "iteration: 75000 loss: 0.0029 lr: 0.02\n",
      "iteration: 75010 loss: 0.0034 lr: 0.02\n",
      "iteration: 75020 loss: 0.0028 lr: 0.02\n",
      "iteration: 75030 loss: 0.0030 lr: 0.02\n",
      "iteration: 75040 loss: 0.0030 lr: 0.02\n",
      "iteration: 75050 loss: 0.0034 lr: 0.02\n",
      "iteration: 75060 loss: 0.0030 lr: 0.02\n",
      "iteration: 75070 loss: 0.0033 lr: 0.02\n",
      "iteration: 75080 loss: 0.0031 lr: 0.02\n",
      "iteration: 75090 loss: 0.0034 lr: 0.02\n",
      "iteration: 75100 loss: 0.0031 lr: 0.02\n",
      "iteration: 75110 loss: 0.0041 lr: 0.02\n",
      "iteration: 75120 loss: 0.0030 lr: 0.02\n",
      "iteration: 75130 loss: 0.0035 lr: 0.02\n",
      "iteration: 75140 loss: 0.0039 lr: 0.02\n",
      "iteration: 75150 loss: 0.0033 lr: 0.02\n",
      "iteration: 75160 loss: 0.0030 lr: 0.02\n",
      "iteration: 75170 loss: 0.0030 lr: 0.02\n",
      "iteration: 75180 loss: 0.0040 lr: 0.02\n",
      "iteration: 75190 loss: 0.0038 lr: 0.02\n",
      "iteration: 75200 loss: 0.0028 lr: 0.02\n",
      "iteration: 75210 loss: 0.0041 lr: 0.02\n",
      "iteration: 75220 loss: 0.0038 lr: 0.02\n",
      "iteration: 75230 loss: 0.0027 lr: 0.02\n",
      "iteration: 75240 loss: 0.0031 lr: 0.02\n",
      "iteration: 75250 loss: 0.0042 lr: 0.02\n",
      "iteration: 75260 loss: 0.0034 lr: 0.02\n",
      "iteration: 75270 loss: 0.0034 lr: 0.02\n",
      "iteration: 75280 loss: 0.0030 lr: 0.02\n",
      "iteration: 75290 loss: 0.0038 lr: 0.02\n",
      "iteration: 75300 loss: 0.0038 lr: 0.02\n",
      "iteration: 75310 loss: 0.0034 lr: 0.02\n",
      "iteration: 75320 loss: 0.0032 lr: 0.02\n",
      "iteration: 75330 loss: 0.0032 lr: 0.02\n",
      "iteration: 75340 loss: 0.0029 lr: 0.02\n",
      "iteration: 75350 loss: 0.0041 lr: 0.02\n",
      "iteration: 75360 loss: 0.0029 lr: 0.02\n",
      "iteration: 75370 loss: 0.0031 lr: 0.02\n",
      "iteration: 75380 loss: 0.0033 lr: 0.02\n",
      "iteration: 75390 loss: 0.0029 lr: 0.02\n",
      "iteration: 75400 loss: 0.0028 lr: 0.02\n",
      "iteration: 75410 loss: 0.0032 lr: 0.02\n",
      "iteration: 75420 loss: 0.0035 lr: 0.02\n",
      "iteration: 75430 loss: 0.0038 lr: 0.02\n",
      "iteration: 75440 loss: 0.0033 lr: 0.02\n",
      "iteration: 75450 loss: 0.0034 lr: 0.02\n",
      "iteration: 75460 loss: 0.0039 lr: 0.02\n",
      "iteration: 75470 loss: 0.0035 lr: 0.02\n",
      "iteration: 75480 loss: 0.0038 lr: 0.02\n",
      "iteration: 75490 loss: 0.0041 lr: 0.02\n",
      "iteration: 75500 loss: 0.0034 lr: 0.02\n",
      "iteration: 75510 loss: 0.0027 lr: 0.02\n",
      "iteration: 75520 loss: 0.0025 lr: 0.02\n",
      "iteration: 75530 loss: 0.0031 lr: 0.02\n",
      "iteration: 75540 loss: 0.0043 lr: 0.02\n",
      "iteration: 75550 loss: 0.0034 lr: 0.02\n",
      "iteration: 75560 loss: 0.0038 lr: 0.02\n",
      "iteration: 75570 loss: 0.0033 lr: 0.02\n",
      "iteration: 75580 loss: 0.0029 lr: 0.02\n",
      "iteration: 75590 loss: 0.0032 lr: 0.02\n",
      "iteration: 75600 loss: 0.0036 lr: 0.02\n",
      "iteration: 75610 loss: 0.0028 lr: 0.02\n",
      "iteration: 75620 loss: 0.0031 lr: 0.02\n",
      "iteration: 75630 loss: 0.0032 lr: 0.02\n",
      "iteration: 75640 loss: 0.0026 lr: 0.02\n",
      "iteration: 75650 loss: 0.0025 lr: 0.02\n",
      "iteration: 75660 loss: 0.0029 lr: 0.02\n",
      "iteration: 75670 loss: 0.0029 lr: 0.02\n",
      "iteration: 75680 loss: 0.0036 lr: 0.02\n",
      "iteration: 75690 loss: 0.0031 lr: 0.02\n",
      "iteration: 75700 loss: 0.0030 lr: 0.02\n",
      "iteration: 75710 loss: 0.0034 lr: 0.02\n",
      "iteration: 75720 loss: 0.0036 lr: 0.02\n",
      "iteration: 75730 loss: 0.0031 lr: 0.02\n",
      "iteration: 75740 loss: 0.0025 lr: 0.02\n",
      "iteration: 75750 loss: 0.0031 lr: 0.02\n",
      "iteration: 75760 loss: 0.0038 lr: 0.02\n",
      "iteration: 75770 loss: 0.0033 lr: 0.02\n",
      "iteration: 75780 loss: 0.0041 lr: 0.02\n",
      "iteration: 75790 loss: 0.0034 lr: 0.02\n",
      "iteration: 75800 loss: 0.0031 lr: 0.02\n",
      "iteration: 75810 loss: 0.0041 lr: 0.02\n",
      "iteration: 75820 loss: 0.0025 lr: 0.02\n",
      "iteration: 75830 loss: 0.0039 lr: 0.02\n",
      "iteration: 75840 loss: 0.0035 lr: 0.02\n",
      "iteration: 75850 loss: 0.0024 lr: 0.02\n",
      "iteration: 75860 loss: 0.0062 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 75870 loss: 0.0031 lr: 0.02\n",
      "iteration: 75880 loss: 0.0040 lr: 0.02\n",
      "iteration: 75890 loss: 0.0033 lr: 0.02\n",
      "iteration: 75900 loss: 0.0026 lr: 0.02\n",
      "iteration: 75910 loss: 0.0027 lr: 0.02\n",
      "iteration: 75920 loss: 0.0035 lr: 0.02\n",
      "iteration: 75930 loss: 0.0031 lr: 0.02\n",
      "iteration: 75940 loss: 0.0028 lr: 0.02\n",
      "iteration: 75950 loss: 0.0029 lr: 0.02\n",
      "iteration: 75960 loss: 0.0033 lr: 0.02\n",
      "iteration: 75970 loss: 0.0032 lr: 0.02\n",
      "iteration: 75980 loss: 0.0031 lr: 0.02\n",
      "iteration: 75990 loss: 0.0033 lr: 0.02\n",
      "iteration: 76000 loss: 0.0031 lr: 0.02\n",
      "iteration: 76010 loss: 0.0041 lr: 0.02\n",
      "iteration: 76020 loss: 0.0028 lr: 0.02\n",
      "iteration: 76030 loss: 0.0031 lr: 0.02\n",
      "iteration: 76040 loss: 0.0033 lr: 0.02\n",
      "iteration: 76050 loss: 0.0029 lr: 0.02\n",
      "iteration: 76060 loss: 0.0025 lr: 0.02\n",
      "iteration: 76070 loss: 0.0025 lr: 0.02\n",
      "iteration: 76080 loss: 0.0031 lr: 0.02\n",
      "iteration: 76090 loss: 0.0033 lr: 0.02\n",
      "iteration: 76100 loss: 0.0032 lr: 0.02\n",
      "iteration: 76110 loss: 0.0037 lr: 0.02\n",
      "iteration: 76120 loss: 0.0035 lr: 0.02\n",
      "iteration: 76130 loss: 0.0036 lr: 0.02\n",
      "iteration: 76140 loss: 0.0036 lr: 0.02\n",
      "iteration: 76150 loss: 0.0025 lr: 0.02\n",
      "iteration: 76160 loss: 0.0032 lr: 0.02\n",
      "iteration: 76170 loss: 0.0024 lr: 0.02\n",
      "iteration: 76180 loss: 0.0029 lr: 0.02\n",
      "iteration: 76190 loss: 0.0041 lr: 0.02\n",
      "iteration: 76200 loss: 0.0027 lr: 0.02\n",
      "iteration: 76210 loss: 0.0027 lr: 0.02\n",
      "iteration: 76220 loss: 0.0036 lr: 0.02\n",
      "iteration: 76230 loss: 0.0030 lr: 0.02\n",
      "iteration: 76240 loss: 0.0028 lr: 0.02\n",
      "iteration: 76250 loss: 0.0040 lr: 0.02\n",
      "iteration: 76260 loss: 0.0031 lr: 0.02\n",
      "iteration: 76270 loss: 0.0040 lr: 0.02\n",
      "iteration: 76280 loss: 0.0030 lr: 0.02\n",
      "iteration: 76290 loss: 0.0030 lr: 0.02\n",
      "iteration: 76300 loss: 0.0036 lr: 0.02\n",
      "iteration: 76310 loss: 0.0027 lr: 0.02\n",
      "iteration: 76320 loss: 0.0034 lr: 0.02\n",
      "iteration: 76330 loss: 0.0036 lr: 0.02\n",
      "iteration: 76340 loss: 0.0031 lr: 0.02\n",
      "iteration: 76350 loss: 0.0034 lr: 0.02\n",
      "iteration: 76360 loss: 0.0030 lr: 0.02\n",
      "iteration: 76370 loss: 0.0035 lr: 0.02\n",
      "iteration: 76380 loss: 0.0030 lr: 0.02\n",
      "iteration: 76390 loss: 0.0029 lr: 0.02\n",
      "iteration: 76400 loss: 0.0032 lr: 0.02\n",
      "iteration: 76410 loss: 0.0029 lr: 0.02\n",
      "iteration: 76420 loss: 0.0028 lr: 0.02\n",
      "iteration: 76430 loss: 0.0024 lr: 0.02\n",
      "iteration: 76440 loss: 0.0046 lr: 0.02\n",
      "iteration: 76450 loss: 0.0030 lr: 0.02\n",
      "iteration: 76460 loss: 0.0043 lr: 0.02\n",
      "iteration: 76470 loss: 0.0029 lr: 0.02\n",
      "iteration: 76480 loss: 0.0040 lr: 0.02\n",
      "iteration: 76490 loss: 0.0038 lr: 0.02\n",
      "iteration: 76500 loss: 0.0045 lr: 0.02\n",
      "iteration: 76510 loss: 0.0032 lr: 0.02\n",
      "iteration: 76520 loss: 0.0033 lr: 0.02\n",
      "iteration: 76530 loss: 0.0031 lr: 0.02\n",
      "iteration: 76540 loss: 0.0036 lr: 0.02\n",
      "iteration: 76550 loss: 0.0036 lr: 0.02\n",
      "iteration: 76560 loss: 0.0032 lr: 0.02\n",
      "iteration: 76570 loss: 0.0028 lr: 0.02\n",
      "iteration: 76580 loss: 0.0032 lr: 0.02\n",
      "iteration: 76590 loss: 0.0034 lr: 0.02\n",
      "iteration: 76600 loss: 0.0028 lr: 0.02\n",
      "iteration: 76610 loss: 0.0026 lr: 0.02\n",
      "iteration: 76620 loss: 0.0040 lr: 0.02\n",
      "iteration: 76630 loss: 0.0037 lr: 0.02\n",
      "iteration: 76640 loss: 0.0030 lr: 0.02\n",
      "iteration: 76650 loss: 0.0028 lr: 0.02\n",
      "iteration: 76660 loss: 0.0032 lr: 0.02\n",
      "iteration: 76670 loss: 0.0032 lr: 0.02\n",
      "iteration: 76680 loss: 0.0035 lr: 0.02\n",
      "iteration: 76690 loss: 0.0035 lr: 0.02\n",
      "iteration: 76700 loss: 0.0039 lr: 0.02\n",
      "iteration: 76710 loss: 0.0035 lr: 0.02\n",
      "iteration: 76720 loss: 0.0038 lr: 0.02\n",
      "iteration: 76730 loss: 0.0036 lr: 0.02\n",
      "iteration: 76740 loss: 0.0033 lr: 0.02\n",
      "iteration: 76750 loss: 0.0029 lr: 0.02\n",
      "iteration: 76760 loss: 0.0043 lr: 0.02\n",
      "iteration: 76770 loss: 0.0023 lr: 0.02\n",
      "iteration: 76780 loss: 0.0039 lr: 0.02\n",
      "iteration: 76790 loss: 0.0029 lr: 0.02\n",
      "iteration: 76800 loss: 0.0027 lr: 0.02\n",
      "iteration: 76810 loss: 0.0032 lr: 0.02\n",
      "iteration: 76820 loss: 0.0029 lr: 0.02\n",
      "iteration: 76830 loss: 0.0032 lr: 0.02\n",
      "iteration: 76840 loss: 0.0027 lr: 0.02\n",
      "iteration: 76850 loss: 0.0035 lr: 0.02\n",
      "iteration: 76860 loss: 0.0032 lr: 0.02\n",
      "iteration: 76870 loss: 0.0030 lr: 0.02\n",
      "iteration: 76880 loss: 0.0029 lr: 0.02\n",
      "iteration: 76890 loss: 0.0036 lr: 0.02\n",
      "iteration: 76900 loss: 0.0036 lr: 0.02\n",
      "iteration: 76910 loss: 0.0029 lr: 0.02\n",
      "iteration: 76920 loss: 0.0030 lr: 0.02\n",
      "iteration: 76930 loss: 0.0029 lr: 0.02\n",
      "iteration: 76940 loss: 0.0031 lr: 0.02\n",
      "iteration: 76950 loss: 0.0027 lr: 0.02\n",
      "iteration: 76960 loss: 0.0029 lr: 0.02\n",
      "iteration: 76970 loss: 0.0032 lr: 0.02\n",
      "iteration: 76980 loss: 0.0032 lr: 0.02\n",
      "iteration: 76990 loss: 0.0029 lr: 0.02\n",
      "iteration: 77000 loss: 0.0035 lr: 0.02\n",
      "iteration: 77010 loss: 0.0030 lr: 0.02\n",
      "iteration: 77020 loss: 0.0033 lr: 0.02\n",
      "iteration: 77030 loss: 0.0043 lr: 0.02\n",
      "iteration: 77040 loss: 0.0039 lr: 0.02\n",
      "iteration: 77050 loss: 0.0022 lr: 0.02\n",
      "iteration: 77060 loss: 0.0032 lr: 0.02\n",
      "iteration: 77070 loss: 0.0027 lr: 0.02\n",
      "iteration: 77080 loss: 0.0023 lr: 0.02\n",
      "iteration: 77090 loss: 0.0038 lr: 0.02\n",
      "iteration: 77100 loss: 0.0039 lr: 0.02\n",
      "iteration: 77110 loss: 0.0034 lr: 0.02\n",
      "iteration: 77120 loss: 0.0039 lr: 0.02\n",
      "iteration: 77130 loss: 0.0031 lr: 0.02\n",
      "iteration: 77140 loss: 0.0031 lr: 0.02\n",
      "iteration: 77150 loss: 0.0033 lr: 0.02\n",
      "iteration: 77160 loss: 0.0032 lr: 0.02\n",
      "iteration: 77170 loss: 0.0030 lr: 0.02\n",
      "iteration: 77180 loss: 0.0029 lr: 0.02\n",
      "iteration: 77190 loss: 0.0030 lr: 0.02\n",
      "iteration: 77200 loss: 0.0033 lr: 0.02\n",
      "iteration: 77210 loss: 0.0036 lr: 0.02\n",
      "iteration: 77220 loss: 0.0032 lr: 0.02\n",
      "iteration: 77230 loss: 0.0035 lr: 0.02\n",
      "iteration: 77240 loss: 0.0030 lr: 0.02\n",
      "iteration: 77250 loss: 0.0040 lr: 0.02\n",
      "iteration: 77260 loss: 0.0032 lr: 0.02\n",
      "iteration: 77270 loss: 0.0040 lr: 0.02\n",
      "iteration: 77280 loss: 0.0033 lr: 0.02\n",
      "iteration: 77290 loss: 0.0040 lr: 0.02\n",
      "iteration: 77300 loss: 0.0028 lr: 0.02\n",
      "iteration: 77310 loss: 0.0032 lr: 0.02\n",
      "iteration: 77320 loss: 0.0039 lr: 0.02\n",
      "iteration: 77330 loss: 0.0036 lr: 0.02\n",
      "iteration: 77340 loss: 0.0039 lr: 0.02\n",
      "iteration: 77350 loss: 0.0052 lr: 0.02\n",
      "iteration: 77360 loss: 0.0039 lr: 0.02\n",
      "iteration: 77370 loss: 0.0057 lr: 0.02\n",
      "iteration: 77380 loss: 0.0039 lr: 0.02\n",
      "iteration: 77390 loss: 0.0043 lr: 0.02\n",
      "iteration: 77400 loss: 0.0034 lr: 0.02\n",
      "iteration: 77410 loss: 0.0038 lr: 0.02\n",
      "iteration: 77420 loss: 0.0042 lr: 0.02\n",
      "iteration: 77430 loss: 0.0026 lr: 0.02\n",
      "iteration: 77440 loss: 0.0038 lr: 0.02\n",
      "iteration: 77450 loss: 0.0032 lr: 0.02\n",
      "iteration: 77460 loss: 0.0032 lr: 0.02\n",
      "iteration: 77470 loss: 0.0043 lr: 0.02\n",
      "iteration: 77480 loss: 0.0039 lr: 0.02\n",
      "iteration: 77490 loss: 0.0033 lr: 0.02\n",
      "iteration: 77500 loss: 0.0038 lr: 0.02\n",
      "iteration: 77510 loss: 0.0037 lr: 0.02\n",
      "iteration: 77520 loss: 0.0036 lr: 0.02\n",
      "iteration: 77530 loss: 0.0043 lr: 0.02\n",
      "iteration: 77540 loss: 0.0023 lr: 0.02\n",
      "iteration: 77550 loss: 0.0027 lr: 0.02\n",
      "iteration: 77560 loss: 0.0035 lr: 0.02\n",
      "iteration: 77570 loss: 0.0034 lr: 0.02\n",
      "iteration: 77580 loss: 0.0031 lr: 0.02\n",
      "iteration: 77590 loss: 0.0033 lr: 0.02\n",
      "iteration: 77600 loss: 0.0032 lr: 0.02\n",
      "iteration: 77610 loss: 0.0035 lr: 0.02\n",
      "iteration: 77620 loss: 0.0033 lr: 0.02\n",
      "iteration: 77630 loss: 0.0028 lr: 0.02\n",
      "iteration: 77640 loss: 0.0026 lr: 0.02\n",
      "iteration: 77650 loss: 0.0035 lr: 0.02\n",
      "iteration: 77660 loss: 0.0028 lr: 0.02\n",
      "iteration: 77670 loss: 0.0038 lr: 0.02\n",
      "iteration: 77680 loss: 0.0024 lr: 0.02\n",
      "iteration: 77690 loss: 0.0042 lr: 0.02\n",
      "iteration: 77700 loss: 0.0031 lr: 0.02\n",
      "iteration: 77710 loss: 0.0035 lr: 0.02\n",
      "iteration: 77720 loss: 0.0040 lr: 0.02\n",
      "iteration: 77730 loss: 0.0031 lr: 0.02\n",
      "iteration: 77740 loss: 0.0032 lr: 0.02\n",
      "iteration: 77750 loss: 0.0039 lr: 0.02\n",
      "iteration: 77760 loss: 0.0028 lr: 0.02\n",
      "iteration: 77770 loss: 0.0038 lr: 0.02\n",
      "iteration: 77780 loss: 0.0033 lr: 0.02\n",
      "iteration: 77790 loss: 0.0030 lr: 0.02\n",
      "iteration: 77800 loss: 0.0038 lr: 0.02\n",
      "iteration: 77810 loss: 0.0035 lr: 0.02\n",
      "iteration: 77820 loss: 0.0025 lr: 0.02\n",
      "iteration: 77830 loss: 0.0031 lr: 0.02\n",
      "iteration: 77840 loss: 0.0035 lr: 0.02\n",
      "iteration: 77850 loss: 0.0027 lr: 0.02\n",
      "iteration: 77860 loss: 0.0027 lr: 0.02\n",
      "iteration: 77870 loss: 0.0039 lr: 0.02\n",
      "iteration: 77880 loss: 0.0037 lr: 0.02\n",
      "iteration: 77890 loss: 0.0040 lr: 0.02\n",
      "iteration: 77900 loss: 0.0028 lr: 0.02\n",
      "iteration: 77910 loss: 0.0033 lr: 0.02\n",
      "iteration: 77920 loss: 0.0032 lr: 0.02\n",
      "iteration: 77930 loss: 0.0026 lr: 0.02\n",
      "iteration: 77940 loss: 0.0033 lr: 0.02\n",
      "iteration: 77950 loss: 0.0036 lr: 0.02\n",
      "iteration: 77960 loss: 0.0036 lr: 0.02\n",
      "iteration: 77970 loss: 0.0033 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 77980 loss: 0.0035 lr: 0.02\n",
      "iteration: 77990 loss: 0.0039 lr: 0.02\n",
      "iteration: 78000 loss: 0.0046 lr: 0.02\n",
      "iteration: 78010 loss: 0.0023 lr: 0.02\n",
      "iteration: 78020 loss: 0.0030 lr: 0.02\n",
      "iteration: 78030 loss: 0.0039 lr: 0.02\n",
      "iteration: 78040 loss: 0.0039 lr: 0.02\n",
      "iteration: 78050 loss: 0.0040 lr: 0.02\n",
      "iteration: 78060 loss: 0.0036 lr: 0.02\n",
      "iteration: 78070 loss: 0.0036 lr: 0.02\n",
      "iteration: 78080 loss: 0.0028 lr: 0.02\n",
      "iteration: 78090 loss: 0.0029 lr: 0.02\n",
      "iteration: 78100 loss: 0.0050 lr: 0.02\n",
      "iteration: 78110 loss: 0.0043 lr: 0.02\n",
      "iteration: 78120 loss: 0.0031 lr: 0.02\n",
      "iteration: 78130 loss: 0.0029 lr: 0.02\n",
      "iteration: 78140 loss: 0.0041 lr: 0.02\n",
      "iteration: 78150 loss: 0.0033 lr: 0.02\n",
      "iteration: 78160 loss: 0.0037 lr: 0.02\n",
      "iteration: 78170 loss: 0.0039 lr: 0.02\n",
      "iteration: 78180 loss: 0.0029 lr: 0.02\n",
      "iteration: 78190 loss: 0.0034 lr: 0.02\n",
      "iteration: 78200 loss: 0.0030 lr: 0.02\n",
      "iteration: 78210 loss: 0.0027 lr: 0.02\n",
      "iteration: 78220 loss: 0.0030 lr: 0.02\n",
      "iteration: 78230 loss: 0.0033 lr: 0.02\n",
      "iteration: 78240 loss: 0.0034 lr: 0.02\n",
      "iteration: 78250 loss: 0.0026 lr: 0.02\n",
      "iteration: 78260 loss: 0.0028 lr: 0.02\n",
      "iteration: 78270 loss: 0.0033 lr: 0.02\n",
      "iteration: 78280 loss: 0.0035 lr: 0.02\n",
      "iteration: 78290 loss: 0.0034 lr: 0.02\n",
      "iteration: 78300 loss: 0.0033 lr: 0.02\n",
      "iteration: 78310 loss: 0.0033 lr: 0.02\n",
      "iteration: 78320 loss: 0.0036 lr: 0.02\n",
      "iteration: 78330 loss: 0.0040 lr: 0.02\n",
      "iteration: 78340 loss: 0.0027 lr: 0.02\n",
      "iteration: 78350 loss: 0.0032 lr: 0.02\n",
      "iteration: 78360 loss: 0.0041 lr: 0.02\n",
      "iteration: 78370 loss: 0.0042 lr: 0.02\n",
      "iteration: 78380 loss: 0.0046 lr: 0.02\n",
      "iteration: 78390 loss: 0.0027 lr: 0.02\n",
      "iteration: 78400 loss: 0.0041 lr: 0.02\n",
      "iteration: 78410 loss: 0.0030 lr: 0.02\n",
      "iteration: 78420 loss: 0.0032 lr: 0.02\n",
      "iteration: 78430 loss: 0.0025 lr: 0.02\n",
      "iteration: 78440 loss: 0.0037 lr: 0.02\n",
      "iteration: 78450 loss: 0.0034 lr: 0.02\n",
      "iteration: 78460 loss: 0.0041 lr: 0.02\n",
      "iteration: 78470 loss: 0.0031 lr: 0.02\n",
      "iteration: 78480 loss: 0.0039 lr: 0.02\n",
      "iteration: 78490 loss: 0.0036 lr: 0.02\n",
      "iteration: 78500 loss: 0.0034 lr: 0.02\n",
      "iteration: 78510 loss: 0.0037 lr: 0.02\n",
      "iteration: 78520 loss: 0.0034 lr: 0.02\n",
      "iteration: 78530 loss: 0.0028 lr: 0.02\n",
      "iteration: 78540 loss: 0.0034 lr: 0.02\n",
      "iteration: 78550 loss: 0.0031 lr: 0.02\n",
      "iteration: 78560 loss: 0.0035 lr: 0.02\n",
      "iteration: 78570 loss: 0.0034 lr: 0.02\n",
      "iteration: 78580 loss: 0.0035 lr: 0.02\n",
      "iteration: 78590 loss: 0.0035 lr: 0.02\n",
      "iteration: 78600 loss: 0.0033 lr: 0.02\n",
      "iteration: 78610 loss: 0.0044 lr: 0.02\n",
      "iteration: 78620 loss: 0.0039 lr: 0.02\n",
      "iteration: 78630 loss: 0.0039 lr: 0.02\n",
      "iteration: 78640 loss: 0.0035 lr: 0.02\n",
      "iteration: 78650 loss: 0.0028 lr: 0.02\n",
      "iteration: 78660 loss: 0.0033 lr: 0.02\n",
      "iteration: 78670 loss: 0.0037 lr: 0.02\n",
      "iteration: 78680 loss: 0.0047 lr: 0.02\n",
      "iteration: 78690 loss: 0.0028 lr: 0.02\n",
      "iteration: 78700 loss: 0.0033 lr: 0.02\n",
      "iteration: 78710 loss: 0.0033 lr: 0.02\n",
      "iteration: 78720 loss: 0.0036 lr: 0.02\n",
      "iteration: 78730 loss: 0.0034 lr: 0.02\n",
      "iteration: 78740 loss: 0.0030 lr: 0.02\n",
      "iteration: 78750 loss: 0.0030 lr: 0.02\n",
      "iteration: 78760 loss: 0.0035 lr: 0.02\n",
      "iteration: 78770 loss: 0.0029 lr: 0.02\n",
      "iteration: 78780 loss: 0.0034 lr: 0.02\n",
      "iteration: 78790 loss: 0.0033 lr: 0.02\n",
      "iteration: 78800 loss: 0.0036 lr: 0.02\n",
      "iteration: 78810 loss: 0.0029 lr: 0.02\n",
      "iteration: 78820 loss: 0.0030 lr: 0.02\n",
      "iteration: 78830 loss: 0.0039 lr: 0.02\n",
      "iteration: 78840 loss: 0.0026 lr: 0.02\n",
      "iteration: 78850 loss: 0.0041 lr: 0.02\n",
      "iteration: 78860 loss: 0.0041 lr: 0.02\n",
      "iteration: 78870 loss: 0.0033 lr: 0.02\n",
      "iteration: 78880 loss: 0.0026 lr: 0.02\n",
      "iteration: 78890 loss: 0.0034 lr: 0.02\n",
      "iteration: 78900 loss: 0.0044 lr: 0.02\n",
      "iteration: 78910 loss: 0.0030 lr: 0.02\n",
      "iteration: 78920 loss: 0.0038 lr: 0.02\n",
      "iteration: 78930 loss: 0.0035 lr: 0.02\n",
      "iteration: 78940 loss: 0.0042 lr: 0.02\n",
      "iteration: 78950 loss: 0.0039 lr: 0.02\n",
      "iteration: 78960 loss: 0.0033 lr: 0.02\n",
      "iteration: 78970 loss: 0.0036 lr: 0.02\n",
      "iteration: 78980 loss: 0.0037 lr: 0.02\n",
      "iteration: 78990 loss: 0.0031 lr: 0.02\n",
      "iteration: 79000 loss: 0.0036 lr: 0.02\n",
      "iteration: 79010 loss: 0.0035 lr: 0.02\n",
      "iteration: 79020 loss: 0.0036 lr: 0.02\n",
      "iteration: 79030 loss: 0.0024 lr: 0.02\n",
      "iteration: 79040 loss: 0.0027 lr: 0.02\n",
      "iteration: 79050 loss: 0.0031 lr: 0.02\n",
      "iteration: 79060 loss: 0.0030 lr: 0.02\n",
      "iteration: 79070 loss: 0.0027 lr: 0.02\n",
      "iteration: 79080 loss: 0.0031 lr: 0.02\n",
      "iteration: 79090 loss: 0.0026 lr: 0.02\n",
      "iteration: 79100 loss: 0.0029 lr: 0.02\n",
      "iteration: 79110 loss: 0.0038 lr: 0.02\n",
      "iteration: 79120 loss: 0.0037 lr: 0.02\n",
      "iteration: 79130 loss: 0.0032 lr: 0.02\n",
      "iteration: 79140 loss: 0.0034 lr: 0.02\n",
      "iteration: 79150 loss: 0.0027 lr: 0.02\n",
      "iteration: 79160 loss: 0.0030 lr: 0.02\n",
      "iteration: 79170 loss: 0.0031 lr: 0.02\n",
      "iteration: 79180 loss: 0.0030 lr: 0.02\n",
      "iteration: 79190 loss: 0.0042 lr: 0.02\n",
      "iteration: 79200 loss: 0.0040 lr: 0.02\n",
      "iteration: 79210 loss: 0.0031 lr: 0.02\n",
      "iteration: 79220 loss: 0.0034 lr: 0.02\n",
      "iteration: 79230 loss: 0.0039 lr: 0.02\n",
      "iteration: 79240 loss: 0.0040 lr: 0.02\n",
      "iteration: 79250 loss: 0.0039 lr: 0.02\n",
      "iteration: 79260 loss: 0.0030 lr: 0.02\n",
      "iteration: 79270 loss: 0.0026 lr: 0.02\n",
      "iteration: 79280 loss: 0.0033 lr: 0.02\n",
      "iteration: 79290 loss: 0.0035 lr: 0.02\n",
      "iteration: 79300 loss: 0.0039 lr: 0.02\n",
      "iteration: 79310 loss: 0.0032 lr: 0.02\n",
      "iteration: 79320 loss: 0.0031 lr: 0.02\n",
      "iteration: 79330 loss: 0.0029 lr: 0.02\n",
      "iteration: 79340 loss: 0.0032 lr: 0.02\n",
      "iteration: 79350 loss: 0.0030 lr: 0.02\n",
      "iteration: 79360 loss: 0.0030 lr: 0.02\n",
      "iteration: 79370 loss: 0.0034 lr: 0.02\n",
      "iteration: 79380 loss: 0.0024 lr: 0.02\n",
      "iteration: 79390 loss: 0.0031 lr: 0.02\n",
      "iteration: 79400 loss: 0.0035 lr: 0.02\n",
      "iteration: 79410 loss: 0.0032 lr: 0.02\n",
      "iteration: 79420 loss: 0.0030 lr: 0.02\n",
      "iteration: 79430 loss: 0.0029 lr: 0.02\n",
      "iteration: 79440 loss: 0.0029 lr: 0.02\n",
      "iteration: 79450 loss: 0.0033 lr: 0.02\n",
      "iteration: 79460 loss: 0.0045 lr: 0.02\n",
      "iteration: 79470 loss: 0.0027 lr: 0.02\n",
      "iteration: 79480 loss: 0.0034 lr: 0.02\n",
      "iteration: 79490 loss: 0.0032 lr: 0.02\n",
      "iteration: 79500 loss: 0.0033 lr: 0.02\n",
      "iteration: 79510 loss: 0.0030 lr: 0.02\n",
      "iteration: 79520 loss: 0.0027 lr: 0.02\n",
      "iteration: 79530 loss: 0.0041 lr: 0.02\n",
      "iteration: 79540 loss: 0.0039 lr: 0.02\n",
      "iteration: 79550 loss: 0.0032 lr: 0.02\n",
      "iteration: 79560 loss: 0.0033 lr: 0.02\n",
      "iteration: 79570 loss: 0.0031 lr: 0.02\n",
      "iteration: 79580 loss: 0.0036 lr: 0.02\n",
      "iteration: 79590 loss: 0.0030 lr: 0.02\n",
      "iteration: 79600 loss: 0.0036 lr: 0.02\n",
      "iteration: 79610 loss: 0.0029 lr: 0.02\n",
      "iteration: 79620 loss: 0.0031 lr: 0.02\n",
      "iteration: 79630 loss: 0.0034 lr: 0.02\n",
      "iteration: 79640 loss: 0.0028 lr: 0.02\n",
      "iteration: 79650 loss: 0.0042 lr: 0.02\n",
      "iteration: 79660 loss: 0.0032 lr: 0.02\n",
      "iteration: 79670 loss: 0.0036 lr: 0.02\n",
      "iteration: 79680 loss: 0.0029 lr: 0.02\n",
      "iteration: 79690 loss: 0.0031 lr: 0.02\n",
      "iteration: 79700 loss: 0.0030 lr: 0.02\n",
      "iteration: 79710 loss: 0.0027 lr: 0.02\n",
      "iteration: 79720 loss: 0.0033 lr: 0.02\n",
      "iteration: 79730 loss: 0.0031 lr: 0.02\n",
      "iteration: 79740 loss: 0.0029 lr: 0.02\n",
      "iteration: 79750 loss: 0.0035 lr: 0.02\n",
      "iteration: 79760 loss: 0.0038 lr: 0.02\n",
      "iteration: 79770 loss: 0.0032 lr: 0.02\n",
      "iteration: 79780 loss: 0.0031 lr: 0.02\n",
      "iteration: 79790 loss: 0.0029 lr: 0.02\n",
      "iteration: 79800 loss: 0.0032 lr: 0.02\n",
      "iteration: 79810 loss: 0.0030 lr: 0.02\n",
      "iteration: 79820 loss: 0.0039 lr: 0.02\n",
      "iteration: 79830 loss: 0.0029 lr: 0.02\n",
      "iteration: 79840 loss: 0.0025 lr: 0.02\n",
      "iteration: 79850 loss: 0.0029 lr: 0.02\n",
      "iteration: 79860 loss: 0.0027 lr: 0.02\n",
      "iteration: 79870 loss: 0.0025 lr: 0.02\n",
      "iteration: 79880 loss: 0.0030 lr: 0.02\n",
      "iteration: 79890 loss: 0.0039 lr: 0.02\n",
      "iteration: 79900 loss: 0.0026 lr: 0.02\n",
      "iteration: 79910 loss: 0.0039 lr: 0.02\n",
      "iteration: 79920 loss: 0.0034 lr: 0.02\n",
      "iteration: 79930 loss: 0.0033 lr: 0.02\n",
      "iteration: 79940 loss: 0.0032 lr: 0.02\n",
      "iteration: 79950 loss: 0.0033 lr: 0.02\n",
      "iteration: 79960 loss: 0.0031 lr: 0.02\n",
      "iteration: 79970 loss: 0.0029 lr: 0.02\n",
      "iteration: 79980 loss: 0.0037 lr: 0.02\n",
      "iteration: 79990 loss: 0.0030 lr: 0.02\n",
      "iteration: 80000 loss: 0.0029 lr: 0.02\n",
      "iteration: 80010 loss: 0.0033 lr: 0.02\n",
      "iteration: 80020 loss: 0.0039 lr: 0.02\n",
      "iteration: 80030 loss: 0.0037 lr: 0.02\n",
      "iteration: 80040 loss: 0.0029 lr: 0.02\n",
      "iteration: 80050 loss: 0.0032 lr: 0.02\n",
      "iteration: 80060 loss: 0.0035 lr: 0.02\n",
      "iteration: 80070 loss: 0.0028 lr: 0.02\n",
      "iteration: 80080 loss: 0.0034 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 80090 loss: 0.0039 lr: 0.02\n",
      "iteration: 80100 loss: 0.0035 lr: 0.02\n",
      "iteration: 80110 loss: 0.0035 lr: 0.02\n",
      "iteration: 80120 loss: 0.0031 lr: 0.02\n",
      "iteration: 80130 loss: 0.0041 lr: 0.02\n",
      "iteration: 80140 loss: 0.0034 lr: 0.02\n",
      "iteration: 80150 loss: 0.0033 lr: 0.02\n",
      "iteration: 80160 loss: 0.0025 lr: 0.02\n",
      "iteration: 80170 loss: 0.0028 lr: 0.02\n",
      "iteration: 80180 loss: 0.0031 lr: 0.02\n",
      "iteration: 80190 loss: 0.0030 lr: 0.02\n",
      "iteration: 80200 loss: 0.0024 lr: 0.02\n",
      "iteration: 80210 loss: 0.0028 lr: 0.02\n",
      "iteration: 80220 loss: 0.0038 lr: 0.02\n",
      "iteration: 80230 loss: 0.0040 lr: 0.02\n",
      "iteration: 80240 loss: 0.0028 lr: 0.02\n",
      "iteration: 80250 loss: 0.0041 lr: 0.02\n",
      "iteration: 80260 loss: 0.0025 lr: 0.02\n",
      "iteration: 80270 loss: 0.0033 lr: 0.02\n",
      "iteration: 80280 loss: 0.0031 lr: 0.02\n",
      "iteration: 80290 loss: 0.0036 lr: 0.02\n",
      "iteration: 80300 loss: 0.0030 lr: 0.02\n",
      "iteration: 80310 loss: 0.0038 lr: 0.02\n",
      "iteration: 80320 loss: 0.0029 lr: 0.02\n",
      "iteration: 80330 loss: 0.0024 lr: 0.02\n",
      "iteration: 80340 loss: 0.0032 lr: 0.02\n",
      "iteration: 80350 loss: 0.0037 lr: 0.02\n",
      "iteration: 80360 loss: 0.0032 lr: 0.02\n",
      "iteration: 80370 loss: 0.0026 lr: 0.02\n",
      "iteration: 80380 loss: 0.0029 lr: 0.02\n",
      "iteration: 80390 loss: 0.0032 lr: 0.02\n",
      "iteration: 80400 loss: 0.0031 lr: 0.02\n",
      "iteration: 80410 loss: 0.0031 lr: 0.02\n",
      "iteration: 80420 loss: 0.0031 lr: 0.02\n",
      "iteration: 80430 loss: 0.0034 lr: 0.02\n",
      "iteration: 80440 loss: 0.0037 lr: 0.02\n",
      "iteration: 80450 loss: 0.0034 lr: 0.02\n",
      "iteration: 80460 loss: 0.0027 lr: 0.02\n",
      "iteration: 80470 loss: 0.0038 lr: 0.02\n",
      "iteration: 80480 loss: 0.0033 lr: 0.02\n",
      "iteration: 80490 loss: 0.0028 lr: 0.02\n",
      "iteration: 80500 loss: 0.0025 lr: 0.02\n",
      "iteration: 80510 loss: 0.0034 lr: 0.02\n",
      "iteration: 80520 loss: 0.0038 lr: 0.02\n",
      "iteration: 80530 loss: 0.0028 lr: 0.02\n",
      "iteration: 80540 loss: 0.0040 lr: 0.02\n",
      "iteration: 80550 loss: 0.0039 lr: 0.02\n",
      "iteration: 80560 loss: 0.0039 lr: 0.02\n",
      "iteration: 80570 loss: 0.0040 lr: 0.02\n",
      "iteration: 80580 loss: 0.0037 lr: 0.02\n",
      "iteration: 80590 loss: 0.0034 lr: 0.02\n",
      "iteration: 80600 loss: 0.0037 lr: 0.02\n",
      "iteration: 80610 loss: 0.0033 lr: 0.02\n",
      "iteration: 80620 loss: 0.0033 lr: 0.02\n",
      "iteration: 80630 loss: 0.0029 lr: 0.02\n",
      "iteration: 80640 loss: 0.0036 lr: 0.02\n",
      "iteration: 80650 loss: 0.0027 lr: 0.02\n",
      "iteration: 80660 loss: 0.0023 lr: 0.02\n",
      "iteration: 80670 loss: 0.0026 lr: 0.02\n",
      "iteration: 80680 loss: 0.0035 lr: 0.02\n",
      "iteration: 80690 loss: 0.0032 lr: 0.02\n",
      "iteration: 80700 loss: 0.0031 lr: 0.02\n",
      "iteration: 80710 loss: 0.0036 lr: 0.02\n",
      "iteration: 80720 loss: 0.0031 lr: 0.02\n",
      "iteration: 80730 loss: 0.0031 lr: 0.02\n",
      "iteration: 80740 loss: 0.0036 lr: 0.02\n",
      "iteration: 80750 loss: 0.0027 lr: 0.02\n",
      "iteration: 80760 loss: 0.0030 lr: 0.02\n",
      "iteration: 80770 loss: 0.0026 lr: 0.02\n",
      "iteration: 80780 loss: 0.0037 lr: 0.02\n",
      "iteration: 80790 loss: 0.0029 lr: 0.02\n",
      "iteration: 80800 loss: 0.0032 lr: 0.02\n",
      "iteration: 80810 loss: 0.0027 lr: 0.02\n",
      "iteration: 80820 loss: 0.0042 lr: 0.02\n",
      "iteration: 80830 loss: 0.0028 lr: 0.02\n",
      "iteration: 80840 loss: 0.0032 lr: 0.02\n",
      "iteration: 80850 loss: 0.0024 lr: 0.02\n",
      "iteration: 80860 loss: 0.0034 lr: 0.02\n",
      "iteration: 80870 loss: 0.0035 lr: 0.02\n",
      "iteration: 80880 loss: 0.0037 lr: 0.02\n",
      "iteration: 80890 loss: 0.0030 lr: 0.02\n",
      "iteration: 80900 loss: 0.0028 lr: 0.02\n",
      "iteration: 80910 loss: 0.0033 lr: 0.02\n",
      "iteration: 80920 loss: 0.0031 lr: 0.02\n",
      "iteration: 80930 loss: 0.0022 lr: 0.02\n",
      "iteration: 80940 loss: 0.0025 lr: 0.02\n",
      "iteration: 80950 loss: 0.0032 lr: 0.02\n",
      "iteration: 80960 loss: 0.0028 lr: 0.02\n",
      "iteration: 80970 loss: 0.0042 lr: 0.02\n",
      "iteration: 80980 loss: 0.0034 lr: 0.02\n",
      "iteration: 80990 loss: 0.0039 lr: 0.02\n",
      "iteration: 81000 loss: 0.0038 lr: 0.02\n",
      "iteration: 81010 loss: 0.0029 lr: 0.02\n",
      "iteration: 81020 loss: 0.0033 lr: 0.02\n",
      "iteration: 81030 loss: 0.0028 lr: 0.02\n",
      "iteration: 81040 loss: 0.0036 lr: 0.02\n",
      "iteration: 81050 loss: 0.0027 lr: 0.02\n",
      "iteration: 81060 loss: 0.0035 lr: 0.02\n",
      "iteration: 81070 loss: 0.0031 lr: 0.02\n",
      "iteration: 81080 loss: 0.0026 lr: 0.02\n",
      "iteration: 81090 loss: 0.0033 lr: 0.02\n",
      "iteration: 81100 loss: 0.0036 lr: 0.02\n",
      "iteration: 81110 loss: 0.0028 lr: 0.02\n",
      "iteration: 81120 loss: 0.0034 lr: 0.02\n",
      "iteration: 81130 loss: 0.0039 lr: 0.02\n",
      "iteration: 81140 loss: 0.0032 lr: 0.02\n",
      "iteration: 81150 loss: 0.0032 lr: 0.02\n",
      "iteration: 81160 loss: 0.0034 lr: 0.02\n",
      "iteration: 81170 loss: 0.0030 lr: 0.02\n",
      "iteration: 81180 loss: 0.0034 lr: 0.02\n",
      "iteration: 81190 loss: 0.0038 lr: 0.02\n",
      "iteration: 81200 loss: 0.0038 lr: 0.02\n",
      "iteration: 81210 loss: 0.0032 lr: 0.02\n",
      "iteration: 81220 loss: 0.0038 lr: 0.02\n",
      "iteration: 81230 loss: 0.0030 lr: 0.02\n",
      "iteration: 81240 loss: 0.0035 lr: 0.02\n",
      "iteration: 81250 loss: 0.0036 lr: 0.02\n",
      "iteration: 81260 loss: 0.0033 lr: 0.02\n",
      "iteration: 81270 loss: 0.0040 lr: 0.02\n",
      "iteration: 81280 loss: 0.0036 lr: 0.02\n",
      "iteration: 81290 loss: 0.0031 lr: 0.02\n",
      "iteration: 81300 loss: 0.0029 lr: 0.02\n",
      "iteration: 81310 loss: 0.0040 lr: 0.02\n",
      "iteration: 81320 loss: 0.0031 lr: 0.02\n",
      "iteration: 81330 loss: 0.0026 lr: 0.02\n",
      "iteration: 81340 loss: 0.0037 lr: 0.02\n",
      "iteration: 81350 loss: 0.0027 lr: 0.02\n",
      "iteration: 81360 loss: 0.0038 lr: 0.02\n",
      "iteration: 81370 loss: 0.0034 lr: 0.02\n",
      "iteration: 81380 loss: 0.0039 lr: 0.02\n",
      "iteration: 81390 loss: 0.0031 lr: 0.02\n",
      "iteration: 81400 loss: 0.0031 lr: 0.02\n",
      "iteration: 81410 loss: 0.0029 lr: 0.02\n",
      "iteration: 81420 loss: 0.0034 lr: 0.02\n",
      "iteration: 81430 loss: 0.0025 lr: 0.02\n",
      "iteration: 81440 loss: 0.0026 lr: 0.02\n",
      "iteration: 81450 loss: 0.0032 lr: 0.02\n",
      "iteration: 81460 loss: 0.0027 lr: 0.02\n",
      "iteration: 81470 loss: 0.0031 lr: 0.02\n",
      "iteration: 81480 loss: 0.0031 lr: 0.02\n",
      "iteration: 81490 loss: 0.0032 lr: 0.02\n",
      "iteration: 81500 loss: 0.0035 lr: 0.02\n",
      "iteration: 81510 loss: 0.0028 lr: 0.02\n",
      "iteration: 81520 loss: 0.0032 lr: 0.02\n",
      "iteration: 81530 loss: 0.0026 lr: 0.02\n",
      "iteration: 81540 loss: 0.0024 lr: 0.02\n",
      "iteration: 81550 loss: 0.0028 lr: 0.02\n",
      "iteration: 81560 loss: 0.0032 lr: 0.02\n",
      "iteration: 81570 loss: 0.0030 lr: 0.02\n",
      "iteration: 81580 loss: 0.0040 lr: 0.02\n",
      "iteration: 81590 loss: 0.0031 lr: 0.02\n",
      "iteration: 81600 loss: 0.0033 lr: 0.02\n",
      "iteration: 81610 loss: 0.0028 lr: 0.02\n",
      "iteration: 81620 loss: 0.0028 lr: 0.02\n",
      "iteration: 81630 loss: 0.0026 lr: 0.02\n",
      "iteration: 81640 loss: 0.0029 lr: 0.02\n",
      "iteration: 81650 loss: 0.0033 lr: 0.02\n",
      "iteration: 81660 loss: 0.0026 lr: 0.02\n",
      "iteration: 81670 loss: 0.0026 lr: 0.02\n",
      "iteration: 81680 loss: 0.0030 lr: 0.02\n",
      "iteration: 81690 loss: 0.0028 lr: 0.02\n",
      "iteration: 81700 loss: 0.0036 lr: 0.02\n",
      "iteration: 81710 loss: 0.0030 lr: 0.02\n",
      "iteration: 81720 loss: 0.0038 lr: 0.02\n",
      "iteration: 81730 loss: 0.0026 lr: 0.02\n",
      "iteration: 81740 loss: 0.0034 lr: 0.02\n",
      "iteration: 81750 loss: 0.0039 lr: 0.02\n",
      "iteration: 81760 loss: 0.0027 lr: 0.02\n",
      "iteration: 81770 loss: 0.0028 lr: 0.02\n",
      "iteration: 81780 loss: 0.0030 lr: 0.02\n",
      "iteration: 81790 loss: 0.0036 lr: 0.02\n",
      "iteration: 81800 loss: 0.0027 lr: 0.02\n",
      "iteration: 81810 loss: 0.0035 lr: 0.02\n",
      "iteration: 81820 loss: 0.0034 lr: 0.02\n",
      "iteration: 81830 loss: 0.0033 lr: 0.02\n",
      "iteration: 81840 loss: 0.0041 lr: 0.02\n",
      "iteration: 81850 loss: 0.0033 lr: 0.02\n",
      "iteration: 81860 loss: 0.0035 lr: 0.02\n",
      "iteration: 81870 loss: 0.0033 lr: 0.02\n",
      "iteration: 81880 loss: 0.0033 lr: 0.02\n",
      "iteration: 81890 loss: 0.0029 lr: 0.02\n",
      "iteration: 81900 loss: 0.0033 lr: 0.02\n",
      "iteration: 81910 loss: 0.0026 lr: 0.02\n",
      "iteration: 81920 loss: 0.0030 lr: 0.02\n",
      "iteration: 81930 loss: 0.0028 lr: 0.02\n",
      "iteration: 81940 loss: 0.0025 lr: 0.02\n",
      "iteration: 81950 loss: 0.0030 lr: 0.02\n",
      "iteration: 81960 loss: 0.0026 lr: 0.02\n",
      "iteration: 81970 loss: 0.0031 lr: 0.02\n",
      "iteration: 81980 loss: 0.0032 lr: 0.02\n",
      "iteration: 81990 loss: 0.0035 lr: 0.02\n",
      "iteration: 82000 loss: 0.0032 lr: 0.02\n",
      "iteration: 82010 loss: 0.0029 lr: 0.02\n",
      "iteration: 82020 loss: 0.0030 lr: 0.02\n",
      "iteration: 82030 loss: 0.0025 lr: 0.02\n",
      "iteration: 82040 loss: 0.0055 lr: 0.02\n",
      "iteration: 82050 loss: 0.0024 lr: 0.02\n",
      "iteration: 82060 loss: 0.0035 lr: 0.02\n",
      "iteration: 82070 loss: 0.0030 lr: 0.02\n",
      "iteration: 82080 loss: 0.0039 lr: 0.02\n",
      "iteration: 82090 loss: 0.0037 lr: 0.02\n",
      "iteration: 82100 loss: 0.0035 lr: 0.02\n",
      "iteration: 82110 loss: 0.0035 lr: 0.02\n",
      "iteration: 82120 loss: 0.0035 lr: 0.02\n",
      "iteration: 82130 loss: 0.0035 lr: 0.02\n",
      "iteration: 82140 loss: 0.0034 lr: 0.02\n",
      "iteration: 82150 loss: 0.0035 lr: 0.02\n",
      "iteration: 82160 loss: 0.0033 lr: 0.02\n",
      "iteration: 82170 loss: 0.0032 lr: 0.02\n",
      "iteration: 82180 loss: 0.0037 lr: 0.02\n",
      "iteration: 82190 loss: 0.0024 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 82200 loss: 0.0029 lr: 0.02\n",
      "iteration: 82210 loss: 0.0029 lr: 0.02\n",
      "iteration: 82220 loss: 0.0032 lr: 0.02\n",
      "iteration: 82230 loss: 0.0033 lr: 0.02\n",
      "iteration: 82240 loss: 0.0033 lr: 0.02\n",
      "iteration: 82250 loss: 0.0032 lr: 0.02\n",
      "iteration: 82260 loss: 0.0027 lr: 0.02\n",
      "iteration: 82270 loss: 0.0031 lr: 0.02\n",
      "iteration: 82280 loss: 0.0028 lr: 0.02\n",
      "iteration: 82290 loss: 0.0028 lr: 0.02\n",
      "iteration: 82300 loss: 0.0031 lr: 0.02\n",
      "iteration: 82310 loss: 0.0027 lr: 0.02\n",
      "iteration: 82320 loss: 0.0029 lr: 0.02\n",
      "iteration: 82330 loss: 0.0034 lr: 0.02\n",
      "iteration: 82340 loss: 0.0030 lr: 0.02\n",
      "iteration: 82350 loss: 0.0027 lr: 0.02\n",
      "iteration: 82360 loss: 0.0026 lr: 0.02\n",
      "iteration: 82370 loss: 0.0035 lr: 0.02\n",
      "iteration: 82380 loss: 0.0041 lr: 0.02\n",
      "iteration: 82390 loss: 0.0030 lr: 0.02\n",
      "iteration: 82400 loss: 0.0036 lr: 0.02\n",
      "iteration: 82410 loss: 0.0037 lr: 0.02\n",
      "iteration: 82420 loss: 0.0029 lr: 0.02\n",
      "iteration: 82430 loss: 0.0034 lr: 0.02\n",
      "iteration: 82440 loss: 0.0030 lr: 0.02\n",
      "iteration: 82450 loss: 0.0032 lr: 0.02\n",
      "iteration: 82460 loss: 0.0035 lr: 0.02\n",
      "iteration: 82470 loss: 0.0032 lr: 0.02\n",
      "iteration: 82480 loss: 0.0028 lr: 0.02\n",
      "iteration: 82490 loss: 0.0032 lr: 0.02\n",
      "iteration: 82500 loss: 0.0031 lr: 0.02\n",
      "iteration: 82510 loss: 0.0040 lr: 0.02\n",
      "iteration: 82520 loss: 0.0031 lr: 0.02\n",
      "iteration: 82530 loss: 0.0028 lr: 0.02\n",
      "iteration: 82540 loss: 0.0037 lr: 0.02\n",
      "iteration: 82550 loss: 0.0033 lr: 0.02\n",
      "iteration: 82560 loss: 0.0032 lr: 0.02\n",
      "iteration: 82570 loss: 0.0031 lr: 0.02\n",
      "iteration: 82580 loss: 0.0034 lr: 0.02\n",
      "iteration: 82590 loss: 0.0035 lr: 0.02\n",
      "iteration: 82600 loss: 0.0034 lr: 0.02\n",
      "iteration: 82610 loss: 0.0035 lr: 0.02\n",
      "iteration: 82620 loss: 0.0028 lr: 0.02\n",
      "iteration: 82630 loss: 0.0028 lr: 0.02\n",
      "iteration: 82640 loss: 0.0032 lr: 0.02\n",
      "iteration: 82650 loss: 0.0036 lr: 0.02\n",
      "iteration: 82660 loss: 0.0029 lr: 0.02\n",
      "iteration: 82670 loss: 0.0031 lr: 0.02\n",
      "iteration: 82680 loss: 0.0028 lr: 0.02\n",
      "iteration: 82690 loss: 0.0024 lr: 0.02\n",
      "iteration: 82700 loss: 0.0035 lr: 0.02\n",
      "iteration: 82710 loss: 0.0031 lr: 0.02\n",
      "iteration: 82720 loss: 0.0034 lr: 0.02\n",
      "iteration: 82730 loss: 0.0032 lr: 0.02\n",
      "iteration: 82740 loss: 0.0036 lr: 0.02\n",
      "iteration: 82750 loss: 0.0022 lr: 0.02\n",
      "iteration: 82760 loss: 0.0028 lr: 0.02\n",
      "iteration: 82770 loss: 0.0043 lr: 0.02\n",
      "iteration: 82780 loss: 0.0032 lr: 0.02\n",
      "iteration: 82790 loss: 0.0026 lr: 0.02\n",
      "iteration: 82800 loss: 0.0030 lr: 0.02\n",
      "iteration: 82810 loss: 0.0029 lr: 0.02\n",
      "iteration: 82820 loss: 0.0040 lr: 0.02\n",
      "iteration: 82830 loss: 0.0027 lr: 0.02\n",
      "iteration: 82840 loss: 0.0031 lr: 0.02\n",
      "iteration: 82850 loss: 0.0026 lr: 0.02\n",
      "iteration: 82860 loss: 0.0025 lr: 0.02\n",
      "iteration: 82870 loss: 0.0039 lr: 0.02\n",
      "iteration: 82880 loss: 0.0028 lr: 0.02\n",
      "iteration: 82890 loss: 0.0030 lr: 0.02\n",
      "iteration: 82900 loss: 0.0028 lr: 0.02\n",
      "iteration: 82910 loss: 0.0031 lr: 0.02\n",
      "iteration: 82920 loss: 0.0029 lr: 0.02\n",
      "iteration: 82930 loss: 0.0031 lr: 0.02\n",
      "iteration: 82940 loss: 0.0036 lr: 0.02\n",
      "iteration: 82950 loss: 0.0038 lr: 0.02\n",
      "iteration: 82960 loss: 0.0036 lr: 0.02\n",
      "iteration: 82970 loss: 0.0030 lr: 0.02\n",
      "iteration: 82980 loss: 0.0031 lr: 0.02\n",
      "iteration: 82990 loss: 0.0030 lr: 0.02\n",
      "iteration: 83000 loss: 0.0027 lr: 0.02\n",
      "iteration: 83010 loss: 0.0028 lr: 0.02\n",
      "iteration: 83020 loss: 0.0032 lr: 0.02\n",
      "iteration: 83030 loss: 0.0042 lr: 0.02\n",
      "iteration: 83040 loss: 0.0025 lr: 0.02\n",
      "iteration: 83050 loss: 0.0030 lr: 0.02\n",
      "iteration: 83060 loss: 0.0042 lr: 0.02\n",
      "iteration: 83070 loss: 0.0031 lr: 0.02\n",
      "iteration: 83080 loss: 0.0039 lr: 0.02\n",
      "iteration: 83090 loss: 0.0033 lr: 0.02\n",
      "iteration: 83100 loss: 0.0034 lr: 0.02\n",
      "iteration: 83110 loss: 0.0039 lr: 0.02\n",
      "iteration: 83120 loss: 0.0041 lr: 0.02\n",
      "iteration: 83130 loss: 0.0034 lr: 0.02\n",
      "iteration: 83140 loss: 0.0032 lr: 0.02\n",
      "iteration: 83150 loss: 0.0038 lr: 0.02\n",
      "iteration: 83160 loss: 0.0033 lr: 0.02\n",
      "iteration: 83170 loss: 0.0030 lr: 0.02\n",
      "iteration: 83180 loss: 0.0035 lr: 0.02\n",
      "iteration: 83190 loss: 0.0029 lr: 0.02\n",
      "iteration: 83200 loss: 0.0029 lr: 0.02\n",
      "iteration: 83210 loss: 0.0028 lr: 0.02\n",
      "iteration: 83220 loss: 0.0029 lr: 0.02\n",
      "iteration: 83230 loss: 0.0028 lr: 0.02\n",
      "iteration: 83240 loss: 0.0032 lr: 0.02\n",
      "iteration: 83250 loss: 0.0031 lr: 0.02\n",
      "iteration: 83260 loss: 0.0042 lr: 0.02\n",
      "iteration: 83270 loss: 0.0033 lr: 0.02\n",
      "iteration: 83280 loss: 0.0037 lr: 0.02\n",
      "iteration: 83290 loss: 0.0035 lr: 0.02\n",
      "iteration: 83300 loss: 0.0038 lr: 0.02\n",
      "iteration: 83310 loss: 0.0028 lr: 0.02\n",
      "iteration: 83320 loss: 0.0029 lr: 0.02\n",
      "iteration: 83330 loss: 0.0030 lr: 0.02\n",
      "iteration: 83340 loss: 0.0033 lr: 0.02\n",
      "iteration: 83350 loss: 0.0033 lr: 0.02\n",
      "iteration: 83360 loss: 0.0027 lr: 0.02\n",
      "iteration: 83370 loss: 0.0035 lr: 0.02\n",
      "iteration: 83380 loss: 0.0048 lr: 0.02\n",
      "iteration: 83390 loss: 0.0032 lr: 0.02\n",
      "iteration: 83400 loss: 0.0030 lr: 0.02\n",
      "iteration: 83410 loss: 0.0030 lr: 0.02\n",
      "iteration: 83420 loss: 0.0033 lr: 0.02\n",
      "iteration: 83430 loss: 0.0033 lr: 0.02\n",
      "iteration: 83440 loss: 0.0033 lr: 0.02\n",
      "iteration: 83450 loss: 0.0031 lr: 0.02\n",
      "iteration: 83460 loss: 0.0037 lr: 0.02\n",
      "iteration: 83470 loss: 0.0028 lr: 0.02\n",
      "iteration: 83480 loss: 0.0034 lr: 0.02\n",
      "iteration: 83490 loss: 0.0028 lr: 0.02\n",
      "iteration: 83500 loss: 0.0029 lr: 0.02\n",
      "iteration: 83510 loss: 0.0033 lr: 0.02\n",
      "iteration: 83520 loss: 0.0035 lr: 0.02\n",
      "iteration: 83530 loss: 0.0031 lr: 0.02\n",
      "iteration: 83540 loss: 0.0029 lr: 0.02\n",
      "iteration: 83550 loss: 0.0031 lr: 0.02\n",
      "iteration: 83560 loss: 0.0026 lr: 0.02\n",
      "iteration: 83570 loss: 0.0035 lr: 0.02\n",
      "iteration: 83580 loss: 0.0031 lr: 0.02\n",
      "iteration: 83590 loss: 0.0030 lr: 0.02\n",
      "iteration: 83600 loss: 0.0031 lr: 0.02\n",
      "iteration: 83610 loss: 0.0033 lr: 0.02\n",
      "iteration: 83620 loss: 0.0028 lr: 0.02\n",
      "iteration: 83630 loss: 0.0034 lr: 0.02\n",
      "iteration: 83640 loss: 0.0036 lr: 0.02\n",
      "iteration: 83650 loss: 0.0029 lr: 0.02\n",
      "iteration: 83660 loss: 0.0034 lr: 0.02\n",
      "iteration: 83670 loss: 0.0031 lr: 0.02\n",
      "iteration: 83680 loss: 0.0027 lr: 0.02\n",
      "iteration: 83690 loss: 0.0036 lr: 0.02\n",
      "iteration: 83700 loss: 0.0028 lr: 0.02\n",
      "iteration: 83710 loss: 0.0031 lr: 0.02\n",
      "iteration: 83720 loss: 0.0031 lr: 0.02\n",
      "iteration: 83730 loss: 0.0027 lr: 0.02\n",
      "iteration: 83740 loss: 0.0035 lr: 0.02\n",
      "iteration: 83750 loss: 0.0030 lr: 0.02\n",
      "iteration: 83760 loss: 0.0038 lr: 0.02\n",
      "iteration: 83770 loss: 0.0026 lr: 0.02\n",
      "iteration: 83780 loss: 0.0029 lr: 0.02\n",
      "iteration: 83790 loss: 0.0035 lr: 0.02\n",
      "iteration: 83800 loss: 0.0026 lr: 0.02\n",
      "iteration: 83810 loss: 0.0024 lr: 0.02\n",
      "iteration: 83820 loss: 0.0033 lr: 0.02\n",
      "iteration: 83830 loss: 0.0039 lr: 0.02\n",
      "iteration: 83840 loss: 0.0032 lr: 0.02\n",
      "iteration: 83850 loss: 0.0030 lr: 0.02\n",
      "iteration: 83860 loss: 0.0031 lr: 0.02\n",
      "iteration: 83870 loss: 0.0033 lr: 0.02\n",
      "iteration: 83880 loss: 0.0038 lr: 0.02\n",
      "iteration: 83890 loss: 0.0032 lr: 0.02\n",
      "iteration: 83900 loss: 0.0029 lr: 0.02\n",
      "iteration: 83910 loss: 0.0028 lr: 0.02\n",
      "iteration: 83920 loss: 0.0032 lr: 0.02\n",
      "iteration: 83930 loss: 0.0030 lr: 0.02\n",
      "iteration: 83940 loss: 0.0026 lr: 0.02\n",
      "iteration: 83950 loss: 0.0038 lr: 0.02\n",
      "iteration: 83960 loss: 0.0031 lr: 0.02\n",
      "iteration: 83970 loss: 0.0028 lr: 0.02\n",
      "iteration: 83980 loss: 0.0025 lr: 0.02\n",
      "iteration: 83990 loss: 0.0041 lr: 0.02\n",
      "iteration: 84000 loss: 0.0037 lr: 0.02\n",
      "iteration: 84010 loss: 0.0034 lr: 0.02\n",
      "iteration: 84020 loss: 0.0040 lr: 0.02\n",
      "iteration: 84030 loss: 0.0028 lr: 0.02\n",
      "iteration: 84040 loss: 0.0028 lr: 0.02\n",
      "iteration: 84050 loss: 0.0025 lr: 0.02\n",
      "iteration: 84060 loss: 0.0041 lr: 0.02\n",
      "iteration: 84070 loss: 0.0032 lr: 0.02\n",
      "iteration: 84080 loss: 0.0038 lr: 0.02\n",
      "iteration: 84090 loss: 0.0032 lr: 0.02\n",
      "iteration: 84100 loss: 0.0032 lr: 0.02\n",
      "iteration: 84110 loss: 0.0032 lr: 0.02\n",
      "iteration: 84120 loss: 0.0029 lr: 0.02\n",
      "iteration: 84130 loss: 0.0028 lr: 0.02\n",
      "iteration: 84140 loss: 0.0034 lr: 0.02\n",
      "iteration: 84150 loss: 0.0027 lr: 0.02\n",
      "iteration: 84160 loss: 0.0034 lr: 0.02\n",
      "iteration: 84170 loss: 0.0027 lr: 0.02\n",
      "iteration: 84180 loss: 0.0025 lr: 0.02\n",
      "iteration: 84190 loss: 0.0031 lr: 0.02\n",
      "iteration: 84200 loss: 0.0031 lr: 0.02\n",
      "iteration: 84210 loss: 0.0036 lr: 0.02\n",
      "iteration: 84220 loss: 0.0031 lr: 0.02\n",
      "iteration: 84230 loss: 0.0035 lr: 0.02\n",
      "iteration: 84240 loss: 0.0028 lr: 0.02\n",
      "iteration: 84250 loss: 0.0031 lr: 0.02\n",
      "iteration: 84260 loss: 0.0035 lr: 0.02\n",
      "iteration: 84270 loss: 0.0027 lr: 0.02\n",
      "iteration: 84280 loss: 0.0030 lr: 0.02\n",
      "iteration: 84290 loss: 0.0031 lr: 0.02\n",
      "iteration: 84300 loss: 0.0035 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 84310 loss: 0.0034 lr: 0.02\n",
      "iteration: 84320 loss: 0.0037 lr: 0.02\n",
      "iteration: 84330 loss: 0.0026 lr: 0.02\n",
      "iteration: 84340 loss: 0.0035 lr: 0.02\n",
      "iteration: 84350 loss: 0.0036 lr: 0.02\n",
      "iteration: 84360 loss: 0.0027 lr: 0.02\n",
      "iteration: 84370 loss: 0.0034 lr: 0.02\n",
      "iteration: 84380 loss: 0.0025 lr: 0.02\n",
      "iteration: 84390 loss: 0.0035 lr: 0.02\n",
      "iteration: 84400 loss: 0.0036 lr: 0.02\n",
      "iteration: 84410 loss: 0.0032 lr: 0.02\n",
      "iteration: 84420 loss: 0.0023 lr: 0.02\n",
      "iteration: 84430 loss: 0.0028 lr: 0.02\n",
      "iteration: 84440 loss: 0.0025 lr: 0.02\n",
      "iteration: 84450 loss: 0.0031 lr: 0.02\n",
      "iteration: 84460 loss: 0.0023 lr: 0.02\n",
      "iteration: 84470 loss: 0.0029 lr: 0.02\n",
      "iteration: 84480 loss: 0.0024 lr: 0.02\n",
      "iteration: 84490 loss: 0.0028 lr: 0.02\n",
      "iteration: 84500 loss: 0.0030 lr: 0.02\n",
      "iteration: 84510 loss: 0.0024 lr: 0.02\n",
      "iteration: 84520 loss: 0.0031 lr: 0.02\n",
      "iteration: 84530 loss: 0.0030 lr: 0.02\n",
      "iteration: 84540 loss: 0.0035 lr: 0.02\n",
      "iteration: 84550 loss: 0.0025 lr: 0.02\n",
      "iteration: 84560 loss: 0.0029 lr: 0.02\n",
      "iteration: 84570 loss: 0.0025 lr: 0.02\n",
      "iteration: 84580 loss: 0.0024 lr: 0.02\n",
      "iteration: 84590 loss: 0.0031 lr: 0.02\n",
      "iteration: 84600 loss: 0.0033 lr: 0.02\n",
      "iteration: 84610 loss: 0.0023 lr: 0.02\n",
      "iteration: 84620 loss: 0.0027 lr: 0.02\n",
      "iteration: 84630 loss: 0.0031 lr: 0.02\n",
      "iteration: 84640 loss: 0.0034 lr: 0.02\n",
      "iteration: 84650 loss: 0.0035 lr: 0.02\n",
      "iteration: 84660 loss: 0.0029 lr: 0.02\n",
      "iteration: 84670 loss: 0.0038 lr: 0.02\n",
      "iteration: 84680 loss: 0.0032 lr: 0.02\n",
      "iteration: 84690 loss: 0.0041 lr: 0.02\n",
      "iteration: 84700 loss: 0.0031 lr: 0.02\n",
      "iteration: 84710 loss: 0.0028 lr: 0.02\n",
      "iteration: 84720 loss: 0.0028 lr: 0.02\n",
      "iteration: 84730 loss: 0.0030 lr: 0.02\n",
      "iteration: 84740 loss: 0.0036 lr: 0.02\n",
      "iteration: 84750 loss: 0.0031 lr: 0.02\n",
      "iteration: 84760 loss: 0.0035 lr: 0.02\n",
      "iteration: 84770 loss: 0.0034 lr: 0.02\n",
      "iteration: 84780 loss: 0.0027 lr: 0.02\n",
      "iteration: 84790 loss: 0.0026 lr: 0.02\n",
      "iteration: 84800 loss: 0.0025 lr: 0.02\n",
      "iteration: 84810 loss: 0.0039 lr: 0.02\n",
      "iteration: 84820 loss: 0.0029 lr: 0.02\n",
      "iteration: 84830 loss: 0.0026 lr: 0.02\n",
      "iteration: 84840 loss: 0.0031 lr: 0.02\n",
      "iteration: 84850 loss: 0.0028 lr: 0.02\n",
      "iteration: 84860 loss: 0.0031 lr: 0.02\n",
      "iteration: 84870 loss: 0.0030 lr: 0.02\n",
      "iteration: 84880 loss: 0.0026 lr: 0.02\n",
      "iteration: 84890 loss: 0.0025 lr: 0.02\n",
      "iteration: 84900 loss: 0.0031 lr: 0.02\n",
      "iteration: 84910 loss: 0.0034 lr: 0.02\n",
      "iteration: 84920 loss: 0.0024 lr: 0.02\n",
      "iteration: 84930 loss: 0.0044 lr: 0.02\n",
      "iteration: 84940 loss: 0.0039 lr: 0.02\n",
      "iteration: 84950 loss: 0.0028 lr: 0.02\n",
      "iteration: 84960 loss: 0.0035 lr: 0.02\n",
      "iteration: 84970 loss: 0.0028 lr: 0.02\n",
      "iteration: 84980 loss: 0.0031 lr: 0.02\n",
      "iteration: 84990 loss: 0.0024 lr: 0.02\n",
      "iteration: 85000 loss: 0.0023 lr: 0.02\n",
      "iteration: 85010 loss: 0.0040 lr: 0.02\n",
      "iteration: 85020 loss: 0.0036 lr: 0.02\n",
      "iteration: 85030 loss: 0.0034 lr: 0.02\n",
      "iteration: 85040 loss: 0.0027 lr: 0.02\n",
      "iteration: 85050 loss: 0.0043 lr: 0.02\n",
      "iteration: 85060 loss: 0.0039 lr: 0.02\n",
      "iteration: 85070 loss: 0.0028 lr: 0.02\n",
      "iteration: 85080 loss: 0.0023 lr: 0.02\n",
      "iteration: 85090 loss: 0.0024 lr: 0.02\n",
      "iteration: 85100 loss: 0.0030 lr: 0.02\n",
      "iteration: 85110 loss: 0.0034 lr: 0.02\n",
      "iteration: 85120 loss: 0.0023 lr: 0.02\n",
      "iteration: 85130 loss: 0.0036 lr: 0.02\n",
      "iteration: 85140 loss: 0.0034 lr: 0.02\n",
      "iteration: 85150 loss: 0.0031 lr: 0.02\n",
      "iteration: 85160 loss: 0.0041 lr: 0.02\n",
      "iteration: 85170 loss: 0.0035 lr: 0.02\n",
      "iteration: 85180 loss: 0.0038 lr: 0.02\n",
      "iteration: 85190 loss: 0.0034 lr: 0.02\n",
      "iteration: 85200 loss: 0.0035 lr: 0.02\n",
      "iteration: 85210 loss: 0.0033 lr: 0.02\n",
      "iteration: 85220 loss: 0.0026 lr: 0.02\n",
      "iteration: 85230 loss: 0.0026 lr: 0.02\n",
      "iteration: 85240 loss: 0.0026 lr: 0.02\n",
      "iteration: 85250 loss: 0.0039 lr: 0.02\n",
      "iteration: 85260 loss: 0.0025 lr: 0.02\n",
      "iteration: 85270 loss: 0.0034 lr: 0.02\n",
      "iteration: 85280 loss: 0.0032 lr: 0.02\n",
      "iteration: 85290 loss: 0.0026 lr: 0.02\n",
      "iteration: 85300 loss: 0.0036 lr: 0.02\n",
      "iteration: 85310 loss: 0.0035 lr: 0.02\n",
      "iteration: 85320 loss: 0.0025 lr: 0.02\n",
      "iteration: 85330 loss: 0.0023 lr: 0.02\n",
      "iteration: 85340 loss: 0.0025 lr: 0.02\n",
      "iteration: 85350 loss: 0.0034 lr: 0.02\n",
      "iteration: 85360 loss: 0.0040 lr: 0.02\n",
      "iteration: 85370 loss: 0.0027 lr: 0.02\n",
      "iteration: 85380 loss: 0.0032 lr: 0.02\n",
      "iteration: 85390 loss: 0.0038 lr: 0.02\n",
      "iteration: 85400 loss: 0.0033 lr: 0.02\n",
      "iteration: 85410 loss: 0.0026 lr: 0.02\n",
      "iteration: 85420 loss: 0.0047 lr: 0.02\n",
      "iteration: 85430 loss: 0.0037 lr: 0.02\n",
      "iteration: 85440 loss: 0.0028 lr: 0.02\n",
      "iteration: 85450 loss: 0.0038 lr: 0.02\n",
      "iteration: 85460 loss: 0.0034 lr: 0.02\n",
      "iteration: 85470 loss: 0.0028 lr: 0.02\n",
      "iteration: 85480 loss: 0.0029 lr: 0.02\n",
      "iteration: 85490 loss: 0.0025 lr: 0.02\n",
      "iteration: 85500 loss: 0.0032 lr: 0.02\n",
      "iteration: 85510 loss: 0.0038 lr: 0.02\n",
      "iteration: 85520 loss: 0.0030 lr: 0.02\n",
      "iteration: 85530 loss: 0.0040 lr: 0.02\n",
      "iteration: 85540 loss: 0.0039 lr: 0.02\n",
      "iteration: 85550 loss: 0.0029 lr: 0.02\n",
      "iteration: 85560 loss: 0.0031 lr: 0.02\n",
      "iteration: 85570 loss: 0.0029 lr: 0.02\n",
      "iteration: 85580 loss: 0.0040 lr: 0.02\n",
      "iteration: 85590 loss: 0.0039 lr: 0.02\n",
      "iteration: 85600 loss: 0.0042 lr: 0.02\n",
      "iteration: 85610 loss: 0.0026 lr: 0.02\n",
      "iteration: 85620 loss: 0.0030 lr: 0.02\n",
      "iteration: 85630 loss: 0.0026 lr: 0.02\n",
      "iteration: 85640 loss: 0.0031 lr: 0.02\n",
      "iteration: 85650 loss: 0.0036 lr: 0.02\n",
      "iteration: 85660 loss: 0.0028 lr: 0.02\n",
      "iteration: 85670 loss: 0.0035 lr: 0.02\n",
      "iteration: 85680 loss: 0.0031 lr: 0.02\n",
      "iteration: 85690 loss: 0.0030 lr: 0.02\n",
      "iteration: 85700 loss: 0.0027 lr: 0.02\n",
      "iteration: 85710 loss: 0.0028 lr: 0.02\n",
      "iteration: 85720 loss: 0.0032 lr: 0.02\n",
      "iteration: 85730 loss: 0.0031 lr: 0.02\n",
      "iteration: 85740 loss: 0.0027 lr: 0.02\n",
      "iteration: 85750 loss: 0.0035 lr: 0.02\n",
      "iteration: 85760 loss: 0.0029 lr: 0.02\n",
      "iteration: 85770 loss: 0.0029 lr: 0.02\n",
      "iteration: 85780 loss: 0.0033 lr: 0.02\n",
      "iteration: 85790 loss: 0.0027 lr: 0.02\n",
      "iteration: 85800 loss: 0.0034 lr: 0.02\n",
      "iteration: 85810 loss: 0.0028 lr: 0.02\n",
      "iteration: 85820 loss: 0.0039 lr: 0.02\n",
      "iteration: 85830 loss: 0.0029 lr: 0.02\n",
      "iteration: 85840 loss: 0.0025 lr: 0.02\n",
      "iteration: 85850 loss: 0.0036 lr: 0.02\n",
      "iteration: 85860 loss: 0.0031 lr: 0.02\n",
      "iteration: 85870 loss: 0.0032 lr: 0.02\n",
      "iteration: 85880 loss: 0.0040 lr: 0.02\n",
      "iteration: 85890 loss: 0.0035 lr: 0.02\n",
      "iteration: 85900 loss: 0.0043 lr: 0.02\n",
      "iteration: 85910 loss: 0.0033 lr: 0.02\n",
      "iteration: 85920 loss: 0.0028 lr: 0.02\n",
      "iteration: 85930 loss: 0.0030 lr: 0.02\n",
      "iteration: 85940 loss: 0.0034 lr: 0.02\n",
      "iteration: 85950 loss: 0.0030 lr: 0.02\n",
      "iteration: 85960 loss: 0.0029 lr: 0.02\n",
      "iteration: 85970 loss: 0.0033 lr: 0.02\n",
      "iteration: 85980 loss: 0.0033 lr: 0.02\n",
      "iteration: 85990 loss: 0.0030 lr: 0.02\n",
      "iteration: 86000 loss: 0.0036 lr: 0.02\n",
      "iteration: 86010 loss: 0.0037 lr: 0.02\n",
      "iteration: 86020 loss: 0.0029 lr: 0.02\n",
      "iteration: 86030 loss: 0.0036 lr: 0.02\n",
      "iteration: 86040 loss: 0.0038 lr: 0.02\n",
      "iteration: 86050 loss: 0.0033 lr: 0.02\n",
      "iteration: 86060 loss: 0.0034 lr: 0.02\n",
      "iteration: 86070 loss: 0.0042 lr: 0.02\n",
      "iteration: 86080 loss: 0.0039 lr: 0.02\n",
      "iteration: 86090 loss: 0.0040 lr: 0.02\n",
      "iteration: 86100 loss: 0.0037 lr: 0.02\n",
      "iteration: 86110 loss: 0.0033 lr: 0.02\n",
      "iteration: 86120 loss: 0.0033 lr: 0.02\n",
      "iteration: 86130 loss: 0.0023 lr: 0.02\n",
      "iteration: 86140 loss: 0.0028 lr: 0.02\n",
      "iteration: 86150 loss: 0.0027 lr: 0.02\n",
      "iteration: 86160 loss: 0.0033 lr: 0.02\n",
      "iteration: 86170 loss: 0.0027 lr: 0.02\n",
      "iteration: 86180 loss: 0.0032 lr: 0.02\n",
      "iteration: 86190 loss: 0.0031 lr: 0.02\n",
      "iteration: 86200 loss: 0.0035 lr: 0.02\n",
      "iteration: 86210 loss: 0.0024 lr: 0.02\n",
      "iteration: 86220 loss: 0.0037 lr: 0.02\n",
      "iteration: 86230 loss: 0.0040 lr: 0.02\n",
      "iteration: 86240 loss: 0.0032 lr: 0.02\n",
      "iteration: 86250 loss: 0.0031 lr: 0.02\n",
      "iteration: 86260 loss: 0.0030 lr: 0.02\n",
      "iteration: 86270 loss: 0.0031 lr: 0.02\n",
      "iteration: 86280 loss: 0.0033 lr: 0.02\n",
      "iteration: 86290 loss: 0.0031 lr: 0.02\n",
      "iteration: 86300 loss: 0.0023 lr: 0.02\n",
      "iteration: 86310 loss: 0.0037 lr: 0.02\n",
      "iteration: 86320 loss: 0.0029 lr: 0.02\n",
      "iteration: 86330 loss: 0.0033 lr: 0.02\n",
      "iteration: 86340 loss: 0.0028 lr: 0.02\n",
      "iteration: 86350 loss: 0.0028 lr: 0.02\n",
      "iteration: 86360 loss: 0.0026 lr: 0.02\n",
      "iteration: 86370 loss: 0.0029 lr: 0.02\n",
      "iteration: 86380 loss: 0.0030 lr: 0.02\n",
      "iteration: 86390 loss: 0.0029 lr: 0.02\n",
      "iteration: 86400 loss: 0.0029 lr: 0.02\n",
      "iteration: 86410 loss: 0.0032 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 86420 loss: 0.0036 lr: 0.02\n",
      "iteration: 86430 loss: 0.0032 lr: 0.02\n",
      "iteration: 86440 loss: 0.0030 lr: 0.02\n",
      "iteration: 86450 loss: 0.0027 lr: 0.02\n",
      "iteration: 86460 loss: 0.0039 lr: 0.02\n",
      "iteration: 86470 loss: 0.0035 lr: 0.02\n",
      "iteration: 86480 loss: 0.0036 lr: 0.02\n",
      "iteration: 86490 loss: 0.0030 lr: 0.02\n",
      "iteration: 86500 loss: 0.0033 lr: 0.02\n",
      "iteration: 86510 loss: 0.0028 lr: 0.02\n",
      "iteration: 86520 loss: 0.0030 lr: 0.02\n",
      "iteration: 86530 loss: 0.0027 lr: 0.02\n",
      "iteration: 86540 loss: 0.0026 lr: 0.02\n",
      "iteration: 86550 loss: 0.0026 lr: 0.02\n",
      "iteration: 86560 loss: 0.0038 lr: 0.02\n",
      "iteration: 86570 loss: 0.0027 lr: 0.02\n",
      "iteration: 86580 loss: 0.0031 lr: 0.02\n",
      "iteration: 86590 loss: 0.0031 lr: 0.02\n",
      "iteration: 86600 loss: 0.0022 lr: 0.02\n",
      "iteration: 86610 loss: 0.0032 lr: 0.02\n",
      "iteration: 86620 loss: 0.0039 lr: 0.02\n",
      "iteration: 86630 loss: 0.0028 lr: 0.02\n",
      "iteration: 86640 loss: 0.0037 lr: 0.02\n",
      "iteration: 86650 loss: 0.0027 lr: 0.02\n",
      "iteration: 86660 loss: 0.0028 lr: 0.02\n",
      "iteration: 86670 loss: 0.0032 lr: 0.02\n",
      "iteration: 86680 loss: 0.0034 lr: 0.02\n",
      "iteration: 86690 loss: 0.0027 lr: 0.02\n",
      "iteration: 86700 loss: 0.0037 lr: 0.02\n",
      "iteration: 86710 loss: 0.0033 lr: 0.02\n",
      "iteration: 86720 loss: 0.0026 lr: 0.02\n",
      "iteration: 86730 loss: 0.0036 lr: 0.02\n",
      "iteration: 86740 loss: 0.0026 lr: 0.02\n",
      "iteration: 86750 loss: 0.0026 lr: 0.02\n",
      "iteration: 86760 loss: 0.0034 lr: 0.02\n",
      "iteration: 86770 loss: 0.0036 lr: 0.02\n",
      "iteration: 86780 loss: 0.0026 lr: 0.02\n",
      "iteration: 86790 loss: 0.0026 lr: 0.02\n",
      "iteration: 86800 loss: 0.0026 lr: 0.02\n",
      "iteration: 86810 loss: 0.0027 lr: 0.02\n",
      "iteration: 86820 loss: 0.0034 lr: 0.02\n",
      "iteration: 86830 loss: 0.0022 lr: 0.02\n",
      "iteration: 86840 loss: 0.0045 lr: 0.02\n",
      "iteration: 86850 loss: 0.0031 lr: 0.02\n",
      "iteration: 86860 loss: 0.0048 lr: 0.02\n",
      "iteration: 86870 loss: 0.0028 lr: 0.02\n",
      "iteration: 86880 loss: 0.0021 lr: 0.02\n",
      "iteration: 86890 loss: 0.0028 lr: 0.02\n",
      "iteration: 86900 loss: 0.0029 lr: 0.02\n",
      "iteration: 86910 loss: 0.0033 lr: 0.02\n",
      "iteration: 86920 loss: 0.0029 lr: 0.02\n",
      "iteration: 86930 loss: 0.0029 lr: 0.02\n",
      "iteration: 86940 loss: 0.0033 lr: 0.02\n",
      "iteration: 86950 loss: 0.0038 lr: 0.02\n",
      "iteration: 86960 loss: 0.0025 lr: 0.02\n",
      "iteration: 86970 loss: 0.0035 lr: 0.02\n",
      "iteration: 86980 loss: 0.0028 lr: 0.02\n",
      "iteration: 86990 loss: 0.0036 lr: 0.02\n",
      "iteration: 87000 loss: 0.0036 lr: 0.02\n",
      "iteration: 87010 loss: 0.0028 lr: 0.02\n",
      "iteration: 87020 loss: 0.0038 lr: 0.02\n",
      "iteration: 87030 loss: 0.0030 lr: 0.02\n",
      "iteration: 87040 loss: 0.0036 lr: 0.02\n",
      "iteration: 87050 loss: 0.0040 lr: 0.02\n",
      "iteration: 87060 loss: 0.0030 lr: 0.02\n",
      "iteration: 87070 loss: 0.0033 lr: 0.02\n",
      "iteration: 87080 loss: 0.0030 lr: 0.02\n",
      "iteration: 87090 loss: 0.0026 lr: 0.02\n",
      "iteration: 87100 loss: 0.0026 lr: 0.02\n",
      "iteration: 87110 loss: 0.0033 lr: 0.02\n",
      "iteration: 87120 loss: 0.0027 lr: 0.02\n",
      "iteration: 87130 loss: 0.0038 lr: 0.02\n",
      "iteration: 87140 loss: 0.0030 lr: 0.02\n",
      "iteration: 87150 loss: 0.0046 lr: 0.02\n",
      "iteration: 87160 loss: 0.0032 lr: 0.02\n",
      "iteration: 87170 loss: 0.0043 lr: 0.02\n",
      "iteration: 87180 loss: 0.0022 lr: 0.02\n",
      "iteration: 87190 loss: 0.0044 lr: 0.02\n",
      "iteration: 87200 loss: 0.0032 lr: 0.02\n",
      "iteration: 87210 loss: 0.0035 lr: 0.02\n",
      "iteration: 87220 loss: 0.0035 lr: 0.02\n",
      "iteration: 87230 loss: 0.0032 lr: 0.02\n",
      "iteration: 87240 loss: 0.0028 lr: 0.02\n",
      "iteration: 87250 loss: 0.0029 lr: 0.02\n",
      "iteration: 87260 loss: 0.0042 lr: 0.02\n",
      "iteration: 87270 loss: 0.0032 lr: 0.02\n",
      "iteration: 87280 loss: 0.0027 lr: 0.02\n",
      "iteration: 87290 loss: 0.0028 lr: 0.02\n",
      "iteration: 87300 loss: 0.0039 lr: 0.02\n",
      "iteration: 87310 loss: 0.0030 lr: 0.02\n",
      "iteration: 87320 loss: 0.0029 lr: 0.02\n",
      "iteration: 87330 loss: 0.0032 lr: 0.02\n",
      "iteration: 87340 loss: 0.0030 lr: 0.02\n",
      "iteration: 87350 loss: 0.0035 lr: 0.02\n",
      "iteration: 87360 loss: 0.0049 lr: 0.02\n",
      "iteration: 87370 loss: 0.0032 lr: 0.02\n",
      "iteration: 87380 loss: 0.0029 lr: 0.02\n",
      "iteration: 87390 loss: 0.0024 lr: 0.02\n",
      "iteration: 87400 loss: 0.0035 lr: 0.02\n",
      "iteration: 87410 loss: 0.0027 lr: 0.02\n",
      "iteration: 87420 loss: 0.0031 lr: 0.02\n",
      "iteration: 87430 loss: 0.0033 lr: 0.02\n",
      "iteration: 87440 loss: 0.0032 lr: 0.02\n",
      "iteration: 87450 loss: 0.0028 lr: 0.02\n",
      "iteration: 87460 loss: 0.0030 lr: 0.02\n",
      "iteration: 87470 loss: 0.0030 lr: 0.02\n",
      "iteration: 87480 loss: 0.0035 lr: 0.02\n",
      "iteration: 87490 loss: 0.0026 lr: 0.02\n",
      "iteration: 87500 loss: 0.0034 lr: 0.02\n",
      "iteration: 87510 loss: 0.0033 lr: 0.02\n",
      "iteration: 87520 loss: 0.0035 lr: 0.02\n",
      "iteration: 87530 loss: 0.0031 lr: 0.02\n",
      "iteration: 87540 loss: 0.0028 lr: 0.02\n",
      "iteration: 87550 loss: 0.0032 lr: 0.02\n",
      "iteration: 87560 loss: 0.0032 lr: 0.02\n",
      "iteration: 87570 loss: 0.0034 lr: 0.02\n",
      "iteration: 87580 loss: 0.0024 lr: 0.02\n",
      "iteration: 87590 loss: 0.0034 lr: 0.02\n",
      "iteration: 87600 loss: 0.0034 lr: 0.02\n",
      "iteration: 87610 loss: 0.0024 lr: 0.02\n",
      "iteration: 87620 loss: 0.0033 lr: 0.02\n",
      "iteration: 87630 loss: 0.0032 lr: 0.02\n",
      "iteration: 87640 loss: 0.0025 lr: 0.02\n",
      "iteration: 87650 loss: 0.0033 lr: 0.02\n",
      "iteration: 87660 loss: 0.0040 lr: 0.02\n",
      "iteration: 87670 loss: 0.0031 lr: 0.02\n",
      "iteration: 87680 loss: 0.0036 lr: 0.02\n",
      "iteration: 87690 loss: 0.0026 lr: 0.02\n",
      "iteration: 87700 loss: 0.0031 lr: 0.02\n",
      "iteration: 87710 loss: 0.0032 lr: 0.02\n",
      "iteration: 87720 loss: 0.0027 lr: 0.02\n",
      "iteration: 87730 loss: 0.0034 lr: 0.02\n",
      "iteration: 87740 loss: 0.0025 lr: 0.02\n",
      "iteration: 87750 loss: 0.0035 lr: 0.02\n",
      "iteration: 87760 loss: 0.0028 lr: 0.02\n",
      "iteration: 87770 loss: 0.0033 lr: 0.02\n",
      "iteration: 87780 loss: 0.0025 lr: 0.02\n",
      "iteration: 87790 loss: 0.0028 lr: 0.02\n",
      "iteration: 87800 loss: 0.0032 lr: 0.02\n",
      "iteration: 87810 loss: 0.0031 lr: 0.02\n",
      "iteration: 87820 loss: 0.0030 lr: 0.02\n",
      "iteration: 87830 loss: 0.0030 lr: 0.02\n",
      "iteration: 87840 loss: 0.0029 lr: 0.02\n",
      "iteration: 87850 loss: 0.0035 lr: 0.02\n",
      "iteration: 87860 loss: 0.0032 lr: 0.02\n",
      "iteration: 87870 loss: 0.0028 lr: 0.02\n",
      "iteration: 87880 loss: 0.0029 lr: 0.02\n",
      "iteration: 87890 loss: 0.0031 lr: 0.02\n",
      "iteration: 87900 loss: 0.0032 lr: 0.02\n",
      "iteration: 87910 loss: 0.0027 lr: 0.02\n",
      "iteration: 87920 loss: 0.0031 lr: 0.02\n",
      "iteration: 87930 loss: 0.0031 lr: 0.02\n",
      "iteration: 87940 loss: 0.0026 lr: 0.02\n",
      "iteration: 87950 loss: 0.0024 lr: 0.02\n",
      "iteration: 87960 loss: 0.0021 lr: 0.02\n",
      "iteration: 87970 loss: 0.0025 lr: 0.02\n",
      "iteration: 87980 loss: 0.0042 lr: 0.02\n",
      "iteration: 87990 loss: 0.0033 lr: 0.02\n",
      "iteration: 88000 loss: 0.0040 lr: 0.02\n",
      "iteration: 88010 loss: 0.0036 lr: 0.02\n",
      "iteration: 88020 loss: 0.0038 lr: 0.02\n",
      "iteration: 88030 loss: 0.0034 lr: 0.02\n",
      "iteration: 88040 loss: 0.0035 lr: 0.02\n",
      "iteration: 88050 loss: 0.0036 lr: 0.02\n",
      "iteration: 88060 loss: 0.0029 lr: 0.02\n",
      "iteration: 88070 loss: 0.0032 lr: 0.02\n",
      "iteration: 88080 loss: 0.0038 lr: 0.02\n",
      "iteration: 88090 loss: 0.0034 lr: 0.02\n",
      "iteration: 88100 loss: 0.0035 lr: 0.02\n",
      "iteration: 88110 loss: 0.0027 lr: 0.02\n",
      "iteration: 88120 loss: 0.0030 lr: 0.02\n",
      "iteration: 88130 loss: 0.0028 lr: 0.02\n",
      "iteration: 88140 loss: 0.0020 lr: 0.02\n",
      "iteration: 88150 loss: 0.0037 lr: 0.02\n",
      "iteration: 88160 loss: 0.0040 lr: 0.02\n",
      "iteration: 88170 loss: 0.0028 lr: 0.02\n",
      "iteration: 88180 loss: 0.0045 lr: 0.02\n",
      "iteration: 88190 loss: 0.0034 lr: 0.02\n",
      "iteration: 88200 loss: 0.0030 lr: 0.02\n",
      "iteration: 88210 loss: 0.0024 lr: 0.02\n",
      "iteration: 88220 loss: 0.0031 lr: 0.02\n",
      "iteration: 88230 loss: 0.0024 lr: 0.02\n",
      "iteration: 88240 loss: 0.0031 lr: 0.02\n",
      "iteration: 88250 loss: 0.0028 lr: 0.02\n",
      "iteration: 88260 loss: 0.0025 lr: 0.02\n",
      "iteration: 88270 loss: 0.0043 lr: 0.02\n",
      "iteration: 88280 loss: 0.0037 lr: 0.02\n",
      "iteration: 88290 loss: 0.0033 lr: 0.02\n",
      "iteration: 88300 loss: 0.0027 lr: 0.02\n",
      "iteration: 88310 loss: 0.0035 lr: 0.02\n",
      "iteration: 88320 loss: 0.0023 lr: 0.02\n",
      "iteration: 88330 loss: 0.0032 lr: 0.02\n",
      "iteration: 88340 loss: 0.0028 lr: 0.02\n",
      "iteration: 88350 loss: 0.0026 lr: 0.02\n",
      "iteration: 88360 loss: 0.0032 lr: 0.02\n",
      "iteration: 88370 loss: 0.0029 lr: 0.02\n",
      "iteration: 88380 loss: 0.0035 lr: 0.02\n",
      "iteration: 88390 loss: 0.0037 lr: 0.02\n",
      "iteration: 88400 loss: 0.0028 lr: 0.02\n",
      "iteration: 88410 loss: 0.0043 lr: 0.02\n",
      "iteration: 88420 loss: 0.0051 lr: 0.02\n",
      "iteration: 88430 loss: 0.0038 lr: 0.02\n",
      "iteration: 88440 loss: 0.0035 lr: 0.02\n",
      "iteration: 88450 loss: 0.0034 lr: 0.02\n",
      "iteration: 88460 loss: 0.0034 lr: 0.02\n",
      "iteration: 88470 loss: 0.0032 lr: 0.02\n",
      "iteration: 88480 loss: 0.0027 lr: 0.02\n",
      "iteration: 88490 loss: 0.0032 lr: 0.02\n",
      "iteration: 88500 loss: 0.0030 lr: 0.02\n",
      "iteration: 88510 loss: 0.0035 lr: 0.02\n",
      "iteration: 88520 loss: 0.0030 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 88530 loss: 0.0027 lr: 0.02\n",
      "iteration: 88540 loss: 0.0035 lr: 0.02\n",
      "iteration: 88550 loss: 0.0029 lr: 0.02\n",
      "iteration: 88560 loss: 0.0031 lr: 0.02\n",
      "iteration: 88570 loss: 0.0030 lr: 0.02\n",
      "iteration: 88580 loss: 0.0035 lr: 0.02\n",
      "iteration: 88590 loss: 0.0024 lr: 0.02\n",
      "iteration: 88600 loss: 0.0032 lr: 0.02\n",
      "iteration: 88610 loss: 0.0024 lr: 0.02\n",
      "iteration: 88620 loss: 0.0032 lr: 0.02\n",
      "iteration: 88630 loss: 0.0030 lr: 0.02\n",
      "iteration: 88640 loss: 0.0041 lr: 0.02\n",
      "iteration: 88650 loss: 0.0029 lr: 0.02\n",
      "iteration: 88660 loss: 0.0031 lr: 0.02\n",
      "iteration: 88670 loss: 0.0027 lr: 0.02\n",
      "iteration: 88680 loss: 0.0044 lr: 0.02\n",
      "iteration: 88690 loss: 0.0025 lr: 0.02\n",
      "iteration: 88700 loss: 0.0029 lr: 0.02\n",
      "iteration: 88710 loss: 0.0031 lr: 0.02\n",
      "iteration: 88720 loss: 0.0035 lr: 0.02\n",
      "iteration: 88730 loss: 0.0030 lr: 0.02\n",
      "iteration: 88740 loss: 0.0029 lr: 0.02\n",
      "iteration: 88750 loss: 0.0035 lr: 0.02\n",
      "iteration: 88760 loss: 0.0027 lr: 0.02\n",
      "iteration: 88770 loss: 0.0029 lr: 0.02\n",
      "iteration: 88780 loss: 0.0043 lr: 0.02\n",
      "iteration: 88790 loss: 0.0031 lr: 0.02\n",
      "iteration: 88800 loss: 0.0051 lr: 0.02\n",
      "iteration: 88810 loss: 0.0026 lr: 0.02\n",
      "iteration: 88820 loss: 0.0038 lr: 0.02\n",
      "iteration: 88830 loss: 0.0029 lr: 0.02\n",
      "iteration: 88840 loss: 0.0028 lr: 0.02\n",
      "iteration: 88850 loss: 0.0032 lr: 0.02\n",
      "iteration: 88860 loss: 0.0035 lr: 0.02\n",
      "iteration: 88870 loss: 0.0024 lr: 0.02\n",
      "iteration: 88880 loss: 0.0024 lr: 0.02\n",
      "iteration: 88890 loss: 0.0037 lr: 0.02\n",
      "iteration: 88900 loss: 0.0035 lr: 0.02\n",
      "iteration: 88910 loss: 0.0031 lr: 0.02\n",
      "iteration: 88920 loss: 0.0030 lr: 0.02\n",
      "iteration: 88930 loss: 0.0028 lr: 0.02\n",
      "iteration: 88940 loss: 0.0043 lr: 0.02\n",
      "iteration: 88950 loss: 0.0038 lr: 0.02\n",
      "iteration: 88960 loss: 0.0028 lr: 0.02\n",
      "iteration: 88970 loss: 0.0029 lr: 0.02\n",
      "iteration: 88980 loss: 0.0037 lr: 0.02\n",
      "iteration: 88990 loss: 0.0030 lr: 0.02\n",
      "iteration: 89000 loss: 0.0041 lr: 0.02\n",
      "iteration: 89010 loss: 0.0033 lr: 0.02\n",
      "iteration: 89020 loss: 0.0033 lr: 0.02\n",
      "iteration: 89030 loss: 0.0035 lr: 0.02\n",
      "iteration: 89040 loss: 0.0035 lr: 0.02\n",
      "iteration: 89050 loss: 0.0036 lr: 0.02\n",
      "iteration: 89060 loss: 0.0025 lr: 0.02\n",
      "iteration: 89070 loss: 0.0033 lr: 0.02\n",
      "iteration: 89080 loss: 0.0028 lr: 0.02\n",
      "iteration: 89090 loss: 0.0031 lr: 0.02\n",
      "iteration: 89100 loss: 0.0034 lr: 0.02\n",
      "iteration: 89110 loss: 0.0028 lr: 0.02\n",
      "iteration: 89120 loss: 0.0034 lr: 0.02\n",
      "iteration: 89130 loss: 0.0035 lr: 0.02\n",
      "iteration: 89140 loss: 0.0033 lr: 0.02\n",
      "iteration: 89150 loss: 0.0032 lr: 0.02\n",
      "iteration: 89160 loss: 0.0025 lr: 0.02\n",
      "iteration: 89170 loss: 0.0029 lr: 0.02\n",
      "iteration: 89180 loss: 0.0022 lr: 0.02\n",
      "iteration: 89190 loss: 0.0022 lr: 0.02\n",
      "iteration: 89200 loss: 0.0028 lr: 0.02\n",
      "iteration: 89210 loss: 0.0031 lr: 0.02\n",
      "iteration: 89220 loss: 0.0024 lr: 0.02\n",
      "iteration: 89230 loss: 0.0030 lr: 0.02\n",
      "iteration: 89240 loss: 0.0026 lr: 0.02\n",
      "iteration: 89250 loss: 0.0033 lr: 0.02\n",
      "iteration: 89260 loss: 0.0030 lr: 0.02\n",
      "iteration: 89270 loss: 0.0025 lr: 0.02\n",
      "iteration: 89280 loss: 0.0021 lr: 0.02\n",
      "iteration: 89290 loss: 0.0036 lr: 0.02\n",
      "iteration: 89300 loss: 0.0031 lr: 0.02\n",
      "iteration: 89310 loss: 0.0020 lr: 0.02\n",
      "iteration: 89320 loss: 0.0029 lr: 0.02\n",
      "iteration: 89330 loss: 0.0031 lr: 0.02\n",
      "iteration: 89340 loss: 0.0039 lr: 0.02\n",
      "iteration: 89350 loss: 0.0032 lr: 0.02\n",
      "iteration: 89360 loss: 0.0042 lr: 0.02\n",
      "iteration: 89370 loss: 0.0031 lr: 0.02\n",
      "iteration: 89380 loss: 0.0029 lr: 0.02\n",
      "iteration: 89390 loss: 0.0027 lr: 0.02\n",
      "iteration: 89400 loss: 0.0029 lr: 0.02\n",
      "iteration: 89410 loss: 0.0037 lr: 0.02\n",
      "iteration: 89420 loss: 0.0037 lr: 0.02\n",
      "iteration: 89430 loss: 0.0032 lr: 0.02\n",
      "iteration: 89440 loss: 0.0037 lr: 0.02\n",
      "iteration: 89450 loss: 0.0033 lr: 0.02\n",
      "iteration: 89460 loss: 0.0023 lr: 0.02\n",
      "iteration: 89470 loss: 0.0036 lr: 0.02\n",
      "iteration: 89480 loss: 0.0028 lr: 0.02\n",
      "iteration: 89490 loss: 0.0032 lr: 0.02\n",
      "iteration: 89500 loss: 0.0028 lr: 0.02\n",
      "iteration: 89510 loss: 0.0033 lr: 0.02\n",
      "iteration: 89520 loss: 0.0031 lr: 0.02\n",
      "iteration: 89530 loss: 0.0035 lr: 0.02\n",
      "iteration: 89540 loss: 0.0024 lr: 0.02\n",
      "iteration: 89550 loss: 0.0035 lr: 0.02\n",
      "iteration: 89560 loss: 0.0040 lr: 0.02\n",
      "iteration: 89570 loss: 0.0036 lr: 0.02\n",
      "iteration: 89580 loss: 0.0034 lr: 0.02\n",
      "iteration: 89590 loss: 0.0037 lr: 0.02\n",
      "iteration: 89600 loss: 0.0027 lr: 0.02\n",
      "iteration: 89610 loss: 0.0032 lr: 0.02\n",
      "iteration: 89620 loss: 0.0025 lr: 0.02\n",
      "iteration: 89630 loss: 0.0026 lr: 0.02\n",
      "iteration: 89640 loss: 0.0031 lr: 0.02\n",
      "iteration: 89650 loss: 0.0026 lr: 0.02\n",
      "iteration: 89660 loss: 0.0022 lr: 0.02\n",
      "iteration: 89670 loss: 0.0028 lr: 0.02\n",
      "iteration: 89680 loss: 0.0027 lr: 0.02\n",
      "iteration: 89690 loss: 0.0023 lr: 0.02\n",
      "iteration: 89700 loss: 0.0026 lr: 0.02\n",
      "iteration: 89710 loss: 0.0031 lr: 0.02\n",
      "iteration: 89720 loss: 0.0028 lr: 0.02\n",
      "iteration: 89730 loss: 0.0033 lr: 0.02\n",
      "iteration: 89740 loss: 0.0037 lr: 0.02\n",
      "iteration: 89750 loss: 0.0030 lr: 0.02\n",
      "iteration: 89760 loss: 0.0025 lr: 0.02\n",
      "iteration: 89770 loss: 0.0029 lr: 0.02\n",
      "iteration: 89780 loss: 0.0032 lr: 0.02\n",
      "iteration: 89790 loss: 0.0030 lr: 0.02\n",
      "iteration: 89800 loss: 0.0026 lr: 0.02\n",
      "iteration: 89810 loss: 0.0024 lr: 0.02\n",
      "iteration: 89820 loss: 0.0028 lr: 0.02\n",
      "iteration: 89830 loss: 0.0043 lr: 0.02\n",
      "iteration: 89840 loss: 0.0030 lr: 0.02\n",
      "iteration: 89850 loss: 0.0038 lr: 0.02\n",
      "iteration: 89860 loss: 0.0030 lr: 0.02\n",
      "iteration: 89870 loss: 0.0025 lr: 0.02\n",
      "iteration: 89880 loss: 0.0037 lr: 0.02\n",
      "iteration: 89890 loss: 0.0031 lr: 0.02\n",
      "iteration: 89900 loss: 0.0027 lr: 0.02\n",
      "iteration: 89910 loss: 0.0030 lr: 0.02\n",
      "iteration: 89920 loss: 0.0055 lr: 0.02\n",
      "iteration: 89930 loss: 0.0029 lr: 0.02\n",
      "iteration: 89940 loss: 0.0030 lr: 0.02\n",
      "iteration: 89950 loss: 0.0043 lr: 0.02\n",
      "iteration: 89960 loss: 0.0024 lr: 0.02\n",
      "iteration: 89970 loss: 0.0029 lr: 0.02\n",
      "iteration: 89980 loss: 0.0037 lr: 0.02\n",
      "iteration: 89990 loss: 0.0033 lr: 0.02\n",
      "iteration: 90000 loss: 0.0038 lr: 0.02\n",
      "iteration: 90010 loss: 0.0029 lr: 0.02\n",
      "iteration: 90020 loss: 0.0032 lr: 0.02\n",
      "iteration: 90030 loss: 0.0029 lr: 0.02\n",
      "iteration: 90040 loss: 0.0038 lr: 0.02\n",
      "iteration: 90050 loss: 0.0031 lr: 0.02\n",
      "iteration: 90060 loss: 0.0031 lr: 0.02\n",
      "iteration: 90070 loss: 0.0031 lr: 0.02\n",
      "iteration: 90080 loss: 0.0026 lr: 0.02\n",
      "iteration: 90090 loss: 0.0030 lr: 0.02\n",
      "iteration: 90100 loss: 0.0029 lr: 0.02\n",
      "iteration: 90110 loss: 0.0030 lr: 0.02\n",
      "iteration: 90120 loss: 0.0028 lr: 0.02\n",
      "iteration: 90130 loss: 0.0024 lr: 0.02\n",
      "iteration: 90140 loss: 0.0035 lr: 0.02\n",
      "iteration: 90150 loss: 0.0025 lr: 0.02\n",
      "iteration: 90160 loss: 0.0036 lr: 0.02\n",
      "iteration: 90170 loss: 0.0023 lr: 0.02\n",
      "iteration: 90180 loss: 0.0027 lr: 0.02\n",
      "iteration: 90190 loss: 0.0028 lr: 0.02\n",
      "iteration: 90200 loss: 0.0032 lr: 0.02\n",
      "iteration: 90210 loss: 0.0037 lr: 0.02\n",
      "iteration: 90220 loss: 0.0030 lr: 0.02\n",
      "iteration: 90230 loss: 0.0027 lr: 0.02\n",
      "iteration: 90240 loss: 0.0026 lr: 0.02\n",
      "iteration: 90250 loss: 0.0028 lr: 0.02\n",
      "iteration: 90260 loss: 0.0038 lr: 0.02\n",
      "iteration: 90270 loss: 0.0030 lr: 0.02\n",
      "iteration: 90280 loss: 0.0033 lr: 0.02\n",
      "iteration: 90290 loss: 0.0026 lr: 0.02\n",
      "iteration: 90300 loss: 0.0026 lr: 0.02\n",
      "iteration: 90310 loss: 0.0027 lr: 0.02\n",
      "iteration: 90320 loss: 0.0025 lr: 0.02\n",
      "iteration: 90330 loss: 0.0038 lr: 0.02\n",
      "iteration: 90340 loss: 0.0021 lr: 0.02\n",
      "iteration: 90350 loss: 0.0032 lr: 0.02\n",
      "iteration: 90360 loss: 0.0029 lr: 0.02\n",
      "iteration: 90370 loss: 0.0026 lr: 0.02\n",
      "iteration: 90380 loss: 0.0026 lr: 0.02\n",
      "iteration: 90390 loss: 0.0032 lr: 0.02\n",
      "iteration: 90400 loss: 0.0031 lr: 0.02\n",
      "iteration: 90410 loss: 0.0031 lr: 0.02\n",
      "iteration: 90420 loss: 0.0040 lr: 0.02\n",
      "iteration: 90430 loss: 0.0023 lr: 0.02\n",
      "iteration: 90440 loss: 0.0032 lr: 0.02\n",
      "iteration: 90450 loss: 0.0023 lr: 0.02\n",
      "iteration: 90460 loss: 0.0033 lr: 0.02\n",
      "iteration: 90470 loss: 0.0025 lr: 0.02\n",
      "iteration: 90480 loss: 0.0030 lr: 0.02\n",
      "iteration: 90490 loss: 0.0027 lr: 0.02\n",
      "iteration: 90500 loss: 0.0024 lr: 0.02\n",
      "iteration: 90510 loss: 0.0026 lr: 0.02\n",
      "iteration: 90520 loss: 0.0028 lr: 0.02\n",
      "iteration: 90530 loss: 0.0022 lr: 0.02\n",
      "iteration: 90540 loss: 0.0038 lr: 0.02\n",
      "iteration: 90550 loss: 0.0028 lr: 0.02\n",
      "iteration: 90560 loss: 0.0029 lr: 0.02\n",
      "iteration: 90570 loss: 0.0028 lr: 0.02\n",
      "iteration: 90580 loss: 0.0027 lr: 0.02\n",
      "iteration: 90590 loss: 0.0035 lr: 0.02\n",
      "iteration: 90600 loss: 0.0025 lr: 0.02\n",
      "iteration: 90610 loss: 0.0030 lr: 0.02\n",
      "iteration: 90620 loss: 0.0028 lr: 0.02\n",
      "iteration: 90630 loss: 0.0025 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 90640 loss: 0.0039 lr: 0.02\n",
      "iteration: 90650 loss: 0.0032 lr: 0.02\n",
      "iteration: 90660 loss: 0.0027 lr: 0.02\n",
      "iteration: 90670 loss: 0.0035 lr: 0.02\n",
      "iteration: 90680 loss: 0.0030 lr: 0.02\n",
      "iteration: 90690 loss: 0.0037 lr: 0.02\n",
      "iteration: 90700 loss: 0.0025 lr: 0.02\n",
      "iteration: 90710 loss: 0.0026 lr: 0.02\n",
      "iteration: 90720 loss: 0.0027 lr: 0.02\n",
      "iteration: 90730 loss: 0.0030 lr: 0.02\n",
      "iteration: 90740 loss: 0.0030 lr: 0.02\n",
      "iteration: 90750 loss: 0.0032 lr: 0.02\n",
      "iteration: 90760 loss: 0.0029 lr: 0.02\n",
      "iteration: 90770 loss: 0.0030 lr: 0.02\n",
      "iteration: 90780 loss: 0.0023 lr: 0.02\n",
      "iteration: 90790 loss: 0.0035 lr: 0.02\n",
      "iteration: 90800 loss: 0.0031 lr: 0.02\n",
      "iteration: 90810 loss: 0.0038 lr: 0.02\n",
      "iteration: 90820 loss: 0.0037 lr: 0.02\n",
      "iteration: 90830 loss: 0.0029 lr: 0.02\n",
      "iteration: 90840 loss: 0.0034 lr: 0.02\n",
      "iteration: 90850 loss: 0.0023 lr: 0.02\n",
      "iteration: 90860 loss: 0.0033 lr: 0.02\n",
      "iteration: 90870 loss: 0.0028 lr: 0.02\n",
      "iteration: 90880 loss: 0.0036 lr: 0.02\n",
      "iteration: 90890 loss: 0.0032 lr: 0.02\n",
      "iteration: 90900 loss: 0.0023 lr: 0.02\n",
      "iteration: 90910 loss: 0.0028 lr: 0.02\n",
      "iteration: 90920 loss: 0.0029 lr: 0.02\n",
      "iteration: 90930 loss: 0.0036 lr: 0.02\n",
      "iteration: 90940 loss: 0.0026 lr: 0.02\n",
      "iteration: 90950 loss: 0.0028 lr: 0.02\n",
      "iteration: 90960 loss: 0.0027 lr: 0.02\n",
      "iteration: 90970 loss: 0.0026 lr: 0.02\n",
      "iteration: 90980 loss: 0.0036 lr: 0.02\n",
      "iteration: 90990 loss: 0.0041 lr: 0.02\n",
      "iteration: 91000 loss: 0.0034 lr: 0.02\n",
      "iteration: 91010 loss: 0.0023 lr: 0.02\n",
      "iteration: 91020 loss: 0.0032 lr: 0.02\n",
      "iteration: 91030 loss: 0.0027 lr: 0.02\n",
      "iteration: 91040 loss: 0.0028 lr: 0.02\n",
      "iteration: 91050 loss: 0.0028 lr: 0.02\n",
      "iteration: 91060 loss: 0.0024 lr: 0.02\n",
      "iteration: 91070 loss: 0.0030 lr: 0.02\n",
      "iteration: 91080 loss: 0.0026 lr: 0.02\n",
      "iteration: 91090 loss: 0.0028 lr: 0.02\n",
      "iteration: 91100 loss: 0.0029 lr: 0.02\n",
      "iteration: 91110 loss: 0.0030 lr: 0.02\n",
      "iteration: 91120 loss: 0.0032 lr: 0.02\n",
      "iteration: 91130 loss: 0.0034 lr: 0.02\n",
      "iteration: 91140 loss: 0.0027 lr: 0.02\n",
      "iteration: 91150 loss: 0.0034 lr: 0.02\n",
      "iteration: 91160 loss: 0.0024 lr: 0.02\n",
      "iteration: 91170 loss: 0.0029 lr: 0.02\n",
      "iteration: 91180 loss: 0.0029 lr: 0.02\n",
      "iteration: 91190 loss: 0.0029 lr: 0.02\n",
      "iteration: 91200 loss: 0.0031 lr: 0.02\n",
      "iteration: 91210 loss: 0.0036 lr: 0.02\n",
      "iteration: 91220 loss: 0.0026 lr: 0.02\n",
      "iteration: 91230 loss: 0.0035 lr: 0.02\n",
      "iteration: 91240 loss: 0.0028 lr: 0.02\n",
      "iteration: 91250 loss: 0.0029 lr: 0.02\n",
      "iteration: 91260 loss: 0.0031 lr: 0.02\n",
      "iteration: 91270 loss: 0.0027 lr: 0.02\n",
      "iteration: 91280 loss: 0.0033 lr: 0.02\n",
      "iteration: 91290 loss: 0.0036 lr: 0.02\n",
      "iteration: 91300 loss: 0.0026 lr: 0.02\n",
      "iteration: 91310 loss: 0.0031 lr: 0.02\n",
      "iteration: 91320 loss: 0.0036 lr: 0.02\n",
      "iteration: 91330 loss: 0.0033 lr: 0.02\n",
      "iteration: 91340 loss: 0.0024 lr: 0.02\n",
      "iteration: 91350 loss: 0.0030 lr: 0.02\n",
      "iteration: 91360 loss: 0.0024 lr: 0.02\n",
      "iteration: 91370 loss: 0.0033 lr: 0.02\n",
      "iteration: 91380 loss: 0.0031 lr: 0.02\n",
      "iteration: 91390 loss: 0.0030 lr: 0.02\n",
      "iteration: 91400 loss: 0.0032 lr: 0.02\n",
      "iteration: 91410 loss: 0.0037 lr: 0.02\n",
      "iteration: 91420 loss: 0.0027 lr: 0.02\n",
      "iteration: 91430 loss: 0.0030 lr: 0.02\n",
      "iteration: 91440 loss: 0.0033 lr: 0.02\n",
      "iteration: 91450 loss: 0.0035 lr: 0.02\n",
      "iteration: 91460 loss: 0.0037 lr: 0.02\n",
      "iteration: 91470 loss: 0.0030 lr: 0.02\n",
      "iteration: 91480 loss: 0.0026 lr: 0.02\n",
      "iteration: 91490 loss: 0.0035 lr: 0.02\n",
      "iteration: 91500 loss: 0.0035 lr: 0.02\n",
      "iteration: 91510 loss: 0.0028 lr: 0.02\n",
      "iteration: 91520 loss: 0.0037 lr: 0.02\n",
      "iteration: 91530 loss: 0.0030 lr: 0.02\n",
      "iteration: 91540 loss: 0.0024 lr: 0.02\n",
      "iteration: 91550 loss: 0.0028 lr: 0.02\n",
      "iteration: 91560 loss: 0.0023 lr: 0.02\n",
      "iteration: 91570 loss: 0.0027 lr: 0.02\n",
      "iteration: 91580 loss: 0.0027 lr: 0.02\n",
      "iteration: 91590 loss: 0.0025 lr: 0.02\n",
      "iteration: 91600 loss: 0.0033 lr: 0.02\n",
      "iteration: 91610 loss: 0.0027 lr: 0.02\n",
      "iteration: 91620 loss: 0.0038 lr: 0.02\n",
      "iteration: 91630 loss: 0.0029 lr: 0.02\n",
      "iteration: 91640 loss: 0.0040 lr: 0.02\n",
      "iteration: 91650 loss: 0.0029 lr: 0.02\n",
      "iteration: 91660 loss: 0.0023 lr: 0.02\n",
      "iteration: 91670 loss: 0.0028 lr: 0.02\n",
      "iteration: 91680 loss: 0.0033 lr: 0.02\n",
      "iteration: 91690 loss: 0.0025 lr: 0.02\n",
      "iteration: 91700 loss: 0.0029 lr: 0.02\n",
      "iteration: 91710 loss: 0.0033 lr: 0.02\n",
      "iteration: 91720 loss: 0.0035 lr: 0.02\n",
      "iteration: 91730 loss: 0.0039 lr: 0.02\n",
      "iteration: 91740 loss: 0.0026 lr: 0.02\n",
      "iteration: 91750 loss: 0.0030 lr: 0.02\n",
      "iteration: 91760 loss: 0.0032 lr: 0.02\n",
      "iteration: 91770 loss: 0.0021 lr: 0.02\n",
      "iteration: 91780 loss: 0.0026 lr: 0.02\n",
      "iteration: 91790 loss: 0.0028 lr: 0.02\n",
      "iteration: 91800 loss: 0.0024 lr: 0.02\n",
      "iteration: 91810 loss: 0.0026 lr: 0.02\n",
      "iteration: 91820 loss: 0.0029 lr: 0.02\n",
      "iteration: 91830 loss: 0.0023 lr: 0.02\n",
      "iteration: 91840 loss: 0.0025 lr: 0.02\n",
      "iteration: 91850 loss: 0.0030 lr: 0.02\n",
      "iteration: 91860 loss: 0.0026 lr: 0.02\n",
      "iteration: 91870 loss: 0.0031 lr: 0.02\n",
      "iteration: 91880 loss: 0.0025 lr: 0.02\n",
      "iteration: 91890 loss: 0.0027 lr: 0.02\n",
      "iteration: 91900 loss: 0.0034 lr: 0.02\n",
      "iteration: 91910 loss: 0.0032 lr: 0.02\n",
      "iteration: 91920 loss: 0.0028 lr: 0.02\n",
      "iteration: 91930 loss: 0.0030 lr: 0.02\n",
      "iteration: 91940 loss: 0.0042 lr: 0.02\n",
      "iteration: 91950 loss: 0.0025 lr: 0.02\n",
      "iteration: 91960 loss: 0.0033 lr: 0.02\n",
      "iteration: 91970 loss: 0.0025 lr: 0.02\n",
      "iteration: 91980 loss: 0.0029 lr: 0.02\n",
      "iteration: 91990 loss: 0.0024 lr: 0.02\n",
      "iteration: 92000 loss: 0.0034 lr: 0.02\n",
      "iteration: 92010 loss: 0.0021 lr: 0.02\n",
      "iteration: 92020 loss: 0.0022 lr: 0.02\n",
      "iteration: 92030 loss: 0.0027 lr: 0.02\n",
      "iteration: 92040 loss: 0.0029 lr: 0.02\n",
      "iteration: 92050 loss: 0.0031 lr: 0.02\n",
      "iteration: 92060 loss: 0.0019 lr: 0.02\n",
      "iteration: 92070 loss: 0.0024 lr: 0.02\n",
      "iteration: 92080 loss: 0.0023 lr: 0.02\n",
      "iteration: 92090 loss: 0.0032 lr: 0.02\n",
      "iteration: 92100 loss: 0.0029 lr: 0.02\n",
      "iteration: 92110 loss: 0.0029 lr: 0.02\n",
      "iteration: 92120 loss: 0.0029 lr: 0.02\n",
      "iteration: 92130 loss: 0.0027 lr: 0.02\n",
      "iteration: 92140 loss: 0.0044 lr: 0.02\n",
      "iteration: 92150 loss: 0.0026 lr: 0.02\n",
      "iteration: 92160 loss: 0.0029 lr: 0.02\n",
      "iteration: 92170 loss: 0.0030 lr: 0.02\n",
      "iteration: 92180 loss: 0.0032 lr: 0.02\n",
      "iteration: 92190 loss: 0.0025 lr: 0.02\n",
      "iteration: 92200 loss: 0.0026 lr: 0.02\n",
      "iteration: 92210 loss: 0.0027 lr: 0.02\n",
      "iteration: 92220 loss: 0.0031 lr: 0.02\n",
      "iteration: 92230 loss: 0.0035 lr: 0.02\n",
      "iteration: 92240 loss: 0.0031 lr: 0.02\n",
      "iteration: 92250 loss: 0.0032 lr: 0.02\n",
      "iteration: 92260 loss: 0.0027 lr: 0.02\n",
      "iteration: 92270 loss: 0.0039 lr: 0.02\n",
      "iteration: 92280 loss: 0.0027 lr: 0.02\n",
      "iteration: 92290 loss: 0.0024 lr: 0.02\n",
      "iteration: 92300 loss: 0.0029 lr: 0.02\n",
      "iteration: 92310 loss: 0.0037 lr: 0.02\n",
      "iteration: 92320 loss: 0.0025 lr: 0.02\n",
      "iteration: 92330 loss: 0.0029 lr: 0.02\n",
      "iteration: 92340 loss: 0.0031 lr: 0.02\n",
      "iteration: 92350 loss: 0.0034 lr: 0.02\n",
      "iteration: 92360 loss: 0.0027 lr: 0.02\n",
      "iteration: 92370 loss: 0.0036 lr: 0.02\n",
      "iteration: 92380 loss: 0.0035 lr: 0.02\n",
      "iteration: 92390 loss: 0.0037 lr: 0.02\n",
      "iteration: 92400 loss: 0.0027 lr: 0.02\n",
      "iteration: 92410 loss: 0.0035 lr: 0.02\n",
      "iteration: 92420 loss: 0.0026 lr: 0.02\n",
      "iteration: 92430 loss: 0.0029 lr: 0.02\n",
      "iteration: 92440 loss: 0.0025 lr: 0.02\n",
      "iteration: 92450 loss: 0.0030 lr: 0.02\n",
      "iteration: 92460 loss: 0.0029 lr: 0.02\n",
      "iteration: 92470 loss: 0.0029 lr: 0.02\n",
      "iteration: 92480 loss: 0.0029 lr: 0.02\n",
      "iteration: 92490 loss: 0.0033 lr: 0.02\n",
      "iteration: 92500 loss: 0.0029 lr: 0.02\n",
      "iteration: 92510 loss: 0.0024 lr: 0.02\n",
      "iteration: 92520 loss: 0.0029 lr: 0.02\n",
      "iteration: 92530 loss: 0.0028 lr: 0.02\n",
      "iteration: 92540 loss: 0.0038 lr: 0.02\n",
      "iteration: 92550 loss: 0.0027 lr: 0.02\n",
      "iteration: 92560 loss: 0.0028 lr: 0.02\n",
      "iteration: 92570 loss: 0.0027 lr: 0.02\n",
      "iteration: 92580 loss: 0.0027 lr: 0.02\n",
      "iteration: 92590 loss: 0.0028 lr: 0.02\n",
      "iteration: 92600 loss: 0.0029 lr: 0.02\n",
      "iteration: 92610 loss: 0.0029 lr: 0.02\n",
      "iteration: 92620 loss: 0.0042 lr: 0.02\n",
      "iteration: 92630 loss: 0.0036 lr: 0.02\n",
      "iteration: 92640 loss: 0.0040 lr: 0.02\n",
      "iteration: 92650 loss: 0.0038 lr: 0.02\n",
      "iteration: 92660 loss: 0.0028 lr: 0.02\n",
      "iteration: 92670 loss: 0.0037 lr: 0.02\n",
      "iteration: 92680 loss: 0.0034 lr: 0.02\n",
      "iteration: 92690 loss: 0.0030 lr: 0.02\n",
      "iteration: 92700 loss: 0.0032 lr: 0.02\n",
      "iteration: 92710 loss: 0.0026 lr: 0.02\n",
      "iteration: 92720 loss: 0.0024 lr: 0.02\n",
      "iteration: 92730 loss: 0.0032 lr: 0.02\n",
      "iteration: 92740 loss: 0.0035 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 92750 loss: 0.0027 lr: 0.02\n",
      "iteration: 92760 loss: 0.0034 lr: 0.02\n",
      "iteration: 92770 loss: 0.0031 lr: 0.02\n",
      "iteration: 92780 loss: 0.0031 lr: 0.02\n",
      "iteration: 92790 loss: 0.0039 lr: 0.02\n",
      "iteration: 92800 loss: 0.0027 lr: 0.02\n",
      "iteration: 92810 loss: 0.0037 lr: 0.02\n",
      "iteration: 92820 loss: 0.0032 lr: 0.02\n",
      "iteration: 92830 loss: 0.0025 lr: 0.02\n",
      "iteration: 92840 loss: 0.0027 lr: 0.02\n",
      "iteration: 92850 loss: 0.0035 lr: 0.02\n",
      "iteration: 92860 loss: 0.0030 lr: 0.02\n",
      "iteration: 92870 loss: 0.0030 lr: 0.02\n",
      "iteration: 92880 loss: 0.0035 lr: 0.02\n",
      "iteration: 92890 loss: 0.0023 lr: 0.02\n",
      "iteration: 92900 loss: 0.0028 lr: 0.02\n",
      "iteration: 92910 loss: 0.0032 lr: 0.02\n",
      "iteration: 92920 loss: 0.0031 lr: 0.02\n",
      "iteration: 92930 loss: 0.0026 lr: 0.02\n",
      "iteration: 92940 loss: 0.0033 lr: 0.02\n",
      "iteration: 92950 loss: 0.0033 lr: 0.02\n",
      "iteration: 92960 loss: 0.0030 lr: 0.02\n",
      "iteration: 92970 loss: 0.0038 lr: 0.02\n",
      "iteration: 92980 loss: 0.0030 lr: 0.02\n",
      "iteration: 92990 loss: 0.0029 lr: 0.02\n",
      "iteration: 93000 loss: 0.0034 lr: 0.02\n",
      "iteration: 93010 loss: 0.0031 lr: 0.02\n",
      "iteration: 93020 loss: 0.0034 lr: 0.02\n",
      "iteration: 93030 loss: 0.0027 lr: 0.02\n",
      "iteration: 93040 loss: 0.0025 lr: 0.02\n",
      "iteration: 93050 loss: 0.0035 lr: 0.02\n",
      "iteration: 93060 loss: 0.0030 lr: 0.02\n",
      "iteration: 93070 loss: 0.0032 lr: 0.02\n",
      "iteration: 93080 loss: 0.0037 lr: 0.02\n",
      "iteration: 93090 loss: 0.0025 lr: 0.02\n",
      "iteration: 93100 loss: 0.0031 lr: 0.02\n",
      "iteration: 93110 loss: 0.0025 lr: 0.02\n",
      "iteration: 93120 loss: 0.0024 lr: 0.02\n",
      "iteration: 93130 loss: 0.0028 lr: 0.02\n",
      "iteration: 93140 loss: 0.0026 lr: 0.02\n",
      "iteration: 93150 loss: 0.0028 lr: 0.02\n",
      "iteration: 93160 loss: 0.0035 lr: 0.02\n",
      "iteration: 93170 loss: 0.0028 lr: 0.02\n",
      "iteration: 93180 loss: 0.0036 lr: 0.02\n",
      "iteration: 93190 loss: 0.0028 lr: 0.02\n",
      "iteration: 93200 loss: 0.0031 lr: 0.02\n",
      "iteration: 93210 loss: 0.0035 lr: 0.02\n",
      "iteration: 93220 loss: 0.0029 lr: 0.02\n",
      "iteration: 93230 loss: 0.0026 lr: 0.02\n",
      "iteration: 93240 loss: 0.0042 lr: 0.02\n",
      "iteration: 93250 loss: 0.0028 lr: 0.02\n",
      "iteration: 93260 loss: 0.0025 lr: 0.02\n",
      "iteration: 93270 loss: 0.0041 lr: 0.02\n",
      "iteration: 93280 loss: 0.0028 lr: 0.02\n",
      "iteration: 93290 loss: 0.0033 lr: 0.02\n",
      "iteration: 93300 loss: 0.0031 lr: 0.02\n",
      "iteration: 93310 loss: 0.0028 lr: 0.02\n",
      "iteration: 93320 loss: 0.0031 lr: 0.02\n",
      "iteration: 93330 loss: 0.0033 lr: 0.02\n",
      "iteration: 93340 loss: 0.0031 lr: 0.02\n",
      "iteration: 93350 loss: 0.0029 lr: 0.02\n",
      "iteration: 93360 loss: 0.0027 lr: 0.02\n",
      "iteration: 93370 loss: 0.0034 lr: 0.02\n",
      "iteration: 93380 loss: 0.0030 lr: 0.02\n",
      "iteration: 93390 loss: 0.0038 lr: 0.02\n",
      "iteration: 93400 loss: 0.0044 lr: 0.02\n",
      "iteration: 93410 loss: 0.0032 lr: 0.02\n",
      "iteration: 93420 loss: 0.0025 lr: 0.02\n",
      "iteration: 93430 loss: 0.0027 lr: 0.02\n",
      "iteration: 93440 loss: 0.0023 lr: 0.02\n",
      "iteration: 93450 loss: 0.0031 lr: 0.02\n",
      "iteration: 93460 loss: 0.0031 lr: 0.02\n",
      "iteration: 93470 loss: 0.0028 lr: 0.02\n",
      "iteration: 93480 loss: 0.0029 lr: 0.02\n",
      "iteration: 93490 loss: 0.0030 lr: 0.02\n",
      "iteration: 93500 loss: 0.0040 lr: 0.02\n",
      "iteration: 93510 loss: 0.0033 lr: 0.02\n",
      "iteration: 93520 loss: 0.0032 lr: 0.02\n",
      "iteration: 93530 loss: 0.0034 lr: 0.02\n",
      "iteration: 93540 loss: 0.0026 lr: 0.02\n",
      "iteration: 93550 loss: 0.0025 lr: 0.02\n",
      "iteration: 93560 loss: 0.0031 lr: 0.02\n",
      "iteration: 93570 loss: 0.0031 lr: 0.02\n",
      "iteration: 93580 loss: 0.0025 lr: 0.02\n",
      "iteration: 93590 loss: 0.0028 lr: 0.02\n",
      "iteration: 93600 loss: 0.0033 lr: 0.02\n",
      "iteration: 93610 loss: 0.0030 lr: 0.02\n",
      "iteration: 93620 loss: 0.0039 lr: 0.02\n",
      "iteration: 93630 loss: 0.0027 lr: 0.02\n",
      "iteration: 93640 loss: 0.0026 lr: 0.02\n",
      "iteration: 93650 loss: 0.0022 lr: 0.02\n",
      "iteration: 93660 loss: 0.0031 lr: 0.02\n",
      "iteration: 93670 loss: 0.0031 lr: 0.02\n",
      "iteration: 93680 loss: 0.0037 lr: 0.02\n",
      "iteration: 93690 loss: 0.0026 lr: 0.02\n",
      "iteration: 93700 loss: 0.0022 lr: 0.02\n",
      "iteration: 93710 loss: 0.0028 lr: 0.02\n",
      "iteration: 93720 loss: 0.0025 lr: 0.02\n",
      "iteration: 93730 loss: 0.0027 lr: 0.02\n",
      "iteration: 93740 loss: 0.0029 lr: 0.02\n",
      "iteration: 93750 loss: 0.0026 lr: 0.02\n",
      "iteration: 93760 loss: 0.0048 lr: 0.02\n",
      "iteration: 93770 loss: 0.0024 lr: 0.02\n",
      "iteration: 93780 loss: 0.0038 lr: 0.02\n",
      "iteration: 93790 loss: 0.0034 lr: 0.02\n",
      "iteration: 93800 loss: 0.0039 lr: 0.02\n",
      "iteration: 93810 loss: 0.0026 lr: 0.02\n",
      "iteration: 93820 loss: 0.0035 lr: 0.02\n",
      "iteration: 93830 loss: 0.0029 lr: 0.02\n",
      "iteration: 93840 loss: 0.0025 lr: 0.02\n",
      "iteration: 93850 loss: 0.0034 lr: 0.02\n",
      "iteration: 93860 loss: 0.0041 lr: 0.02\n",
      "iteration: 93870 loss: 0.0031 lr: 0.02\n",
      "iteration: 93880 loss: 0.0031 lr: 0.02\n",
      "iteration: 93890 loss: 0.0031 lr: 0.02\n",
      "iteration: 93900 loss: 0.0026 lr: 0.02\n",
      "iteration: 93910 loss: 0.0025 lr: 0.02\n",
      "iteration: 93920 loss: 0.0030 lr: 0.02\n",
      "iteration: 93930 loss: 0.0034 lr: 0.02\n",
      "iteration: 93940 loss: 0.0025 lr: 0.02\n",
      "iteration: 93950 loss: 0.0031 lr: 0.02\n",
      "iteration: 93960 loss: 0.0024 lr: 0.02\n",
      "iteration: 93970 loss: 0.0026 lr: 0.02\n",
      "iteration: 93980 loss: 0.0027 lr: 0.02\n",
      "iteration: 93990 loss: 0.0023 lr: 0.02\n",
      "iteration: 94000 loss: 0.0031 lr: 0.02\n",
      "iteration: 94010 loss: 0.0033 lr: 0.02\n",
      "iteration: 94020 loss: 0.0031 lr: 0.02\n",
      "iteration: 94030 loss: 0.0031 lr: 0.02\n",
      "iteration: 94040 loss: 0.0023 lr: 0.02\n",
      "iteration: 94050 loss: 0.0029 lr: 0.02\n",
      "iteration: 94060 loss: 0.0031 lr: 0.02\n",
      "iteration: 94070 loss: 0.0026 lr: 0.02\n",
      "iteration: 94080 loss: 0.0024 lr: 0.02\n",
      "iteration: 94090 loss: 0.0036 lr: 0.02\n",
      "iteration: 94100 loss: 0.0033 lr: 0.02\n",
      "iteration: 94110 loss: 0.0029 lr: 0.02\n",
      "iteration: 94120 loss: 0.0027 lr: 0.02\n",
      "iteration: 94130 loss: 0.0047 lr: 0.02\n",
      "iteration: 94140 loss: 0.0027 lr: 0.02\n",
      "iteration: 94150 loss: 0.0032 lr: 0.02\n",
      "iteration: 94160 loss: 0.0023 lr: 0.02\n",
      "iteration: 94170 loss: 0.0027 lr: 0.02\n",
      "iteration: 94180 loss: 0.0033 lr: 0.02\n",
      "iteration: 94190 loss: 0.0034 lr: 0.02\n",
      "iteration: 94200 loss: 0.0026 lr: 0.02\n",
      "iteration: 94210 loss: 0.0027 lr: 0.02\n",
      "iteration: 94220 loss: 0.0024 lr: 0.02\n",
      "iteration: 94230 loss: 0.0026 lr: 0.02\n",
      "iteration: 94240 loss: 0.0024 lr: 0.02\n",
      "iteration: 94250 loss: 0.0036 lr: 0.02\n",
      "iteration: 94260 loss: 0.0025 lr: 0.02\n",
      "iteration: 94270 loss: 0.0022 lr: 0.02\n",
      "iteration: 94280 loss: 0.0044 lr: 0.02\n",
      "iteration: 94290 loss: 0.0022 lr: 0.02\n",
      "iteration: 94300 loss: 0.0043 lr: 0.02\n",
      "iteration: 94310 loss: 0.0034 lr: 0.02\n",
      "iteration: 94320 loss: 0.0032 lr: 0.02\n",
      "iteration: 94330 loss: 0.0032 lr: 0.02\n",
      "iteration: 94340 loss: 0.0026 lr: 0.02\n",
      "iteration: 94350 loss: 0.0026 lr: 0.02\n",
      "iteration: 94360 loss: 0.0038 lr: 0.02\n",
      "iteration: 94370 loss: 0.0022 lr: 0.02\n",
      "iteration: 94380 loss: 0.0036 lr: 0.02\n",
      "iteration: 94390 loss: 0.0033 lr: 0.02\n",
      "iteration: 94400 loss: 0.0030 lr: 0.02\n",
      "iteration: 94410 loss: 0.0028 lr: 0.02\n",
      "iteration: 94420 loss: 0.0029 lr: 0.02\n",
      "iteration: 94430 loss: 0.0027 lr: 0.02\n",
      "iteration: 94440 loss: 0.0023 lr: 0.02\n",
      "iteration: 94450 loss: 0.0025 lr: 0.02\n",
      "iteration: 94460 loss: 0.0028 lr: 0.02\n",
      "iteration: 94470 loss: 0.0025 lr: 0.02\n",
      "iteration: 94480 loss: 0.0037 lr: 0.02\n",
      "iteration: 94490 loss: 0.0022 lr: 0.02\n",
      "iteration: 94500 loss: 0.0030 lr: 0.02\n",
      "iteration: 94510 loss: 0.0026 lr: 0.02\n",
      "iteration: 94520 loss: 0.0031 lr: 0.02\n",
      "iteration: 94530 loss: 0.0027 lr: 0.02\n",
      "iteration: 94540 loss: 0.0027 lr: 0.02\n",
      "iteration: 94550 loss: 0.0035 lr: 0.02\n",
      "iteration: 94560 loss: 0.0028 lr: 0.02\n",
      "iteration: 94570 loss: 0.0035 lr: 0.02\n",
      "iteration: 94580 loss: 0.0034 lr: 0.02\n",
      "iteration: 94590 loss: 0.0030 lr: 0.02\n",
      "iteration: 94600 loss: 0.0036 lr: 0.02\n",
      "iteration: 94610 loss: 0.0026 lr: 0.02\n",
      "iteration: 94620 loss: 0.0029 lr: 0.02\n",
      "iteration: 94630 loss: 0.0027 lr: 0.02\n",
      "iteration: 94640 loss: 0.0030 lr: 0.02\n",
      "iteration: 94650 loss: 0.0027 lr: 0.02\n",
      "iteration: 94660 loss: 0.0031 lr: 0.02\n",
      "iteration: 94670 loss: 0.0020 lr: 0.02\n",
      "iteration: 94680 loss: 0.0020 lr: 0.02\n",
      "iteration: 94690 loss: 0.0029 lr: 0.02\n",
      "iteration: 94700 loss: 0.0034 lr: 0.02\n",
      "iteration: 94710 loss: 0.0032 lr: 0.02\n",
      "iteration: 94720 loss: 0.0024 lr: 0.02\n",
      "iteration: 94730 loss: 0.0026 lr: 0.02\n",
      "iteration: 94740 loss: 0.0027 lr: 0.02\n",
      "iteration: 94750 loss: 0.0023 lr: 0.02\n",
      "iteration: 94760 loss: 0.0039 lr: 0.02\n",
      "iteration: 94770 loss: 0.0022 lr: 0.02\n",
      "iteration: 94780 loss: 0.0031 lr: 0.02\n",
      "iteration: 94790 loss: 0.0033 lr: 0.02\n",
      "iteration: 94800 loss: 0.0026 lr: 0.02\n",
      "iteration: 94810 loss: 0.0024 lr: 0.02\n",
      "iteration: 94820 loss: 0.0027 lr: 0.02\n",
      "iteration: 94830 loss: 0.0030 lr: 0.02\n",
      "iteration: 94840 loss: 0.0031 lr: 0.02\n",
      "iteration: 94850 loss: 0.0027 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 94860 loss: 0.0025 lr: 0.02\n",
      "iteration: 94870 loss: 0.0027 lr: 0.02\n",
      "iteration: 94880 loss: 0.0024 lr: 0.02\n",
      "iteration: 94890 loss: 0.0029 lr: 0.02\n",
      "iteration: 94900 loss: 0.0024 lr: 0.02\n",
      "iteration: 94910 loss: 0.0030 lr: 0.02\n",
      "iteration: 94920 loss: 0.0028 lr: 0.02\n",
      "iteration: 94930 loss: 0.0027 lr: 0.02\n",
      "iteration: 94940 loss: 0.0025 lr: 0.02\n",
      "iteration: 94950 loss: 0.0029 lr: 0.02\n",
      "iteration: 94960 loss: 0.0024 lr: 0.02\n",
      "iteration: 94970 loss: 0.0035 lr: 0.02\n",
      "iteration: 94980 loss: 0.0028 lr: 0.02\n",
      "iteration: 94990 loss: 0.0037 lr: 0.02\n",
      "iteration: 95000 loss: 0.0026 lr: 0.02\n",
      "iteration: 95010 loss: 0.0024 lr: 0.02\n",
      "iteration: 95020 loss: 0.0034 lr: 0.02\n",
      "iteration: 95030 loss: 0.0033 lr: 0.02\n",
      "iteration: 95040 loss: 0.0028 lr: 0.02\n",
      "iteration: 95050 loss: 0.0041 lr: 0.02\n",
      "iteration: 95060 loss: 0.0027 lr: 0.02\n",
      "iteration: 95070 loss: 0.0024 lr: 0.02\n",
      "iteration: 95080 loss: 0.0033 lr: 0.02\n",
      "iteration: 95090 loss: 0.0026 lr: 0.02\n",
      "iteration: 95100 loss: 0.0028 lr: 0.02\n",
      "iteration: 95110 loss: 0.0030 lr: 0.02\n",
      "iteration: 95120 loss: 0.0026 lr: 0.02\n",
      "iteration: 95130 loss: 0.0036 lr: 0.02\n",
      "iteration: 95140 loss: 0.0024 lr: 0.02\n",
      "iteration: 95150 loss: 0.0032 lr: 0.02\n",
      "iteration: 95160 loss: 0.0031 lr: 0.02\n",
      "iteration: 95170 loss: 0.0025 lr: 0.02\n",
      "iteration: 95180 loss: 0.0027 lr: 0.02\n",
      "iteration: 95190 loss: 0.0028 lr: 0.02\n",
      "iteration: 95200 loss: 0.0033 lr: 0.02\n",
      "iteration: 95210 loss: 0.0034 lr: 0.02\n",
      "iteration: 95220 loss: 0.0036 lr: 0.02\n",
      "iteration: 95230 loss: 0.0033 lr: 0.02\n",
      "iteration: 95240 loss: 0.0029 lr: 0.02\n",
      "iteration: 95250 loss: 0.0030 lr: 0.02\n",
      "iteration: 95260 loss: 0.0027 lr: 0.02\n",
      "iteration: 95270 loss: 0.0032 lr: 0.02\n",
      "iteration: 95280 loss: 0.0038 lr: 0.02\n",
      "iteration: 95290 loss: 0.0023 lr: 0.02\n",
      "iteration: 95300 loss: 0.0030 lr: 0.02\n",
      "iteration: 95310 loss: 0.0025 lr: 0.02\n",
      "iteration: 95320 loss: 0.0038 lr: 0.02\n",
      "iteration: 95330 loss: 0.0028 lr: 0.02\n",
      "iteration: 95340 loss: 0.0028 lr: 0.02\n",
      "iteration: 95350 loss: 0.0022 lr: 0.02\n",
      "iteration: 95360 loss: 0.0022 lr: 0.02\n",
      "iteration: 95370 loss: 0.0029 lr: 0.02\n",
      "iteration: 95380 loss: 0.0030 lr: 0.02\n",
      "iteration: 95390 loss: 0.0029 lr: 0.02\n",
      "iteration: 95400 loss: 0.0030 lr: 0.02\n",
      "iteration: 95410 loss: 0.0022 lr: 0.02\n",
      "iteration: 95420 loss: 0.0027 lr: 0.02\n",
      "iteration: 95430 loss: 0.0039 lr: 0.02\n",
      "iteration: 95440 loss: 0.0027 lr: 0.02\n",
      "iteration: 95450 loss: 0.0026 lr: 0.02\n",
      "iteration: 95460 loss: 0.0028 lr: 0.02\n",
      "iteration: 95470 loss: 0.0026 lr: 0.02\n",
      "iteration: 95480 loss: 0.0031 lr: 0.02\n",
      "iteration: 95490 loss: 0.0027 lr: 0.02\n",
      "iteration: 95500 loss: 0.0032 lr: 0.02\n",
      "iteration: 95510 loss: 0.0040 lr: 0.02\n",
      "iteration: 95520 loss: 0.0027 lr: 0.02\n",
      "iteration: 95530 loss: 0.0033 lr: 0.02\n",
      "iteration: 95540 loss: 0.0024 lr: 0.02\n",
      "iteration: 95550 loss: 0.0033 lr: 0.02\n",
      "iteration: 95560 loss: 0.0038 lr: 0.02\n",
      "iteration: 95570 loss: 0.0041 lr: 0.02\n",
      "iteration: 95580 loss: 0.0028 lr: 0.02\n",
      "iteration: 95590 loss: 0.0026 lr: 0.02\n",
      "iteration: 95600 loss: 0.0025 lr: 0.02\n",
      "iteration: 95610 loss: 0.0026 lr: 0.02\n",
      "iteration: 95620 loss: 0.0027 lr: 0.02\n",
      "iteration: 95630 loss: 0.0024 lr: 0.02\n",
      "iteration: 95640 loss: 0.0025 lr: 0.02\n",
      "iteration: 95650 loss: 0.0033 lr: 0.02\n",
      "iteration: 95660 loss: 0.0025 lr: 0.02\n",
      "iteration: 95670 loss: 0.0032 lr: 0.02\n",
      "iteration: 95680 loss: 0.0032 lr: 0.02\n",
      "iteration: 95690 loss: 0.0025 lr: 0.02\n",
      "iteration: 95700 loss: 0.0028 lr: 0.02\n",
      "iteration: 95710 loss: 0.0038 lr: 0.02\n",
      "iteration: 95720 loss: 0.0029 lr: 0.02\n",
      "iteration: 95730 loss: 0.0031 lr: 0.02\n",
      "iteration: 95740 loss: 0.0034 lr: 0.02\n",
      "iteration: 95750 loss: 0.0029 lr: 0.02\n",
      "iteration: 95760 loss: 0.0028 lr: 0.02\n",
      "iteration: 95770 loss: 0.0030 lr: 0.02\n",
      "iteration: 95780 loss: 0.0025 lr: 0.02\n",
      "iteration: 95790 loss: 0.0027 lr: 0.02\n",
      "iteration: 95800 loss: 0.0027 lr: 0.02\n",
      "iteration: 95810 loss: 0.0030 lr: 0.02\n",
      "iteration: 95820 loss: 0.0030 lr: 0.02\n",
      "iteration: 95830 loss: 0.0033 lr: 0.02\n",
      "iteration: 95840 loss: 0.0027 lr: 0.02\n",
      "iteration: 95850 loss: 0.0025 lr: 0.02\n",
      "iteration: 95860 loss: 0.0030 lr: 0.02\n",
      "iteration: 95870 loss: 0.0028 lr: 0.02\n",
      "iteration: 95880 loss: 0.0033 lr: 0.02\n",
      "iteration: 95890 loss: 0.0029 lr: 0.02\n",
      "iteration: 95900 loss: 0.0029 lr: 0.02\n",
      "iteration: 95910 loss: 0.0028 lr: 0.02\n",
      "iteration: 95920 loss: 0.0024 lr: 0.02\n",
      "iteration: 95930 loss: 0.0030 lr: 0.02\n",
      "iteration: 95940 loss: 0.0043 lr: 0.02\n",
      "iteration: 95950 loss: 0.0044 lr: 0.02\n",
      "iteration: 95960 loss: 0.0031 lr: 0.02\n",
      "iteration: 95970 loss: 0.0025 lr: 0.02\n",
      "iteration: 95980 loss: 0.0026 lr: 0.02\n",
      "iteration: 95990 loss: 0.0026 lr: 0.02\n",
      "iteration: 96000 loss: 0.0033 lr: 0.02\n",
      "iteration: 96010 loss: 0.0026 lr: 0.02\n",
      "iteration: 96020 loss: 0.0030 lr: 0.02\n",
      "iteration: 96030 loss: 0.0029 lr: 0.02\n",
      "iteration: 96040 loss: 0.0028 lr: 0.02\n",
      "iteration: 96050 loss: 0.0028 lr: 0.02\n",
      "iteration: 96060 loss: 0.0039 lr: 0.02\n",
      "iteration: 96070 loss: 0.0025 lr: 0.02\n",
      "iteration: 96080 loss: 0.0031 lr: 0.02\n",
      "iteration: 96090 loss: 0.0026 lr: 0.02\n",
      "iteration: 96100 loss: 0.0023 lr: 0.02\n",
      "iteration: 96110 loss: 0.0037 lr: 0.02\n",
      "iteration: 96120 loss: 0.0030 lr: 0.02\n",
      "iteration: 96130 loss: 0.0033 lr: 0.02\n",
      "iteration: 96140 loss: 0.0031 lr: 0.02\n",
      "iteration: 96150 loss: 0.0032 lr: 0.02\n",
      "iteration: 96160 loss: 0.0032 lr: 0.02\n",
      "iteration: 96170 loss: 0.0033 lr: 0.02\n",
      "iteration: 96180 loss: 0.0028 lr: 0.02\n",
      "iteration: 96190 loss: 0.0024 lr: 0.02\n",
      "iteration: 96200 loss: 0.0030 lr: 0.02\n",
      "iteration: 96210 loss: 0.0029 lr: 0.02\n",
      "iteration: 96220 loss: 0.0023 lr: 0.02\n",
      "iteration: 96230 loss: 0.0025 lr: 0.02\n",
      "iteration: 96240 loss: 0.0027 lr: 0.02\n",
      "iteration: 96250 loss: 0.0027 lr: 0.02\n",
      "iteration: 96260 loss: 0.0031 lr: 0.02\n",
      "iteration: 96270 loss: 0.0028 lr: 0.02\n",
      "iteration: 96280 loss: 0.0024 lr: 0.02\n",
      "iteration: 96290 loss: 0.0031 lr: 0.02\n",
      "iteration: 96300 loss: 0.0030 lr: 0.02\n",
      "iteration: 96310 loss: 0.0035 lr: 0.02\n",
      "iteration: 96320 loss: 0.0029 lr: 0.02\n",
      "iteration: 96330 loss: 0.0033 lr: 0.02\n",
      "iteration: 96340 loss: 0.0027 lr: 0.02\n",
      "iteration: 96350 loss: 0.0028 lr: 0.02\n",
      "iteration: 96360 loss: 0.0024 lr: 0.02\n",
      "iteration: 96370 loss: 0.0029 lr: 0.02\n",
      "iteration: 96380 loss: 0.0030 lr: 0.02\n",
      "iteration: 96390 loss: 0.0026 lr: 0.02\n",
      "iteration: 96400 loss: 0.0030 lr: 0.02\n",
      "iteration: 96410 loss: 0.0032 lr: 0.02\n",
      "iteration: 96420 loss: 0.0024 lr: 0.02\n",
      "iteration: 96430 loss: 0.0038 lr: 0.02\n",
      "iteration: 96440 loss: 0.0032 lr: 0.02\n",
      "iteration: 96450 loss: 0.0024 lr: 0.02\n",
      "iteration: 96460 loss: 0.0025 lr: 0.02\n",
      "iteration: 96470 loss: 0.0025 lr: 0.02\n",
      "iteration: 96480 loss: 0.0026 lr: 0.02\n",
      "iteration: 96490 loss: 0.0031 lr: 0.02\n",
      "iteration: 96500 loss: 0.0028 lr: 0.02\n",
      "iteration: 96510 loss: 0.0024 lr: 0.02\n",
      "iteration: 96520 loss: 0.0038 lr: 0.02\n",
      "iteration: 96530 loss: 0.0027 lr: 0.02\n",
      "iteration: 96540 loss: 0.0031 lr: 0.02\n",
      "iteration: 96550 loss: 0.0042 lr: 0.02\n",
      "iteration: 96560 loss: 0.0032 lr: 0.02\n",
      "iteration: 96570 loss: 0.0034 lr: 0.02\n",
      "iteration: 96580 loss: 0.0029 lr: 0.02\n",
      "iteration: 96590 loss: 0.0038 lr: 0.02\n",
      "iteration: 96600 loss: 0.0024 lr: 0.02\n",
      "iteration: 96610 loss: 0.0034 lr: 0.02\n",
      "iteration: 96620 loss: 0.0021 lr: 0.02\n",
      "iteration: 96630 loss: 0.0026 lr: 0.02\n",
      "iteration: 96640 loss: 0.0027 lr: 0.02\n",
      "iteration: 96650 loss: 0.0026 lr: 0.02\n",
      "iteration: 96660 loss: 0.0022 lr: 0.02\n",
      "iteration: 96670 loss: 0.0027 lr: 0.02\n",
      "iteration: 96680 loss: 0.0022 lr: 0.02\n",
      "iteration: 96690 loss: 0.0026 lr: 0.02\n",
      "iteration: 96700 loss: 0.0036 lr: 0.02\n",
      "iteration: 96710 loss: 0.0025 lr: 0.02\n",
      "iteration: 96720 loss: 0.0028 lr: 0.02\n",
      "iteration: 96730 loss: 0.0033 lr: 0.02\n",
      "iteration: 96740 loss: 0.0024 lr: 0.02\n",
      "iteration: 96750 loss: 0.0033 lr: 0.02\n",
      "iteration: 96760 loss: 0.0029 lr: 0.02\n",
      "iteration: 96770 loss: 0.0029 lr: 0.02\n",
      "iteration: 96780 loss: 0.0023 lr: 0.02\n",
      "iteration: 96790 loss: 0.0025 lr: 0.02\n",
      "iteration: 96800 loss: 0.0027 lr: 0.02\n",
      "iteration: 96810 loss: 0.0019 lr: 0.02\n",
      "iteration: 96820 loss: 0.0036 lr: 0.02\n",
      "iteration: 96830 loss: 0.0027 lr: 0.02\n",
      "iteration: 96840 loss: 0.0027 lr: 0.02\n",
      "iteration: 96850 loss: 0.0024 lr: 0.02\n",
      "iteration: 96860 loss: 0.0030 lr: 0.02\n",
      "iteration: 96870 loss: 0.0041 lr: 0.02\n",
      "iteration: 96880 loss: 0.0026 lr: 0.02\n",
      "iteration: 96890 loss: 0.0033 lr: 0.02\n",
      "iteration: 96900 loss: 0.0032 lr: 0.02\n",
      "iteration: 96910 loss: 0.0026 lr: 0.02\n",
      "iteration: 96920 loss: 0.0034 lr: 0.02\n",
      "iteration: 96930 loss: 0.0032 lr: 0.02\n",
      "iteration: 96940 loss: 0.0034 lr: 0.02\n",
      "iteration: 96950 loss: 0.0027 lr: 0.02\n",
      "iteration: 96960 loss: 0.0031 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 96970 loss: 0.0025 lr: 0.02\n",
      "iteration: 96980 loss: 0.0028 lr: 0.02\n",
      "iteration: 96990 loss: 0.0026 lr: 0.02\n",
      "iteration: 97000 loss: 0.0027 lr: 0.02\n",
      "iteration: 97010 loss: 0.0029 lr: 0.02\n",
      "iteration: 97020 loss: 0.0023 lr: 0.02\n",
      "iteration: 97030 loss: 0.0031 lr: 0.02\n",
      "iteration: 97040 loss: 0.0026 lr: 0.02\n",
      "iteration: 97050 loss: 0.0027 lr: 0.02\n",
      "iteration: 97060 loss: 0.0032 lr: 0.02\n",
      "iteration: 97070 loss: 0.0035 lr: 0.02\n",
      "iteration: 97080 loss: 0.0023 lr: 0.02\n",
      "iteration: 97090 loss: 0.0025 lr: 0.02\n",
      "iteration: 97100 loss: 0.0024 lr: 0.02\n",
      "iteration: 97110 loss: 0.0034 lr: 0.02\n",
      "iteration: 97120 loss: 0.0034 lr: 0.02\n",
      "iteration: 97130 loss: 0.0028 lr: 0.02\n",
      "iteration: 97140 loss: 0.0030 lr: 0.02\n",
      "iteration: 97150 loss: 0.0027 lr: 0.02\n",
      "iteration: 97160 loss: 0.0043 lr: 0.02\n",
      "iteration: 97170 loss: 0.0031 lr: 0.02\n",
      "iteration: 97180 loss: 0.0023 lr: 0.02\n",
      "iteration: 97190 loss: 0.0025 lr: 0.02\n",
      "iteration: 97200 loss: 0.0025 lr: 0.02\n",
      "iteration: 97210 loss: 0.0038 lr: 0.02\n",
      "iteration: 97220 loss: 0.0031 lr: 0.02\n",
      "iteration: 97230 loss: 0.0025 lr: 0.02\n",
      "iteration: 97240 loss: 0.0032 lr: 0.02\n",
      "iteration: 97250 loss: 0.0033 lr: 0.02\n",
      "iteration: 97260 loss: 0.0031 lr: 0.02\n",
      "iteration: 97270 loss: 0.0022 lr: 0.02\n",
      "iteration: 97280 loss: 0.0020 lr: 0.02\n",
      "iteration: 97290 loss: 0.0024 lr: 0.02\n",
      "iteration: 97300 loss: 0.0026 lr: 0.02\n",
      "iteration: 97310 loss: 0.0027 lr: 0.02\n",
      "iteration: 97320 loss: 0.0032 lr: 0.02\n",
      "iteration: 97330 loss: 0.0023 lr: 0.02\n",
      "iteration: 97340 loss: 0.0032 lr: 0.02\n",
      "iteration: 97350 loss: 0.0028 lr: 0.02\n",
      "iteration: 97360 loss: 0.0027 lr: 0.02\n",
      "iteration: 97370 loss: 0.0035 lr: 0.02\n",
      "iteration: 97380 loss: 0.0027 lr: 0.02\n",
      "iteration: 97390 loss: 0.0046 lr: 0.02\n",
      "iteration: 97400 loss: 0.0037 lr: 0.02\n",
      "iteration: 97410 loss: 0.0029 lr: 0.02\n",
      "iteration: 97420 loss: 0.0040 lr: 0.02\n",
      "iteration: 97430 loss: 0.0037 lr: 0.02\n",
      "iteration: 97440 loss: 0.0033 lr: 0.02\n",
      "iteration: 97450 loss: 0.0026 lr: 0.02\n",
      "iteration: 97460 loss: 0.0026 lr: 0.02\n",
      "iteration: 97470 loss: 0.0028 lr: 0.02\n",
      "iteration: 97480 loss: 0.0024 lr: 0.02\n",
      "iteration: 97490 loss: 0.0047 lr: 0.02\n",
      "iteration: 97500 loss: 0.0028 lr: 0.02\n",
      "iteration: 97510 loss: 0.0024 lr: 0.02\n",
      "iteration: 97520 loss: 0.0025 lr: 0.02\n",
      "iteration: 97530 loss: 0.0028 lr: 0.02\n",
      "iteration: 97540 loss: 0.0025 lr: 0.02\n",
      "iteration: 97550 loss: 0.0027 lr: 0.02\n",
      "iteration: 97560 loss: 0.0026 lr: 0.02\n",
      "iteration: 97570 loss: 0.0038 lr: 0.02\n",
      "iteration: 97580 loss: 0.0030 lr: 0.02\n",
      "iteration: 97590 loss: 0.0029 lr: 0.02\n",
      "iteration: 97600 loss: 0.0026 lr: 0.02\n",
      "iteration: 97610 loss: 0.0038 lr: 0.02\n",
      "iteration: 97620 loss: 0.0023 lr: 0.02\n",
      "iteration: 97630 loss: 0.0033 lr: 0.02\n",
      "iteration: 97640 loss: 0.0031 lr: 0.02\n",
      "iteration: 97650 loss: 0.0031 lr: 0.02\n",
      "iteration: 97660 loss: 0.0031 lr: 0.02\n",
      "iteration: 97670 loss: 0.0030 lr: 0.02\n",
      "iteration: 97680 loss: 0.0037 lr: 0.02\n",
      "iteration: 97690 loss: 0.0029 lr: 0.02\n",
      "iteration: 97700 loss: 0.0028 lr: 0.02\n",
      "iteration: 97710 loss: 0.0030 lr: 0.02\n",
      "iteration: 97720 loss: 0.0028 lr: 0.02\n",
      "iteration: 97730 loss: 0.0028 lr: 0.02\n",
      "iteration: 97740 loss: 0.0033 lr: 0.02\n",
      "iteration: 97750 loss: 0.0034 lr: 0.02\n",
      "iteration: 97760 loss: 0.0030 lr: 0.02\n",
      "iteration: 97770 loss: 0.0030 lr: 0.02\n",
      "iteration: 97780 loss: 0.0024 lr: 0.02\n",
      "iteration: 97790 loss: 0.0025 lr: 0.02\n",
      "iteration: 97800 loss: 0.0025 lr: 0.02\n",
      "iteration: 97810 loss: 0.0027 lr: 0.02\n",
      "iteration: 97820 loss: 0.0028 lr: 0.02\n",
      "iteration: 97830 loss: 0.0032 lr: 0.02\n",
      "iteration: 97840 loss: 0.0029 lr: 0.02\n",
      "iteration: 97850 loss: 0.0028 lr: 0.02\n",
      "iteration: 97860 loss: 0.0033 lr: 0.02\n",
      "iteration: 97870 loss: 0.0026 lr: 0.02\n",
      "iteration: 97880 loss: 0.0033 lr: 0.02\n",
      "iteration: 97890 loss: 0.0030 lr: 0.02\n",
      "iteration: 97900 loss: 0.0031 lr: 0.02\n",
      "iteration: 97910 loss: 0.0030 lr: 0.02\n",
      "iteration: 97920 loss: 0.0022 lr: 0.02\n",
      "iteration: 97930 loss: 0.0026 lr: 0.02\n",
      "iteration: 97940 loss: 0.0022 lr: 0.02\n",
      "iteration: 97950 loss: 0.0028 lr: 0.02\n",
      "iteration: 97960 loss: 0.0025 lr: 0.02\n",
      "iteration: 97970 loss: 0.0026 lr: 0.02\n",
      "iteration: 97980 loss: 0.0023 lr: 0.02\n",
      "iteration: 97990 loss: 0.0025 lr: 0.02\n",
      "iteration: 98000 loss: 0.0026 lr: 0.02\n",
      "iteration: 98010 loss: 0.0027 lr: 0.02\n",
      "iteration: 98020 loss: 0.0030 lr: 0.02\n",
      "iteration: 98030 loss: 0.0027 lr: 0.02\n",
      "iteration: 98040 loss: 0.0022 lr: 0.02\n",
      "iteration: 98050 loss: 0.0030 lr: 0.02\n",
      "iteration: 98060 loss: 0.0024 lr: 0.02\n",
      "iteration: 98070 loss: 0.0029 lr: 0.02\n",
      "iteration: 98080 loss: 0.0027 lr: 0.02\n",
      "iteration: 98090 loss: 0.0031 lr: 0.02\n",
      "iteration: 98100 loss: 0.0028 lr: 0.02\n",
      "iteration: 98110 loss: 0.0023 lr: 0.02\n",
      "iteration: 98120 loss: 0.0026 lr: 0.02\n",
      "iteration: 98130 loss: 0.0039 lr: 0.02\n",
      "iteration: 98140 loss: 0.0030 lr: 0.02\n",
      "iteration: 98150 loss: 0.0027 lr: 0.02\n",
      "iteration: 98160 loss: 0.0029 lr: 0.02\n",
      "iteration: 98170 loss: 0.0025 lr: 0.02\n",
      "iteration: 98180 loss: 0.0023 lr: 0.02\n",
      "iteration: 98190 loss: 0.0028 lr: 0.02\n",
      "iteration: 98200 loss: 0.0024 lr: 0.02\n",
      "iteration: 98210 loss: 0.0034 lr: 0.02\n",
      "iteration: 98220 loss: 0.0024 lr: 0.02\n",
      "iteration: 98230 loss: 0.0026 lr: 0.02\n",
      "iteration: 98240 loss: 0.0030 lr: 0.02\n",
      "iteration: 98250 loss: 0.0029 lr: 0.02\n",
      "iteration: 98260 loss: 0.0027 lr: 0.02\n",
      "iteration: 98270 loss: 0.0025 lr: 0.02\n",
      "iteration: 98280 loss: 0.0027 lr: 0.02\n",
      "iteration: 98290 loss: 0.0034 lr: 0.02\n",
      "iteration: 98300 loss: 0.0029 lr: 0.02\n",
      "iteration: 98310 loss: 0.0031 lr: 0.02\n",
      "iteration: 98320 loss: 0.0030 lr: 0.02\n",
      "iteration: 98330 loss: 0.0039 lr: 0.02\n",
      "iteration: 98340 loss: 0.0033 lr: 0.02\n",
      "iteration: 98350 loss: 0.0031 lr: 0.02\n",
      "iteration: 98360 loss: 0.0023 lr: 0.02\n",
      "iteration: 98370 loss: 0.0028 lr: 0.02\n",
      "iteration: 98380 loss: 0.0029 lr: 0.02\n",
      "iteration: 98390 loss: 0.0025 lr: 0.02\n",
      "iteration: 98400 loss: 0.0030 lr: 0.02\n",
      "iteration: 98410 loss: 0.0030 lr: 0.02\n",
      "iteration: 98420 loss: 0.0031 lr: 0.02\n",
      "iteration: 98430 loss: 0.0036 lr: 0.02\n",
      "iteration: 98440 loss: 0.0028 lr: 0.02\n",
      "iteration: 98450 loss: 0.0025 lr: 0.02\n",
      "iteration: 98460 loss: 0.0027 lr: 0.02\n",
      "iteration: 98470 loss: 0.0026 lr: 0.02\n",
      "iteration: 98480 loss: 0.0036 lr: 0.02\n",
      "iteration: 98490 loss: 0.0024 lr: 0.02\n",
      "iteration: 98500 loss: 0.0021 lr: 0.02\n",
      "iteration: 98510 loss: 0.0034 lr: 0.02\n",
      "iteration: 98520 loss: 0.0033 lr: 0.02\n",
      "iteration: 98530 loss: 0.0037 lr: 0.02\n",
      "iteration: 98540 loss: 0.0028 lr: 0.02\n",
      "iteration: 98550 loss: 0.0025 lr: 0.02\n",
      "iteration: 98560 loss: 0.0028 lr: 0.02\n",
      "iteration: 98570 loss: 0.0026 lr: 0.02\n",
      "iteration: 98580 loss: 0.0022 lr: 0.02\n",
      "iteration: 98590 loss: 0.0029 lr: 0.02\n",
      "iteration: 98600 loss: 0.0032 lr: 0.02\n",
      "iteration: 98610 loss: 0.0027 lr: 0.02\n",
      "iteration: 98620 loss: 0.0021 lr: 0.02\n",
      "iteration: 98630 loss: 0.0030 lr: 0.02\n",
      "iteration: 98640 loss: 0.0027 lr: 0.02\n",
      "iteration: 98650 loss: 0.0025 lr: 0.02\n",
      "iteration: 98660 loss: 0.0024 lr: 0.02\n",
      "iteration: 98670 loss: 0.0033 lr: 0.02\n",
      "iteration: 98680 loss: 0.0040 lr: 0.02\n",
      "iteration: 98690 loss: 0.0035 lr: 0.02\n",
      "iteration: 98700 loss: 0.0024 lr: 0.02\n",
      "iteration: 98710 loss: 0.0030 lr: 0.02\n",
      "iteration: 98720 loss: 0.0030 lr: 0.02\n",
      "iteration: 98730 loss: 0.0026 lr: 0.02\n",
      "iteration: 98740 loss: 0.0028 lr: 0.02\n",
      "iteration: 98750 loss: 0.0026 lr: 0.02\n",
      "iteration: 98760 loss: 0.0026 lr: 0.02\n",
      "iteration: 98770 loss: 0.0025 lr: 0.02\n",
      "iteration: 98780 loss: 0.0022 lr: 0.02\n",
      "iteration: 98790 loss: 0.0022 lr: 0.02\n",
      "iteration: 98800 loss: 0.0029 lr: 0.02\n",
      "iteration: 98810 loss: 0.0032 lr: 0.02\n",
      "iteration: 98820 loss: 0.0029 lr: 0.02\n",
      "iteration: 98830 loss: 0.0024 lr: 0.02\n",
      "iteration: 98840 loss: 0.0035 lr: 0.02\n",
      "iteration: 98850 loss: 0.0028 lr: 0.02\n",
      "iteration: 98860 loss: 0.0029 lr: 0.02\n",
      "iteration: 98870 loss: 0.0032 lr: 0.02\n",
      "iteration: 98880 loss: 0.0028 lr: 0.02\n",
      "iteration: 98890 loss: 0.0028 lr: 0.02\n",
      "iteration: 98900 loss: 0.0032 lr: 0.02\n",
      "iteration: 98910 loss: 0.0024 lr: 0.02\n",
      "iteration: 98920 loss: 0.0036 lr: 0.02\n",
      "iteration: 98930 loss: 0.0023 lr: 0.02\n",
      "iteration: 98940 loss: 0.0028 lr: 0.02\n",
      "iteration: 98950 loss: 0.0033 lr: 0.02\n",
      "iteration: 98960 loss: 0.0025 lr: 0.02\n",
      "iteration: 98970 loss: 0.0031 lr: 0.02\n",
      "iteration: 98980 loss: 0.0036 lr: 0.02\n",
      "iteration: 98990 loss: 0.0033 lr: 0.02\n",
      "iteration: 99000 loss: 0.0028 lr: 0.02\n",
      "iteration: 99010 loss: 0.0028 lr: 0.02\n",
      "iteration: 99020 loss: 0.0028 lr: 0.02\n",
      "iteration: 99030 loss: 0.0030 lr: 0.02\n",
      "iteration: 99040 loss: 0.0029 lr: 0.02\n",
      "iteration: 99050 loss: 0.0023 lr: 0.02\n",
      "iteration: 99060 loss: 0.0031 lr: 0.02\n",
      "iteration: 99070 loss: 0.0035 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 99080 loss: 0.0030 lr: 0.02\n",
      "iteration: 99090 loss: 0.0026 lr: 0.02\n",
      "iteration: 99100 loss: 0.0032 lr: 0.02\n",
      "iteration: 99110 loss: 0.0024 lr: 0.02\n",
      "iteration: 99120 loss: 0.0026 lr: 0.02\n",
      "iteration: 99130 loss: 0.0028 lr: 0.02\n",
      "iteration: 99140 loss: 0.0037 lr: 0.02\n",
      "iteration: 99150 loss: 0.0026 lr: 0.02\n",
      "iteration: 99160 loss: 0.0029 lr: 0.02\n",
      "iteration: 99170 loss: 0.0025 lr: 0.02\n",
      "iteration: 99180 loss: 0.0027 lr: 0.02\n",
      "iteration: 99190 loss: 0.0030 lr: 0.02\n",
      "iteration: 99200 loss: 0.0031 lr: 0.02\n",
      "iteration: 99210 loss: 0.0035 lr: 0.02\n",
      "iteration: 99220 loss: 0.0037 lr: 0.02\n",
      "iteration: 99230 loss: 0.0029 lr: 0.02\n",
      "iteration: 99240 loss: 0.0032 lr: 0.02\n",
      "iteration: 99250 loss: 0.0024 lr: 0.02\n",
      "iteration: 99260 loss: 0.0048 lr: 0.02\n",
      "iteration: 99270 loss: 0.0029 lr: 0.02\n",
      "iteration: 99280 loss: 0.0036 lr: 0.02\n",
      "iteration: 99290 loss: 0.0026 lr: 0.02\n",
      "iteration: 99300 loss: 0.0039 lr: 0.02\n",
      "iteration: 99310 loss: 0.0033 lr: 0.02\n",
      "iteration: 99320 loss: 0.0047 lr: 0.02\n",
      "iteration: 99330 loss: 0.0034 lr: 0.02\n",
      "iteration: 99340 loss: 0.0025 lr: 0.02\n",
      "iteration: 99350 loss: 0.0034 lr: 0.02\n",
      "iteration: 99360 loss: 0.0029 lr: 0.02\n",
      "iteration: 99370 loss: 0.0022 lr: 0.02\n",
      "iteration: 99380 loss: 0.0029 lr: 0.02\n",
      "iteration: 99390 loss: 0.0032 lr: 0.02\n",
      "iteration: 99400 loss: 0.0033 lr: 0.02\n",
      "iteration: 99410 loss: 0.0031 lr: 0.02\n",
      "iteration: 99420 loss: 0.0028 lr: 0.02\n",
      "iteration: 99430 loss: 0.0037 lr: 0.02\n",
      "iteration: 99440 loss: 0.0037 lr: 0.02\n",
      "iteration: 99450 loss: 0.0029 lr: 0.02\n",
      "iteration: 99460 loss: 0.0029 lr: 0.02\n",
      "iteration: 99470 loss: 0.0029 lr: 0.02\n",
      "iteration: 99480 loss: 0.0032 lr: 0.02\n",
      "iteration: 99490 loss: 0.0025 lr: 0.02\n",
      "iteration: 99500 loss: 0.0030 lr: 0.02\n",
      "iteration: 99510 loss: 0.0036 lr: 0.02\n",
      "iteration: 99520 loss: 0.0028 lr: 0.02\n",
      "iteration: 99530 loss: 0.0032 lr: 0.02\n",
      "iteration: 99540 loss: 0.0027 lr: 0.02\n",
      "iteration: 99550 loss: 0.0025 lr: 0.02\n",
      "iteration: 99560 loss: 0.0034 lr: 0.02\n",
      "iteration: 99570 loss: 0.0031 lr: 0.02\n",
      "iteration: 99580 loss: 0.0031 lr: 0.02\n",
      "iteration: 99590 loss: 0.0040 lr: 0.02\n",
      "iteration: 99600 loss: 0.0029 lr: 0.02\n",
      "iteration: 99610 loss: 0.0041 lr: 0.02\n",
      "iteration: 99620 loss: 0.0024 lr: 0.02\n",
      "iteration: 99630 loss: 0.0023 lr: 0.02\n",
      "iteration: 99640 loss: 0.0029 lr: 0.02\n",
      "iteration: 99650 loss: 0.0027 lr: 0.02\n",
      "iteration: 99660 loss: 0.0027 lr: 0.02\n",
      "iteration: 99670 loss: 0.0032 lr: 0.02\n",
      "iteration: 99680 loss: 0.0032 lr: 0.02\n",
      "iteration: 99690 loss: 0.0028 lr: 0.02\n",
      "iteration: 99700 loss: 0.0028 lr: 0.02\n",
      "iteration: 99710 loss: 0.0021 lr: 0.02\n",
      "iteration: 99720 loss: 0.0025 lr: 0.02\n",
      "iteration: 99730 loss: 0.0026 lr: 0.02\n",
      "iteration: 99740 loss: 0.0036 lr: 0.02\n",
      "iteration: 99750 loss: 0.0033 lr: 0.02\n",
      "iteration: 99760 loss: 0.0030 lr: 0.02\n",
      "iteration: 99770 loss: 0.0045 lr: 0.02\n",
      "iteration: 99780 loss: 0.0027 lr: 0.02\n",
      "iteration: 99790 loss: 0.0028 lr: 0.02\n",
      "iteration: 99800 loss: 0.0032 lr: 0.02\n",
      "iteration: 99810 loss: 0.0030 lr: 0.02\n",
      "iteration: 99820 loss: 0.0024 lr: 0.02\n",
      "iteration: 99830 loss: 0.0030 lr: 0.02\n",
      "iteration: 99840 loss: 0.0033 lr: 0.02\n",
      "iteration: 99850 loss: 0.0026 lr: 0.02\n",
      "iteration: 99860 loss: 0.0030 lr: 0.02\n",
      "iteration: 99870 loss: 0.0031 lr: 0.02\n",
      "iteration: 99880 loss: 0.0028 lr: 0.02\n",
      "iteration: 99890 loss: 0.0027 lr: 0.02\n",
      "iteration: 99900 loss: 0.0035 lr: 0.02\n",
      "iteration: 99910 loss: 0.0034 lr: 0.02\n",
      "iteration: 99920 loss: 0.0031 lr: 0.02\n",
      "iteration: 99930 loss: 0.0031 lr: 0.02\n",
      "iteration: 99940 loss: 0.0044 lr: 0.02\n",
      "iteration: 99950 loss: 0.0026 lr: 0.02\n",
      "iteration: 99960 loss: 0.0028 lr: 0.02\n",
      "iteration: 99970 loss: 0.0033 lr: 0.02\n",
      "iteration: 99980 loss: 0.0030 lr: 0.02\n",
      "iteration: 99990 loss: 0.0022 lr: 0.02\n",
      "iteration: 100000 loss: 0.0031 lr: 0.02\n",
      "iteration: 100010 loss: 0.0023 lr: 0.02\n",
      "iteration: 100020 loss: 0.0024 lr: 0.02\n",
      "iteration: 100030 loss: 0.0025 lr: 0.02\n",
      "iteration: 100040 loss: 0.0019 lr: 0.02\n",
      "iteration: 100050 loss: 0.0028 lr: 0.02\n",
      "iteration: 100060 loss: 0.0026 lr: 0.02\n",
      "iteration: 100070 loss: 0.0031 lr: 0.02\n",
      "iteration: 100080 loss: 0.0025 lr: 0.02\n",
      "iteration: 100090 loss: 0.0040 lr: 0.02\n",
      "iteration: 100100 loss: 0.0027 lr: 0.02\n",
      "iteration: 100110 loss: 0.0024 lr: 0.02\n",
      "iteration: 100120 loss: 0.0029 lr: 0.02\n",
      "iteration: 100130 loss: 0.0025 lr: 0.02\n",
      "iteration: 100140 loss: 0.0030 lr: 0.02\n",
      "iteration: 100150 loss: 0.0028 lr: 0.02\n",
      "iteration: 100160 loss: 0.0025 lr: 0.02\n",
      "iteration: 100170 loss: 0.0026 lr: 0.02\n",
      "iteration: 100180 loss: 0.0027 lr: 0.02\n",
      "iteration: 100190 loss: 0.0039 lr: 0.02\n",
      "iteration: 100200 loss: 0.0026 lr: 0.02\n",
      "iteration: 100210 loss: 0.0025 lr: 0.02\n",
      "iteration: 100220 loss: 0.0024 lr: 0.02\n",
      "iteration: 100230 loss: 0.0022 lr: 0.02\n",
      "iteration: 100240 loss: 0.0022 lr: 0.02\n",
      "iteration: 100250 loss: 0.0026 lr: 0.02\n",
      "iteration: 100260 loss: 0.0025 lr: 0.02\n",
      "iteration: 100270 loss: 0.0022 lr: 0.02\n",
      "iteration: 100280 loss: 0.0028 lr: 0.02\n",
      "iteration: 100290 loss: 0.0022 lr: 0.02\n",
      "iteration: 100300 loss: 0.0037 lr: 0.02\n",
      "iteration: 100310 loss: 0.0030 lr: 0.02\n",
      "iteration: 100320 loss: 0.0028 lr: 0.02\n",
      "iteration: 100330 loss: 0.0030 lr: 0.02\n",
      "iteration: 100340 loss: 0.0023 lr: 0.02\n",
      "iteration: 100350 loss: 0.0029 lr: 0.02\n",
      "iteration: 100360 loss: 0.0035 lr: 0.02\n",
      "iteration: 100370 loss: 0.0023 lr: 0.02\n",
      "iteration: 100380 loss: 0.0028 lr: 0.02\n",
      "iteration: 100390 loss: 0.0022 lr: 0.02\n",
      "iteration: 100400 loss: 0.0030 lr: 0.02\n",
      "iteration: 100410 loss: 0.0035 lr: 0.02\n",
      "iteration: 100420 loss: 0.0023 lr: 0.02\n",
      "iteration: 100430 loss: 0.0030 lr: 0.02\n",
      "iteration: 100440 loss: 0.0033 lr: 0.02\n",
      "iteration: 100450 loss: 0.0026 lr: 0.02\n",
      "iteration: 100460 loss: 0.0035 lr: 0.02\n",
      "iteration: 100470 loss: 0.0026 lr: 0.02\n",
      "iteration: 100480 loss: 0.0021 lr: 0.02\n",
      "iteration: 100490 loss: 0.0035 lr: 0.02\n",
      "iteration: 100500 loss: 0.0024 lr: 0.02\n",
      "iteration: 100510 loss: 0.0027 lr: 0.02\n",
      "iteration: 100520 loss: 0.0030 lr: 0.02\n",
      "iteration: 100530 loss: 0.0028 lr: 0.02\n",
      "iteration: 100540 loss: 0.0027 lr: 0.02\n",
      "iteration: 100550 loss: 0.0026 lr: 0.02\n",
      "iteration: 100560 loss: 0.0036 lr: 0.02\n",
      "iteration: 100570 loss: 0.0033 lr: 0.02\n",
      "iteration: 100580 loss: 0.0029 lr: 0.02\n",
      "iteration: 100590 loss: 0.0029 lr: 0.02\n",
      "iteration: 100600 loss: 0.0023 lr: 0.02\n",
      "iteration: 100610 loss: 0.0028 lr: 0.02\n",
      "iteration: 100620 loss: 0.0028 lr: 0.02\n",
      "iteration: 100630 loss: 0.0041 lr: 0.02\n",
      "iteration: 100640 loss: 0.0030 lr: 0.02\n",
      "iteration: 100650 loss: 0.0024 lr: 0.02\n",
      "iteration: 100660 loss: 0.0035 lr: 0.02\n",
      "iteration: 100670 loss: 0.0037 lr: 0.02\n",
      "iteration: 100680 loss: 0.0033 lr: 0.02\n",
      "iteration: 100690 loss: 0.0029 lr: 0.02\n",
      "iteration: 100700 loss: 0.0027 lr: 0.02\n",
      "iteration: 100710 loss: 0.0026 lr: 0.02\n",
      "iteration: 100720 loss: 0.0028 lr: 0.02\n",
      "iteration: 100730 loss: 0.0029 lr: 0.02\n",
      "iteration: 100740 loss: 0.0038 lr: 0.02\n",
      "iteration: 100750 loss: 0.0026 lr: 0.02\n",
      "iteration: 100760 loss: 0.0036 lr: 0.02\n",
      "iteration: 100770 loss: 0.0029 lr: 0.02\n",
      "iteration: 100780 loss: 0.0022 lr: 0.02\n",
      "iteration: 100790 loss: 0.0030 lr: 0.02\n",
      "iteration: 100800 loss: 0.0029 lr: 0.02\n",
      "iteration: 100810 loss: 0.0034 lr: 0.02\n",
      "iteration: 100820 loss: 0.0027 lr: 0.02\n",
      "iteration: 100830 loss: 0.0032 lr: 0.02\n",
      "iteration: 100840 loss: 0.0027 lr: 0.02\n",
      "iteration: 100850 loss: 0.0028 lr: 0.02\n",
      "iteration: 100860 loss: 0.0029 lr: 0.02\n",
      "iteration: 100870 loss: 0.0029 lr: 0.02\n",
      "iteration: 100880 loss: 0.0038 lr: 0.02\n",
      "iteration: 100890 loss: 0.0030 lr: 0.02\n",
      "iteration: 100900 loss: 0.0025 lr: 0.02\n",
      "iteration: 100910 loss: 0.0025 lr: 0.02\n",
      "iteration: 100920 loss: 0.0032 lr: 0.02\n",
      "iteration: 100930 loss: 0.0030 lr: 0.02\n",
      "iteration: 100940 loss: 0.0033 lr: 0.02\n",
      "iteration: 100950 loss: 0.0021 lr: 0.02\n",
      "iteration: 100960 loss: 0.0025 lr: 0.02\n",
      "iteration: 100970 loss: 0.0027 lr: 0.02\n",
      "iteration: 100980 loss: 0.0030 lr: 0.02\n",
      "iteration: 100990 loss: 0.0024 lr: 0.02\n",
      "iteration: 101000 loss: 0.0024 lr: 0.02\n",
      "iteration: 101010 loss: 0.0025 lr: 0.02\n",
      "iteration: 101020 loss: 0.0033 lr: 0.02\n",
      "iteration: 101030 loss: 0.0026 lr: 0.02\n",
      "iteration: 101040 loss: 0.0031 lr: 0.02\n",
      "iteration: 101050 loss: 0.0026 lr: 0.02\n",
      "iteration: 101060 loss: 0.0028 lr: 0.02\n",
      "iteration: 101070 loss: 0.0032 lr: 0.02\n",
      "iteration: 101080 loss: 0.0025 lr: 0.02\n",
      "iteration: 101090 loss: 0.0026 lr: 0.02\n",
      "iteration: 101100 loss: 0.0025 lr: 0.02\n",
      "iteration: 101110 loss: 0.0027 lr: 0.02\n",
      "iteration: 101120 loss: 0.0032 lr: 0.02\n",
      "iteration: 101130 loss: 0.0025 lr: 0.02\n",
      "iteration: 101140 loss: 0.0019 lr: 0.02\n",
      "iteration: 101150 loss: 0.0024 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 101160 loss: 0.0029 lr: 0.02\n",
      "iteration: 101170 loss: 0.0030 lr: 0.02\n",
      "iteration: 101180 loss: 0.0034 lr: 0.02\n",
      "iteration: 101190 loss: 0.0037 lr: 0.02\n",
      "iteration: 101200 loss: 0.0032 lr: 0.02\n",
      "iteration: 101210 loss: 0.0041 lr: 0.02\n",
      "iteration: 101220 loss: 0.0025 lr: 0.02\n",
      "iteration: 101230 loss: 0.0027 lr: 0.02\n",
      "iteration: 101240 loss: 0.0032 lr: 0.02\n",
      "iteration: 101250 loss: 0.0029 lr: 0.02\n",
      "iteration: 101260 loss: 0.0022 lr: 0.02\n",
      "iteration: 101270 loss: 0.0034 lr: 0.02\n",
      "iteration: 101280 loss: 0.0025 lr: 0.02\n",
      "iteration: 101290 loss: 0.0032 lr: 0.02\n",
      "iteration: 101300 loss: 0.0017 lr: 0.02\n",
      "iteration: 101310 loss: 0.0035 lr: 0.02\n",
      "iteration: 101320 loss: 0.0023 lr: 0.02\n",
      "iteration: 101330 loss: 0.0030 lr: 0.02\n",
      "iteration: 101340 loss: 0.0022 lr: 0.02\n",
      "iteration: 101350 loss: 0.0038 lr: 0.02\n",
      "iteration: 101360 loss: 0.0022 lr: 0.02\n",
      "iteration: 101370 loss: 0.0030 lr: 0.02\n",
      "iteration: 101380 loss: 0.0039 lr: 0.02\n",
      "iteration: 101390 loss: 0.0026 lr: 0.02\n",
      "iteration: 101400 loss: 0.0026 lr: 0.02\n",
      "iteration: 101410 loss: 0.0026 lr: 0.02\n",
      "iteration: 101420 loss: 0.0035 lr: 0.02\n",
      "iteration: 101430 loss: 0.0030 lr: 0.02\n",
      "iteration: 101440 loss: 0.0034 lr: 0.02\n",
      "iteration: 101450 loss: 0.0024 lr: 0.02\n",
      "iteration: 101460 loss: 0.0025 lr: 0.02\n",
      "iteration: 101470 loss: 0.0035 lr: 0.02\n",
      "iteration: 101480 loss: 0.0036 lr: 0.02\n",
      "iteration: 101490 loss: 0.0029 lr: 0.02\n",
      "iteration: 101500 loss: 0.0028 lr: 0.02\n",
      "iteration: 101510 loss: 0.0036 lr: 0.02\n",
      "iteration: 101520 loss: 0.0030 lr: 0.02\n",
      "iteration: 101530 loss: 0.0035 lr: 0.02\n",
      "iteration: 101540 loss: 0.0026 lr: 0.02\n",
      "iteration: 101550 loss: 0.0028 lr: 0.02\n",
      "iteration: 101560 loss: 0.0033 lr: 0.02\n",
      "iteration: 101570 loss: 0.0026 lr: 0.02\n",
      "iteration: 101580 loss: 0.0031 lr: 0.02\n",
      "iteration: 101590 loss: 0.0028 lr: 0.02\n",
      "iteration: 101600 loss: 0.0024 lr: 0.02\n",
      "iteration: 101610 loss: 0.0035 lr: 0.02\n",
      "iteration: 101620 loss: 0.0022 lr: 0.02\n",
      "iteration: 101630 loss: 0.0026 lr: 0.02\n",
      "iteration: 101640 loss: 0.0027 lr: 0.02\n",
      "iteration: 101650 loss: 0.0031 lr: 0.02\n",
      "iteration: 101660 loss: 0.0021 lr: 0.02\n",
      "iteration: 101670 loss: 0.0039 lr: 0.02\n",
      "iteration: 101680 loss: 0.0030 lr: 0.02\n",
      "iteration: 101690 loss: 0.0030 lr: 0.02\n",
      "iteration: 101700 loss: 0.0031 lr: 0.02\n",
      "iteration: 101710 loss: 0.0021 lr: 0.02\n",
      "iteration: 101720 loss: 0.0028 lr: 0.02\n",
      "iteration: 101730 loss: 0.0033 lr: 0.02\n",
      "iteration: 101740 loss: 0.0028 lr: 0.02\n",
      "iteration: 101750 loss: 0.0033 lr: 0.02\n",
      "iteration: 101760 loss: 0.0034 lr: 0.02\n",
      "iteration: 101770 loss: 0.0036 lr: 0.02\n",
      "iteration: 101780 loss: 0.0023 lr: 0.02\n",
      "iteration: 101790 loss: 0.0038 lr: 0.02\n",
      "iteration: 101800 loss: 0.0029 lr: 0.02\n",
      "iteration: 101810 loss: 0.0027 lr: 0.02\n",
      "iteration: 101820 loss: 0.0036 lr: 0.02\n",
      "iteration: 101830 loss: 0.0025 lr: 0.02\n",
      "iteration: 101840 loss: 0.0032 lr: 0.02\n",
      "iteration: 101850 loss: 0.0028 lr: 0.02\n",
      "iteration: 101860 loss: 0.0030 lr: 0.02\n",
      "iteration: 101870 loss: 0.0026 lr: 0.02\n",
      "iteration: 101880 loss: 0.0030 lr: 0.02\n",
      "iteration: 101890 loss: 0.0024 lr: 0.02\n",
      "iteration: 101900 loss: 0.0027 lr: 0.02\n",
      "iteration: 101910 loss: 0.0028 lr: 0.02\n",
      "iteration: 101920 loss: 0.0026 lr: 0.02\n",
      "iteration: 101930 loss: 0.0034 lr: 0.02\n",
      "iteration: 101940 loss: 0.0028 lr: 0.02\n",
      "iteration: 101950 loss: 0.0029 lr: 0.02\n",
      "iteration: 101960 loss: 0.0030 lr: 0.02\n",
      "iteration: 101970 loss: 0.0027 lr: 0.02\n",
      "iteration: 101980 loss: 0.0030 lr: 0.02\n",
      "iteration: 101990 loss: 0.0020 lr: 0.02\n",
      "iteration: 102000 loss: 0.0023 lr: 0.02\n",
      "iteration: 102010 loss: 0.0025 lr: 0.02\n",
      "iteration: 102020 loss: 0.0041 lr: 0.02\n",
      "iteration: 102030 loss: 0.0023 lr: 0.02\n",
      "iteration: 102040 loss: 0.0024 lr: 0.02\n",
      "iteration: 102050 loss: 0.0023 lr: 0.02\n",
      "iteration: 102060 loss: 0.0028 lr: 0.02\n",
      "iteration: 102070 loss: 0.0027 lr: 0.02\n",
      "iteration: 102080 loss: 0.0027 lr: 0.02\n",
      "iteration: 102090 loss: 0.0030 lr: 0.02\n",
      "iteration: 102100 loss: 0.0041 lr: 0.02\n",
      "iteration: 102110 loss: 0.0035 lr: 0.02\n",
      "iteration: 102120 loss: 0.0025 lr: 0.02\n",
      "iteration: 102130 loss: 0.0032 lr: 0.02\n",
      "iteration: 102140 loss: 0.0030 lr: 0.02\n",
      "iteration: 102150 loss: 0.0036 lr: 0.02\n",
      "iteration: 102160 loss: 0.0024 lr: 0.02\n",
      "iteration: 102170 loss: 0.0027 lr: 0.02\n",
      "iteration: 102180 loss: 0.0029 lr: 0.02\n",
      "iteration: 102190 loss: 0.0029 lr: 0.02\n",
      "iteration: 102200 loss: 0.0029 lr: 0.02\n",
      "iteration: 102210 loss: 0.0040 lr: 0.02\n",
      "iteration: 102220 loss: 0.0028 lr: 0.02\n",
      "iteration: 102230 loss: 0.0027 lr: 0.02\n",
      "iteration: 102240 loss: 0.0034 lr: 0.02\n",
      "iteration: 102250 loss: 0.0027 lr: 0.02\n",
      "iteration: 102260 loss: 0.0030 lr: 0.02\n",
      "iteration: 102270 loss: 0.0026 lr: 0.02\n",
      "iteration: 102280 loss: 0.0044 lr: 0.02\n",
      "iteration: 102290 loss: 0.0028 lr: 0.02\n",
      "iteration: 102300 loss: 0.0024 lr: 0.02\n",
      "iteration: 102310 loss: 0.0020 lr: 0.02\n",
      "iteration: 102320 loss: 0.0027 lr: 0.02\n",
      "iteration: 102330 loss: 0.0022 lr: 0.02\n",
      "iteration: 102340 loss: 0.0034 lr: 0.02\n",
      "iteration: 102350 loss: 0.0031 lr: 0.02\n",
      "iteration: 102360 loss: 0.0032 lr: 0.02\n",
      "iteration: 102370 loss: 0.0024 lr: 0.02\n",
      "iteration: 102380 loss: 0.0025 lr: 0.02\n",
      "iteration: 102390 loss: 0.0025 lr: 0.02\n",
      "iteration: 102400 loss: 0.0028 lr: 0.02\n",
      "iteration: 102410 loss: 0.0039 lr: 0.02\n",
      "iteration: 102420 loss: 0.0034 lr: 0.02\n",
      "iteration: 102430 loss: 0.0031 lr: 0.02\n",
      "iteration: 102440 loss: 0.0037 lr: 0.02\n",
      "iteration: 102450 loss: 0.0035 lr: 0.02\n",
      "iteration: 102460 loss: 0.0029 lr: 0.02\n",
      "iteration: 102470 loss: 0.0029 lr: 0.02\n",
      "iteration: 102480 loss: 0.0043 lr: 0.02\n",
      "iteration: 102490 loss: 0.0031 lr: 0.02\n",
      "iteration: 102500 loss: 0.0034 lr: 0.02\n",
      "iteration: 102510 loss: 0.0026 lr: 0.02\n",
      "iteration: 102520 loss: 0.0025 lr: 0.02\n",
      "iteration: 102530 loss: 0.0027 lr: 0.02\n",
      "iteration: 102540 loss: 0.0024 lr: 0.02\n",
      "iteration: 102550 loss: 0.0032 lr: 0.02\n",
      "iteration: 102560 loss: 0.0034 lr: 0.02\n",
      "iteration: 102570 loss: 0.0027 lr: 0.02\n",
      "iteration: 102580 loss: 0.0027 lr: 0.02\n",
      "iteration: 102590 loss: 0.0028 lr: 0.02\n",
      "iteration: 102600 loss: 0.0034 lr: 0.02\n",
      "iteration: 102610 loss: 0.0030 lr: 0.02\n",
      "iteration: 102620 loss: 0.0025 lr: 0.02\n",
      "iteration: 102630 loss: 0.0033 lr: 0.02\n",
      "iteration: 102640 loss: 0.0030 lr: 0.02\n",
      "iteration: 102650 loss: 0.0025 lr: 0.02\n",
      "iteration: 102660 loss: 0.0023 lr: 0.02\n",
      "iteration: 102670 loss: 0.0028 lr: 0.02\n",
      "iteration: 102680 loss: 0.0028 lr: 0.02\n",
      "iteration: 102690 loss: 0.0030 lr: 0.02\n",
      "iteration: 102700 loss: 0.0029 lr: 0.02\n",
      "iteration: 102710 loss: 0.0024 lr: 0.02\n",
      "iteration: 102720 loss: 0.0028 lr: 0.02\n",
      "iteration: 102730 loss: 0.0026 lr: 0.02\n",
      "iteration: 102740 loss: 0.0025 lr: 0.02\n",
      "iteration: 102750 loss: 0.0026 lr: 0.02\n",
      "iteration: 102760 loss: 0.0038 lr: 0.02\n",
      "iteration: 102770 loss: 0.0029 lr: 0.02\n",
      "iteration: 102780 loss: 0.0027 lr: 0.02\n",
      "iteration: 102790 loss: 0.0026 lr: 0.02\n",
      "iteration: 102800 loss: 0.0022 lr: 0.02\n",
      "iteration: 102810 loss: 0.0024 lr: 0.02\n",
      "iteration: 102820 loss: 0.0029 lr: 0.02\n",
      "iteration: 102830 loss: 0.0036 lr: 0.02\n",
      "iteration: 102840 loss: 0.0028 lr: 0.02\n",
      "iteration: 102850 loss: 0.0024 lr: 0.02\n",
      "iteration: 102860 loss: 0.0023 lr: 0.02\n",
      "iteration: 102870 loss: 0.0021 lr: 0.02\n",
      "iteration: 102880 loss: 0.0027 lr: 0.02\n",
      "iteration: 102890 loss: 0.0026 lr: 0.02\n",
      "iteration: 102900 loss: 0.0032 lr: 0.02\n",
      "iteration: 102910 loss: 0.0029 lr: 0.02\n",
      "iteration: 102920 loss: 0.0031 lr: 0.02\n",
      "iteration: 102930 loss: 0.0034 lr: 0.02\n",
      "iteration: 102940 loss: 0.0030 lr: 0.02\n",
      "iteration: 102950 loss: 0.0026 lr: 0.02\n",
      "iteration: 102960 loss: 0.0030 lr: 0.02\n",
      "iteration: 102970 loss: 0.0024 lr: 0.02\n",
      "iteration: 102980 loss: 0.0022 lr: 0.02\n",
      "iteration: 102990 loss: 0.0033 lr: 0.02\n",
      "iteration: 103000 loss: 0.0026 lr: 0.02\n",
      "iteration: 103010 loss: 0.0031 lr: 0.02\n",
      "iteration: 103020 loss: 0.0017 lr: 0.02\n",
      "iteration: 103030 loss: 0.0021 lr: 0.02\n",
      "iteration: 103040 loss: 0.0032 lr: 0.02\n",
      "iteration: 103050 loss: 0.0028 lr: 0.02\n",
      "iteration: 103060 loss: 0.0037 lr: 0.02\n",
      "iteration: 103070 loss: 0.0023 lr: 0.02\n",
      "iteration: 103080 loss: 0.0036 lr: 0.02\n",
      "iteration: 103090 loss: 0.0029 lr: 0.02\n",
      "iteration: 103100 loss: 0.0030 lr: 0.02\n",
      "iteration: 103110 loss: 0.0021 lr: 0.02\n",
      "iteration: 103120 loss: 0.0025 lr: 0.02\n",
      "iteration: 103130 loss: 0.0024 lr: 0.02\n",
      "iteration: 103140 loss: 0.0021 lr: 0.02\n",
      "iteration: 103150 loss: 0.0035 lr: 0.02\n",
      "iteration: 103160 loss: 0.0024 lr: 0.02\n",
      "iteration: 103170 loss: 0.0021 lr: 0.02\n",
      "iteration: 103180 loss: 0.0026 lr: 0.02\n",
      "iteration: 103190 loss: 0.0030 lr: 0.02\n",
      "iteration: 103200 loss: 0.0028 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 103210 loss: 0.0024 lr: 0.02\n",
      "iteration: 103220 loss: 0.0032 lr: 0.02\n",
      "iteration: 103230 loss: 0.0027 lr: 0.02\n",
      "iteration: 103240 loss: 0.0030 lr: 0.02\n",
      "iteration: 103250 loss: 0.0024 lr: 0.02\n",
      "iteration: 103260 loss: 0.0030 lr: 0.02\n",
      "iteration: 103270 loss: 0.0034 lr: 0.02\n",
      "iteration: 103280 loss: 0.0030 lr: 0.02\n",
      "iteration: 103290 loss: 0.0031 lr: 0.02\n",
      "iteration: 103300 loss: 0.0028 lr: 0.02\n",
      "iteration: 103310 loss: 0.0023 lr: 0.02\n",
      "iteration: 103320 loss: 0.0028 lr: 0.02\n",
      "iteration: 103330 loss: 0.0024 lr: 0.02\n",
      "iteration: 103340 loss: 0.0037 lr: 0.02\n",
      "iteration: 103350 loss: 0.0029 lr: 0.02\n",
      "iteration: 103360 loss: 0.0037 lr: 0.02\n",
      "iteration: 103370 loss: 0.0021 lr: 0.02\n",
      "iteration: 103380 loss: 0.0033 lr: 0.02\n",
      "iteration: 103390 loss: 0.0025 lr: 0.02\n",
      "iteration: 103400 loss: 0.0028 lr: 0.02\n",
      "iteration: 103410 loss: 0.0033 lr: 0.02\n",
      "iteration: 103420 loss: 0.0038 lr: 0.02\n",
      "iteration: 103430 loss: 0.0029 lr: 0.02\n",
      "iteration: 103440 loss: 0.0022 lr: 0.02\n",
      "iteration: 103450 loss: 0.0029 lr: 0.02\n",
      "iteration: 103460 loss: 0.0029 lr: 0.02\n",
      "iteration: 103470 loss: 0.0032 lr: 0.02\n",
      "iteration: 103480 loss: 0.0022 lr: 0.02\n",
      "iteration: 103490 loss: 0.0028 lr: 0.02\n",
      "iteration: 103500 loss: 0.0028 lr: 0.02\n",
      "iteration: 103510 loss: 0.0027 lr: 0.02\n",
      "iteration: 103520 loss: 0.0029 lr: 0.02\n",
      "iteration: 103530 loss: 0.0029 lr: 0.02\n",
      "iteration: 103540 loss: 0.0035 lr: 0.02\n",
      "iteration: 103550 loss: 0.0024 lr: 0.02\n",
      "iteration: 103560 loss: 0.0025 lr: 0.02\n",
      "iteration: 103570 loss: 0.0027 lr: 0.02\n",
      "iteration: 103580 loss: 0.0031 lr: 0.02\n",
      "iteration: 103590 loss: 0.0027 lr: 0.02\n",
      "iteration: 103600 loss: 0.0026 lr: 0.02\n",
      "iteration: 103610 loss: 0.0028 lr: 0.02\n",
      "iteration: 103620 loss: 0.0022 lr: 0.02\n",
      "iteration: 103630 loss: 0.0025 lr: 0.02\n",
      "iteration: 103640 loss: 0.0026 lr: 0.02\n",
      "iteration: 103650 loss: 0.0031 lr: 0.02\n",
      "iteration: 103660 loss: 0.0028 lr: 0.02\n",
      "iteration: 103670 loss: 0.0042 lr: 0.02\n",
      "iteration: 103680 loss: 0.0025 lr: 0.02\n",
      "iteration: 103690 loss: 0.0040 lr: 0.02\n",
      "iteration: 103700 loss: 0.0029 lr: 0.02\n",
      "iteration: 103710 loss: 0.0032 lr: 0.02\n",
      "iteration: 103720 loss: 0.0027 lr: 0.02\n",
      "iteration: 103730 loss: 0.0022 lr: 0.02\n",
      "iteration: 103740 loss: 0.0030 lr: 0.02\n",
      "iteration: 103750 loss: 0.0024 lr: 0.02\n",
      "iteration: 103760 loss: 0.0032 lr: 0.02\n",
      "iteration: 103770 loss: 0.0030 lr: 0.02\n",
      "iteration: 103780 loss: 0.0025 lr: 0.02\n",
      "iteration: 103790 loss: 0.0023 lr: 0.02\n",
      "iteration: 103800 loss: 0.0035 lr: 0.02\n",
      "iteration: 103810 loss: 0.0027 lr: 0.02\n",
      "iteration: 103820 loss: 0.0035 lr: 0.02\n",
      "iteration: 103830 loss: 0.0024 lr: 0.02\n",
      "iteration: 103840 loss: 0.0032 lr: 0.02\n",
      "iteration: 103850 loss: 0.0029 lr: 0.02\n",
      "iteration: 103860 loss: 0.0031 lr: 0.02\n",
      "iteration: 103870 loss: 0.0034 lr: 0.02\n",
      "iteration: 103880 loss: 0.0029 lr: 0.02\n",
      "iteration: 103890 loss: 0.0026 lr: 0.02\n",
      "iteration: 103900 loss: 0.0031 lr: 0.02\n",
      "iteration: 103910 loss: 0.0026 lr: 0.02\n",
      "iteration: 103920 loss: 0.0023 lr: 0.02\n",
      "iteration: 103930 loss: 0.0031 lr: 0.02\n",
      "iteration: 103940 loss: 0.0028 lr: 0.02\n",
      "iteration: 103950 loss: 0.0024 lr: 0.02\n",
      "iteration: 103960 loss: 0.0026 lr: 0.02\n",
      "iteration: 103970 loss: 0.0023 lr: 0.02\n",
      "iteration: 103980 loss: 0.0028 lr: 0.02\n",
      "iteration: 103990 loss: 0.0025 lr: 0.02\n",
      "iteration: 104000 loss: 0.0023 lr: 0.02\n",
      "iteration: 104010 loss: 0.0026 lr: 0.02\n",
      "iteration: 104020 loss: 0.0024 lr: 0.02\n",
      "iteration: 104030 loss: 0.0027 lr: 0.02\n",
      "iteration: 104040 loss: 0.0025 lr: 0.02\n",
      "iteration: 104050 loss: 0.0025 lr: 0.02\n",
      "iteration: 104060 loss: 0.0034 lr: 0.02\n",
      "iteration: 104070 loss: 0.0027 lr: 0.02\n",
      "iteration: 104080 loss: 0.0031 lr: 0.02\n",
      "iteration: 104090 loss: 0.0030 lr: 0.02\n",
      "iteration: 104100 loss: 0.0031 lr: 0.02\n",
      "iteration: 104110 loss: 0.0029 lr: 0.02\n",
      "iteration: 104120 loss: 0.0026 lr: 0.02\n",
      "iteration: 104130 loss: 0.0027 lr: 0.02\n",
      "iteration: 104140 loss: 0.0023 lr: 0.02\n",
      "iteration: 104150 loss: 0.0024 lr: 0.02\n",
      "iteration: 104160 loss: 0.0024 lr: 0.02\n",
      "iteration: 104170 loss: 0.0030 lr: 0.02\n",
      "iteration: 104180 loss: 0.0023 lr: 0.02\n",
      "iteration: 104190 loss: 0.0031 lr: 0.02\n",
      "iteration: 104200 loss: 0.0028 lr: 0.02\n",
      "iteration: 104210 loss: 0.0031 lr: 0.02\n",
      "iteration: 104220 loss: 0.0029 lr: 0.02\n",
      "iteration: 104230 loss: 0.0032 lr: 0.02\n",
      "iteration: 104240 loss: 0.0030 lr: 0.02\n",
      "iteration: 104250 loss: 0.0027 lr: 0.02\n",
      "iteration: 104260 loss: 0.0024 lr: 0.02\n",
      "iteration: 104270 loss: 0.0027 lr: 0.02\n",
      "iteration: 104280 loss: 0.0026 lr: 0.02\n",
      "iteration: 104290 loss: 0.0027 lr: 0.02\n",
      "iteration: 104300 loss: 0.0023 lr: 0.02\n",
      "iteration: 104310 loss: 0.0034 lr: 0.02\n",
      "iteration: 104320 loss: 0.0022 lr: 0.02\n",
      "iteration: 104330 loss: 0.0024 lr: 0.02\n",
      "iteration: 104340 loss: 0.0025 lr: 0.02\n",
      "iteration: 104350 loss: 0.0019 lr: 0.02\n",
      "iteration: 104360 loss: 0.0022 lr: 0.02\n",
      "iteration: 104370 loss: 0.0027 lr: 0.02\n",
      "iteration: 104380 loss: 0.0022 lr: 0.02\n",
      "iteration: 104390 loss: 0.0022 lr: 0.02\n",
      "iteration: 104400 loss: 0.0023 lr: 0.02\n",
      "iteration: 104410 loss: 0.0028 lr: 0.02\n",
      "iteration: 104420 loss: 0.0025 lr: 0.02\n",
      "iteration: 104430 loss: 0.0026 lr: 0.02\n",
      "iteration: 104440 loss: 0.0029 lr: 0.02\n",
      "iteration: 104450 loss: 0.0030 lr: 0.02\n",
      "iteration: 104460 loss: 0.0029 lr: 0.02\n",
      "iteration: 104470 loss: 0.0021 lr: 0.02\n",
      "iteration: 104480 loss: 0.0026 lr: 0.02\n",
      "iteration: 104490 loss: 0.0025 lr: 0.02\n",
      "iteration: 104500 loss: 0.0027 lr: 0.02\n",
      "iteration: 104510 loss: 0.0022 lr: 0.02\n",
      "iteration: 104520 loss: 0.0025 lr: 0.02\n",
      "iteration: 104530 loss: 0.0031 lr: 0.02\n",
      "iteration: 104540 loss: 0.0025 lr: 0.02\n",
      "iteration: 104550 loss: 0.0025 lr: 0.02\n",
      "iteration: 104560 loss: 0.0024 lr: 0.02\n",
      "iteration: 104570 loss: 0.0029 lr: 0.02\n",
      "iteration: 104580 loss: 0.0033 lr: 0.02\n",
      "iteration: 104590 loss: 0.0022 lr: 0.02\n",
      "iteration: 104600 loss: 0.0039 lr: 0.02\n",
      "iteration: 104610 loss: 0.0031 lr: 0.02\n",
      "iteration: 104620 loss: 0.0029 lr: 0.02\n",
      "iteration: 104630 loss: 0.0033 lr: 0.02\n",
      "iteration: 104640 loss: 0.0027 lr: 0.02\n",
      "iteration: 104650 loss: 0.0035 lr: 0.02\n",
      "iteration: 104660 loss: 0.0020 lr: 0.02\n",
      "iteration: 104670 loss: 0.0033 lr: 0.02\n",
      "iteration: 104680 loss: 0.0029 lr: 0.02\n",
      "iteration: 104690 loss: 0.0026 lr: 0.02\n",
      "iteration: 104700 loss: 0.0025 lr: 0.02\n",
      "iteration: 104710 loss: 0.0034 lr: 0.02\n",
      "iteration: 104720 loss: 0.0028 lr: 0.02\n",
      "iteration: 104730 loss: 0.0026 lr: 0.02\n",
      "iteration: 104740 loss: 0.0028 lr: 0.02\n",
      "iteration: 104750 loss: 0.0020 lr: 0.02\n",
      "iteration: 104760 loss: 0.0037 lr: 0.02\n",
      "iteration: 104770 loss: 0.0026 lr: 0.02\n",
      "iteration: 104780 loss: 0.0022 lr: 0.02\n",
      "iteration: 104790 loss: 0.0027 lr: 0.02\n",
      "iteration: 104800 loss: 0.0018 lr: 0.02\n",
      "iteration: 104810 loss: 0.0022 lr: 0.02\n",
      "iteration: 104820 loss: 0.0029 lr: 0.02\n",
      "iteration: 104830 loss: 0.0032 lr: 0.02\n",
      "iteration: 104840 loss: 0.0033 lr: 0.02\n",
      "iteration: 104850 loss: 0.0030 lr: 0.02\n",
      "iteration: 104860 loss: 0.0024 lr: 0.02\n",
      "iteration: 104870 loss: 0.0026 lr: 0.02\n",
      "iteration: 104880 loss: 0.0022 lr: 0.02\n",
      "iteration: 104890 loss: 0.0029 lr: 0.02\n",
      "iteration: 104900 loss: 0.0025 lr: 0.02\n",
      "iteration: 104910 loss: 0.0037 lr: 0.02\n",
      "iteration: 104920 loss: 0.0028 lr: 0.02\n",
      "iteration: 104930 loss: 0.0027 lr: 0.02\n",
      "iteration: 104940 loss: 0.0036 lr: 0.02\n",
      "iteration: 104950 loss: 0.0028 lr: 0.02\n",
      "iteration: 104960 loss: 0.0037 lr: 0.02\n",
      "iteration: 104970 loss: 0.0021 lr: 0.02\n",
      "iteration: 104980 loss: 0.0028 lr: 0.02\n",
      "iteration: 104990 loss: 0.0025 lr: 0.02\n",
      "iteration: 105000 loss: 0.0032 lr: 0.02\n",
      "iteration: 105010 loss: 0.0029 lr: 0.02\n",
      "iteration: 105020 loss: 0.0026 lr: 0.02\n",
      "iteration: 105030 loss: 0.0024 lr: 0.02\n",
      "iteration: 105040 loss: 0.0025 lr: 0.02\n",
      "iteration: 105050 loss: 0.0026 lr: 0.02\n",
      "iteration: 105060 loss: 0.0032 lr: 0.02\n",
      "iteration: 105070 loss: 0.0025 lr: 0.02\n",
      "iteration: 105080 loss: 0.0028 lr: 0.02\n",
      "iteration: 105090 loss: 0.0025 lr: 0.02\n",
      "iteration: 105100 loss: 0.0032 lr: 0.02\n",
      "iteration: 105110 loss: 0.0027 lr: 0.02\n",
      "iteration: 105120 loss: 0.0026 lr: 0.02\n",
      "iteration: 105130 loss: 0.0040 lr: 0.02\n",
      "iteration: 105140 loss: 0.0023 lr: 0.02\n",
      "iteration: 105150 loss: 0.0029 lr: 0.02\n",
      "iteration: 105160 loss: 0.0021 lr: 0.02\n",
      "iteration: 105170 loss: 0.0033 lr: 0.02\n",
      "iteration: 105180 loss: 0.0019 lr: 0.02\n",
      "iteration: 105190 loss: 0.0035 lr: 0.02\n",
      "iteration: 105200 loss: 0.0030 lr: 0.02\n",
      "iteration: 105210 loss: 0.0025 lr: 0.02\n",
      "iteration: 105220 loss: 0.0030 lr: 0.02\n",
      "iteration: 105230 loss: 0.0027 lr: 0.02\n",
      "iteration: 105240 loss: 0.0029 lr: 0.02\n",
      "iteration: 105250 loss: 0.0025 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 105260 loss: 0.0031 lr: 0.02\n",
      "iteration: 105270 loss: 0.0031 lr: 0.02\n",
      "iteration: 105280 loss: 0.0029 lr: 0.02\n",
      "iteration: 105290 loss: 0.0027 lr: 0.02\n",
      "iteration: 105300 loss: 0.0033 lr: 0.02\n",
      "iteration: 105310 loss: 0.0030 lr: 0.02\n",
      "iteration: 105320 loss: 0.0025 lr: 0.02\n",
      "iteration: 105330 loss: 0.0033 lr: 0.02\n",
      "iteration: 105340 loss: 0.0034 lr: 0.02\n",
      "iteration: 105350 loss: 0.0030 lr: 0.02\n",
      "iteration: 105360 loss: 0.0030 lr: 0.02\n",
      "iteration: 105370 loss: 0.0023 lr: 0.02\n",
      "iteration: 105380 loss: 0.0032 lr: 0.02\n",
      "iteration: 105390 loss: 0.0028 lr: 0.02\n",
      "iteration: 105400 loss: 0.0026 lr: 0.02\n",
      "iteration: 105410 loss: 0.0038 lr: 0.02\n",
      "iteration: 105420 loss: 0.0030 lr: 0.02\n",
      "iteration: 105430 loss: 0.0028 lr: 0.02\n",
      "iteration: 105440 loss: 0.0026 lr: 0.02\n",
      "iteration: 105450 loss: 0.0031 lr: 0.02\n",
      "iteration: 105460 loss: 0.0029 lr: 0.02\n",
      "iteration: 105470 loss: 0.0025 lr: 0.02\n",
      "iteration: 105480 loss: 0.0031 lr: 0.02\n",
      "iteration: 105490 loss: 0.0027 lr: 0.02\n",
      "iteration: 105500 loss: 0.0022 lr: 0.02\n",
      "iteration: 105510 loss: 0.0025 lr: 0.02\n",
      "iteration: 105520 loss: 0.0021 lr: 0.02\n",
      "iteration: 105530 loss: 0.0031 lr: 0.02\n",
      "iteration: 105540 loss: 0.0027 lr: 0.02\n",
      "iteration: 105550 loss: 0.0030 lr: 0.02\n",
      "iteration: 105560 loss: 0.0036 lr: 0.02\n",
      "iteration: 105570 loss: 0.0027 lr: 0.02\n",
      "iteration: 105580 loss: 0.0031 lr: 0.02\n",
      "iteration: 105590 loss: 0.0023 lr: 0.02\n",
      "iteration: 105600 loss: 0.0029 lr: 0.02\n",
      "iteration: 105610 loss: 0.0027 lr: 0.02\n",
      "iteration: 105620 loss: 0.0021 lr: 0.02\n",
      "iteration: 105630 loss: 0.0023 lr: 0.02\n",
      "iteration: 105640 loss: 0.0027 lr: 0.02\n",
      "iteration: 105650 loss: 0.0033 lr: 0.02\n",
      "iteration: 105660 loss: 0.0034 lr: 0.02\n",
      "iteration: 105670 loss: 0.0031 lr: 0.02\n",
      "iteration: 105680 loss: 0.0029 lr: 0.02\n",
      "iteration: 105690 loss: 0.0029 lr: 0.02\n",
      "iteration: 105700 loss: 0.0025 lr: 0.02\n",
      "iteration: 105710 loss: 0.0032 lr: 0.02\n",
      "iteration: 105720 loss: 0.0028 lr: 0.02\n",
      "iteration: 105730 loss: 0.0022 lr: 0.02\n",
      "iteration: 105740 loss: 0.0031 lr: 0.02\n",
      "iteration: 105750 loss: 0.0028 lr: 0.02\n",
      "iteration: 105760 loss: 0.0025 lr: 0.02\n",
      "iteration: 105770 loss: 0.0020 lr: 0.02\n",
      "iteration: 105780 loss: 0.0026 lr: 0.02\n",
      "iteration: 105790 loss: 0.0028 lr: 0.02\n",
      "iteration: 105800 loss: 0.0026 lr: 0.02\n",
      "iteration: 105810 loss: 0.0021 lr: 0.02\n",
      "iteration: 105820 loss: 0.0028 lr: 0.02\n",
      "iteration: 105830 loss: 0.0025 lr: 0.02\n",
      "iteration: 105840 loss: 0.0027 lr: 0.02\n",
      "iteration: 105850 loss: 0.0032 lr: 0.02\n",
      "iteration: 105860 loss: 0.0030 lr: 0.02\n",
      "iteration: 105870 loss: 0.0024 lr: 0.02\n",
      "iteration: 105880 loss: 0.0027 lr: 0.02\n",
      "iteration: 105890 loss: 0.0027 lr: 0.02\n",
      "iteration: 105900 loss: 0.0029 lr: 0.02\n",
      "iteration: 105910 loss: 0.0024 lr: 0.02\n",
      "iteration: 105920 loss: 0.0030 lr: 0.02\n",
      "iteration: 105930 loss: 0.0028 lr: 0.02\n",
      "iteration: 105940 loss: 0.0024 lr: 0.02\n",
      "iteration: 105950 loss: 0.0026 lr: 0.02\n",
      "iteration: 105960 loss: 0.0023 lr: 0.02\n",
      "iteration: 105970 loss: 0.0022 lr: 0.02\n",
      "iteration: 105980 loss: 0.0023 lr: 0.02\n",
      "iteration: 105990 loss: 0.0023 lr: 0.02\n",
      "iteration: 106000 loss: 0.0026 lr: 0.02\n",
      "iteration: 106010 loss: 0.0026 lr: 0.02\n",
      "iteration: 106020 loss: 0.0040 lr: 0.02\n",
      "iteration: 106030 loss: 0.0026 lr: 0.02\n",
      "iteration: 106040 loss: 0.0032 lr: 0.02\n",
      "iteration: 106050 loss: 0.0033 lr: 0.02\n",
      "iteration: 106060 loss: 0.0030 lr: 0.02\n",
      "iteration: 106070 loss: 0.0029 lr: 0.02\n",
      "iteration: 106080 loss: 0.0022 lr: 0.02\n",
      "iteration: 106090 loss: 0.0029 lr: 0.02\n",
      "iteration: 106100 loss: 0.0032 lr: 0.02\n",
      "iteration: 106110 loss: 0.0023 lr: 0.02\n",
      "iteration: 106120 loss: 0.0032 lr: 0.02\n",
      "iteration: 106130 loss: 0.0030 lr: 0.02\n",
      "iteration: 106140 loss: 0.0029 lr: 0.02\n",
      "iteration: 106150 loss: 0.0025 lr: 0.02\n",
      "iteration: 106160 loss: 0.0022 lr: 0.02\n",
      "iteration: 106170 loss: 0.0028 lr: 0.02\n",
      "iteration: 106180 loss: 0.0035 lr: 0.02\n",
      "iteration: 106190 loss: 0.0029 lr: 0.02\n",
      "iteration: 106200 loss: 0.0027 lr: 0.02\n",
      "iteration: 106210 loss: 0.0025 lr: 0.02\n",
      "iteration: 106220 loss: 0.0023 lr: 0.02\n",
      "iteration: 106230 loss: 0.0034 lr: 0.02\n",
      "iteration: 106240 loss: 0.0027 lr: 0.02\n",
      "iteration: 106250 loss: 0.0029 lr: 0.02\n",
      "iteration: 106260 loss: 0.0027 lr: 0.02\n",
      "iteration: 106270 loss: 0.0032 lr: 0.02\n",
      "iteration: 106280 loss: 0.0025 lr: 0.02\n",
      "iteration: 106290 loss: 0.0024 lr: 0.02\n",
      "iteration: 106300 loss: 0.0032 lr: 0.02\n",
      "iteration: 106310 loss: 0.0036 lr: 0.02\n",
      "iteration: 106320 loss: 0.0024 lr: 0.02\n",
      "iteration: 106330 loss: 0.0024 lr: 0.02\n",
      "iteration: 106340 loss: 0.0023 lr: 0.02\n",
      "iteration: 106350 loss: 0.0020 lr: 0.02\n",
      "iteration: 106360 loss: 0.0026 lr: 0.02\n",
      "iteration: 106370 loss: 0.0028 lr: 0.02\n",
      "iteration: 106380 loss: 0.0023 lr: 0.02\n",
      "iteration: 106390 loss: 0.0025 lr: 0.02\n",
      "iteration: 106400 loss: 0.0026 lr: 0.02\n",
      "iteration: 106410 loss: 0.0026 lr: 0.02\n",
      "iteration: 106420 loss: 0.0031 lr: 0.02\n",
      "iteration: 106430 loss: 0.0039 lr: 0.02\n",
      "iteration: 106440 loss: 0.0033 lr: 0.02\n",
      "iteration: 106450 loss: 0.0022 lr: 0.02\n",
      "iteration: 106460 loss: 0.0035 lr: 0.02\n",
      "iteration: 106470 loss: 0.0028 lr: 0.02\n",
      "iteration: 106480 loss: 0.0027 lr: 0.02\n",
      "iteration: 106490 loss: 0.0033 lr: 0.02\n",
      "iteration: 106500 loss: 0.0028 lr: 0.02\n",
      "iteration: 106510 loss: 0.0026 lr: 0.02\n",
      "iteration: 106520 loss: 0.0024 lr: 0.02\n",
      "iteration: 106530 loss: 0.0027 lr: 0.02\n",
      "iteration: 106540 loss: 0.0029 lr: 0.02\n",
      "iteration: 106550 loss: 0.0023 lr: 0.02\n",
      "iteration: 106560 loss: 0.0020 lr: 0.02\n",
      "iteration: 106570 loss: 0.0021 lr: 0.02\n",
      "iteration: 106580 loss: 0.0034 lr: 0.02\n",
      "iteration: 106590 loss: 0.0032 lr: 0.02\n",
      "iteration: 106600 loss: 0.0024 lr: 0.02\n",
      "iteration: 106610 loss: 0.0031 lr: 0.02\n",
      "iteration: 106620 loss: 0.0023 lr: 0.02\n",
      "iteration: 106630 loss: 0.0032 lr: 0.02\n",
      "iteration: 106640 loss: 0.0037 lr: 0.02\n",
      "iteration: 106650 loss: 0.0024 lr: 0.02\n",
      "iteration: 106660 loss: 0.0022 lr: 0.02\n",
      "iteration: 106670 loss: 0.0025 lr: 0.02\n",
      "iteration: 106680 loss: 0.0026 lr: 0.02\n",
      "iteration: 106690 loss: 0.0028 lr: 0.02\n",
      "iteration: 106700 loss: 0.0031 lr: 0.02\n",
      "iteration: 106710 loss: 0.0032 lr: 0.02\n",
      "iteration: 106720 loss: 0.0026 lr: 0.02\n",
      "iteration: 106730 loss: 0.0027 lr: 0.02\n",
      "iteration: 106740 loss: 0.0027 lr: 0.02\n",
      "iteration: 106750 loss: 0.0025 lr: 0.02\n",
      "iteration: 106760 loss: 0.0023 lr: 0.02\n",
      "iteration: 106770 loss: 0.0026 lr: 0.02\n",
      "iteration: 106780 loss: 0.0037 lr: 0.02\n",
      "iteration: 106790 loss: 0.0023 lr: 0.02\n",
      "iteration: 106800 loss: 0.0037 lr: 0.02\n",
      "iteration: 106810 loss: 0.0031 lr: 0.02\n",
      "iteration: 106820 loss: 0.0025 lr: 0.02\n",
      "iteration: 106830 loss: 0.0030 lr: 0.02\n",
      "iteration: 106840 loss: 0.0031 lr: 0.02\n",
      "iteration: 106850 loss: 0.0034 lr: 0.02\n",
      "iteration: 106860 loss: 0.0038 lr: 0.02\n",
      "iteration: 106870 loss: 0.0026 lr: 0.02\n",
      "iteration: 106880 loss: 0.0027 lr: 0.02\n",
      "iteration: 106890 loss: 0.0036 lr: 0.02\n",
      "iteration: 106900 loss: 0.0031 lr: 0.02\n",
      "iteration: 106910 loss: 0.0020 lr: 0.02\n",
      "iteration: 106920 loss: 0.0025 lr: 0.02\n",
      "iteration: 106930 loss: 0.0028 lr: 0.02\n",
      "iteration: 106940 loss: 0.0025 lr: 0.02\n",
      "iteration: 106950 loss: 0.0030 lr: 0.02\n",
      "iteration: 106960 loss: 0.0027 lr: 0.02\n",
      "iteration: 106970 loss: 0.0026 lr: 0.02\n",
      "iteration: 106980 loss: 0.0027 lr: 0.02\n",
      "iteration: 106990 loss: 0.0029 lr: 0.02\n",
      "iteration: 107000 loss: 0.0020 lr: 0.02\n",
      "iteration: 107010 loss: 0.0025 lr: 0.02\n",
      "iteration: 107020 loss: 0.0030 lr: 0.02\n",
      "iteration: 107030 loss: 0.0030 lr: 0.02\n",
      "iteration: 107040 loss: 0.0028 lr: 0.02\n",
      "iteration: 107050 loss: 0.0026 lr: 0.02\n",
      "iteration: 107060 loss: 0.0033 lr: 0.02\n",
      "iteration: 107070 loss: 0.0025 lr: 0.02\n",
      "iteration: 107080 loss: 0.0036 lr: 0.02\n",
      "iteration: 107090 loss: 0.0028 lr: 0.02\n",
      "iteration: 107100 loss: 0.0025 lr: 0.02\n",
      "iteration: 107110 loss: 0.0030 lr: 0.02\n",
      "iteration: 107120 loss: 0.0020 lr: 0.02\n",
      "iteration: 107130 loss: 0.0024 lr: 0.02\n",
      "iteration: 107140 loss: 0.0022 lr: 0.02\n",
      "iteration: 107150 loss: 0.0024 lr: 0.02\n",
      "iteration: 107160 loss: 0.0031 lr: 0.02\n",
      "iteration: 107170 loss: 0.0026 lr: 0.02\n",
      "iteration: 107180 loss: 0.0020 lr: 0.02\n",
      "iteration: 107190 loss: 0.0025 lr: 0.02\n",
      "iteration: 107200 loss: 0.0023 lr: 0.02\n",
      "iteration: 107210 loss: 0.0032 lr: 0.02\n",
      "iteration: 107220 loss: 0.0023 lr: 0.02\n",
      "iteration: 107230 loss: 0.0023 lr: 0.02\n",
      "iteration: 107240 loss: 0.0022 lr: 0.02\n",
      "iteration: 107250 loss: 0.0027 lr: 0.02\n",
      "iteration: 107260 loss: 0.0029 lr: 0.02\n",
      "iteration: 107270 loss: 0.0027 lr: 0.02\n",
      "iteration: 107280 loss: 0.0028 lr: 0.02\n",
      "iteration: 107290 loss: 0.0028 lr: 0.02\n",
      "iteration: 107300 loss: 0.0026 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 107310 loss: 0.0026 lr: 0.02\n",
      "iteration: 107320 loss: 0.0027 lr: 0.02\n",
      "iteration: 107330 loss: 0.0025 lr: 0.02\n",
      "iteration: 107340 loss: 0.0037 lr: 0.02\n",
      "iteration: 107350 loss: 0.0027 lr: 0.02\n",
      "iteration: 107360 loss: 0.0047 lr: 0.02\n",
      "iteration: 107370 loss: 0.0026 lr: 0.02\n",
      "iteration: 107380 loss: 0.0022 lr: 0.02\n",
      "iteration: 107390 loss: 0.0040 lr: 0.02\n",
      "iteration: 107400 loss: 0.0026 lr: 0.02\n",
      "iteration: 107410 loss: 0.0023 lr: 0.02\n",
      "iteration: 107420 loss: 0.0016 lr: 0.02\n",
      "iteration: 107430 loss: 0.0024 lr: 0.02\n",
      "iteration: 107440 loss: 0.0036 lr: 0.02\n",
      "iteration: 107450 loss: 0.0031 lr: 0.02\n",
      "iteration: 107460 loss: 0.0025 lr: 0.02\n",
      "iteration: 107470 loss: 0.0029 lr: 0.02\n",
      "iteration: 107480 loss: 0.0026 lr: 0.02\n",
      "iteration: 107490 loss: 0.0030 lr: 0.02\n",
      "iteration: 107500 loss: 0.0024 lr: 0.02\n",
      "iteration: 107510 loss: 0.0025 lr: 0.02\n",
      "iteration: 107520 loss: 0.0030 lr: 0.02\n",
      "iteration: 107530 loss: 0.0036 lr: 0.02\n",
      "iteration: 107540 loss: 0.0031 lr: 0.02\n",
      "iteration: 107550 loss: 0.0026 lr: 0.02\n",
      "iteration: 107560 loss: 0.0022 lr: 0.02\n",
      "iteration: 107570 loss: 0.0032 lr: 0.02\n",
      "iteration: 107580 loss: 0.0026 lr: 0.02\n",
      "iteration: 107590 loss: 0.0025 lr: 0.02\n",
      "iteration: 107600 loss: 0.0034 lr: 0.02\n",
      "iteration: 107610 loss: 0.0021 lr: 0.02\n",
      "iteration: 107620 loss: 0.0031 lr: 0.02\n",
      "iteration: 107630 loss: 0.0034 lr: 0.02\n",
      "iteration: 107640 loss: 0.0028 lr: 0.02\n",
      "iteration: 107650 loss: 0.0027 lr: 0.02\n",
      "iteration: 107660 loss: 0.0022 lr: 0.02\n",
      "iteration: 107670 loss: 0.0035 lr: 0.02\n",
      "iteration: 107680 loss: 0.0026 lr: 0.02\n",
      "iteration: 107690 loss: 0.0024 lr: 0.02\n",
      "iteration: 107700 loss: 0.0025 lr: 0.02\n",
      "iteration: 107710 loss: 0.0036 lr: 0.02\n",
      "iteration: 107720 loss: 0.0025 lr: 0.02\n",
      "iteration: 107730 loss: 0.0029 lr: 0.02\n",
      "iteration: 107740 loss: 0.0027 lr: 0.02\n",
      "iteration: 107750 loss: 0.0022 lr: 0.02\n",
      "iteration: 107760 loss: 0.0021 lr: 0.02\n",
      "iteration: 107770 loss: 0.0032 lr: 0.02\n",
      "iteration: 107780 loss: 0.0024 lr: 0.02\n",
      "iteration: 107790 loss: 0.0026 lr: 0.02\n",
      "iteration: 107800 loss: 0.0023 lr: 0.02\n",
      "iteration: 107810 loss: 0.0022 lr: 0.02\n",
      "iteration: 107820 loss: 0.0026 lr: 0.02\n",
      "iteration: 107830 loss: 0.0022 lr: 0.02\n",
      "iteration: 107840 loss: 0.0024 lr: 0.02\n",
      "iteration: 107850 loss: 0.0020 lr: 0.02\n",
      "iteration: 107860 loss: 0.0027 lr: 0.02\n",
      "iteration: 107870 loss: 0.0024 lr: 0.02\n",
      "iteration: 107880 loss: 0.0027 lr: 0.02\n",
      "iteration: 107890 loss: 0.0024 lr: 0.02\n",
      "iteration: 107900 loss: 0.0023 lr: 0.02\n",
      "iteration: 107910 loss: 0.0024 lr: 0.02\n",
      "iteration: 107920 loss: 0.0029 lr: 0.02\n",
      "iteration: 107930 loss: 0.0024 lr: 0.02\n",
      "iteration: 107940 loss: 0.0024 lr: 0.02\n",
      "iteration: 107950 loss: 0.0023 lr: 0.02\n",
      "iteration: 107960 loss: 0.0022 lr: 0.02\n",
      "iteration: 107970 loss: 0.0026 lr: 0.02\n",
      "iteration: 107980 loss: 0.0024 lr: 0.02\n",
      "iteration: 107990 loss: 0.0038 lr: 0.02\n",
      "iteration: 108000 loss: 0.0028 lr: 0.02\n",
      "iteration: 108010 loss: 0.0030 lr: 0.02\n",
      "iteration: 108020 loss: 0.0035 lr: 0.02\n",
      "iteration: 108030 loss: 0.0022 lr: 0.02\n",
      "iteration: 108040 loss: 0.0029 lr: 0.02\n",
      "iteration: 108050 loss: 0.0028 lr: 0.02\n",
      "iteration: 108060 loss: 0.0022 lr: 0.02\n",
      "iteration: 108070 loss: 0.0028 lr: 0.02\n",
      "iteration: 108080 loss: 0.0025 lr: 0.02\n",
      "iteration: 108090 loss: 0.0027 lr: 0.02\n",
      "iteration: 108100 loss: 0.0033 lr: 0.02\n",
      "iteration: 108110 loss: 0.0027 lr: 0.02\n",
      "iteration: 108120 loss: 0.0022 lr: 0.02\n",
      "iteration: 108130 loss: 0.0027 lr: 0.02\n",
      "iteration: 108140 loss: 0.0026 lr: 0.02\n",
      "iteration: 108150 loss: 0.0029 lr: 0.02\n",
      "iteration: 108160 loss: 0.0026 lr: 0.02\n",
      "iteration: 108170 loss: 0.0029 lr: 0.02\n",
      "iteration: 108180 loss: 0.0024 lr: 0.02\n",
      "iteration: 108190 loss: 0.0021 lr: 0.02\n",
      "iteration: 108200 loss: 0.0023 lr: 0.02\n",
      "iteration: 108210 loss: 0.0026 lr: 0.02\n",
      "iteration: 108220 loss: 0.0031 lr: 0.02\n",
      "iteration: 108230 loss: 0.0027 lr: 0.02\n",
      "iteration: 108240 loss: 0.0031 lr: 0.02\n",
      "iteration: 108250 loss: 0.0029 lr: 0.02\n",
      "iteration: 108260 loss: 0.0022 lr: 0.02\n",
      "iteration: 108270 loss: 0.0028 lr: 0.02\n",
      "iteration: 108280 loss: 0.0032 lr: 0.02\n",
      "iteration: 108290 loss: 0.0025 lr: 0.02\n",
      "iteration: 108300 loss: 0.0030 lr: 0.02\n",
      "iteration: 108310 loss: 0.0031 lr: 0.02\n",
      "iteration: 108320 loss: 0.0025 lr: 0.02\n",
      "iteration: 108330 loss: 0.0027 lr: 0.02\n",
      "iteration: 108340 loss: 0.0024 lr: 0.02\n",
      "iteration: 108350 loss: 0.0029 lr: 0.02\n",
      "iteration: 108360 loss: 0.0035 lr: 0.02\n",
      "iteration: 108370 loss: 0.0024 lr: 0.02\n",
      "iteration: 108380 loss: 0.0026 lr: 0.02\n",
      "iteration: 108390 loss: 0.0025 lr: 0.02\n",
      "iteration: 108400 loss: 0.0031 lr: 0.02\n",
      "iteration: 108410 loss: 0.0021 lr: 0.02\n",
      "iteration: 108420 loss: 0.0025 lr: 0.02\n",
      "iteration: 108430 loss: 0.0024 lr: 0.02\n",
      "iteration: 108440 loss: 0.0024 lr: 0.02\n",
      "iteration: 108450 loss: 0.0022 lr: 0.02\n",
      "iteration: 108460 loss: 0.0033 lr: 0.02\n",
      "iteration: 108470 loss: 0.0042 lr: 0.02\n",
      "iteration: 108480 loss: 0.0026 lr: 0.02\n",
      "iteration: 108490 loss: 0.0030 lr: 0.02\n",
      "iteration: 108500 loss: 0.0034 lr: 0.02\n",
      "iteration: 108510 loss: 0.0040 lr: 0.02\n",
      "iteration: 108520 loss: 0.0027 lr: 0.02\n",
      "iteration: 108530 loss: 0.0034 lr: 0.02\n",
      "iteration: 108540 loss: 0.0030 lr: 0.02\n",
      "iteration: 108550 loss: 0.0033 lr: 0.02\n",
      "iteration: 108560 loss: 0.0025 lr: 0.02\n",
      "iteration: 108570 loss: 0.0028 lr: 0.02\n",
      "iteration: 108580 loss: 0.0024 lr: 0.02\n",
      "iteration: 108590 loss: 0.0026 lr: 0.02\n",
      "iteration: 108600 loss: 0.0028 lr: 0.02\n",
      "iteration: 108610 loss: 0.0029 lr: 0.02\n",
      "iteration: 108620 loss: 0.0026 lr: 0.02\n",
      "iteration: 108630 loss: 0.0025 lr: 0.02\n",
      "iteration: 108640 loss: 0.0027 lr: 0.02\n",
      "iteration: 108650 loss: 0.0024 lr: 0.02\n",
      "iteration: 108660 loss: 0.0028 lr: 0.02\n",
      "iteration: 108670 loss: 0.0022 lr: 0.02\n",
      "iteration: 108680 loss: 0.0022 lr: 0.02\n",
      "iteration: 108690 loss: 0.0034 lr: 0.02\n",
      "iteration: 108700 loss: 0.0021 lr: 0.02\n",
      "iteration: 108710 loss: 0.0025 lr: 0.02\n",
      "iteration: 108720 loss: 0.0022 lr: 0.02\n",
      "iteration: 108730 loss: 0.0029 lr: 0.02\n",
      "iteration: 108740 loss: 0.0032 lr: 0.02\n",
      "iteration: 108750 loss: 0.0026 lr: 0.02\n",
      "iteration: 108760 loss: 0.0028 lr: 0.02\n",
      "iteration: 108770 loss: 0.0023 lr: 0.02\n",
      "iteration: 108780 loss: 0.0027 lr: 0.02\n",
      "iteration: 108790 loss: 0.0028 lr: 0.02\n",
      "iteration: 108800 loss: 0.0031 lr: 0.02\n",
      "iteration: 108810 loss: 0.0017 lr: 0.02\n",
      "iteration: 108820 loss: 0.0030 lr: 0.02\n",
      "iteration: 108830 loss: 0.0023 lr: 0.02\n",
      "iteration: 108840 loss: 0.0028 lr: 0.02\n",
      "iteration: 108850 loss: 0.0023 lr: 0.02\n",
      "iteration: 108860 loss: 0.0029 lr: 0.02\n",
      "iteration: 108870 loss: 0.0022 lr: 0.02\n",
      "iteration: 108880 loss: 0.0025 lr: 0.02\n",
      "iteration: 108890 loss: 0.0027 lr: 0.02\n",
      "iteration: 108900 loss: 0.0028 lr: 0.02\n",
      "iteration: 108910 loss: 0.0020 lr: 0.02\n",
      "iteration: 108920 loss: 0.0025 lr: 0.02\n",
      "iteration: 108930 loss: 0.0028 lr: 0.02\n",
      "iteration: 108940 loss: 0.0025 lr: 0.02\n",
      "iteration: 108950 loss: 0.0037 lr: 0.02\n",
      "iteration: 108960 loss: 0.0024 lr: 0.02\n",
      "iteration: 108970 loss: 0.0029 lr: 0.02\n",
      "iteration: 108980 loss: 0.0027 lr: 0.02\n",
      "iteration: 108990 loss: 0.0040 lr: 0.02\n",
      "iteration: 109000 loss: 0.0029 lr: 0.02\n",
      "iteration: 109010 loss: 0.0038 lr: 0.02\n",
      "iteration: 109020 loss: 0.0026 lr: 0.02\n",
      "iteration: 109030 loss: 0.0026 lr: 0.02\n",
      "iteration: 109040 loss: 0.0027 lr: 0.02\n",
      "iteration: 109050 loss: 0.0021 lr: 0.02\n",
      "iteration: 109060 loss: 0.0025 lr: 0.02\n",
      "iteration: 109070 loss: 0.0028 lr: 0.02\n",
      "iteration: 109080 loss: 0.0024 lr: 0.02\n",
      "iteration: 109090 loss: 0.0057 lr: 0.02\n",
      "iteration: 109100 loss: 0.0023 lr: 0.02\n",
      "iteration: 109110 loss: 0.0038 lr: 0.02\n",
      "iteration: 109120 loss: 0.0042 lr: 0.02\n",
      "iteration: 109130 loss: 0.0031 lr: 0.02\n",
      "iteration: 109140 loss: 0.0032 lr: 0.02\n",
      "iteration: 109150 loss: 0.0027 lr: 0.02\n",
      "iteration: 109160 loss: 0.0034 lr: 0.02\n",
      "iteration: 109170 loss: 0.0028 lr: 0.02\n",
      "iteration: 109180 loss: 0.0035 lr: 0.02\n",
      "iteration: 109190 loss: 0.0026 lr: 0.02\n",
      "iteration: 109200 loss: 0.0034 lr: 0.02\n",
      "iteration: 109210 loss: 0.0026 lr: 0.02\n",
      "iteration: 109220 loss: 0.0036 lr: 0.02\n",
      "iteration: 109230 loss: 0.0031 lr: 0.02\n",
      "iteration: 109240 loss: 0.0031 lr: 0.02\n",
      "iteration: 109250 loss: 0.0032 lr: 0.02\n",
      "iteration: 109260 loss: 0.0024 lr: 0.02\n",
      "iteration: 109270 loss: 0.0031 lr: 0.02\n",
      "iteration: 109280 loss: 0.0028 lr: 0.02\n",
      "iteration: 109290 loss: 0.0033 lr: 0.02\n",
      "iteration: 109300 loss: 0.0024 lr: 0.02\n",
      "iteration: 109310 loss: 0.0030 lr: 0.02\n",
      "iteration: 109320 loss: 0.0025 lr: 0.02\n",
      "iteration: 109330 loss: 0.0031 lr: 0.02\n",
      "iteration: 109340 loss: 0.0033 lr: 0.02\n",
      "iteration: 109350 loss: 0.0030 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 109360 loss: 0.0019 lr: 0.02\n",
      "iteration: 109370 loss: 0.0037 lr: 0.02\n",
      "iteration: 109380 loss: 0.0031 lr: 0.02\n",
      "iteration: 109390 loss: 0.0038 lr: 0.02\n",
      "iteration: 109400 loss: 0.0024 lr: 0.02\n",
      "iteration: 109410 loss: 0.0035 lr: 0.02\n",
      "iteration: 109420 loss: 0.0027 lr: 0.02\n",
      "iteration: 109430 loss: 0.0025 lr: 0.02\n",
      "iteration: 109440 loss: 0.0031 lr: 0.02\n",
      "iteration: 109450 loss: 0.0029 lr: 0.02\n",
      "iteration: 109460 loss: 0.0026 lr: 0.02\n",
      "iteration: 109470 loss: 0.0026 lr: 0.02\n",
      "iteration: 109480 loss: 0.0023 lr: 0.02\n",
      "iteration: 109490 loss: 0.0022 lr: 0.02\n",
      "iteration: 109500 loss: 0.0028 lr: 0.02\n",
      "iteration: 109510 loss: 0.0025 lr: 0.02\n",
      "iteration: 109520 loss: 0.0032 lr: 0.02\n",
      "iteration: 109530 loss: 0.0030 lr: 0.02\n",
      "iteration: 109540 loss: 0.0026 lr: 0.02\n",
      "iteration: 109550 loss: 0.0027 lr: 0.02\n",
      "iteration: 109560 loss: 0.0029 lr: 0.02\n",
      "iteration: 109570 loss: 0.0019 lr: 0.02\n",
      "iteration: 109580 loss: 0.0025 lr: 0.02\n",
      "iteration: 109590 loss: 0.0021 lr: 0.02\n",
      "iteration: 109600 loss: 0.0032 lr: 0.02\n",
      "iteration: 109610 loss: 0.0027 lr: 0.02\n",
      "iteration: 109620 loss: 0.0022 lr: 0.02\n",
      "iteration: 109630 loss: 0.0031 lr: 0.02\n",
      "iteration: 109640 loss: 0.0018 lr: 0.02\n",
      "iteration: 109650 loss: 0.0021 lr: 0.02\n",
      "iteration: 109660 loss: 0.0026 lr: 0.02\n",
      "iteration: 109670 loss: 0.0028 lr: 0.02\n",
      "iteration: 109680 loss: 0.0023 lr: 0.02\n",
      "iteration: 109690 loss: 0.0028 lr: 0.02\n",
      "iteration: 109700 loss: 0.0022 lr: 0.02\n",
      "iteration: 109710 loss: 0.0028 lr: 0.02\n",
      "iteration: 109720 loss: 0.0028 lr: 0.02\n",
      "iteration: 109730 loss: 0.0022 lr: 0.02\n",
      "iteration: 109740 loss: 0.0023 lr: 0.02\n",
      "iteration: 109750 loss: 0.0027 lr: 0.02\n",
      "iteration: 109760 loss: 0.0027 lr: 0.02\n",
      "iteration: 109770 loss: 0.0026 lr: 0.02\n",
      "iteration: 109780 loss: 0.0028 lr: 0.02\n",
      "iteration: 109790 loss: 0.0036 lr: 0.02\n",
      "iteration: 109800 loss: 0.0021 lr: 0.02\n",
      "iteration: 109810 loss: 0.0028 lr: 0.02\n",
      "iteration: 109820 loss: 0.0027 lr: 0.02\n",
      "iteration: 109830 loss: 0.0033 lr: 0.02\n",
      "iteration: 109840 loss: 0.0025 lr: 0.02\n",
      "iteration: 109850 loss: 0.0031 lr: 0.02\n",
      "iteration: 109860 loss: 0.0023 lr: 0.02\n",
      "iteration: 109870 loss: 0.0018 lr: 0.02\n",
      "iteration: 109880 loss: 0.0023 lr: 0.02\n",
      "iteration: 109890 loss: 0.0022 lr: 0.02\n",
      "iteration: 109900 loss: 0.0028 lr: 0.02\n",
      "iteration: 109910 loss: 0.0026 lr: 0.02\n",
      "iteration: 109920 loss: 0.0044 lr: 0.02\n",
      "iteration: 109930 loss: 0.0030 lr: 0.02\n",
      "iteration: 109940 loss: 0.0029 lr: 0.02\n",
      "iteration: 109950 loss: 0.0028 lr: 0.02\n",
      "iteration: 109960 loss: 0.0027 lr: 0.02\n",
      "iteration: 109970 loss: 0.0030 lr: 0.02\n",
      "iteration: 109980 loss: 0.0023 lr: 0.02\n",
      "iteration: 109990 loss: 0.0028 lr: 0.02\n",
      "iteration: 110000 loss: 0.0035 lr: 0.02\n",
      "iteration: 110010 loss: 0.0024 lr: 0.02\n",
      "iteration: 110020 loss: 0.0021 lr: 0.02\n",
      "iteration: 110030 loss: 0.0026 lr: 0.02\n",
      "iteration: 110040 loss: 0.0032 lr: 0.02\n",
      "iteration: 110050 loss: 0.0030 lr: 0.02\n",
      "iteration: 110060 loss: 0.0029 lr: 0.02\n",
      "iteration: 110070 loss: 0.0022 lr: 0.02\n",
      "iteration: 110080 loss: 0.0033 lr: 0.02\n",
      "iteration: 110090 loss: 0.0021 lr: 0.02\n",
      "iteration: 110100 loss: 0.0022 lr: 0.02\n",
      "iteration: 110110 loss: 0.0027 lr: 0.02\n",
      "iteration: 110120 loss: 0.0039 lr: 0.02\n",
      "iteration: 110130 loss: 0.0029 lr: 0.02\n",
      "iteration: 110140 loss: 0.0027 lr: 0.02\n",
      "iteration: 110150 loss: 0.0034 lr: 0.02\n",
      "iteration: 110160 loss: 0.0027 lr: 0.02\n",
      "iteration: 110170 loss: 0.0027 lr: 0.02\n",
      "iteration: 110180 loss: 0.0026 lr: 0.02\n",
      "iteration: 110190 loss: 0.0030 lr: 0.02\n",
      "iteration: 110200 loss: 0.0024 lr: 0.02\n",
      "iteration: 110210 loss: 0.0024 lr: 0.02\n",
      "iteration: 110220 loss: 0.0028 lr: 0.02\n",
      "iteration: 110230 loss: 0.0027 lr: 0.02\n",
      "iteration: 110240 loss: 0.0023 lr: 0.02\n",
      "iteration: 110250 loss: 0.0022 lr: 0.02\n",
      "iteration: 110260 loss: 0.0018 lr: 0.02\n",
      "iteration: 110270 loss: 0.0025 lr: 0.02\n",
      "iteration: 110280 loss: 0.0029 lr: 0.02\n",
      "iteration: 110290 loss: 0.0022 lr: 0.02\n",
      "iteration: 110300 loss: 0.0030 lr: 0.02\n",
      "iteration: 110310 loss: 0.0029 lr: 0.02\n",
      "iteration: 110320 loss: 0.0024 lr: 0.02\n",
      "iteration: 110330 loss: 0.0028 lr: 0.02\n",
      "iteration: 110340 loss: 0.0036 lr: 0.02\n",
      "iteration: 110350 loss: 0.0026 lr: 0.02\n",
      "iteration: 110360 loss: 0.0027 lr: 0.02\n",
      "iteration: 110370 loss: 0.0026 lr: 0.02\n",
      "iteration: 110380 loss: 0.0033 lr: 0.02\n",
      "iteration: 110390 loss: 0.0024 lr: 0.02\n",
      "iteration: 110400 loss: 0.0024 lr: 0.02\n",
      "iteration: 110410 loss: 0.0024 lr: 0.02\n",
      "iteration: 110420 loss: 0.0029 lr: 0.02\n",
      "iteration: 110430 loss: 0.0029 lr: 0.02\n",
      "iteration: 110440 loss: 0.0028 lr: 0.02\n",
      "iteration: 110450 loss: 0.0026 lr: 0.02\n",
      "iteration: 110460 loss: 0.0034 lr: 0.02\n",
      "iteration: 110470 loss: 0.0038 lr: 0.02\n",
      "iteration: 110480 loss: 0.0030 lr: 0.02\n",
      "iteration: 110490 loss: 0.0033 lr: 0.02\n",
      "iteration: 110500 loss: 0.0026 lr: 0.02\n",
      "iteration: 110510 loss: 0.0025 lr: 0.02\n",
      "iteration: 110520 loss: 0.0023 lr: 0.02\n",
      "iteration: 110530 loss: 0.0038 lr: 0.02\n",
      "iteration: 110540 loss: 0.0023 lr: 0.02\n",
      "iteration: 110550 loss: 0.0028 lr: 0.02\n",
      "iteration: 110560 loss: 0.0028 lr: 0.02\n",
      "iteration: 110570 loss: 0.0021 lr: 0.02\n",
      "iteration: 110580 loss: 0.0024 lr: 0.02\n",
      "iteration: 110590 loss: 0.0024 lr: 0.02\n",
      "iteration: 110600 loss: 0.0026 lr: 0.02\n",
      "iteration: 110610 loss: 0.0024 lr: 0.02\n",
      "iteration: 110620 loss: 0.0022 lr: 0.02\n",
      "iteration: 110630 loss: 0.0029 lr: 0.02\n",
      "iteration: 110640 loss: 0.0021 lr: 0.02\n",
      "iteration: 110650 loss: 0.0023 lr: 0.02\n",
      "iteration: 110660 loss: 0.0033 lr: 0.02\n",
      "iteration: 110670 loss: 0.0031 lr: 0.02\n",
      "iteration: 110680 loss: 0.0029 lr: 0.02\n",
      "iteration: 110690 loss: 0.0024 lr: 0.02\n",
      "iteration: 110700 loss: 0.0027 lr: 0.02\n",
      "iteration: 110710 loss: 0.0022 lr: 0.02\n",
      "iteration: 110720 loss: 0.0025 lr: 0.02\n",
      "iteration: 110730 loss: 0.0025 lr: 0.02\n",
      "iteration: 110740 loss: 0.0028 lr: 0.02\n",
      "iteration: 110750 loss: 0.0027 lr: 0.02\n",
      "iteration: 110760 loss: 0.0024 lr: 0.02\n",
      "iteration: 110770 loss: 0.0027 lr: 0.02\n",
      "iteration: 110780 loss: 0.0020 lr: 0.02\n",
      "iteration: 110790 loss: 0.0036 lr: 0.02\n",
      "iteration: 110800 loss: 0.0025 lr: 0.02\n",
      "iteration: 110810 loss: 0.0033 lr: 0.02\n",
      "iteration: 110820 loss: 0.0028 lr: 0.02\n",
      "iteration: 110830 loss: 0.0033 lr: 0.02\n",
      "iteration: 110840 loss: 0.0021 lr: 0.02\n",
      "iteration: 110850 loss: 0.0030 lr: 0.02\n",
      "iteration: 110860 loss: 0.0023 lr: 0.02\n",
      "iteration: 110870 loss: 0.0026 lr: 0.02\n",
      "iteration: 110880 loss: 0.0029 lr: 0.02\n",
      "iteration: 110890 loss: 0.0027 lr: 0.02\n",
      "iteration: 110900 loss: 0.0028 lr: 0.02\n",
      "iteration: 110910 loss: 0.0027 lr: 0.02\n",
      "iteration: 110920 loss: 0.0034 lr: 0.02\n",
      "iteration: 110930 loss: 0.0021 lr: 0.02\n",
      "iteration: 110940 loss: 0.0025 lr: 0.02\n",
      "iteration: 110950 loss: 0.0024 lr: 0.02\n",
      "iteration: 110960 loss: 0.0030 lr: 0.02\n",
      "iteration: 110970 loss: 0.0027 lr: 0.02\n",
      "iteration: 110980 loss: 0.0025 lr: 0.02\n",
      "iteration: 110990 loss: 0.0029 lr: 0.02\n",
      "iteration: 111000 loss: 0.0025 lr: 0.02\n",
      "iteration: 111010 loss: 0.0021 lr: 0.02\n",
      "iteration: 111020 loss: 0.0031 lr: 0.02\n",
      "iteration: 111030 loss: 0.0025 lr: 0.02\n",
      "iteration: 111040 loss: 0.0028 lr: 0.02\n",
      "iteration: 111050 loss: 0.0024 lr: 0.02\n",
      "iteration: 111060 loss: 0.0031 lr: 0.02\n",
      "iteration: 111070 loss: 0.0030 lr: 0.02\n",
      "iteration: 111080 loss: 0.0020 lr: 0.02\n",
      "iteration: 111090 loss: 0.0030 lr: 0.02\n",
      "iteration: 111100 loss: 0.0035 lr: 0.02\n",
      "iteration: 111110 loss: 0.0027 lr: 0.02\n",
      "iteration: 111120 loss: 0.0020 lr: 0.02\n",
      "iteration: 111130 loss: 0.0030 lr: 0.02\n",
      "iteration: 111140 loss: 0.0024 lr: 0.02\n",
      "iteration: 111150 loss: 0.0032 lr: 0.02\n",
      "iteration: 111160 loss: 0.0032 lr: 0.02\n",
      "iteration: 111170 loss: 0.0026 lr: 0.02\n",
      "iteration: 111180 loss: 0.0024 lr: 0.02\n",
      "iteration: 111190 loss: 0.0031 lr: 0.02\n",
      "iteration: 111200 loss: 0.0028 lr: 0.02\n",
      "iteration: 111210 loss: 0.0030 lr: 0.02\n",
      "iteration: 111220 loss: 0.0025 lr: 0.02\n",
      "iteration: 111230 loss: 0.0018 lr: 0.02\n",
      "iteration: 111240 loss: 0.0028 lr: 0.02\n",
      "iteration: 111250 loss: 0.0021 lr: 0.02\n",
      "iteration: 111260 loss: 0.0036 lr: 0.02\n",
      "iteration: 111270 loss: 0.0036 lr: 0.02\n",
      "iteration: 111280 loss: 0.0025 lr: 0.02\n",
      "iteration: 111290 loss: 0.0022 lr: 0.02\n",
      "iteration: 111300 loss: 0.0028 lr: 0.02\n",
      "iteration: 111310 loss: 0.0030 lr: 0.02\n",
      "iteration: 111320 loss: 0.0027 lr: 0.02\n",
      "iteration: 111330 loss: 0.0023 lr: 0.02\n",
      "iteration: 111340 loss: 0.0022 lr: 0.02\n",
      "iteration: 111350 loss: 0.0031 lr: 0.02\n",
      "iteration: 111360 loss: 0.0027 lr: 0.02\n",
      "iteration: 111370 loss: 0.0028 lr: 0.02\n",
      "iteration: 111380 loss: 0.0025 lr: 0.02\n",
      "iteration: 111390 loss: 0.0031 lr: 0.02\n",
      "iteration: 111400 loss: 0.0026 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 111410 loss: 0.0026 lr: 0.02\n",
      "iteration: 111420 loss: 0.0022 lr: 0.02\n",
      "iteration: 111430 loss: 0.0025 lr: 0.02\n",
      "iteration: 111440 loss: 0.0023 lr: 0.02\n",
      "iteration: 111450 loss: 0.0020 lr: 0.02\n",
      "iteration: 111460 loss: 0.0015 lr: 0.02\n",
      "iteration: 111470 loss: 0.0027 lr: 0.02\n",
      "iteration: 111480 loss: 0.0029 lr: 0.02\n",
      "iteration: 111490 loss: 0.0036 lr: 0.02\n",
      "iteration: 111500 loss: 0.0026 lr: 0.02\n",
      "iteration: 111510 loss: 0.0020 lr: 0.02\n",
      "iteration: 111520 loss: 0.0031 lr: 0.02\n",
      "iteration: 111530 loss: 0.0020 lr: 0.02\n",
      "iteration: 111540 loss: 0.0034 lr: 0.02\n",
      "iteration: 111550 loss: 0.0032 lr: 0.02\n",
      "iteration: 111560 loss: 0.0025 lr: 0.02\n",
      "iteration: 111570 loss: 0.0026 lr: 0.02\n",
      "iteration: 111580 loss: 0.0028 lr: 0.02\n",
      "iteration: 111590 loss: 0.0034 lr: 0.02\n",
      "iteration: 111600 loss: 0.0024 lr: 0.02\n",
      "iteration: 111610 loss: 0.0022 lr: 0.02\n",
      "iteration: 111620 loss: 0.0036 lr: 0.02\n",
      "iteration: 111630 loss: 0.0025 lr: 0.02\n",
      "iteration: 111640 loss: 0.0033 lr: 0.02\n",
      "iteration: 111650 loss: 0.0034 lr: 0.02\n",
      "iteration: 111660 loss: 0.0038 lr: 0.02\n",
      "iteration: 111670 loss: 0.0028 lr: 0.02\n",
      "iteration: 111680 loss: 0.0024 lr: 0.02\n",
      "iteration: 111690 loss: 0.0030 lr: 0.02\n",
      "iteration: 111700 loss: 0.0027 lr: 0.02\n",
      "iteration: 111710 loss: 0.0028 lr: 0.02\n",
      "iteration: 111720 loss: 0.0029 lr: 0.02\n",
      "iteration: 111730 loss: 0.0024 lr: 0.02\n",
      "iteration: 111740 loss: 0.0040 lr: 0.02\n",
      "iteration: 111750 loss: 0.0029 lr: 0.02\n",
      "iteration: 111760 loss: 0.0027 lr: 0.02\n",
      "iteration: 111770 loss: 0.0034 lr: 0.02\n",
      "iteration: 111780 loss: 0.0026 lr: 0.02\n",
      "iteration: 111790 loss: 0.0029 lr: 0.02\n",
      "iteration: 111800 loss: 0.0023 lr: 0.02\n",
      "iteration: 111810 loss: 0.0030 lr: 0.02\n",
      "iteration: 111820 loss: 0.0031 lr: 0.02\n",
      "iteration: 111830 loss: 0.0030 lr: 0.02\n",
      "iteration: 111840 loss: 0.0027 lr: 0.02\n",
      "iteration: 111850 loss: 0.0026 lr: 0.02\n",
      "iteration: 111860 loss: 0.0022 lr: 0.02\n",
      "iteration: 111870 loss: 0.0029 lr: 0.02\n",
      "iteration: 111880 loss: 0.0019 lr: 0.02\n",
      "iteration: 111890 loss: 0.0019 lr: 0.02\n",
      "iteration: 111900 loss: 0.0032 lr: 0.02\n",
      "iteration: 111910 loss: 0.0026 lr: 0.02\n",
      "iteration: 111920 loss: 0.0027 lr: 0.02\n",
      "iteration: 111930 loss: 0.0030 lr: 0.02\n",
      "iteration: 111940 loss: 0.0032 lr: 0.02\n",
      "iteration: 111950 loss: 0.0035 lr: 0.02\n",
      "iteration: 111960 loss: 0.0031 lr: 0.02\n",
      "iteration: 111970 loss: 0.0025 lr: 0.02\n",
      "iteration: 111980 loss: 0.0029 lr: 0.02\n",
      "iteration: 111990 loss: 0.0021 lr: 0.02\n",
      "iteration: 112000 loss: 0.0028 lr: 0.02\n",
      "iteration: 112010 loss: 0.0024 lr: 0.02\n",
      "iteration: 112020 loss: 0.0024 lr: 0.02\n",
      "iteration: 112030 loss: 0.0032 lr: 0.02\n",
      "iteration: 112040 loss: 0.0031 lr: 0.02\n",
      "iteration: 112050 loss: 0.0029 lr: 0.02\n",
      "iteration: 112060 loss: 0.0035 lr: 0.02\n",
      "iteration: 112070 loss: 0.0026 lr: 0.02\n",
      "iteration: 112080 loss: 0.0030 lr: 0.02\n",
      "iteration: 112090 loss: 0.0036 lr: 0.02\n",
      "iteration: 112100 loss: 0.0024 lr: 0.02\n",
      "iteration: 112110 loss: 0.0035 lr: 0.02\n",
      "iteration: 112120 loss: 0.0027 lr: 0.02\n",
      "iteration: 112130 loss: 0.0031 lr: 0.02\n",
      "iteration: 112140 loss: 0.0027 lr: 0.02\n",
      "iteration: 112150 loss: 0.0026 lr: 0.02\n",
      "iteration: 112160 loss: 0.0023 lr: 0.02\n",
      "iteration: 112170 loss: 0.0017 lr: 0.02\n",
      "iteration: 112180 loss: 0.0021 lr: 0.02\n",
      "iteration: 112190 loss: 0.0028 lr: 0.02\n",
      "iteration: 112200 loss: 0.0028 lr: 0.02\n",
      "iteration: 112210 loss: 0.0026 lr: 0.02\n",
      "iteration: 112220 loss: 0.0025 lr: 0.02\n",
      "iteration: 112230 loss: 0.0024 lr: 0.02\n",
      "iteration: 112240 loss: 0.0024 lr: 0.02\n",
      "iteration: 112250 loss: 0.0027 lr: 0.02\n",
      "iteration: 112260 loss: 0.0032 lr: 0.02\n",
      "iteration: 112270 loss: 0.0033 lr: 0.02\n",
      "iteration: 112280 loss: 0.0036 lr: 0.02\n",
      "iteration: 112290 loss: 0.0030 lr: 0.02\n",
      "iteration: 112300 loss: 0.0033 lr: 0.02\n",
      "iteration: 112310 loss: 0.0023 lr: 0.02\n",
      "iteration: 112320 loss: 0.0024 lr: 0.02\n",
      "iteration: 112330 loss: 0.0024 lr: 0.02\n",
      "iteration: 112340 loss: 0.0029 lr: 0.02\n",
      "iteration: 112350 loss: 0.0021 lr: 0.02\n",
      "iteration: 112360 loss: 0.0032 lr: 0.02\n",
      "iteration: 112370 loss: 0.0028 lr: 0.02\n",
      "iteration: 112380 loss: 0.0029 lr: 0.02\n",
      "iteration: 112390 loss: 0.0034 lr: 0.02\n",
      "iteration: 112400 loss: 0.0029 lr: 0.02\n",
      "iteration: 112410 loss: 0.0030 lr: 0.02\n",
      "iteration: 112420 loss: 0.0028 lr: 0.02\n",
      "iteration: 112430 loss: 0.0025 lr: 0.02\n",
      "iteration: 112440 loss: 0.0026 lr: 0.02\n",
      "iteration: 112450 loss: 0.0025 lr: 0.02\n",
      "iteration: 112460 loss: 0.0022 lr: 0.02\n",
      "iteration: 112470 loss: 0.0031 lr: 0.02\n",
      "iteration: 112480 loss: 0.0032 lr: 0.02\n",
      "iteration: 112490 loss: 0.0033 lr: 0.02\n",
      "iteration: 112500 loss: 0.0023 lr: 0.02\n",
      "iteration: 112510 loss: 0.0031 lr: 0.02\n",
      "iteration: 112520 loss: 0.0026 lr: 0.02\n",
      "iteration: 112530 loss: 0.0028 lr: 0.02\n",
      "iteration: 112540 loss: 0.0048 lr: 0.02\n",
      "iteration: 112550 loss: 0.0034 lr: 0.02\n",
      "iteration: 112560 loss: 0.0024 lr: 0.02\n",
      "iteration: 112570 loss: 0.0041 lr: 0.02\n",
      "iteration: 112580 loss: 0.0030 lr: 0.02\n",
      "iteration: 112590 loss: 0.0033 lr: 0.02\n",
      "iteration: 112600 loss: 0.0023 lr: 0.02\n",
      "iteration: 112610 loss: 0.0026 lr: 0.02\n",
      "iteration: 112620 loss: 0.0034 lr: 0.02\n",
      "iteration: 112630 loss: 0.0030 lr: 0.02\n",
      "iteration: 112640 loss: 0.0023 lr: 0.02\n",
      "iteration: 112650 loss: 0.0021 lr: 0.02\n",
      "iteration: 112660 loss: 0.0024 lr: 0.02\n",
      "iteration: 112670 loss: 0.0024 lr: 0.02\n",
      "iteration: 112680 loss: 0.0029 lr: 0.02\n",
      "iteration: 112690 loss: 0.0021 lr: 0.02\n",
      "iteration: 112700 loss: 0.0030 lr: 0.02\n",
      "iteration: 112710 loss: 0.0030 lr: 0.02\n",
      "iteration: 112720 loss: 0.0029 lr: 0.02\n",
      "iteration: 112730 loss: 0.0037 lr: 0.02\n",
      "iteration: 112740 loss: 0.0025 lr: 0.02\n",
      "iteration: 112750 loss: 0.0024 lr: 0.02\n",
      "iteration: 112760 loss: 0.0026 lr: 0.02\n",
      "iteration: 112770 loss: 0.0028 lr: 0.02\n",
      "iteration: 112780 loss: 0.0032 lr: 0.02\n",
      "iteration: 112790 loss: 0.0026 lr: 0.02\n",
      "iteration: 112800 loss: 0.0026 lr: 0.02\n",
      "iteration: 112810 loss: 0.0028 lr: 0.02\n",
      "iteration: 112820 loss: 0.0026 lr: 0.02\n",
      "iteration: 112830 loss: 0.0033 lr: 0.02\n",
      "iteration: 112840 loss: 0.0023 lr: 0.02\n",
      "iteration: 112850 loss: 0.0028 lr: 0.02\n",
      "iteration: 112860 loss: 0.0025 lr: 0.02\n",
      "iteration: 112870 loss: 0.0027 lr: 0.02\n",
      "iteration: 112880 loss: 0.0026 lr: 0.02\n",
      "iteration: 112890 loss: 0.0031 lr: 0.02\n",
      "iteration: 112900 loss: 0.0030 lr: 0.02\n",
      "iteration: 112910 loss: 0.0026 lr: 0.02\n",
      "iteration: 112920 loss: 0.0026 lr: 0.02\n",
      "iteration: 112930 loss: 0.0029 lr: 0.02\n",
      "iteration: 112940 loss: 0.0024 lr: 0.02\n",
      "iteration: 112950 loss: 0.0027 lr: 0.02\n",
      "iteration: 112960 loss: 0.0030 lr: 0.02\n",
      "iteration: 112970 loss: 0.0024 lr: 0.02\n",
      "iteration: 112980 loss: 0.0027 lr: 0.02\n",
      "iteration: 112990 loss: 0.0028 lr: 0.02\n",
      "iteration: 113000 loss: 0.0033 lr: 0.02\n",
      "iteration: 113010 loss: 0.0037 lr: 0.02\n",
      "iteration: 113020 loss: 0.0024 lr: 0.02\n",
      "iteration: 113030 loss: 0.0027 lr: 0.02\n",
      "iteration: 113040 loss: 0.0027 lr: 0.02\n",
      "iteration: 113050 loss: 0.0026 lr: 0.02\n",
      "iteration: 113060 loss: 0.0031 lr: 0.02\n",
      "iteration: 113070 loss: 0.0022 lr: 0.02\n",
      "iteration: 113080 loss: 0.0031 lr: 0.02\n",
      "iteration: 113090 loss: 0.0027 lr: 0.02\n",
      "iteration: 113100 loss: 0.0030 lr: 0.02\n",
      "iteration: 113110 loss: 0.0024 lr: 0.02\n",
      "iteration: 113120 loss: 0.0032 lr: 0.02\n",
      "iteration: 113130 loss: 0.0023 lr: 0.02\n",
      "iteration: 113140 loss: 0.0028 lr: 0.02\n",
      "iteration: 113150 loss: 0.0027 lr: 0.02\n",
      "iteration: 113160 loss: 0.0024 lr: 0.02\n",
      "iteration: 113170 loss: 0.0022 lr: 0.02\n",
      "iteration: 113180 loss: 0.0037 lr: 0.02\n",
      "iteration: 113190 loss: 0.0026 lr: 0.02\n",
      "iteration: 113200 loss: 0.0038 lr: 0.02\n",
      "iteration: 113210 loss: 0.0023 lr: 0.02\n",
      "iteration: 113220 loss: 0.0024 lr: 0.02\n",
      "iteration: 113230 loss: 0.0028 lr: 0.02\n",
      "iteration: 113240 loss: 0.0024 lr: 0.02\n",
      "iteration: 113250 loss: 0.0028 lr: 0.02\n",
      "iteration: 113260 loss: 0.0025 lr: 0.02\n",
      "iteration: 113270 loss: 0.0025 lr: 0.02\n",
      "iteration: 113280 loss: 0.0027 lr: 0.02\n",
      "iteration: 113290 loss: 0.0027 lr: 0.02\n",
      "iteration: 113300 loss: 0.0033 lr: 0.02\n",
      "iteration: 113310 loss: 0.0029 lr: 0.02\n",
      "iteration: 113320 loss: 0.0029 lr: 0.02\n",
      "iteration: 113330 loss: 0.0024 lr: 0.02\n",
      "iteration: 113340 loss: 0.0030 lr: 0.02\n",
      "iteration: 113350 loss: 0.0032 lr: 0.02\n",
      "iteration: 113360 loss: 0.0025 lr: 0.02\n",
      "iteration: 113370 loss: 0.0025 lr: 0.02\n",
      "iteration: 113380 loss: 0.0026 lr: 0.02\n",
      "iteration: 113390 loss: 0.0024 lr: 0.02\n",
      "iteration: 113400 loss: 0.0041 lr: 0.02\n",
      "iteration: 113410 loss: 0.0026 lr: 0.02\n",
      "iteration: 113420 loss: 0.0027 lr: 0.02\n",
      "iteration: 113430 loss: 0.0023 lr: 0.02\n",
      "iteration: 113440 loss: 0.0024 lr: 0.02\n",
      "iteration: 113450 loss: 0.0028 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 113460 loss: 0.0022 lr: 0.02\n",
      "iteration: 113470 loss: 0.0030 lr: 0.02\n",
      "iteration: 113480 loss: 0.0031 lr: 0.02\n",
      "iteration: 113490 loss: 0.0031 lr: 0.02\n",
      "iteration: 113500 loss: 0.0022 lr: 0.02\n",
      "iteration: 113510 loss: 0.0025 lr: 0.02\n",
      "iteration: 113520 loss: 0.0024 lr: 0.02\n",
      "iteration: 113530 loss: 0.0029 lr: 0.02\n",
      "iteration: 113540 loss: 0.0031 lr: 0.02\n",
      "iteration: 113550 loss: 0.0027 lr: 0.02\n",
      "iteration: 113560 loss: 0.0025 lr: 0.02\n",
      "iteration: 113570 loss: 0.0021 lr: 0.02\n",
      "iteration: 113580 loss: 0.0020 lr: 0.02\n",
      "iteration: 113590 loss: 0.0025 lr: 0.02\n",
      "iteration: 113600 loss: 0.0024 lr: 0.02\n",
      "iteration: 113610 loss: 0.0028 lr: 0.02\n",
      "iteration: 113620 loss: 0.0024 lr: 0.02\n",
      "iteration: 113630 loss: 0.0028 lr: 0.02\n",
      "iteration: 113640 loss: 0.0027 lr: 0.02\n",
      "iteration: 113650 loss: 0.0023 lr: 0.02\n",
      "iteration: 113660 loss: 0.0020 lr: 0.02\n",
      "iteration: 113670 loss: 0.0024 lr: 0.02\n",
      "iteration: 113680 loss: 0.0025 lr: 0.02\n",
      "iteration: 113690 loss: 0.0026 lr: 0.02\n",
      "iteration: 113700 loss: 0.0033 lr: 0.02\n",
      "iteration: 113710 loss: 0.0026 lr: 0.02\n",
      "iteration: 113720 loss: 0.0022 lr: 0.02\n",
      "iteration: 113730 loss: 0.0032 lr: 0.02\n",
      "iteration: 113740 loss: 0.0038 lr: 0.02\n",
      "iteration: 113750 loss: 0.0022 lr: 0.02\n",
      "iteration: 113760 loss: 0.0022 lr: 0.02\n",
      "iteration: 113770 loss: 0.0023 lr: 0.02\n",
      "iteration: 113780 loss: 0.0030 lr: 0.02\n",
      "iteration: 113790 loss: 0.0034 lr: 0.02\n",
      "iteration: 113800 loss: 0.0034 lr: 0.02\n",
      "iteration: 113810 loss: 0.0024 lr: 0.02\n",
      "iteration: 113820 loss: 0.0035 lr: 0.02\n",
      "iteration: 113830 loss: 0.0020 lr: 0.02\n",
      "iteration: 113840 loss: 0.0028 lr: 0.02\n",
      "iteration: 113850 loss: 0.0026 lr: 0.02\n",
      "iteration: 113860 loss: 0.0022 lr: 0.02\n",
      "iteration: 113870 loss: 0.0027 lr: 0.02\n",
      "iteration: 113880 loss: 0.0034 lr: 0.02\n",
      "iteration: 113890 loss: 0.0027 lr: 0.02\n",
      "iteration: 113900 loss: 0.0022 lr: 0.02\n",
      "iteration: 113910 loss: 0.0023 lr: 0.02\n",
      "iteration: 113920 loss: 0.0026 lr: 0.02\n",
      "iteration: 113930 loss: 0.0020 lr: 0.02\n",
      "iteration: 113940 loss: 0.0025 lr: 0.02\n",
      "iteration: 113950 loss: 0.0023 lr: 0.02\n",
      "iteration: 113960 loss: 0.0027 lr: 0.02\n",
      "iteration: 113970 loss: 0.0021 lr: 0.02\n",
      "iteration: 113980 loss: 0.0022 lr: 0.02\n",
      "iteration: 113990 loss: 0.0021 lr: 0.02\n",
      "iteration: 114000 loss: 0.0024 lr: 0.02\n",
      "iteration: 114010 loss: 0.0023 lr: 0.02\n",
      "iteration: 114020 loss: 0.0031 lr: 0.02\n",
      "iteration: 114030 loss: 0.0028 lr: 0.02\n",
      "iteration: 114040 loss: 0.0024 lr: 0.02\n",
      "iteration: 114050 loss: 0.0026 lr: 0.02\n",
      "iteration: 114060 loss: 0.0027 lr: 0.02\n",
      "iteration: 114070 loss: 0.0025 lr: 0.02\n",
      "iteration: 114080 loss: 0.0032 lr: 0.02\n",
      "iteration: 114090 loss: 0.0025 lr: 0.02\n",
      "iteration: 114100 loss: 0.0028 lr: 0.02\n",
      "iteration: 114110 loss: 0.0031 lr: 0.02\n",
      "iteration: 114120 loss: 0.0027 lr: 0.02\n",
      "iteration: 114130 loss: 0.0027 lr: 0.02\n",
      "iteration: 114140 loss: 0.0031 lr: 0.02\n",
      "iteration: 114150 loss: 0.0026 lr: 0.02\n",
      "iteration: 114160 loss: 0.0024 lr: 0.02\n",
      "iteration: 114170 loss: 0.0030 lr: 0.02\n",
      "iteration: 114180 loss: 0.0024 lr: 0.02\n",
      "iteration: 114190 loss: 0.0028 lr: 0.02\n",
      "iteration: 114200 loss: 0.0025 lr: 0.02\n",
      "iteration: 114210 loss: 0.0026 lr: 0.02\n",
      "iteration: 114220 loss: 0.0023 lr: 0.02\n",
      "iteration: 114230 loss: 0.0026 lr: 0.02\n",
      "iteration: 114240 loss: 0.0025 lr: 0.02\n",
      "iteration: 114250 loss: 0.0025 lr: 0.02\n",
      "iteration: 114260 loss: 0.0029 lr: 0.02\n",
      "iteration: 114270 loss: 0.0029 lr: 0.02\n",
      "iteration: 114280 loss: 0.0025 lr: 0.02\n",
      "iteration: 114290 loss: 0.0029 lr: 0.02\n",
      "iteration: 114300 loss: 0.0023 lr: 0.02\n",
      "iteration: 114310 loss: 0.0024 lr: 0.02\n",
      "iteration: 114320 loss: 0.0020 lr: 0.02\n",
      "iteration: 114330 loss: 0.0031 lr: 0.02\n",
      "iteration: 114340 loss: 0.0025 lr: 0.02\n",
      "iteration: 114350 loss: 0.0022 lr: 0.02\n",
      "iteration: 114360 loss: 0.0026 lr: 0.02\n",
      "iteration: 114370 loss: 0.0024 lr: 0.02\n",
      "iteration: 114380 loss: 0.0034 lr: 0.02\n",
      "iteration: 114390 loss: 0.0026 lr: 0.02\n",
      "iteration: 114400 loss: 0.0022 lr: 0.02\n",
      "iteration: 114410 loss: 0.0025 lr: 0.02\n",
      "iteration: 114420 loss: 0.0018 lr: 0.02\n",
      "iteration: 114430 loss: 0.0020 lr: 0.02\n",
      "iteration: 114440 loss: 0.0032 lr: 0.02\n",
      "iteration: 114450 loss: 0.0026 lr: 0.02\n",
      "iteration: 114460 loss: 0.0021 lr: 0.02\n",
      "iteration: 114470 loss: 0.0029 lr: 0.02\n",
      "iteration: 114480 loss: 0.0026 lr: 0.02\n",
      "iteration: 114490 loss: 0.0033 lr: 0.02\n",
      "iteration: 114500 loss: 0.0027 lr: 0.02\n",
      "iteration: 114510 loss: 0.0026 lr: 0.02\n",
      "iteration: 114520 loss: 0.0031 lr: 0.02\n",
      "iteration: 114530 loss: 0.0021 lr: 0.02\n",
      "iteration: 114540 loss: 0.0024 lr: 0.02\n",
      "iteration: 114550 loss: 0.0025 lr: 0.02\n",
      "iteration: 114560 loss: 0.0027 lr: 0.02\n",
      "iteration: 114570 loss: 0.0022 lr: 0.02\n",
      "iteration: 114580 loss: 0.0036 lr: 0.02\n",
      "iteration: 114590 loss: 0.0025 lr: 0.02\n",
      "iteration: 114600 loss: 0.0024 lr: 0.02\n",
      "iteration: 114610 loss: 0.0036 lr: 0.02\n",
      "iteration: 114620 loss: 0.0029 lr: 0.02\n",
      "iteration: 114630 loss: 0.0034 lr: 0.02\n",
      "iteration: 114640 loss: 0.0029 lr: 0.02\n",
      "iteration: 114650 loss: 0.0023 lr: 0.02\n",
      "iteration: 114660 loss: 0.0024 lr: 0.02\n",
      "iteration: 114670 loss: 0.0027 lr: 0.02\n",
      "iteration: 114680 loss: 0.0027 lr: 0.02\n",
      "iteration: 114690 loss: 0.0025 lr: 0.02\n",
      "iteration: 114700 loss: 0.0033 lr: 0.02\n",
      "iteration: 114710 loss: 0.0027 lr: 0.02\n",
      "iteration: 114720 loss: 0.0028 lr: 0.02\n",
      "iteration: 114730 loss: 0.0032 lr: 0.02\n",
      "iteration: 114740 loss: 0.0030 lr: 0.02\n",
      "iteration: 114750 loss: 0.0041 lr: 0.02\n",
      "iteration: 114760 loss: 0.0029 lr: 0.02\n",
      "iteration: 114770 loss: 0.0020 lr: 0.02\n",
      "iteration: 114780 loss: 0.0023 lr: 0.02\n",
      "iteration: 114790 loss: 0.0024 lr: 0.02\n",
      "iteration: 114800 loss: 0.0022 lr: 0.02\n",
      "iteration: 114810 loss: 0.0028 lr: 0.02\n",
      "iteration: 114820 loss: 0.0023 lr: 0.02\n",
      "iteration: 114830 loss: 0.0026 lr: 0.02\n",
      "iteration: 114840 loss: 0.0023 lr: 0.02\n",
      "iteration: 114850 loss: 0.0030 lr: 0.02\n",
      "iteration: 114860 loss: 0.0027 lr: 0.02\n",
      "iteration: 114870 loss: 0.0026 lr: 0.02\n",
      "iteration: 114880 loss: 0.0021 lr: 0.02\n",
      "iteration: 114890 loss: 0.0021 lr: 0.02\n",
      "iteration: 114900 loss: 0.0033 lr: 0.02\n",
      "iteration: 114910 loss: 0.0033 lr: 0.02\n",
      "iteration: 114920 loss: 0.0025 lr: 0.02\n",
      "iteration: 114930 loss: 0.0032 lr: 0.02\n",
      "iteration: 114940 loss: 0.0034 lr: 0.02\n",
      "iteration: 114950 loss: 0.0027 lr: 0.02\n",
      "iteration: 114960 loss: 0.0025 lr: 0.02\n",
      "iteration: 114970 loss: 0.0024 lr: 0.02\n",
      "iteration: 114980 loss: 0.0026 lr: 0.02\n",
      "iteration: 114990 loss: 0.0031 lr: 0.02\n",
      "iteration: 115000 loss: 0.0032 lr: 0.02\n",
      "iteration: 115010 loss: 0.0025 lr: 0.02\n",
      "iteration: 115020 loss: 0.0032 lr: 0.02\n",
      "iteration: 115030 loss: 0.0023 lr: 0.02\n",
      "iteration: 115040 loss: 0.0021 lr: 0.02\n",
      "iteration: 115050 loss: 0.0030 lr: 0.02\n",
      "iteration: 115060 loss: 0.0022 lr: 0.02\n",
      "iteration: 115070 loss: 0.0028 lr: 0.02\n",
      "iteration: 115080 loss: 0.0026 lr: 0.02\n",
      "iteration: 115090 loss: 0.0024 lr: 0.02\n",
      "iteration: 115100 loss: 0.0031 lr: 0.02\n",
      "iteration: 115110 loss: 0.0036 lr: 0.02\n",
      "iteration: 115120 loss: 0.0031 lr: 0.02\n",
      "iteration: 115130 loss: 0.0029 lr: 0.02\n",
      "iteration: 115140 loss: 0.0029 lr: 0.02\n",
      "iteration: 115150 loss: 0.0028 lr: 0.02\n",
      "iteration: 115160 loss: 0.0027 lr: 0.02\n",
      "iteration: 115170 loss: 0.0029 lr: 0.02\n",
      "iteration: 115180 loss: 0.0025 lr: 0.02\n",
      "iteration: 115190 loss: 0.0029 lr: 0.02\n",
      "iteration: 115200 loss: 0.0022 lr: 0.02\n",
      "iteration: 115210 loss: 0.0027 lr: 0.02\n",
      "iteration: 115220 loss: 0.0018 lr: 0.02\n",
      "iteration: 115230 loss: 0.0028 lr: 0.02\n",
      "iteration: 115240 loss: 0.0025 lr: 0.02\n",
      "iteration: 115250 loss: 0.0026 lr: 0.02\n",
      "iteration: 115260 loss: 0.0026 lr: 0.02\n",
      "iteration: 115270 loss: 0.0022 lr: 0.02\n",
      "iteration: 115280 loss: 0.0025 lr: 0.02\n",
      "iteration: 115290 loss: 0.0023 lr: 0.02\n",
      "iteration: 115300 loss: 0.0024 lr: 0.02\n",
      "iteration: 115310 loss: 0.0033 lr: 0.02\n",
      "iteration: 115320 loss: 0.0026 lr: 0.02\n",
      "iteration: 115330 loss: 0.0027 lr: 0.02\n",
      "iteration: 115340 loss: 0.0030 lr: 0.02\n",
      "iteration: 115350 loss: 0.0026 lr: 0.02\n",
      "iteration: 115360 loss: 0.0022 lr: 0.02\n",
      "iteration: 115370 loss: 0.0022 lr: 0.02\n",
      "iteration: 115380 loss: 0.0025 lr: 0.02\n",
      "iteration: 115390 loss: 0.0022 lr: 0.02\n",
      "iteration: 115400 loss: 0.0024 lr: 0.02\n",
      "iteration: 115410 loss: 0.0021 lr: 0.02\n",
      "iteration: 115420 loss: 0.0023 lr: 0.02\n",
      "iteration: 115430 loss: 0.0031 lr: 0.02\n",
      "iteration: 115440 loss: 0.0022 lr: 0.02\n",
      "iteration: 115450 loss: 0.0027 lr: 0.02\n",
      "iteration: 115460 loss: 0.0034 lr: 0.02\n",
      "iteration: 115470 loss: 0.0024 lr: 0.02\n",
      "iteration: 115480 loss: 0.0023 lr: 0.02\n",
      "iteration: 115490 loss: 0.0021 lr: 0.02\n",
      "iteration: 115500 loss: 0.0027 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 115510 loss: 0.0028 lr: 0.02\n",
      "iteration: 115520 loss: 0.0029 lr: 0.02\n",
      "iteration: 115530 loss: 0.0028 lr: 0.02\n",
      "iteration: 115540 loss: 0.0029 lr: 0.02\n",
      "iteration: 115550 loss: 0.0025 lr: 0.02\n",
      "iteration: 115560 loss: 0.0020 lr: 0.02\n",
      "iteration: 115570 loss: 0.0026 lr: 0.02\n",
      "iteration: 115580 loss: 0.0018 lr: 0.02\n",
      "iteration: 115590 loss: 0.0024 lr: 0.02\n",
      "iteration: 115600 loss: 0.0026 lr: 0.02\n",
      "iteration: 115610 loss: 0.0023 lr: 0.02\n",
      "iteration: 115620 loss: 0.0028 lr: 0.02\n",
      "iteration: 115630 loss: 0.0027 lr: 0.02\n",
      "iteration: 115640 loss: 0.0032 lr: 0.02\n",
      "iteration: 115650 loss: 0.0042 lr: 0.02\n",
      "iteration: 115660 loss: 0.0023 lr: 0.02\n",
      "iteration: 115670 loss: 0.0023 lr: 0.02\n",
      "iteration: 115680 loss: 0.0026 lr: 0.02\n",
      "iteration: 115690 loss: 0.0025 lr: 0.02\n",
      "iteration: 115700 loss: 0.0022 lr: 0.02\n",
      "iteration: 115710 loss: 0.0026 lr: 0.02\n",
      "iteration: 115720 loss: 0.0022 lr: 0.02\n",
      "iteration: 115730 loss: 0.0024 lr: 0.02\n",
      "iteration: 115740 loss: 0.0025 lr: 0.02\n",
      "iteration: 115750 loss: 0.0024 lr: 0.02\n",
      "iteration: 115760 loss: 0.0028 lr: 0.02\n",
      "iteration: 115770 loss: 0.0022 lr: 0.02\n",
      "iteration: 115780 loss: 0.0028 lr: 0.02\n",
      "iteration: 115790 loss: 0.0019 lr: 0.02\n",
      "iteration: 115800 loss: 0.0017 lr: 0.02\n",
      "iteration: 115810 loss: 0.0021 lr: 0.02\n",
      "iteration: 115820 loss: 0.0024 lr: 0.02\n",
      "iteration: 115830 loss: 0.0024 lr: 0.02\n",
      "iteration: 115840 loss: 0.0025 lr: 0.02\n",
      "iteration: 115850 loss: 0.0023 lr: 0.02\n",
      "iteration: 115860 loss: 0.0025 lr: 0.02\n",
      "iteration: 115870 loss: 0.0031 lr: 0.02\n",
      "iteration: 115880 loss: 0.0020 lr: 0.02\n",
      "iteration: 115890 loss: 0.0031 lr: 0.02\n",
      "iteration: 115900 loss: 0.0025 lr: 0.02\n",
      "iteration: 115910 loss: 0.0028 lr: 0.02\n",
      "iteration: 115920 loss: 0.0029 lr: 0.02\n",
      "iteration: 115930 loss: 0.0019 lr: 0.02\n",
      "iteration: 115940 loss: 0.0027 lr: 0.02\n",
      "iteration: 115950 loss: 0.0023 lr: 0.02\n",
      "iteration: 115960 loss: 0.0022 lr: 0.02\n",
      "iteration: 115970 loss: 0.0021 lr: 0.02\n",
      "iteration: 115980 loss: 0.0026 lr: 0.02\n",
      "iteration: 115990 loss: 0.0027 lr: 0.02\n",
      "iteration: 116000 loss: 0.0024 lr: 0.02\n",
      "iteration: 116010 loss: 0.0023 lr: 0.02\n",
      "iteration: 116020 loss: 0.0022 lr: 0.02\n",
      "iteration: 116030 loss: 0.0024 lr: 0.02\n",
      "iteration: 116040 loss: 0.0028 lr: 0.02\n",
      "iteration: 116050 loss: 0.0035 lr: 0.02\n",
      "iteration: 116060 loss: 0.0023 lr: 0.02\n",
      "iteration: 116070 loss: 0.0028 lr: 0.02\n",
      "iteration: 116080 loss: 0.0021 lr: 0.02\n",
      "iteration: 116090 loss: 0.0033 lr: 0.02\n",
      "iteration: 116100 loss: 0.0029 lr: 0.02\n",
      "iteration: 116110 loss: 0.0028 lr: 0.02\n",
      "iteration: 116120 loss: 0.0032 lr: 0.02\n",
      "iteration: 116130 loss: 0.0023 lr: 0.02\n",
      "iteration: 116140 loss: 0.0029 lr: 0.02\n",
      "iteration: 116150 loss: 0.0025 lr: 0.02\n",
      "iteration: 116160 loss: 0.0033 lr: 0.02\n",
      "iteration: 116170 loss: 0.0026 lr: 0.02\n",
      "iteration: 116180 loss: 0.0026 lr: 0.02\n",
      "iteration: 116190 loss: 0.0022 lr: 0.02\n",
      "iteration: 116200 loss: 0.0022 lr: 0.02\n",
      "iteration: 116210 loss: 0.0031 lr: 0.02\n",
      "iteration: 116220 loss: 0.0033 lr: 0.02\n",
      "iteration: 116230 loss: 0.0028 lr: 0.02\n",
      "iteration: 116240 loss: 0.0024 lr: 0.02\n",
      "iteration: 116250 loss: 0.0026 lr: 0.02\n",
      "iteration: 116260 loss: 0.0021 lr: 0.02\n",
      "iteration: 116270 loss: 0.0023 lr: 0.02\n",
      "iteration: 116280 loss: 0.0028 lr: 0.02\n",
      "iteration: 116290 loss: 0.0023 lr: 0.02\n",
      "iteration: 116300 loss: 0.0024 lr: 0.02\n",
      "iteration: 116310 loss: 0.0023 lr: 0.02\n",
      "iteration: 116320 loss: 0.0021 lr: 0.02\n",
      "iteration: 116330 loss: 0.0023 lr: 0.02\n",
      "iteration: 116340 loss: 0.0028 lr: 0.02\n",
      "iteration: 116350 loss: 0.0022 lr: 0.02\n",
      "iteration: 116360 loss: 0.0037 lr: 0.02\n",
      "iteration: 116370 loss: 0.0031 lr: 0.02\n",
      "iteration: 116380 loss: 0.0023 lr: 0.02\n",
      "iteration: 116390 loss: 0.0025 lr: 0.02\n",
      "iteration: 116400 loss: 0.0021 lr: 0.02\n",
      "iteration: 116410 loss: 0.0028 lr: 0.02\n",
      "iteration: 116420 loss: 0.0022 lr: 0.02\n",
      "iteration: 116430 loss: 0.0022 lr: 0.02\n",
      "iteration: 116440 loss: 0.0029 lr: 0.02\n",
      "iteration: 116450 loss: 0.0031 lr: 0.02\n",
      "iteration: 116460 loss: 0.0033 lr: 0.02\n",
      "iteration: 116470 loss: 0.0027 lr: 0.02\n",
      "iteration: 116480 loss: 0.0028 lr: 0.02\n",
      "iteration: 116490 loss: 0.0024 lr: 0.02\n",
      "iteration: 116500 loss: 0.0034 lr: 0.02\n",
      "iteration: 116510 loss: 0.0024 lr: 0.02\n",
      "iteration: 116520 loss: 0.0029 lr: 0.02\n",
      "iteration: 116530 loss: 0.0030 lr: 0.02\n",
      "iteration: 116540 loss: 0.0025 lr: 0.02\n",
      "iteration: 116550 loss: 0.0022 lr: 0.02\n",
      "iteration: 116560 loss: 0.0028 lr: 0.02\n",
      "iteration: 116570 loss: 0.0026 lr: 0.02\n",
      "iteration: 116580 loss: 0.0026 lr: 0.02\n",
      "iteration: 116590 loss: 0.0028 lr: 0.02\n",
      "iteration: 116600 loss: 0.0030 lr: 0.02\n",
      "iteration: 116610 loss: 0.0030 lr: 0.02\n",
      "iteration: 116620 loss: 0.0028 lr: 0.02\n",
      "iteration: 116630 loss: 0.0019 lr: 0.02\n",
      "iteration: 116640 loss: 0.0027 lr: 0.02\n",
      "iteration: 116650 loss: 0.0025 lr: 0.02\n",
      "iteration: 116660 loss: 0.0032 lr: 0.02\n",
      "iteration: 116670 loss: 0.0027 lr: 0.02\n",
      "iteration: 116680 loss: 0.0024 lr: 0.02\n",
      "iteration: 116690 loss: 0.0031 lr: 0.02\n",
      "iteration: 116700 loss: 0.0027 lr: 0.02\n",
      "iteration: 116710 loss: 0.0027 lr: 0.02\n",
      "iteration: 116720 loss: 0.0035 lr: 0.02\n",
      "iteration: 116730 loss: 0.0029 lr: 0.02\n",
      "iteration: 116740 loss: 0.0026 lr: 0.02\n",
      "iteration: 116750 loss: 0.0024 lr: 0.02\n",
      "iteration: 116760 loss: 0.0020 lr: 0.02\n",
      "iteration: 116770 loss: 0.0027 lr: 0.02\n",
      "iteration: 116780 loss: 0.0029 lr: 0.02\n",
      "iteration: 116790 loss: 0.0026 lr: 0.02\n",
      "iteration: 116800 loss: 0.0027 lr: 0.02\n",
      "iteration: 116810 loss: 0.0024 lr: 0.02\n",
      "iteration: 116820 loss: 0.0028 lr: 0.02\n",
      "iteration: 116830 loss: 0.0028 lr: 0.02\n",
      "iteration: 116840 loss: 0.0029 lr: 0.02\n",
      "iteration: 116850 loss: 0.0028 lr: 0.02\n",
      "iteration: 116860 loss: 0.0022 lr: 0.02\n",
      "iteration: 116870 loss: 0.0024 lr: 0.02\n",
      "iteration: 116880 loss: 0.0031 lr: 0.02\n",
      "iteration: 116890 loss: 0.0030 lr: 0.02\n",
      "iteration: 116900 loss: 0.0038 lr: 0.02\n",
      "iteration: 116910 loss: 0.0025 lr: 0.02\n",
      "iteration: 116920 loss: 0.0034 lr: 0.02\n",
      "iteration: 116930 loss: 0.0019 lr: 0.02\n",
      "iteration: 116940 loss: 0.0024 lr: 0.02\n",
      "iteration: 116950 loss: 0.0030 lr: 0.02\n",
      "iteration: 116960 loss: 0.0020 lr: 0.02\n",
      "iteration: 116970 loss: 0.0028 lr: 0.02\n",
      "iteration: 116980 loss: 0.0032 lr: 0.02\n",
      "iteration: 116990 loss: 0.0024 lr: 0.02\n",
      "iteration: 117000 loss: 0.0023 lr: 0.02\n",
      "iteration: 117010 loss: 0.0027 lr: 0.02\n",
      "iteration: 117020 loss: 0.0029 lr: 0.02\n",
      "iteration: 117030 loss: 0.0028 lr: 0.02\n",
      "iteration: 117040 loss: 0.0026 lr: 0.02\n",
      "iteration: 117050 loss: 0.0028 lr: 0.02\n",
      "iteration: 117060 loss: 0.0026 lr: 0.02\n",
      "iteration: 117070 loss: 0.0024 lr: 0.02\n",
      "iteration: 117080 loss: 0.0027 lr: 0.02\n",
      "iteration: 117090 loss: 0.0033 lr: 0.02\n",
      "iteration: 117100 loss: 0.0028 lr: 0.02\n",
      "iteration: 117110 loss: 0.0032 lr: 0.02\n",
      "iteration: 117120 loss: 0.0028 lr: 0.02\n",
      "iteration: 117130 loss: 0.0028 lr: 0.02\n",
      "iteration: 117140 loss: 0.0025 lr: 0.02\n",
      "iteration: 117150 loss: 0.0025 lr: 0.02\n",
      "iteration: 117160 loss: 0.0024 lr: 0.02\n",
      "iteration: 117170 loss: 0.0026 lr: 0.02\n",
      "iteration: 117180 loss: 0.0024 lr: 0.02\n",
      "iteration: 117190 loss: 0.0026 lr: 0.02\n",
      "iteration: 117200 loss: 0.0034 lr: 0.02\n",
      "iteration: 117210 loss: 0.0020 lr: 0.02\n",
      "iteration: 117220 loss: 0.0026 lr: 0.02\n",
      "iteration: 117230 loss: 0.0022 lr: 0.02\n",
      "iteration: 117240 loss: 0.0021 lr: 0.02\n",
      "iteration: 117250 loss: 0.0028 lr: 0.02\n",
      "iteration: 117260 loss: 0.0025 lr: 0.02\n",
      "iteration: 117270 loss: 0.0029 lr: 0.02\n",
      "iteration: 117280 loss: 0.0027 lr: 0.02\n",
      "iteration: 117290 loss: 0.0022 lr: 0.02\n",
      "iteration: 117300 loss: 0.0031 lr: 0.02\n",
      "iteration: 117310 loss: 0.0024 lr: 0.02\n",
      "iteration: 117320 loss: 0.0023 lr: 0.02\n",
      "iteration: 117330 loss: 0.0022 lr: 0.02\n",
      "iteration: 117340 loss: 0.0030 lr: 0.02\n",
      "iteration: 117350 loss: 0.0028 lr: 0.02\n",
      "iteration: 117360 loss: 0.0028 lr: 0.02\n",
      "iteration: 117370 loss: 0.0028 lr: 0.02\n",
      "iteration: 117380 loss: 0.0026 lr: 0.02\n",
      "iteration: 117390 loss: 0.0027 lr: 0.02\n",
      "iteration: 117400 loss: 0.0026 lr: 0.02\n",
      "iteration: 117410 loss: 0.0027 lr: 0.02\n",
      "iteration: 117420 loss: 0.0029 lr: 0.02\n",
      "iteration: 117430 loss: 0.0033 lr: 0.02\n",
      "iteration: 117440 loss: 0.0044 lr: 0.02\n",
      "iteration: 117450 loss: 0.0035 lr: 0.02\n",
      "iteration: 117460 loss: 0.0030 lr: 0.02\n",
      "iteration: 117470 loss: 0.0026 lr: 0.02\n",
      "iteration: 117480 loss: 0.0024 lr: 0.02\n",
      "iteration: 117490 loss: 0.0026 lr: 0.02\n",
      "iteration: 117500 loss: 0.0026 lr: 0.02\n",
      "iteration: 117510 loss: 0.0029 lr: 0.02\n",
      "iteration: 117520 loss: 0.0024 lr: 0.02\n",
      "iteration: 117530 loss: 0.0028 lr: 0.02\n",
      "iteration: 117540 loss: 0.0023 lr: 0.02\n",
      "iteration: 117550 loss: 0.0028 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 117560 loss: 0.0022 lr: 0.02\n",
      "iteration: 117570 loss: 0.0027 lr: 0.02\n",
      "iteration: 117580 loss: 0.0024 lr: 0.02\n",
      "iteration: 117590 loss: 0.0026 lr: 0.02\n",
      "iteration: 117600 loss: 0.0030 lr: 0.02\n",
      "iteration: 117610 loss: 0.0027 lr: 0.02\n",
      "iteration: 117620 loss: 0.0028 lr: 0.02\n",
      "iteration: 117630 loss: 0.0032 lr: 0.02\n",
      "iteration: 117640 loss: 0.0026 lr: 0.02\n",
      "iteration: 117650 loss: 0.0028 lr: 0.02\n",
      "iteration: 117660 loss: 0.0028 lr: 0.02\n",
      "iteration: 117670 loss: 0.0023 lr: 0.02\n",
      "iteration: 117680 loss: 0.0022 lr: 0.02\n",
      "iteration: 117690 loss: 0.0035 lr: 0.02\n",
      "iteration: 117700 loss: 0.0032 lr: 0.02\n",
      "iteration: 117710 loss: 0.0027 lr: 0.02\n",
      "iteration: 117720 loss: 0.0024 lr: 0.02\n",
      "iteration: 117730 loss: 0.0029 lr: 0.02\n",
      "iteration: 117740 loss: 0.0026 lr: 0.02\n",
      "iteration: 117750 loss: 0.0031 lr: 0.02\n",
      "iteration: 117760 loss: 0.0024 lr: 0.02\n",
      "iteration: 117770 loss: 0.0027 lr: 0.02\n",
      "iteration: 117780 loss: 0.0027 lr: 0.02\n",
      "iteration: 117790 loss: 0.0029 lr: 0.02\n",
      "iteration: 117800 loss: 0.0026 lr: 0.02\n",
      "iteration: 117810 loss: 0.0025 lr: 0.02\n",
      "iteration: 117820 loss: 0.0019 lr: 0.02\n",
      "iteration: 117830 loss: 0.0034 lr: 0.02\n",
      "iteration: 117840 loss: 0.0021 lr: 0.02\n",
      "iteration: 117850 loss: 0.0020 lr: 0.02\n",
      "iteration: 117860 loss: 0.0022 lr: 0.02\n",
      "iteration: 117870 loss: 0.0030 lr: 0.02\n",
      "iteration: 117880 loss: 0.0025 lr: 0.02\n",
      "iteration: 117890 loss: 0.0039 lr: 0.02\n",
      "iteration: 117900 loss: 0.0023 lr: 0.02\n",
      "iteration: 117910 loss: 0.0024 lr: 0.02\n",
      "iteration: 117920 loss: 0.0026 lr: 0.02\n",
      "iteration: 117930 loss: 0.0027 lr: 0.02\n",
      "iteration: 117940 loss: 0.0028 lr: 0.02\n",
      "iteration: 117950 loss: 0.0026 lr: 0.02\n",
      "iteration: 117960 loss: 0.0034 lr: 0.02\n",
      "iteration: 117970 loss: 0.0034 lr: 0.02\n",
      "iteration: 117980 loss: 0.0030 lr: 0.02\n",
      "iteration: 117990 loss: 0.0029 lr: 0.02\n",
      "iteration: 118000 loss: 0.0025 lr: 0.02\n",
      "iteration: 118010 loss: 0.0034 lr: 0.02\n",
      "iteration: 118020 loss: 0.0021 lr: 0.02\n",
      "iteration: 118030 loss: 0.0031 lr: 0.02\n",
      "iteration: 118040 loss: 0.0031 lr: 0.02\n",
      "iteration: 118050 loss: 0.0030 lr: 0.02\n",
      "iteration: 118060 loss: 0.0023 lr: 0.02\n",
      "iteration: 118070 loss: 0.0023 lr: 0.02\n",
      "iteration: 118080 loss: 0.0020 lr: 0.02\n",
      "iteration: 118090 loss: 0.0027 lr: 0.02\n",
      "iteration: 118100 loss: 0.0032 lr: 0.02\n",
      "iteration: 118110 loss: 0.0026 lr: 0.02\n",
      "iteration: 118120 loss: 0.0033 lr: 0.02\n",
      "iteration: 118130 loss: 0.0029 lr: 0.02\n",
      "iteration: 118140 loss: 0.0031 lr: 0.02\n",
      "iteration: 118150 loss: 0.0030 lr: 0.02\n",
      "iteration: 118160 loss: 0.0027 lr: 0.02\n",
      "iteration: 118170 loss: 0.0030 lr: 0.02\n",
      "iteration: 118180 loss: 0.0027 lr: 0.02\n",
      "iteration: 118190 loss: 0.0033 lr: 0.02\n",
      "iteration: 118200 loss: 0.0024 lr: 0.02\n",
      "iteration: 118210 loss: 0.0021 lr: 0.02\n",
      "iteration: 118220 loss: 0.0023 lr: 0.02\n",
      "iteration: 118230 loss: 0.0028 lr: 0.02\n",
      "iteration: 118240 loss: 0.0023 lr: 0.02\n",
      "iteration: 118250 loss: 0.0025 lr: 0.02\n",
      "iteration: 118260 loss: 0.0027 lr: 0.02\n",
      "iteration: 118270 loss: 0.0025 lr: 0.02\n",
      "iteration: 118280 loss: 0.0024 lr: 0.02\n",
      "iteration: 118290 loss: 0.0054 lr: 0.02\n",
      "iteration: 118300 loss: 0.0030 lr: 0.02\n",
      "iteration: 118310 loss: 0.0039 lr: 0.02\n",
      "iteration: 118320 loss: 0.0036 lr: 0.02\n",
      "iteration: 118330 loss: 0.0033 lr: 0.02\n",
      "iteration: 118340 loss: 0.0032 lr: 0.02\n",
      "iteration: 118350 loss: 0.0026 lr: 0.02\n",
      "iteration: 118360 loss: 0.0027 lr: 0.02\n",
      "iteration: 118370 loss: 0.0028 lr: 0.02\n",
      "iteration: 118380 loss: 0.0025 lr: 0.02\n",
      "iteration: 118390 loss: 0.0032 lr: 0.02\n",
      "iteration: 118400 loss: 0.0031 lr: 0.02\n",
      "iteration: 118410 loss: 0.0027 lr: 0.02\n",
      "iteration: 118420 loss: 0.0029 lr: 0.02\n",
      "iteration: 118430 loss: 0.0031 lr: 0.02\n",
      "iteration: 118440 loss: 0.0026 lr: 0.02\n",
      "iteration: 118450 loss: 0.0022 lr: 0.02\n",
      "iteration: 118460 loss: 0.0027 lr: 0.02\n",
      "iteration: 118470 loss: 0.0026 lr: 0.02\n",
      "iteration: 118480 loss: 0.0029 lr: 0.02\n",
      "iteration: 118490 loss: 0.0023 lr: 0.02\n",
      "iteration: 118500 loss: 0.0023 lr: 0.02\n",
      "iteration: 118510 loss: 0.0022 lr: 0.02\n",
      "iteration: 118520 loss: 0.0028 lr: 0.02\n",
      "iteration: 118530 loss: 0.0034 lr: 0.02\n",
      "iteration: 118540 loss: 0.0021 lr: 0.02\n",
      "iteration: 118550 loss: 0.0029 lr: 0.02\n",
      "iteration: 118560 loss: 0.0025 lr: 0.02\n",
      "iteration: 118570 loss: 0.0026 lr: 0.02\n",
      "iteration: 118580 loss: 0.0028 lr: 0.02\n",
      "iteration: 118590 loss: 0.0025 lr: 0.02\n",
      "iteration: 118600 loss: 0.0027 lr: 0.02\n",
      "iteration: 118610 loss: 0.0029 lr: 0.02\n",
      "iteration: 118620 loss: 0.0025 lr: 0.02\n",
      "iteration: 118630 loss: 0.0024 lr: 0.02\n",
      "iteration: 118640 loss: 0.0028 lr: 0.02\n",
      "iteration: 118650 loss: 0.0029 lr: 0.02\n",
      "iteration: 118660 loss: 0.0026 lr: 0.02\n",
      "iteration: 118670 loss: 0.0027 lr: 0.02\n",
      "iteration: 118680 loss: 0.0032 lr: 0.02\n",
      "iteration: 118690 loss: 0.0031 lr: 0.02\n",
      "iteration: 118700 loss: 0.0030 lr: 0.02\n",
      "iteration: 118710 loss: 0.0031 lr: 0.02\n",
      "iteration: 118720 loss: 0.0026 lr: 0.02\n",
      "iteration: 118730 loss: 0.0024 lr: 0.02\n",
      "iteration: 118740 loss: 0.0024 lr: 0.02\n",
      "iteration: 118750 loss: 0.0023 lr: 0.02\n",
      "iteration: 118760 loss: 0.0027 lr: 0.02\n",
      "iteration: 118770 loss: 0.0025 lr: 0.02\n",
      "iteration: 118780 loss: 0.0022 lr: 0.02\n",
      "iteration: 118790 loss: 0.0023 lr: 0.02\n",
      "iteration: 118800 loss: 0.0028 lr: 0.02\n",
      "iteration: 118810 loss: 0.0022 lr: 0.02\n",
      "iteration: 118820 loss: 0.0023 lr: 0.02\n",
      "iteration: 118830 loss: 0.0030 lr: 0.02\n",
      "iteration: 118840 loss: 0.0025 lr: 0.02\n",
      "iteration: 118850 loss: 0.0040 lr: 0.02\n",
      "iteration: 118860 loss: 0.0039 lr: 0.02\n",
      "iteration: 118870 loss: 0.0031 lr: 0.02\n",
      "iteration: 118880 loss: 0.0032 lr: 0.02\n",
      "iteration: 118890 loss: 0.0027 lr: 0.02\n",
      "iteration: 118900 loss: 0.0027 lr: 0.02\n",
      "iteration: 118910 loss: 0.0036 lr: 0.02\n",
      "iteration: 118920 loss: 0.0029 lr: 0.02\n",
      "iteration: 118930 loss: 0.0032 lr: 0.02\n",
      "iteration: 118940 loss: 0.0028 lr: 0.02\n",
      "iteration: 118950 loss: 0.0032 lr: 0.02\n",
      "iteration: 118960 loss: 0.0035 lr: 0.02\n",
      "iteration: 118970 loss: 0.0018 lr: 0.02\n",
      "iteration: 118980 loss: 0.0025 lr: 0.02\n",
      "iteration: 118990 loss: 0.0030 lr: 0.02\n",
      "iteration: 119000 loss: 0.0028 lr: 0.02\n",
      "iteration: 119010 loss: 0.0028 lr: 0.02\n",
      "iteration: 119020 loss: 0.0032 lr: 0.02\n",
      "iteration: 119030 loss: 0.0030 lr: 0.02\n",
      "iteration: 119040 loss: 0.0024 lr: 0.02\n",
      "iteration: 119050 loss: 0.0023 lr: 0.02\n",
      "iteration: 119060 loss: 0.0029 lr: 0.02\n",
      "iteration: 119070 loss: 0.0025 lr: 0.02\n",
      "iteration: 119080 loss: 0.0026 lr: 0.02\n",
      "iteration: 119090 loss: 0.0022 lr: 0.02\n",
      "iteration: 119100 loss: 0.0025 lr: 0.02\n",
      "iteration: 119110 loss: 0.0022 lr: 0.02\n",
      "iteration: 119120 loss: 0.0021 lr: 0.02\n",
      "iteration: 119130 loss: 0.0020 lr: 0.02\n",
      "iteration: 119140 loss: 0.0026 lr: 0.02\n",
      "iteration: 119150 loss: 0.0028 lr: 0.02\n",
      "iteration: 119160 loss: 0.0022 lr: 0.02\n",
      "iteration: 119170 loss: 0.0020 lr: 0.02\n",
      "iteration: 119180 loss: 0.0026 lr: 0.02\n",
      "iteration: 119190 loss: 0.0025 lr: 0.02\n",
      "iteration: 119200 loss: 0.0028 lr: 0.02\n",
      "iteration: 119210 loss: 0.0026 lr: 0.02\n",
      "iteration: 119220 loss: 0.0022 lr: 0.02\n",
      "iteration: 119230 loss: 0.0020 lr: 0.02\n",
      "iteration: 119240 loss: 0.0020 lr: 0.02\n",
      "iteration: 119250 loss: 0.0020 lr: 0.02\n",
      "iteration: 119260 loss: 0.0023 lr: 0.02\n",
      "iteration: 119270 loss: 0.0021 lr: 0.02\n",
      "iteration: 119280 loss: 0.0028 lr: 0.02\n",
      "iteration: 119290 loss: 0.0035 lr: 0.02\n",
      "iteration: 119300 loss: 0.0022 lr: 0.02\n",
      "iteration: 119310 loss: 0.0020 lr: 0.02\n",
      "iteration: 119320 loss: 0.0026 lr: 0.02\n",
      "iteration: 119330 loss: 0.0021 lr: 0.02\n",
      "iteration: 119340 loss: 0.0027 lr: 0.02\n",
      "iteration: 119350 loss: 0.0025 lr: 0.02\n",
      "iteration: 119360 loss: 0.0022 lr: 0.02\n",
      "iteration: 119370 loss: 0.0020 lr: 0.02\n",
      "iteration: 119380 loss: 0.0019 lr: 0.02\n",
      "iteration: 119390 loss: 0.0032 lr: 0.02\n",
      "iteration: 119400 loss: 0.0026 lr: 0.02\n",
      "iteration: 119410 loss: 0.0022 lr: 0.02\n",
      "iteration: 119420 loss: 0.0033 lr: 0.02\n",
      "iteration: 119430 loss: 0.0020 lr: 0.02\n",
      "iteration: 119440 loss: 0.0022 lr: 0.02\n",
      "iteration: 119450 loss: 0.0020 lr: 0.02\n",
      "iteration: 119460 loss: 0.0024 lr: 0.02\n",
      "iteration: 119470 loss: 0.0020 lr: 0.02\n",
      "iteration: 119480 loss: 0.0026 lr: 0.02\n",
      "iteration: 119490 loss: 0.0026 lr: 0.02\n",
      "iteration: 119500 loss: 0.0038 lr: 0.02\n",
      "iteration: 119510 loss: 0.0024 lr: 0.02\n",
      "iteration: 119520 loss: 0.0023 lr: 0.02\n",
      "iteration: 119530 loss: 0.0025 lr: 0.02\n",
      "iteration: 119540 loss: 0.0030 lr: 0.02\n",
      "iteration: 119550 loss: 0.0023 lr: 0.02\n",
      "iteration: 119560 loss: 0.0028 lr: 0.02\n",
      "iteration: 119570 loss: 0.0023 lr: 0.02\n",
      "iteration: 119580 loss: 0.0020 lr: 0.02\n",
      "iteration: 119590 loss: 0.0024 lr: 0.02\n",
      "iteration: 119600 loss: 0.0025 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 119610 loss: 0.0028 lr: 0.02\n",
      "iteration: 119620 loss: 0.0021 lr: 0.02\n",
      "iteration: 119630 loss: 0.0017 lr: 0.02\n",
      "iteration: 119640 loss: 0.0018 lr: 0.02\n",
      "iteration: 119650 loss: 0.0030 lr: 0.02\n",
      "iteration: 119660 loss: 0.0026 lr: 0.02\n",
      "iteration: 119670 loss: 0.0017 lr: 0.02\n",
      "iteration: 119680 loss: 0.0023 lr: 0.02\n",
      "iteration: 119690 loss: 0.0026 lr: 0.02\n",
      "iteration: 119700 loss: 0.0022 lr: 0.02\n",
      "iteration: 119710 loss: 0.0027 lr: 0.02\n",
      "iteration: 119720 loss: 0.0023 lr: 0.02\n",
      "iteration: 119730 loss: 0.0027 lr: 0.02\n",
      "iteration: 119740 loss: 0.0030 lr: 0.02\n",
      "iteration: 119750 loss: 0.0027 lr: 0.02\n",
      "iteration: 119760 loss: 0.0030 lr: 0.02\n",
      "iteration: 119770 loss: 0.0030 lr: 0.02\n",
      "iteration: 119780 loss: 0.0042 lr: 0.02\n",
      "iteration: 119790 loss: 0.0023 lr: 0.02\n",
      "iteration: 119800 loss: 0.0026 lr: 0.02\n",
      "iteration: 119810 loss: 0.0032 lr: 0.02\n",
      "iteration: 119820 loss: 0.0027 lr: 0.02\n",
      "iteration: 119830 loss: 0.0024 lr: 0.02\n",
      "iteration: 119840 loss: 0.0031 lr: 0.02\n",
      "iteration: 119850 loss: 0.0022 lr: 0.02\n",
      "iteration: 119860 loss: 0.0021 lr: 0.02\n",
      "iteration: 119870 loss: 0.0025 lr: 0.02\n",
      "iteration: 119880 loss: 0.0020 lr: 0.02\n",
      "iteration: 119890 loss: 0.0026 lr: 0.02\n",
      "iteration: 119900 loss: 0.0030 lr: 0.02\n",
      "iteration: 119910 loss: 0.0031 lr: 0.02\n",
      "iteration: 119920 loss: 0.0033 lr: 0.02\n",
      "iteration: 119930 loss: 0.0025 lr: 0.02\n",
      "iteration: 119940 loss: 0.0025 lr: 0.02\n",
      "iteration: 119950 loss: 0.0026 lr: 0.02\n",
      "iteration: 119960 loss: 0.0022 lr: 0.02\n",
      "iteration: 119970 loss: 0.0028 lr: 0.02\n",
      "iteration: 119980 loss: 0.0033 lr: 0.02\n",
      "iteration: 119990 loss: 0.0026 lr: 0.02\n",
      "iteration: 120000 loss: 0.0028 lr: 0.02\n",
      "iteration: 120010 loss: 0.0026 lr: 0.02\n",
      "iteration: 120020 loss: 0.0020 lr: 0.02\n",
      "iteration: 120030 loss: 0.0025 lr: 0.02\n",
      "iteration: 120040 loss: 0.0025 lr: 0.02\n",
      "iteration: 120050 loss: 0.0023 lr: 0.02\n",
      "iteration: 120060 loss: 0.0022 lr: 0.02\n",
      "iteration: 120070 loss: 0.0025 lr: 0.02\n",
      "iteration: 120080 loss: 0.0027 lr: 0.02\n",
      "iteration: 120090 loss: 0.0027 lr: 0.02\n",
      "iteration: 120100 loss: 0.0033 lr: 0.02\n",
      "iteration: 120110 loss: 0.0024 lr: 0.02\n",
      "iteration: 120120 loss: 0.0023 lr: 0.02\n",
      "iteration: 120130 loss: 0.0024 lr: 0.02\n",
      "iteration: 120140 loss: 0.0024 lr: 0.02\n",
      "iteration: 120150 loss: 0.0039 lr: 0.02\n",
      "iteration: 120160 loss: 0.0030 lr: 0.02\n",
      "iteration: 120170 loss: 0.0017 lr: 0.02\n",
      "iteration: 120180 loss: 0.0027 lr: 0.02\n",
      "iteration: 120190 loss: 0.0030 lr: 0.02\n",
      "iteration: 120200 loss: 0.0035 lr: 0.02\n",
      "iteration: 120210 loss: 0.0030 lr: 0.02\n",
      "iteration: 120220 loss: 0.0031 lr: 0.02\n",
      "iteration: 120230 loss: 0.0027 lr: 0.02\n",
      "iteration: 120240 loss: 0.0028 lr: 0.02\n",
      "iteration: 120250 loss: 0.0024 lr: 0.02\n",
      "iteration: 120260 loss: 0.0019 lr: 0.02\n",
      "iteration: 120270 loss: 0.0026 lr: 0.02\n",
      "iteration: 120280 loss: 0.0020 lr: 0.02\n",
      "iteration: 120290 loss: 0.0027 lr: 0.02\n",
      "iteration: 120300 loss: 0.0025 lr: 0.02\n",
      "iteration: 120310 loss: 0.0029 lr: 0.02\n",
      "iteration: 120320 loss: 0.0018 lr: 0.02\n",
      "iteration: 120330 loss: 0.0020 lr: 0.02\n",
      "iteration: 120340 loss: 0.0022 lr: 0.02\n",
      "iteration: 120350 loss: 0.0023 lr: 0.02\n",
      "iteration: 120360 loss: 0.0027 lr: 0.02\n",
      "iteration: 120370 loss: 0.0028 lr: 0.02\n",
      "iteration: 120380 loss: 0.0028 lr: 0.02\n",
      "iteration: 120390 loss: 0.0029 lr: 0.02\n",
      "iteration: 120400 loss: 0.0028 lr: 0.02\n",
      "iteration: 120410 loss: 0.0022 lr: 0.02\n",
      "iteration: 120420 loss: 0.0032 lr: 0.02\n",
      "iteration: 120430 loss: 0.0024 lr: 0.02\n",
      "iteration: 120440 loss: 0.0031 lr: 0.02\n",
      "iteration: 120450 loss: 0.0022 lr: 0.02\n",
      "iteration: 120460 loss: 0.0021 lr: 0.02\n",
      "iteration: 120470 loss: 0.0024 lr: 0.02\n",
      "iteration: 120480 loss: 0.0029 lr: 0.02\n",
      "iteration: 120490 loss: 0.0021 lr: 0.02\n",
      "iteration: 120500 loss: 0.0023 lr: 0.02\n",
      "iteration: 120510 loss: 0.0026 lr: 0.02\n",
      "iteration: 120520 loss: 0.0031 lr: 0.02\n",
      "iteration: 120530 loss: 0.0021 lr: 0.02\n",
      "iteration: 120540 loss: 0.0027 lr: 0.02\n",
      "iteration: 120550 loss: 0.0022 lr: 0.02\n",
      "iteration: 120560 loss: 0.0025 lr: 0.02\n",
      "iteration: 120570 loss: 0.0026 lr: 0.02\n",
      "iteration: 120580 loss: 0.0021 lr: 0.02\n",
      "iteration: 120590 loss: 0.0025 lr: 0.02\n",
      "iteration: 120600 loss: 0.0026 lr: 0.02\n",
      "iteration: 120610 loss: 0.0024 lr: 0.02\n",
      "iteration: 120620 loss: 0.0027 lr: 0.02\n",
      "iteration: 120630 loss: 0.0021 lr: 0.02\n",
      "iteration: 120640 loss: 0.0028 lr: 0.02\n",
      "iteration: 120650 loss: 0.0022 lr: 0.02\n",
      "iteration: 120660 loss: 0.0023 lr: 0.02\n",
      "iteration: 120670 loss: 0.0020 lr: 0.02\n",
      "iteration: 120680 loss: 0.0022 lr: 0.02\n",
      "iteration: 120690 loss: 0.0026 lr: 0.02\n",
      "iteration: 120700 loss: 0.0026 lr: 0.02\n",
      "iteration: 120710 loss: 0.0029 lr: 0.02\n",
      "iteration: 120720 loss: 0.0022 lr: 0.02\n",
      "iteration: 120730 loss: 0.0022 lr: 0.02\n",
      "iteration: 120740 loss: 0.0023 lr: 0.02\n",
      "iteration: 120750 loss: 0.0026 lr: 0.02\n",
      "iteration: 120760 loss: 0.0030 lr: 0.02\n",
      "iteration: 120770 loss: 0.0033 lr: 0.02\n",
      "iteration: 120780 loss: 0.0025 lr: 0.02\n",
      "iteration: 120790 loss: 0.0026 lr: 0.02\n",
      "iteration: 120800 loss: 0.0026 lr: 0.02\n",
      "iteration: 120810 loss: 0.0027 lr: 0.02\n",
      "iteration: 120820 loss: 0.0022 lr: 0.02\n",
      "iteration: 120830 loss: 0.0021 lr: 0.02\n",
      "iteration: 120840 loss: 0.0023 lr: 0.02\n",
      "iteration: 120850 loss: 0.0026 lr: 0.02\n",
      "iteration: 120860 loss: 0.0031 lr: 0.02\n",
      "iteration: 120870 loss: 0.0027 lr: 0.02\n",
      "iteration: 120880 loss: 0.0026 lr: 0.02\n",
      "iteration: 120890 loss: 0.0040 lr: 0.02\n",
      "iteration: 120900 loss: 0.0031 lr: 0.02\n",
      "iteration: 120910 loss: 0.0024 lr: 0.02\n",
      "iteration: 120920 loss: 0.0024 lr: 0.02\n",
      "iteration: 120930 loss: 0.0031 lr: 0.02\n",
      "iteration: 120940 loss: 0.0028 lr: 0.02\n",
      "iteration: 120950 loss: 0.0028 lr: 0.02\n",
      "iteration: 120960 loss: 0.0023 lr: 0.02\n",
      "iteration: 120970 loss: 0.0026 lr: 0.02\n",
      "iteration: 120980 loss: 0.0022 lr: 0.02\n",
      "iteration: 120990 loss: 0.0024 lr: 0.02\n",
      "iteration: 121000 loss: 0.0023 lr: 0.02\n",
      "iteration: 121010 loss: 0.0029 lr: 0.02\n",
      "iteration: 121020 loss: 0.0023 lr: 0.02\n",
      "iteration: 121030 loss: 0.0030 lr: 0.02\n",
      "iteration: 121040 loss: 0.0028 lr: 0.02\n",
      "iteration: 121050 loss: 0.0022 lr: 0.02\n",
      "iteration: 121060 loss: 0.0022 lr: 0.02\n",
      "iteration: 121070 loss: 0.0021 lr: 0.02\n",
      "iteration: 121080 loss: 0.0025 lr: 0.02\n",
      "iteration: 121090 loss: 0.0025 lr: 0.02\n",
      "iteration: 121100 loss: 0.0019 lr: 0.02\n",
      "iteration: 121110 loss: 0.0020 lr: 0.02\n",
      "iteration: 121120 loss: 0.0024 lr: 0.02\n",
      "iteration: 121130 loss: 0.0026 lr: 0.02\n",
      "iteration: 121140 loss: 0.0024 lr: 0.02\n",
      "iteration: 121150 loss: 0.0028 lr: 0.02\n",
      "iteration: 121160 loss: 0.0020 lr: 0.02\n",
      "iteration: 121170 loss: 0.0024 lr: 0.02\n",
      "iteration: 121180 loss: 0.0021 lr: 0.02\n",
      "iteration: 121190 loss: 0.0041 lr: 0.02\n",
      "iteration: 121200 loss: 0.0031 lr: 0.02\n",
      "iteration: 121210 loss: 0.0029 lr: 0.02\n",
      "iteration: 121220 loss: 0.0024 lr: 0.02\n",
      "iteration: 121230 loss: 0.0030 lr: 0.02\n",
      "iteration: 121240 loss: 0.0026 lr: 0.02\n",
      "iteration: 121250 loss: 0.0020 lr: 0.02\n",
      "iteration: 121260 loss: 0.0028 lr: 0.02\n",
      "iteration: 121270 loss: 0.0023 lr: 0.02\n",
      "iteration: 121280 loss: 0.0032 lr: 0.02\n",
      "iteration: 121290 loss: 0.0020 lr: 0.02\n",
      "iteration: 121300 loss: 0.0026 lr: 0.02\n",
      "iteration: 121310 loss: 0.0031 lr: 0.02\n",
      "iteration: 121320 loss: 0.0031 lr: 0.02\n",
      "iteration: 121330 loss: 0.0027 lr: 0.02\n",
      "iteration: 121340 loss: 0.0027 lr: 0.02\n",
      "iteration: 121350 loss: 0.0034 lr: 0.02\n",
      "iteration: 121360 loss: 0.0023 lr: 0.02\n",
      "iteration: 121370 loss: 0.0031 lr: 0.02\n",
      "iteration: 121380 loss: 0.0025 lr: 0.02\n",
      "iteration: 121390 loss: 0.0026 lr: 0.02\n",
      "iteration: 121400 loss: 0.0039 lr: 0.02\n",
      "iteration: 121410 loss: 0.0035 lr: 0.02\n",
      "iteration: 121420 loss: 0.0040 lr: 0.02\n",
      "iteration: 121430 loss: 0.0027 lr: 0.02\n",
      "iteration: 121440 loss: 0.0029 lr: 0.02\n",
      "iteration: 121450 loss: 0.0026 lr: 0.02\n",
      "iteration: 121460 loss: 0.0025 lr: 0.02\n",
      "iteration: 121470 loss: 0.0035 lr: 0.02\n",
      "iteration: 121480 loss: 0.0028 lr: 0.02\n",
      "iteration: 121490 loss: 0.0029 lr: 0.02\n",
      "iteration: 121500 loss: 0.0023 lr: 0.02\n",
      "iteration: 121510 loss: 0.0027 lr: 0.02\n",
      "iteration: 121520 loss: 0.0028 lr: 0.02\n",
      "iteration: 121530 loss: 0.0028 lr: 0.02\n",
      "iteration: 121540 loss: 0.0025 lr: 0.02\n",
      "iteration: 121550 loss: 0.0020 lr: 0.02\n",
      "iteration: 121560 loss: 0.0028 lr: 0.02\n",
      "iteration: 121570 loss: 0.0024 lr: 0.02\n",
      "iteration: 121580 loss: 0.0030 lr: 0.02\n",
      "iteration: 121590 loss: 0.0022 lr: 0.02\n",
      "iteration: 121600 loss: 0.0024 lr: 0.02\n",
      "iteration: 121610 loss: 0.0027 lr: 0.02\n",
      "iteration: 121620 loss: 0.0030 lr: 0.02\n",
      "iteration: 121630 loss: 0.0023 lr: 0.02\n",
      "iteration: 121640 loss: 0.0024 lr: 0.02\n",
      "iteration: 121650 loss: 0.0020 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 121660 loss: 0.0026 lr: 0.02\n",
      "iteration: 121670 loss: 0.0020 lr: 0.02\n",
      "iteration: 121680 loss: 0.0025 lr: 0.02\n",
      "iteration: 121690 loss: 0.0024 lr: 0.02\n",
      "iteration: 121700 loss: 0.0033 lr: 0.02\n",
      "iteration: 121710 loss: 0.0028 lr: 0.02\n",
      "iteration: 121720 loss: 0.0024 lr: 0.02\n",
      "iteration: 121730 loss: 0.0027 lr: 0.02\n",
      "iteration: 121740 loss: 0.0027 lr: 0.02\n",
      "iteration: 121750 loss: 0.0023 lr: 0.02\n",
      "iteration: 121760 loss: 0.0025 lr: 0.02\n",
      "iteration: 121770 loss: 0.0029 lr: 0.02\n",
      "iteration: 121780 loss: 0.0029 lr: 0.02\n",
      "iteration: 121790 loss: 0.0028 lr: 0.02\n",
      "iteration: 121800 loss: 0.0032 lr: 0.02\n",
      "iteration: 121810 loss: 0.0028 lr: 0.02\n",
      "iteration: 121820 loss: 0.0024 lr: 0.02\n",
      "iteration: 121830 loss: 0.0022 lr: 0.02\n",
      "iteration: 121840 loss: 0.0029 lr: 0.02\n",
      "iteration: 121850 loss: 0.0026 lr: 0.02\n",
      "iteration: 121860 loss: 0.0024 lr: 0.02\n",
      "iteration: 121870 loss: 0.0045 lr: 0.02\n",
      "iteration: 121880 loss: 0.0026 lr: 0.02\n",
      "iteration: 121890 loss: 0.0027 lr: 0.02\n",
      "iteration: 121900 loss: 0.0025 lr: 0.02\n",
      "iteration: 121910 loss: 0.0026 lr: 0.02\n",
      "iteration: 121920 loss: 0.0030 lr: 0.02\n",
      "iteration: 121930 loss: 0.0030 lr: 0.02\n",
      "iteration: 121940 loss: 0.0020 lr: 0.02\n",
      "iteration: 121950 loss: 0.0022 lr: 0.02\n",
      "iteration: 121960 loss: 0.0016 lr: 0.02\n",
      "iteration: 121970 loss: 0.0028 lr: 0.02\n",
      "iteration: 121980 loss: 0.0019 lr: 0.02\n",
      "iteration: 121990 loss: 0.0024 lr: 0.02\n",
      "iteration: 122000 loss: 0.0030 lr: 0.02\n",
      "iteration: 122010 loss: 0.0020 lr: 0.02\n",
      "iteration: 122020 loss: 0.0026 lr: 0.02\n",
      "iteration: 122030 loss: 0.0024 lr: 0.02\n",
      "iteration: 122040 loss: 0.0019 lr: 0.02\n",
      "iteration: 122050 loss: 0.0022 lr: 0.02\n",
      "iteration: 122060 loss: 0.0029 lr: 0.02\n",
      "iteration: 122070 loss: 0.0025 lr: 0.02\n",
      "iteration: 122080 loss: 0.0025 lr: 0.02\n",
      "iteration: 122090 loss: 0.0027 lr: 0.02\n",
      "iteration: 122100 loss: 0.0023 lr: 0.02\n",
      "iteration: 122110 loss: 0.0028 lr: 0.02\n",
      "iteration: 122120 loss: 0.0027 lr: 0.02\n",
      "iteration: 122130 loss: 0.0021 lr: 0.02\n",
      "iteration: 122140 loss: 0.0029 lr: 0.02\n",
      "iteration: 122150 loss: 0.0025 lr: 0.02\n",
      "iteration: 122160 loss: 0.0026 lr: 0.02\n",
      "iteration: 122170 loss: 0.0031 lr: 0.02\n",
      "iteration: 122180 loss: 0.0027 lr: 0.02\n",
      "iteration: 122190 loss: 0.0025 lr: 0.02\n",
      "iteration: 122200 loss: 0.0028 lr: 0.02\n",
      "iteration: 122210 loss: 0.0023 lr: 0.02\n",
      "iteration: 122220 loss: 0.0029 lr: 0.02\n",
      "iteration: 122230 loss: 0.0021 lr: 0.02\n",
      "iteration: 122240 loss: 0.0030 lr: 0.02\n",
      "iteration: 122250 loss: 0.0032 lr: 0.02\n",
      "iteration: 122260 loss: 0.0021 lr: 0.02\n",
      "iteration: 122270 loss: 0.0022 lr: 0.02\n",
      "iteration: 122280 loss: 0.0027 lr: 0.02\n",
      "iteration: 122290 loss: 0.0024 lr: 0.02\n",
      "iteration: 122300 loss: 0.0029 lr: 0.02\n",
      "iteration: 122310 loss: 0.0021 lr: 0.02\n",
      "iteration: 122320 loss: 0.0024 lr: 0.02\n",
      "iteration: 122330 loss: 0.0029 lr: 0.02\n",
      "iteration: 122340 loss: 0.0025 lr: 0.02\n",
      "iteration: 122350 loss: 0.0022 lr: 0.02\n",
      "iteration: 122360 loss: 0.0028 lr: 0.02\n",
      "iteration: 122370 loss: 0.0027 lr: 0.02\n",
      "iteration: 122380 loss: 0.0022 lr: 0.02\n",
      "iteration: 122390 loss: 0.0026 lr: 0.02\n",
      "iteration: 122400 loss: 0.0026 lr: 0.02\n",
      "iteration: 122410 loss: 0.0027 lr: 0.02\n",
      "iteration: 122420 loss: 0.0026 lr: 0.02\n",
      "iteration: 122430 loss: 0.0022 lr: 0.02\n",
      "iteration: 122440 loss: 0.0023 lr: 0.02\n",
      "iteration: 122450 loss: 0.0032 lr: 0.02\n",
      "iteration: 122460 loss: 0.0023 lr: 0.02\n",
      "iteration: 122470 loss: 0.0036 lr: 0.02\n",
      "iteration: 122480 loss: 0.0019 lr: 0.02\n",
      "iteration: 122490 loss: 0.0022 lr: 0.02\n",
      "iteration: 122500 loss: 0.0020 lr: 0.02\n",
      "iteration: 122510 loss: 0.0028 lr: 0.02\n",
      "iteration: 122520 loss: 0.0032 lr: 0.02\n",
      "iteration: 122530 loss: 0.0026 lr: 0.02\n",
      "iteration: 122540 loss: 0.0027 lr: 0.02\n",
      "iteration: 122550 loss: 0.0028 lr: 0.02\n",
      "iteration: 122560 loss: 0.0031 lr: 0.02\n",
      "iteration: 122570 loss: 0.0025 lr: 0.02\n",
      "iteration: 122580 loss: 0.0024 lr: 0.02\n",
      "iteration: 122590 loss: 0.0026 lr: 0.02\n",
      "iteration: 122600 loss: 0.0023 lr: 0.02\n",
      "iteration: 122610 loss: 0.0030 lr: 0.02\n",
      "iteration: 122620 loss: 0.0031 lr: 0.02\n",
      "iteration: 122630 loss: 0.0029 lr: 0.02\n",
      "iteration: 122640 loss: 0.0026 lr: 0.02\n",
      "iteration: 122650 loss: 0.0024 lr: 0.02\n",
      "iteration: 122660 loss: 0.0025 lr: 0.02\n",
      "iteration: 122670 loss: 0.0025 lr: 0.02\n",
      "iteration: 122680 loss: 0.0030 lr: 0.02\n",
      "iteration: 122690 loss: 0.0032 lr: 0.02\n",
      "iteration: 122700 loss: 0.0022 lr: 0.02\n",
      "iteration: 122710 loss: 0.0029 lr: 0.02\n",
      "iteration: 122720 loss: 0.0020 lr: 0.02\n",
      "iteration: 122730 loss: 0.0031 lr: 0.02\n",
      "iteration: 122740 loss: 0.0024 lr: 0.02\n",
      "iteration: 122750 loss: 0.0021 lr: 0.02\n",
      "iteration: 122760 loss: 0.0028 lr: 0.02\n",
      "iteration: 122770 loss: 0.0029 lr: 0.02\n",
      "iteration: 122780 loss: 0.0024 lr: 0.02\n",
      "iteration: 122790 loss: 0.0027 lr: 0.02\n",
      "iteration: 122800 loss: 0.0027 lr: 0.02\n",
      "iteration: 122810 loss: 0.0025 lr: 0.02\n",
      "iteration: 122820 loss: 0.0025 lr: 0.02\n",
      "iteration: 122830 loss: 0.0024 lr: 0.02\n",
      "iteration: 122840 loss: 0.0024 lr: 0.02\n",
      "iteration: 122850 loss: 0.0023 lr: 0.02\n",
      "iteration: 122860 loss: 0.0029 lr: 0.02\n",
      "iteration: 122870 loss: 0.0033 lr: 0.02\n",
      "iteration: 122880 loss: 0.0021 lr: 0.02\n",
      "iteration: 122890 loss: 0.0020 lr: 0.02\n",
      "iteration: 122900 loss: 0.0029 lr: 0.02\n",
      "iteration: 122910 loss: 0.0025 lr: 0.02\n",
      "iteration: 122920 loss: 0.0028 lr: 0.02\n",
      "iteration: 122930 loss: 0.0028 lr: 0.02\n",
      "iteration: 122940 loss: 0.0023 lr: 0.02\n",
      "iteration: 122950 loss: 0.0024 lr: 0.02\n",
      "iteration: 122960 loss: 0.0026 lr: 0.02\n",
      "iteration: 122970 loss: 0.0024 lr: 0.02\n",
      "iteration: 122980 loss: 0.0032 lr: 0.02\n",
      "iteration: 122990 loss: 0.0026 lr: 0.02\n",
      "iteration: 123000 loss: 0.0021 lr: 0.02\n",
      "iteration: 123010 loss: 0.0028 lr: 0.02\n",
      "iteration: 123020 loss: 0.0022 lr: 0.02\n",
      "iteration: 123030 loss: 0.0030 lr: 0.02\n",
      "iteration: 123040 loss: 0.0026 lr: 0.02\n",
      "iteration: 123050 loss: 0.0025 lr: 0.02\n",
      "iteration: 123060 loss: 0.0024 lr: 0.02\n",
      "iteration: 123070 loss: 0.0021 lr: 0.02\n",
      "iteration: 123080 loss: 0.0025 lr: 0.02\n",
      "iteration: 123090 loss: 0.0029 lr: 0.02\n",
      "iteration: 123100 loss: 0.0029 lr: 0.02\n",
      "iteration: 123110 loss: 0.0026 lr: 0.02\n",
      "iteration: 123120 loss: 0.0026 lr: 0.02\n",
      "iteration: 123130 loss: 0.0028 lr: 0.02\n",
      "iteration: 123140 loss: 0.0020 lr: 0.02\n",
      "iteration: 123150 loss: 0.0024 lr: 0.02\n",
      "iteration: 123160 loss: 0.0023 lr: 0.02\n",
      "iteration: 123170 loss: 0.0023 lr: 0.02\n",
      "iteration: 123180 loss: 0.0034 lr: 0.02\n",
      "iteration: 123190 loss: 0.0030 lr: 0.02\n",
      "iteration: 123200 loss: 0.0029 lr: 0.02\n",
      "iteration: 123210 loss: 0.0031 lr: 0.02\n",
      "iteration: 123220 loss: 0.0027 lr: 0.02\n",
      "iteration: 123230 loss: 0.0022 lr: 0.02\n",
      "iteration: 123240 loss: 0.0024 lr: 0.02\n",
      "iteration: 123250 loss: 0.0027 lr: 0.02\n",
      "iteration: 123260 loss: 0.0027 lr: 0.02\n",
      "iteration: 123270 loss: 0.0020 lr: 0.02\n",
      "iteration: 123280 loss: 0.0031 lr: 0.02\n",
      "iteration: 123290 loss: 0.0034 lr: 0.02\n",
      "iteration: 123300 loss: 0.0031 lr: 0.02\n",
      "iteration: 123310 loss: 0.0023 lr: 0.02\n",
      "iteration: 123320 loss: 0.0032 lr: 0.02\n",
      "iteration: 123330 loss: 0.0026 lr: 0.02\n",
      "iteration: 123340 loss: 0.0024 lr: 0.02\n",
      "iteration: 123350 loss: 0.0025 lr: 0.02\n",
      "iteration: 123360 loss: 0.0027 lr: 0.02\n",
      "iteration: 123370 loss: 0.0028 lr: 0.02\n",
      "iteration: 123380 loss: 0.0026 lr: 0.02\n",
      "iteration: 123390 loss: 0.0028 lr: 0.02\n",
      "iteration: 123400 loss: 0.0025 lr: 0.02\n",
      "iteration: 123410 loss: 0.0022 lr: 0.02\n",
      "iteration: 123420 loss: 0.0021 lr: 0.02\n",
      "iteration: 123430 loss: 0.0030 lr: 0.02\n",
      "iteration: 123440 loss: 0.0021 lr: 0.02\n",
      "iteration: 123450 loss: 0.0020 lr: 0.02\n",
      "iteration: 123460 loss: 0.0031 lr: 0.02\n",
      "iteration: 123470 loss: 0.0029 lr: 0.02\n",
      "iteration: 123480 loss: 0.0027 lr: 0.02\n",
      "iteration: 123490 loss: 0.0034 lr: 0.02\n",
      "iteration: 123500 loss: 0.0024 lr: 0.02\n",
      "iteration: 123510 loss: 0.0027 lr: 0.02\n",
      "iteration: 123520 loss: 0.0022 lr: 0.02\n",
      "iteration: 123530 loss: 0.0022 lr: 0.02\n",
      "iteration: 123540 loss: 0.0021 lr: 0.02\n",
      "iteration: 123550 loss: 0.0027 lr: 0.02\n",
      "iteration: 123560 loss: 0.0027 lr: 0.02\n",
      "iteration: 123570 loss: 0.0031 lr: 0.02\n",
      "iteration: 123580 loss: 0.0029 lr: 0.02\n",
      "iteration: 123590 loss: 0.0027 lr: 0.02\n",
      "iteration: 123600 loss: 0.0020 lr: 0.02\n",
      "iteration: 123610 loss: 0.0026 lr: 0.02\n",
      "iteration: 123620 loss: 0.0035 lr: 0.02\n",
      "iteration: 123630 loss: 0.0040 lr: 0.02\n",
      "iteration: 123640 loss: 0.0019 lr: 0.02\n",
      "iteration: 123650 loss: 0.0025 lr: 0.02\n",
      "iteration: 123660 loss: 0.0028 lr: 0.02\n",
      "iteration: 123670 loss: 0.0027 lr: 0.02\n",
      "iteration: 123680 loss: 0.0023 lr: 0.02\n",
      "iteration: 123690 loss: 0.0026 lr: 0.02\n",
      "iteration: 123700 loss: 0.0027 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 123710 loss: 0.0027 lr: 0.02\n",
      "iteration: 123720 loss: 0.0025 lr: 0.02\n",
      "iteration: 123730 loss: 0.0018 lr: 0.02\n",
      "iteration: 123740 loss: 0.0028 lr: 0.02\n",
      "iteration: 123750 loss: 0.0025 lr: 0.02\n",
      "iteration: 123760 loss: 0.0026 lr: 0.02\n",
      "iteration: 123770 loss: 0.0035 lr: 0.02\n",
      "iteration: 123780 loss: 0.0023 lr: 0.02\n",
      "iteration: 123790 loss: 0.0027 lr: 0.02\n",
      "iteration: 123800 loss: 0.0023 lr: 0.02\n",
      "iteration: 123810 loss: 0.0021 lr: 0.02\n",
      "iteration: 123820 loss: 0.0021 lr: 0.02\n",
      "iteration: 123830 loss: 0.0029 lr: 0.02\n",
      "iteration: 123840 loss: 0.0026 lr: 0.02\n",
      "iteration: 123850 loss: 0.0025 lr: 0.02\n",
      "iteration: 123860 loss: 0.0022 lr: 0.02\n",
      "iteration: 123870 loss: 0.0027 lr: 0.02\n",
      "iteration: 123880 loss: 0.0031 lr: 0.02\n",
      "iteration: 123890 loss: 0.0024 lr: 0.02\n",
      "iteration: 123900 loss: 0.0022 lr: 0.02\n",
      "iteration: 123910 loss: 0.0027 lr: 0.02\n",
      "iteration: 123920 loss: 0.0024 lr: 0.02\n",
      "iteration: 123930 loss: 0.0025 lr: 0.02\n",
      "iteration: 123940 loss: 0.0030 lr: 0.02\n",
      "iteration: 123950 loss: 0.0036 lr: 0.02\n",
      "iteration: 123960 loss: 0.0027 lr: 0.02\n",
      "iteration: 123970 loss: 0.0020 lr: 0.02\n",
      "iteration: 123980 loss: 0.0032 lr: 0.02\n",
      "iteration: 123990 loss: 0.0028 lr: 0.02\n",
      "iteration: 124000 loss: 0.0022 lr: 0.02\n",
      "iteration: 124010 loss: 0.0018 lr: 0.02\n",
      "iteration: 124020 loss: 0.0021 lr: 0.02\n",
      "iteration: 124030 loss: 0.0026 lr: 0.02\n",
      "iteration: 124040 loss: 0.0025 lr: 0.02\n",
      "iteration: 124050 loss: 0.0030 lr: 0.02\n",
      "iteration: 124060 loss: 0.0027 lr: 0.02\n",
      "iteration: 124070 loss: 0.0034 lr: 0.02\n",
      "iteration: 124080 loss: 0.0025 lr: 0.02\n",
      "iteration: 124090 loss: 0.0026 lr: 0.02\n",
      "iteration: 124100 loss: 0.0021 lr: 0.02\n",
      "iteration: 124110 loss: 0.0031 lr: 0.02\n",
      "iteration: 124120 loss: 0.0028 lr: 0.02\n",
      "iteration: 124130 loss: 0.0027 lr: 0.02\n",
      "iteration: 124140 loss: 0.0022 lr: 0.02\n",
      "iteration: 124150 loss: 0.0026 lr: 0.02\n",
      "iteration: 124160 loss: 0.0021 lr: 0.02\n",
      "iteration: 124170 loss: 0.0029 lr: 0.02\n",
      "iteration: 124180 loss: 0.0019 lr: 0.02\n",
      "iteration: 124190 loss: 0.0024 lr: 0.02\n",
      "iteration: 124200 loss: 0.0019 lr: 0.02\n",
      "iteration: 124210 loss: 0.0027 lr: 0.02\n",
      "iteration: 124220 loss: 0.0032 lr: 0.02\n",
      "iteration: 124230 loss: 0.0029 lr: 0.02\n",
      "iteration: 124240 loss: 0.0026 lr: 0.02\n",
      "iteration: 124250 loss: 0.0027 lr: 0.02\n",
      "iteration: 124260 loss: 0.0022 lr: 0.02\n",
      "iteration: 124270 loss: 0.0031 lr: 0.02\n",
      "iteration: 124280 loss: 0.0024 lr: 0.02\n",
      "iteration: 124290 loss: 0.0030 lr: 0.02\n",
      "iteration: 124300 loss: 0.0026 lr: 0.02\n",
      "iteration: 124310 loss: 0.0023 lr: 0.02\n",
      "iteration: 124320 loss: 0.0031 lr: 0.02\n",
      "iteration: 124330 loss: 0.0034 lr: 0.02\n",
      "iteration: 124340 loss: 0.0029 lr: 0.02\n",
      "iteration: 124350 loss: 0.0026 lr: 0.02\n",
      "iteration: 124360 loss: 0.0028 lr: 0.02\n",
      "iteration: 124370 loss: 0.0028 lr: 0.02\n",
      "iteration: 124380 loss: 0.0020 lr: 0.02\n",
      "iteration: 124390 loss: 0.0025 lr: 0.02\n",
      "iteration: 124400 loss: 0.0027 lr: 0.02\n",
      "iteration: 124410 loss: 0.0027 lr: 0.02\n",
      "iteration: 124420 loss: 0.0032 lr: 0.02\n",
      "iteration: 124430 loss: 0.0032 lr: 0.02\n",
      "iteration: 124440 loss: 0.0027 lr: 0.02\n",
      "iteration: 124450 loss: 0.0025 lr: 0.02\n",
      "iteration: 124460 loss: 0.0029 lr: 0.02\n",
      "iteration: 124470 loss: 0.0024 lr: 0.02\n",
      "iteration: 124480 loss: 0.0029 lr: 0.02\n",
      "iteration: 124490 loss: 0.0030 lr: 0.02\n",
      "iteration: 124500 loss: 0.0024 lr: 0.02\n",
      "iteration: 124510 loss: 0.0028 lr: 0.02\n",
      "iteration: 124520 loss: 0.0025 lr: 0.02\n",
      "iteration: 124530 loss: 0.0030 lr: 0.02\n",
      "iteration: 124540 loss: 0.0036 lr: 0.02\n",
      "iteration: 124550 loss: 0.0019 lr: 0.02\n",
      "iteration: 124560 loss: 0.0022 lr: 0.02\n",
      "iteration: 124570 loss: 0.0025 lr: 0.02\n",
      "iteration: 124580 loss: 0.0026 lr: 0.02\n",
      "iteration: 124590 loss: 0.0027 lr: 0.02\n",
      "iteration: 124600 loss: 0.0023 lr: 0.02\n",
      "iteration: 124610 loss: 0.0026 lr: 0.02\n",
      "iteration: 124620 loss: 0.0027 lr: 0.02\n",
      "iteration: 124630 loss: 0.0028 lr: 0.02\n",
      "iteration: 124640 loss: 0.0028 lr: 0.02\n",
      "iteration: 124650 loss: 0.0025 lr: 0.02\n",
      "iteration: 124660 loss: 0.0027 lr: 0.02\n",
      "iteration: 124670 loss: 0.0022 lr: 0.02\n",
      "iteration: 124680 loss: 0.0024 lr: 0.02\n",
      "iteration: 124690 loss: 0.0027 lr: 0.02\n",
      "iteration: 124700 loss: 0.0021 lr: 0.02\n",
      "iteration: 124710 loss: 0.0022 lr: 0.02\n",
      "iteration: 124720 loss: 0.0025 lr: 0.02\n",
      "iteration: 124730 loss: 0.0028 lr: 0.02\n",
      "iteration: 124740 loss: 0.0021 lr: 0.02\n",
      "iteration: 124750 loss: 0.0031 lr: 0.02\n",
      "iteration: 124760 loss: 0.0030 lr: 0.02\n",
      "iteration: 124770 loss: 0.0024 lr: 0.02\n",
      "iteration: 124780 loss: 0.0022 lr: 0.02\n",
      "iteration: 124790 loss: 0.0027 lr: 0.02\n",
      "iteration: 124800 loss: 0.0025 lr: 0.02\n",
      "iteration: 124810 loss: 0.0024 lr: 0.02\n",
      "iteration: 124820 loss: 0.0026 lr: 0.02\n",
      "iteration: 124830 loss: 0.0022 lr: 0.02\n",
      "iteration: 124840 loss: 0.0021 lr: 0.02\n",
      "iteration: 124850 loss: 0.0022 lr: 0.02\n",
      "iteration: 124860 loss: 0.0023 lr: 0.02\n",
      "iteration: 124870 loss: 0.0022 lr: 0.02\n",
      "iteration: 124880 loss: 0.0031 lr: 0.02\n",
      "iteration: 124890 loss: 0.0021 lr: 0.02\n",
      "iteration: 124900 loss: 0.0026 lr: 0.02\n",
      "iteration: 124910 loss: 0.0024 lr: 0.02\n",
      "iteration: 124920 loss: 0.0025 lr: 0.02\n",
      "iteration: 124930 loss: 0.0029 lr: 0.02\n",
      "iteration: 124940 loss: 0.0020 lr: 0.02\n",
      "iteration: 124950 loss: 0.0019 lr: 0.02\n",
      "iteration: 124960 loss: 0.0028 lr: 0.02\n",
      "iteration: 124970 loss: 0.0031 lr: 0.02\n",
      "iteration: 124980 loss: 0.0025 lr: 0.02\n",
      "iteration: 124990 loss: 0.0028 lr: 0.02\n",
      "iteration: 125000 loss: 0.0022 lr: 0.02\n",
      "iteration: 125010 loss: 0.0032 lr: 0.02\n",
      "iteration: 125020 loss: 0.0025 lr: 0.02\n",
      "iteration: 125030 loss: 0.0025 lr: 0.02\n",
      "iteration: 125040 loss: 0.0020 lr: 0.02\n",
      "iteration: 125050 loss: 0.0022 lr: 0.02\n",
      "iteration: 125060 loss: 0.0018 lr: 0.02\n",
      "iteration: 125070 loss: 0.0030 lr: 0.02\n",
      "iteration: 125080 loss: 0.0024 lr: 0.02\n",
      "iteration: 125090 loss: 0.0025 lr: 0.02\n",
      "iteration: 125100 loss: 0.0023 lr: 0.02\n",
      "iteration: 125110 loss: 0.0024 lr: 0.02\n",
      "iteration: 125120 loss: 0.0030 lr: 0.02\n",
      "iteration: 125130 loss: 0.0023 lr: 0.02\n",
      "iteration: 125140 loss: 0.0023 lr: 0.02\n",
      "iteration: 125150 loss: 0.0020 lr: 0.02\n",
      "iteration: 125160 loss: 0.0027 lr: 0.02\n",
      "iteration: 125170 loss: 0.0026 lr: 0.02\n",
      "iteration: 125180 loss: 0.0023 lr: 0.02\n",
      "iteration: 125190 loss: 0.0023 lr: 0.02\n",
      "iteration: 125200 loss: 0.0031 lr: 0.02\n",
      "iteration: 125210 loss: 0.0034 lr: 0.02\n",
      "iteration: 125220 loss: 0.0026 lr: 0.02\n",
      "iteration: 125230 loss: 0.0020 lr: 0.02\n",
      "iteration: 125240 loss: 0.0029 lr: 0.02\n",
      "iteration: 125250 loss: 0.0024 lr: 0.02\n",
      "iteration: 125260 loss: 0.0023 lr: 0.02\n",
      "iteration: 125270 loss: 0.0026 lr: 0.02\n",
      "iteration: 125280 loss: 0.0025 lr: 0.02\n",
      "iteration: 125290 loss: 0.0028 lr: 0.02\n",
      "iteration: 125300 loss: 0.0031 lr: 0.02\n",
      "iteration: 125310 loss: 0.0021 lr: 0.02\n",
      "iteration: 125320 loss: 0.0020 lr: 0.02\n",
      "iteration: 125330 loss: 0.0023 lr: 0.02\n",
      "iteration: 125340 loss: 0.0019 lr: 0.02\n",
      "iteration: 125350 loss: 0.0032 lr: 0.02\n",
      "iteration: 125360 loss: 0.0027 lr: 0.02\n",
      "iteration: 125370 loss: 0.0020 lr: 0.02\n",
      "iteration: 125380 loss: 0.0023 lr: 0.02\n",
      "iteration: 125390 loss: 0.0025 lr: 0.02\n",
      "iteration: 125400 loss: 0.0021 lr: 0.02\n",
      "iteration: 125410 loss: 0.0029 lr: 0.02\n",
      "iteration: 125420 loss: 0.0027 lr: 0.02\n",
      "iteration: 125430 loss: 0.0023 lr: 0.02\n",
      "iteration: 125440 loss: 0.0022 lr: 0.02\n",
      "iteration: 125450 loss: 0.0029 lr: 0.02\n",
      "iteration: 125460 loss: 0.0026 lr: 0.02\n",
      "iteration: 125470 loss: 0.0027 lr: 0.02\n",
      "iteration: 125480 loss: 0.0024 lr: 0.02\n",
      "iteration: 125490 loss: 0.0024 lr: 0.02\n",
      "iteration: 125500 loss: 0.0024 lr: 0.02\n",
      "iteration: 125510 loss: 0.0020 lr: 0.02\n",
      "iteration: 125520 loss: 0.0019 lr: 0.02\n",
      "iteration: 125530 loss: 0.0018 lr: 0.02\n",
      "iteration: 125540 loss: 0.0031 lr: 0.02\n",
      "iteration: 125550 loss: 0.0030 lr: 0.02\n",
      "iteration: 125560 loss: 0.0024 lr: 0.02\n",
      "iteration: 125570 loss: 0.0019 lr: 0.02\n",
      "iteration: 125580 loss: 0.0045 lr: 0.02\n",
      "iteration: 125590 loss: 0.0029 lr: 0.02\n",
      "iteration: 125600 loss: 0.0025 lr: 0.02\n",
      "iteration: 125610 loss: 0.0024 lr: 0.02\n",
      "iteration: 125620 loss: 0.0020 lr: 0.02\n",
      "iteration: 125630 loss: 0.0029 lr: 0.02\n",
      "iteration: 125640 loss: 0.0027 lr: 0.02\n",
      "iteration: 125650 loss: 0.0031 lr: 0.02\n",
      "iteration: 125660 loss: 0.0030 lr: 0.02\n",
      "iteration: 125670 loss: 0.0027 lr: 0.02\n",
      "iteration: 125680 loss: 0.0033 lr: 0.02\n",
      "iteration: 125690 loss: 0.0022 lr: 0.02\n",
      "iteration: 125700 loss: 0.0022 lr: 0.02\n",
      "iteration: 125710 loss: 0.0033 lr: 0.02\n",
      "iteration: 125720 loss: 0.0021 lr: 0.02\n",
      "iteration: 125730 loss: 0.0026 lr: 0.02\n",
      "iteration: 125740 loss: 0.0022 lr: 0.02\n",
      "iteration: 125750 loss: 0.0022 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 125760 loss: 0.0023 lr: 0.02\n",
      "iteration: 125770 loss: 0.0025 lr: 0.02\n",
      "iteration: 125780 loss: 0.0022 lr: 0.02\n",
      "iteration: 125790 loss: 0.0028 lr: 0.02\n",
      "iteration: 125800 loss: 0.0023 lr: 0.02\n",
      "iteration: 125810 loss: 0.0021 lr: 0.02\n",
      "iteration: 125820 loss: 0.0031 lr: 0.02\n",
      "iteration: 125830 loss: 0.0021 lr: 0.02\n",
      "iteration: 125840 loss: 0.0022 lr: 0.02\n",
      "iteration: 125850 loss: 0.0027 lr: 0.02\n",
      "iteration: 125860 loss: 0.0024 lr: 0.02\n",
      "iteration: 125870 loss: 0.0023 lr: 0.02\n",
      "iteration: 125880 loss: 0.0021 lr: 0.02\n",
      "iteration: 125890 loss: 0.0030 lr: 0.02\n",
      "iteration: 125900 loss: 0.0027 lr: 0.02\n",
      "iteration: 125910 loss: 0.0027 lr: 0.02\n",
      "iteration: 125920 loss: 0.0021 lr: 0.02\n",
      "iteration: 125930 loss: 0.0025 lr: 0.02\n",
      "iteration: 125940 loss: 0.0030 lr: 0.02\n",
      "iteration: 125950 loss: 0.0029 lr: 0.02\n",
      "iteration: 125960 loss: 0.0029 lr: 0.02\n",
      "iteration: 125970 loss: 0.0024 lr: 0.02\n",
      "iteration: 125980 loss: 0.0022 lr: 0.02\n",
      "iteration: 125990 loss: 0.0022 lr: 0.02\n",
      "iteration: 126000 loss: 0.0025 lr: 0.02\n",
      "iteration: 126010 loss: 0.0024 lr: 0.02\n",
      "iteration: 126020 loss: 0.0022 lr: 0.02\n",
      "iteration: 126030 loss: 0.0022 lr: 0.02\n",
      "iteration: 126040 loss: 0.0027 lr: 0.02\n",
      "iteration: 126050 loss: 0.0026 lr: 0.02\n",
      "iteration: 126060 loss: 0.0021 lr: 0.02\n",
      "iteration: 126070 loss: 0.0022 lr: 0.02\n",
      "iteration: 126080 loss: 0.0029 lr: 0.02\n",
      "iteration: 126090 loss: 0.0029 lr: 0.02\n",
      "iteration: 126100 loss: 0.0026 lr: 0.02\n",
      "iteration: 126110 loss: 0.0025 lr: 0.02\n",
      "iteration: 126120 loss: 0.0030 lr: 0.02\n",
      "iteration: 126130 loss: 0.0032 lr: 0.02\n",
      "iteration: 126140 loss: 0.0029 lr: 0.02\n",
      "iteration: 126150 loss: 0.0029 lr: 0.02\n",
      "iteration: 126160 loss: 0.0020 lr: 0.02\n",
      "iteration: 126170 loss: 0.0029 lr: 0.02\n",
      "iteration: 126180 loss: 0.0021 lr: 0.02\n",
      "iteration: 126190 loss: 0.0025 lr: 0.02\n",
      "iteration: 126200 loss: 0.0026 lr: 0.02\n",
      "iteration: 126210 loss: 0.0026 lr: 0.02\n",
      "iteration: 126220 loss: 0.0023 lr: 0.02\n",
      "iteration: 126230 loss: 0.0021 lr: 0.02\n",
      "iteration: 126240 loss: 0.0024 lr: 0.02\n",
      "iteration: 126250 loss: 0.0038 lr: 0.02\n",
      "iteration: 126260 loss: 0.0023 lr: 0.02\n",
      "iteration: 126270 loss: 0.0031 lr: 0.02\n",
      "iteration: 126280 loss: 0.0025 lr: 0.02\n",
      "iteration: 126290 loss: 0.0026 lr: 0.02\n",
      "iteration: 126300 loss: 0.0024 lr: 0.02\n",
      "iteration: 126310 loss: 0.0021 lr: 0.02\n",
      "iteration: 126320 loss: 0.0025 lr: 0.02\n",
      "iteration: 126330 loss: 0.0028 lr: 0.02\n",
      "iteration: 126340 loss: 0.0022 lr: 0.02\n",
      "iteration: 126350 loss: 0.0030 lr: 0.02\n",
      "iteration: 126360 loss: 0.0030 lr: 0.02\n",
      "iteration: 126370 loss: 0.0030 lr: 0.02\n",
      "iteration: 126380 loss: 0.0027 lr: 0.02\n",
      "iteration: 126390 loss: 0.0024 lr: 0.02\n",
      "iteration: 126400 loss: 0.0025 lr: 0.02\n",
      "iteration: 126410 loss: 0.0033 lr: 0.02\n",
      "iteration: 126420 loss: 0.0031 lr: 0.02\n",
      "iteration: 126430 loss: 0.0021 lr: 0.02\n",
      "iteration: 126440 loss: 0.0023 lr: 0.02\n",
      "iteration: 126450 loss: 0.0023 lr: 0.02\n",
      "iteration: 126460 loss: 0.0029 lr: 0.02\n",
      "iteration: 126470 loss: 0.0029 lr: 0.02\n",
      "iteration: 126480 loss: 0.0022 lr: 0.02\n",
      "iteration: 126490 loss: 0.0024 lr: 0.02\n",
      "iteration: 126500 loss: 0.0023 lr: 0.02\n",
      "iteration: 126510 loss: 0.0027 lr: 0.02\n",
      "iteration: 126520 loss: 0.0028 lr: 0.02\n",
      "iteration: 126530 loss: 0.0033 lr: 0.02\n",
      "iteration: 126540 loss: 0.0023 lr: 0.02\n",
      "iteration: 126550 loss: 0.0019 lr: 0.02\n",
      "iteration: 126560 loss: 0.0028 lr: 0.02\n",
      "iteration: 126570 loss: 0.0023 lr: 0.02\n",
      "iteration: 126580 loss: 0.0020 lr: 0.02\n",
      "iteration: 126590 loss: 0.0026 lr: 0.02\n",
      "iteration: 126600 loss: 0.0022 lr: 0.02\n",
      "iteration: 126610 loss: 0.0031 lr: 0.02\n",
      "iteration: 126620 loss: 0.0018 lr: 0.02\n",
      "iteration: 126630 loss: 0.0028 lr: 0.02\n",
      "iteration: 126640 loss: 0.0021 lr: 0.02\n",
      "iteration: 126650 loss: 0.0024 lr: 0.02\n",
      "iteration: 126660 loss: 0.0019 lr: 0.02\n",
      "iteration: 126670 loss: 0.0022 lr: 0.02\n",
      "iteration: 126680 loss: 0.0028 lr: 0.02\n",
      "iteration: 126690 loss: 0.0023 lr: 0.02\n",
      "iteration: 126700 loss: 0.0032 lr: 0.02\n",
      "iteration: 126710 loss: 0.0027 lr: 0.02\n",
      "iteration: 126720 loss: 0.0023 lr: 0.02\n",
      "iteration: 126730 loss: 0.0021 lr: 0.02\n",
      "iteration: 126740 loss: 0.0025 lr: 0.02\n",
      "iteration: 126750 loss: 0.0026 lr: 0.02\n",
      "iteration: 126760 loss: 0.0029 lr: 0.02\n",
      "iteration: 126770 loss: 0.0026 lr: 0.02\n",
      "iteration: 126780 loss: 0.0022 lr: 0.02\n",
      "iteration: 126790 loss: 0.0022 lr: 0.02\n",
      "iteration: 126800 loss: 0.0027 lr: 0.02\n",
      "iteration: 126810 loss: 0.0027 lr: 0.02\n",
      "iteration: 126820 loss: 0.0025 lr: 0.02\n",
      "iteration: 126830 loss: 0.0025 lr: 0.02\n",
      "iteration: 126840 loss: 0.0031 lr: 0.02\n",
      "iteration: 126850 loss: 0.0025 lr: 0.02\n",
      "iteration: 126860 loss: 0.0023 lr: 0.02\n",
      "iteration: 126870 loss: 0.0026 lr: 0.02\n",
      "iteration: 126880 loss: 0.0027 lr: 0.02\n",
      "iteration: 126890 loss: 0.0031 lr: 0.02\n",
      "iteration: 126900 loss: 0.0027 lr: 0.02\n",
      "iteration: 126910 loss: 0.0030 lr: 0.02\n",
      "iteration: 126920 loss: 0.0024 lr: 0.02\n",
      "iteration: 126930 loss: 0.0017 lr: 0.02\n",
      "iteration: 126940 loss: 0.0029 lr: 0.02\n",
      "iteration: 126950 loss: 0.0033 lr: 0.02\n",
      "iteration: 126960 loss: 0.0028 lr: 0.02\n",
      "iteration: 126970 loss: 0.0028 lr: 0.02\n",
      "iteration: 126980 loss: 0.0029 lr: 0.02\n",
      "iteration: 126990 loss: 0.0028 lr: 0.02\n",
      "iteration: 127000 loss: 0.0025 lr: 0.02\n",
      "iteration: 127010 loss: 0.0022 lr: 0.02\n",
      "iteration: 127020 loss: 0.0020 lr: 0.02\n",
      "iteration: 127030 loss: 0.0027 lr: 0.02\n",
      "iteration: 127040 loss: 0.0024 lr: 0.02\n",
      "iteration: 127050 loss: 0.0023 lr: 0.02\n",
      "iteration: 127060 loss: 0.0019 lr: 0.02\n",
      "iteration: 127070 loss: 0.0022 lr: 0.02\n",
      "iteration: 127080 loss: 0.0024 lr: 0.02\n",
      "iteration: 127090 loss: 0.0028 lr: 0.02\n",
      "iteration: 127100 loss: 0.0024 lr: 0.02\n",
      "iteration: 127110 loss: 0.0024 lr: 0.02\n",
      "iteration: 127120 loss: 0.0023 lr: 0.02\n",
      "iteration: 127130 loss: 0.0030 lr: 0.02\n",
      "iteration: 127140 loss: 0.0020 lr: 0.02\n",
      "iteration: 127150 loss: 0.0021 lr: 0.02\n",
      "iteration: 127160 loss: 0.0021 lr: 0.02\n",
      "iteration: 127170 loss: 0.0023 lr: 0.02\n",
      "iteration: 127180 loss: 0.0026 lr: 0.02\n",
      "iteration: 127190 loss: 0.0028 lr: 0.02\n",
      "iteration: 127200 loss: 0.0023 lr: 0.02\n",
      "iteration: 127210 loss: 0.0028 lr: 0.02\n",
      "iteration: 127220 loss: 0.0020 lr: 0.02\n",
      "iteration: 127230 loss: 0.0020 lr: 0.02\n",
      "iteration: 127240 loss: 0.0023 lr: 0.02\n",
      "iteration: 127250 loss: 0.0030 lr: 0.02\n",
      "iteration: 127260 loss: 0.0023 lr: 0.02\n",
      "iteration: 127270 loss: 0.0020 lr: 0.02\n",
      "iteration: 127280 loss: 0.0028 lr: 0.02\n",
      "iteration: 127290 loss: 0.0026 lr: 0.02\n",
      "iteration: 127300 loss: 0.0019 lr: 0.02\n",
      "iteration: 127310 loss: 0.0026 lr: 0.02\n",
      "iteration: 127320 loss: 0.0024 lr: 0.02\n",
      "iteration: 127330 loss: 0.0021 lr: 0.02\n",
      "iteration: 127340 loss: 0.0025 lr: 0.02\n",
      "iteration: 127350 loss: 0.0027 lr: 0.02\n",
      "iteration: 127360 loss: 0.0022 lr: 0.02\n",
      "iteration: 127370 loss: 0.0036 lr: 0.02\n",
      "iteration: 127380 loss: 0.0023 lr: 0.02\n",
      "iteration: 127390 loss: 0.0030 lr: 0.02\n",
      "iteration: 127400 loss: 0.0030 lr: 0.02\n",
      "iteration: 127410 loss: 0.0022 lr: 0.02\n",
      "iteration: 127420 loss: 0.0027 lr: 0.02\n",
      "iteration: 127430 loss: 0.0025 lr: 0.02\n",
      "iteration: 127440 loss: 0.0036 lr: 0.02\n",
      "iteration: 127450 loss: 0.0020 lr: 0.02\n",
      "iteration: 127460 loss: 0.0023 lr: 0.02\n",
      "iteration: 127470 loss: 0.0021 lr: 0.02\n",
      "iteration: 127480 loss: 0.0024 lr: 0.02\n",
      "iteration: 127490 loss: 0.0018 lr: 0.02\n",
      "iteration: 127500 loss: 0.0023 lr: 0.02\n",
      "iteration: 127510 loss: 0.0021 lr: 0.02\n",
      "iteration: 127520 loss: 0.0023 lr: 0.02\n",
      "iteration: 127530 loss: 0.0028 lr: 0.02\n",
      "iteration: 127540 loss: 0.0034 lr: 0.02\n",
      "iteration: 127550 loss: 0.0022 lr: 0.02\n",
      "iteration: 127560 loss: 0.0022 lr: 0.02\n",
      "iteration: 127570 loss: 0.0017 lr: 0.02\n",
      "iteration: 127580 loss: 0.0024 lr: 0.02\n",
      "iteration: 127590 loss: 0.0031 lr: 0.02\n",
      "iteration: 127600 loss: 0.0025 lr: 0.02\n",
      "iteration: 127610 loss: 0.0025 lr: 0.02\n",
      "iteration: 127620 loss: 0.0026 lr: 0.02\n",
      "iteration: 127630 loss: 0.0026 lr: 0.02\n",
      "iteration: 127640 loss: 0.0022 lr: 0.02\n",
      "iteration: 127650 loss: 0.0026 lr: 0.02\n",
      "iteration: 127660 loss: 0.0029 lr: 0.02\n",
      "iteration: 127670 loss: 0.0024 lr: 0.02\n",
      "iteration: 127680 loss: 0.0033 lr: 0.02\n",
      "iteration: 127690 loss: 0.0023 lr: 0.02\n",
      "iteration: 127700 loss: 0.0026 lr: 0.02\n",
      "iteration: 127710 loss: 0.0026 lr: 0.02\n",
      "iteration: 127720 loss: 0.0025 lr: 0.02\n",
      "iteration: 127730 loss: 0.0021 lr: 0.02\n",
      "iteration: 127740 loss: 0.0020 lr: 0.02\n",
      "iteration: 127750 loss: 0.0019 lr: 0.02\n",
      "iteration: 127760 loss: 0.0028 lr: 0.02\n",
      "iteration: 127770 loss: 0.0022 lr: 0.02\n",
      "iteration: 127780 loss: 0.0021 lr: 0.02\n",
      "iteration: 127790 loss: 0.0019 lr: 0.02\n",
      "iteration: 127800 loss: 0.0022 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 127810 loss: 0.0023 lr: 0.02\n",
      "iteration: 127820 loss: 0.0026 lr: 0.02\n",
      "iteration: 127830 loss: 0.0024 lr: 0.02\n",
      "iteration: 127840 loss: 0.0030 lr: 0.02\n",
      "iteration: 127850 loss: 0.0029 lr: 0.02\n",
      "iteration: 127860 loss: 0.0023 lr: 0.02\n",
      "iteration: 127870 loss: 0.0028 lr: 0.02\n",
      "iteration: 127880 loss: 0.0025 lr: 0.02\n",
      "iteration: 127890 loss: 0.0026 lr: 0.02\n",
      "iteration: 127900 loss: 0.0022 lr: 0.02\n",
      "iteration: 127910 loss: 0.0024 lr: 0.02\n",
      "iteration: 127920 loss: 0.0032 lr: 0.02\n",
      "iteration: 127930 loss: 0.0023 lr: 0.02\n",
      "iteration: 127940 loss: 0.0031 lr: 0.02\n",
      "iteration: 127950 loss: 0.0022 lr: 0.02\n",
      "iteration: 127960 loss: 0.0031 lr: 0.02\n",
      "iteration: 127970 loss: 0.0029 lr: 0.02\n",
      "iteration: 127980 loss: 0.0025 lr: 0.02\n",
      "iteration: 127990 loss: 0.0027 lr: 0.02\n",
      "iteration: 128000 loss: 0.0022 lr: 0.02\n",
      "iteration: 128010 loss: 0.0021 lr: 0.02\n",
      "iteration: 128020 loss: 0.0020 lr: 0.02\n",
      "iteration: 128030 loss: 0.0026 lr: 0.02\n",
      "iteration: 128040 loss: 0.0025 lr: 0.02\n",
      "iteration: 128050 loss: 0.0031 lr: 0.02\n",
      "iteration: 128060 loss: 0.0026 lr: 0.02\n",
      "iteration: 128070 loss: 0.0031 lr: 0.02\n",
      "iteration: 128080 loss: 0.0022 lr: 0.02\n",
      "iteration: 128090 loss: 0.0023 lr: 0.02\n",
      "iteration: 128100 loss: 0.0032 lr: 0.02\n",
      "iteration: 128110 loss: 0.0018 lr: 0.02\n",
      "iteration: 128120 loss: 0.0019 lr: 0.02\n",
      "iteration: 128130 loss: 0.0027 lr: 0.02\n",
      "iteration: 128140 loss: 0.0025 lr: 0.02\n",
      "iteration: 128150 loss: 0.0032 lr: 0.02\n",
      "iteration: 128160 loss: 0.0030 lr: 0.02\n",
      "iteration: 128170 loss: 0.0026 lr: 0.02\n",
      "iteration: 128180 loss: 0.0034 lr: 0.02\n",
      "iteration: 128190 loss: 0.0023 lr: 0.02\n",
      "iteration: 128200 loss: 0.0024 lr: 0.02\n",
      "iteration: 128210 loss: 0.0026 lr: 0.02\n",
      "iteration: 128220 loss: 0.0017 lr: 0.02\n",
      "iteration: 128230 loss: 0.0029 lr: 0.02\n",
      "iteration: 128240 loss: 0.0017 lr: 0.02\n",
      "iteration: 128250 loss: 0.0028 lr: 0.02\n",
      "iteration: 128260 loss: 0.0021 lr: 0.02\n",
      "iteration: 128270 loss: 0.0028 lr: 0.02\n",
      "iteration: 128280 loss: 0.0022 lr: 0.02\n",
      "iteration: 128290 loss: 0.0024 lr: 0.02\n",
      "iteration: 128300 loss: 0.0031 lr: 0.02\n",
      "iteration: 128310 loss: 0.0023 lr: 0.02\n",
      "iteration: 128320 loss: 0.0027 lr: 0.02\n",
      "iteration: 128330 loss: 0.0031 lr: 0.02\n",
      "iteration: 128340 loss: 0.0023 lr: 0.02\n",
      "iteration: 128350 loss: 0.0024 lr: 0.02\n",
      "iteration: 128360 loss: 0.0024 lr: 0.02\n",
      "iteration: 128370 loss: 0.0026 lr: 0.02\n",
      "iteration: 128380 loss: 0.0018 lr: 0.02\n",
      "iteration: 128390 loss: 0.0025 lr: 0.02\n",
      "iteration: 128400 loss: 0.0024 lr: 0.02\n",
      "iteration: 128410 loss: 0.0025 lr: 0.02\n",
      "iteration: 128420 loss: 0.0028 lr: 0.02\n",
      "iteration: 128430 loss: 0.0025 lr: 0.02\n",
      "iteration: 128440 loss: 0.0026 lr: 0.02\n",
      "iteration: 128450 loss: 0.0022 lr: 0.02\n",
      "iteration: 128460 loss: 0.0027 lr: 0.02\n",
      "iteration: 128470 loss: 0.0028 lr: 0.02\n",
      "iteration: 128480 loss: 0.0034 lr: 0.02\n",
      "iteration: 128490 loss: 0.0029 lr: 0.02\n",
      "iteration: 128500 loss: 0.0023 lr: 0.02\n",
      "iteration: 128510 loss: 0.0026 lr: 0.02\n",
      "iteration: 128520 loss: 0.0031 lr: 0.02\n",
      "iteration: 128530 loss: 0.0028 lr: 0.02\n",
      "iteration: 128540 loss: 0.0025 lr: 0.02\n",
      "iteration: 128550 loss: 0.0023 lr: 0.02\n",
      "iteration: 128560 loss: 0.0025 lr: 0.02\n",
      "iteration: 128570 loss: 0.0020 lr: 0.02\n",
      "iteration: 128580 loss: 0.0024 lr: 0.02\n",
      "iteration: 128590 loss: 0.0029 lr: 0.02\n",
      "iteration: 128600 loss: 0.0031 lr: 0.02\n",
      "iteration: 128610 loss: 0.0031 lr: 0.02\n",
      "iteration: 128620 loss: 0.0029 lr: 0.02\n",
      "iteration: 128630 loss: 0.0023 lr: 0.02\n",
      "iteration: 128640 loss: 0.0033 lr: 0.02\n",
      "iteration: 128650 loss: 0.0031 lr: 0.02\n",
      "iteration: 128660 loss: 0.0019 lr: 0.02\n",
      "iteration: 128670 loss: 0.0025 lr: 0.02\n",
      "iteration: 128680 loss: 0.0021 lr: 0.02\n",
      "iteration: 128690 loss: 0.0023 lr: 0.02\n",
      "iteration: 128700 loss: 0.0028 lr: 0.02\n",
      "iteration: 128710 loss: 0.0026 lr: 0.02\n",
      "iteration: 128720 loss: 0.0025 lr: 0.02\n",
      "iteration: 128730 loss: 0.0026 lr: 0.02\n",
      "iteration: 128740 loss: 0.0017 lr: 0.02\n",
      "iteration: 128750 loss: 0.0027 lr: 0.02\n",
      "iteration: 128760 loss: 0.0021 lr: 0.02\n",
      "iteration: 128770 loss: 0.0031 lr: 0.02\n",
      "iteration: 128780 loss: 0.0025 lr: 0.02\n",
      "iteration: 128790 loss: 0.0027 lr: 0.02\n",
      "iteration: 128800 loss: 0.0020 lr: 0.02\n",
      "iteration: 128810 loss: 0.0022 lr: 0.02\n",
      "iteration: 128820 loss: 0.0027 lr: 0.02\n",
      "iteration: 128830 loss: 0.0018 lr: 0.02\n",
      "iteration: 128840 loss: 0.0025 lr: 0.02\n",
      "iteration: 128850 loss: 0.0026 lr: 0.02\n",
      "iteration: 128860 loss: 0.0023 lr: 0.02\n",
      "iteration: 128870 loss: 0.0030 lr: 0.02\n",
      "iteration: 128880 loss: 0.0018 lr: 0.02\n",
      "iteration: 128890 loss: 0.0027 lr: 0.02\n",
      "iteration: 128900 loss: 0.0020 lr: 0.02\n",
      "iteration: 128910 loss: 0.0023 lr: 0.02\n",
      "iteration: 128920 loss: 0.0031 lr: 0.02\n",
      "iteration: 128930 loss: 0.0023 lr: 0.02\n",
      "iteration: 128940 loss: 0.0023 lr: 0.02\n",
      "iteration: 128950 loss: 0.0027 lr: 0.02\n",
      "iteration: 128960 loss: 0.0024 lr: 0.02\n",
      "iteration: 128970 loss: 0.0032 lr: 0.02\n",
      "iteration: 128980 loss: 0.0026 lr: 0.02\n",
      "iteration: 128990 loss: 0.0023 lr: 0.02\n",
      "iteration: 129000 loss: 0.0030 lr: 0.02\n",
      "iteration: 129010 loss: 0.0025 lr: 0.02\n",
      "iteration: 129020 loss: 0.0025 lr: 0.02\n",
      "iteration: 129030 loss: 0.0022 lr: 0.02\n",
      "iteration: 129040 loss: 0.0025 lr: 0.02\n",
      "iteration: 129050 loss: 0.0020 lr: 0.02\n",
      "iteration: 129060 loss: 0.0023 lr: 0.02\n",
      "iteration: 129070 loss: 0.0021 lr: 0.02\n",
      "iteration: 129080 loss: 0.0019 lr: 0.02\n",
      "iteration: 129090 loss: 0.0028 lr: 0.02\n",
      "iteration: 129100 loss: 0.0024 lr: 0.02\n",
      "iteration: 129110 loss: 0.0022 lr: 0.02\n",
      "iteration: 129120 loss: 0.0027 lr: 0.02\n",
      "iteration: 129130 loss: 0.0021 lr: 0.02\n",
      "iteration: 129140 loss: 0.0030 lr: 0.02\n",
      "iteration: 129150 loss: 0.0023 lr: 0.02\n",
      "iteration: 129160 loss: 0.0024 lr: 0.02\n",
      "iteration: 129170 loss: 0.0024 lr: 0.02\n",
      "iteration: 129180 loss: 0.0025 lr: 0.02\n",
      "iteration: 129190 loss: 0.0027 lr: 0.02\n",
      "iteration: 129200 loss: 0.0029 lr: 0.02\n",
      "iteration: 129210 loss: 0.0022 lr: 0.02\n",
      "iteration: 129220 loss: 0.0022 lr: 0.02\n",
      "iteration: 129230 loss: 0.0024 lr: 0.02\n",
      "iteration: 129240 loss: 0.0027 lr: 0.02\n",
      "iteration: 129250 loss: 0.0029 lr: 0.02\n",
      "iteration: 129260 loss: 0.0024 lr: 0.02\n",
      "iteration: 129270 loss: 0.0020 lr: 0.02\n",
      "iteration: 129280 loss: 0.0027 lr: 0.02\n",
      "iteration: 129290 loss: 0.0023 lr: 0.02\n",
      "iteration: 129300 loss: 0.0020 lr: 0.02\n",
      "iteration: 129310 loss: 0.0023 lr: 0.02\n",
      "iteration: 129320 loss: 0.0021 lr: 0.02\n",
      "iteration: 129330 loss: 0.0026 lr: 0.02\n",
      "iteration: 129340 loss: 0.0025 lr: 0.02\n",
      "iteration: 129350 loss: 0.0022 lr: 0.02\n",
      "iteration: 129360 loss: 0.0022 lr: 0.02\n",
      "iteration: 129370 loss: 0.0024 lr: 0.02\n",
      "iteration: 129380 loss: 0.0020 lr: 0.02\n",
      "iteration: 129390 loss: 0.0021 lr: 0.02\n",
      "iteration: 129400 loss: 0.0021 lr: 0.02\n",
      "iteration: 129410 loss: 0.0027 lr: 0.02\n",
      "iteration: 129420 loss: 0.0031 lr: 0.02\n",
      "iteration: 129430 loss: 0.0018 lr: 0.02\n",
      "iteration: 129440 loss: 0.0022 lr: 0.02\n",
      "iteration: 129450 loss: 0.0027 lr: 0.02\n",
      "iteration: 129460 loss: 0.0026 lr: 0.02\n",
      "iteration: 129470 loss: 0.0030 lr: 0.02\n",
      "iteration: 129480 loss: 0.0027 lr: 0.02\n",
      "iteration: 129490 loss: 0.0022 lr: 0.02\n",
      "iteration: 129500 loss: 0.0021 lr: 0.02\n",
      "iteration: 129510 loss: 0.0032 lr: 0.02\n",
      "iteration: 129520 loss: 0.0019 lr: 0.02\n",
      "iteration: 129530 loss: 0.0021 lr: 0.02\n",
      "iteration: 129540 loss: 0.0028 lr: 0.02\n",
      "iteration: 129550 loss: 0.0020 lr: 0.02\n",
      "iteration: 129560 loss: 0.0027 lr: 0.02\n",
      "iteration: 129570 loss: 0.0026 lr: 0.02\n",
      "iteration: 129580 loss: 0.0021 lr: 0.02\n",
      "iteration: 129590 loss: 0.0027 lr: 0.02\n",
      "iteration: 129600 loss: 0.0028 lr: 0.02\n",
      "iteration: 129610 loss: 0.0027 lr: 0.02\n",
      "iteration: 129620 loss: 0.0023 lr: 0.02\n",
      "iteration: 129630 loss: 0.0024 lr: 0.02\n",
      "iteration: 129640 loss: 0.0030 lr: 0.02\n",
      "iteration: 129650 loss: 0.0024 lr: 0.02\n",
      "iteration: 129660 loss: 0.0022 lr: 0.02\n",
      "iteration: 129670 loss: 0.0024 lr: 0.02\n",
      "iteration: 129680 loss: 0.0026 lr: 0.02\n",
      "iteration: 129690 loss: 0.0028 lr: 0.02\n",
      "iteration: 129700 loss: 0.0030 lr: 0.02\n",
      "iteration: 129710 loss: 0.0025 lr: 0.02\n",
      "iteration: 129720 loss: 0.0023 lr: 0.02\n",
      "iteration: 129730 loss: 0.0024 lr: 0.02\n",
      "iteration: 129740 loss: 0.0027 lr: 0.02\n",
      "iteration: 129750 loss: 0.0025 lr: 0.02\n",
      "iteration: 129760 loss: 0.0024 lr: 0.02\n",
      "iteration: 129770 loss: 0.0026 lr: 0.02\n",
      "iteration: 129780 loss: 0.0028 lr: 0.02\n",
      "iteration: 129790 loss: 0.0022 lr: 0.02\n",
      "iteration: 129800 loss: 0.0026 lr: 0.02\n",
      "iteration: 129810 loss: 0.0025 lr: 0.02\n",
      "iteration: 129820 loss: 0.0023 lr: 0.02\n",
      "iteration: 129830 loss: 0.0019 lr: 0.02\n",
      "iteration: 129840 loss: 0.0025 lr: 0.02\n",
      "iteration: 129850 loss: 0.0022 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 129860 loss: 0.0027 lr: 0.02\n",
      "iteration: 129870 loss: 0.0023 lr: 0.02\n",
      "iteration: 129880 loss: 0.0021 lr: 0.02\n",
      "iteration: 129890 loss: 0.0020 lr: 0.02\n",
      "iteration: 129900 loss: 0.0024 lr: 0.02\n",
      "iteration: 129910 loss: 0.0019 lr: 0.02\n",
      "iteration: 129920 loss: 0.0022 lr: 0.02\n",
      "iteration: 129930 loss: 0.0021 lr: 0.02\n",
      "iteration: 129940 loss: 0.0024 lr: 0.02\n",
      "iteration: 129950 loss: 0.0026 lr: 0.02\n",
      "iteration: 129960 loss: 0.0021 lr: 0.02\n",
      "iteration: 129970 loss: 0.0032 lr: 0.02\n",
      "iteration: 129980 loss: 0.0023 lr: 0.02\n",
      "iteration: 129990 loss: 0.0031 lr: 0.02\n",
      "iteration: 130000 loss: 0.0020 lr: 0.02\n",
      "iteration: 130010 loss: 0.0028 lr: 0.02\n",
      "iteration: 130020 loss: 0.0024 lr: 0.02\n",
      "iteration: 130030 loss: 0.0035 lr: 0.02\n",
      "iteration: 130040 loss: 0.0037 lr: 0.02\n",
      "iteration: 130050 loss: 0.0025 lr: 0.02\n",
      "iteration: 130060 loss: 0.0027 lr: 0.02\n",
      "iteration: 130070 loss: 0.0028 lr: 0.02\n",
      "iteration: 130080 loss: 0.0025 lr: 0.02\n",
      "iteration: 130090 loss: 0.0031 lr: 0.02\n",
      "iteration: 130100 loss: 0.0024 lr: 0.02\n",
      "iteration: 130110 loss: 0.0023 lr: 0.02\n",
      "iteration: 130120 loss: 0.0022 lr: 0.02\n",
      "iteration: 130130 loss: 0.0020 lr: 0.02\n",
      "iteration: 130140 loss: 0.0023 lr: 0.02\n",
      "iteration: 130150 loss: 0.0033 lr: 0.02\n",
      "iteration: 130160 loss: 0.0026 lr: 0.02\n",
      "iteration: 130170 loss: 0.0017 lr: 0.02\n",
      "iteration: 130180 loss: 0.0033 lr: 0.02\n",
      "iteration: 130190 loss: 0.0026 lr: 0.02\n",
      "iteration: 130200 loss: 0.0020 lr: 0.02\n",
      "iteration: 130210 loss: 0.0029 lr: 0.02\n",
      "iteration: 130220 loss: 0.0021 lr: 0.02\n",
      "iteration: 130230 loss: 0.0027 lr: 0.02\n",
      "iteration: 130240 loss: 0.0023 lr: 0.02\n",
      "iteration: 130250 loss: 0.0028 lr: 0.02\n",
      "iteration: 130260 loss: 0.0028 lr: 0.02\n",
      "iteration: 130270 loss: 0.0025 lr: 0.02\n",
      "iteration: 130280 loss: 0.0033 lr: 0.02\n",
      "iteration: 130290 loss: 0.0020 lr: 0.02\n",
      "iteration: 130300 loss: 0.0033 lr: 0.02\n",
      "iteration: 130310 loss: 0.0020 lr: 0.02\n",
      "iteration: 130320 loss: 0.0027 lr: 0.02\n",
      "iteration: 130330 loss: 0.0022 lr: 0.02\n",
      "iteration: 130340 loss: 0.0024 lr: 0.02\n",
      "iteration: 130350 loss: 0.0020 lr: 0.02\n",
      "iteration: 130360 loss: 0.0023 lr: 0.02\n",
      "iteration: 130370 loss: 0.0035 lr: 0.02\n",
      "iteration: 130380 loss: 0.0018 lr: 0.02\n",
      "iteration: 130390 loss: 0.0024 lr: 0.02\n",
      "iteration: 130400 loss: 0.0029 lr: 0.02\n",
      "iteration: 130410 loss: 0.0028 lr: 0.02\n",
      "iteration: 130420 loss: 0.0025 lr: 0.02\n",
      "iteration: 130430 loss: 0.0018 lr: 0.02\n",
      "iteration: 130440 loss: 0.0026 lr: 0.02\n",
      "iteration: 130450 loss: 0.0022 lr: 0.02\n",
      "iteration: 130460 loss: 0.0020 lr: 0.02\n",
      "iteration: 130470 loss: 0.0021 lr: 0.02\n",
      "iteration: 130480 loss: 0.0023 lr: 0.02\n",
      "iteration: 130490 loss: 0.0019 lr: 0.02\n",
      "iteration: 130500 loss: 0.0022 lr: 0.02\n",
      "iteration: 130510 loss: 0.0026 lr: 0.02\n",
      "iteration: 130520 loss: 0.0028 lr: 0.02\n",
      "iteration: 130530 loss: 0.0021 lr: 0.02\n",
      "iteration: 130540 loss: 0.0032 lr: 0.02\n",
      "iteration: 130550 loss: 0.0023 lr: 0.02\n",
      "iteration: 130560 loss: 0.0019 lr: 0.02\n",
      "iteration: 130570 loss: 0.0022 lr: 0.02\n",
      "iteration: 130580 loss: 0.0029 lr: 0.02\n",
      "iteration: 130590 loss: 0.0023 lr: 0.02\n",
      "iteration: 130600 loss: 0.0027 lr: 0.02\n",
      "iteration: 130610 loss: 0.0028 lr: 0.02\n",
      "iteration: 130620 loss: 0.0022 lr: 0.02\n",
      "iteration: 130630 loss: 0.0019 lr: 0.02\n",
      "iteration: 130640 loss: 0.0024 lr: 0.02\n",
      "iteration: 130650 loss: 0.0021 lr: 0.02\n",
      "iteration: 130660 loss: 0.0023 lr: 0.02\n",
      "iteration: 130670 loss: 0.0023 lr: 0.02\n",
      "iteration: 130680 loss: 0.0026 lr: 0.02\n",
      "iteration: 130690 loss: 0.0020 lr: 0.02\n",
      "iteration: 130700 loss: 0.0023 lr: 0.02\n",
      "iteration: 130710 loss: 0.0025 lr: 0.02\n",
      "iteration: 130720 loss: 0.0026 lr: 0.02\n",
      "iteration: 130730 loss: 0.0021 lr: 0.02\n",
      "iteration: 130740 loss: 0.0023 lr: 0.02\n",
      "iteration: 130750 loss: 0.0024 lr: 0.02\n",
      "iteration: 130760 loss: 0.0026 lr: 0.02\n",
      "iteration: 130770 loss: 0.0023 lr: 0.02\n",
      "iteration: 130780 loss: 0.0021 lr: 0.02\n",
      "iteration: 130790 loss: 0.0025 lr: 0.02\n",
      "iteration: 130800 loss: 0.0029 lr: 0.02\n",
      "iteration: 130810 loss: 0.0039 lr: 0.02\n",
      "iteration: 130820 loss: 0.0031 lr: 0.02\n",
      "iteration: 130830 loss: 0.0034 lr: 0.02\n",
      "iteration: 130840 loss: 0.0024 lr: 0.02\n",
      "iteration: 130850 loss: 0.0033 lr: 0.02\n",
      "iteration: 130860 loss: 0.0028 lr: 0.02\n",
      "iteration: 130870 loss: 0.0024 lr: 0.02\n",
      "iteration: 130880 loss: 0.0024 lr: 0.02\n",
      "iteration: 130890 loss: 0.0030 lr: 0.02\n",
      "iteration: 130900 loss: 0.0022 lr: 0.02\n",
      "iteration: 130910 loss: 0.0021 lr: 0.02\n",
      "iteration: 130920 loss: 0.0026 lr: 0.02\n",
      "iteration: 130930 loss: 0.0021 lr: 0.02\n",
      "iteration: 130940 loss: 0.0024 lr: 0.02\n",
      "iteration: 130950 loss: 0.0021 lr: 0.02\n",
      "iteration: 130960 loss: 0.0021 lr: 0.02\n",
      "iteration: 130970 loss: 0.0026 lr: 0.02\n",
      "iteration: 130980 loss: 0.0029 lr: 0.02\n",
      "iteration: 130990 loss: 0.0019 lr: 0.02\n",
      "iteration: 131000 loss: 0.0027 lr: 0.02\n",
      "iteration: 131010 loss: 0.0023 lr: 0.02\n",
      "iteration: 131020 loss: 0.0029 lr: 0.02\n",
      "iteration: 131030 loss: 0.0023 lr: 0.02\n",
      "iteration: 131040 loss: 0.0026 lr: 0.02\n",
      "iteration: 131050 loss: 0.0025 lr: 0.02\n",
      "iteration: 131060 loss: 0.0027 lr: 0.02\n",
      "iteration: 131070 loss: 0.0032 lr: 0.02\n",
      "iteration: 131080 loss: 0.0018 lr: 0.02\n",
      "iteration: 131090 loss: 0.0020 lr: 0.02\n",
      "iteration: 131100 loss: 0.0021 lr: 0.02\n",
      "iteration: 131110 loss: 0.0023 lr: 0.02\n",
      "iteration: 131120 loss: 0.0026 lr: 0.02\n",
      "iteration: 131130 loss: 0.0028 lr: 0.02\n",
      "iteration: 131140 loss: 0.0021 lr: 0.02\n",
      "iteration: 131150 loss: 0.0023 lr: 0.02\n",
      "iteration: 131160 loss: 0.0026 lr: 0.02\n",
      "iteration: 131170 loss: 0.0025 lr: 0.02\n",
      "iteration: 131180 loss: 0.0025 lr: 0.02\n",
      "iteration: 131190 loss: 0.0023 lr: 0.02\n",
      "iteration: 131200 loss: 0.0028 lr: 0.02\n",
      "iteration: 131210 loss: 0.0021 lr: 0.02\n",
      "iteration: 131220 loss: 0.0023 lr: 0.02\n",
      "iteration: 131230 loss: 0.0022 lr: 0.02\n",
      "iteration: 131240 loss: 0.0032 lr: 0.02\n",
      "iteration: 131250 loss: 0.0024 lr: 0.02\n",
      "iteration: 131260 loss: 0.0022 lr: 0.02\n",
      "iteration: 131270 loss: 0.0025 lr: 0.02\n",
      "iteration: 131280 loss: 0.0026 lr: 0.02\n",
      "iteration: 131290 loss: 0.0019 lr: 0.02\n",
      "iteration: 131300 loss: 0.0024 lr: 0.02\n",
      "iteration: 131310 loss: 0.0027 lr: 0.02\n",
      "iteration: 131320 loss: 0.0021 lr: 0.02\n",
      "iteration: 131330 loss: 0.0025 lr: 0.02\n",
      "iteration: 131340 loss: 0.0029 lr: 0.02\n",
      "iteration: 131350 loss: 0.0022 lr: 0.02\n",
      "iteration: 131360 loss: 0.0019 lr: 0.02\n",
      "iteration: 131370 loss: 0.0019 lr: 0.02\n",
      "iteration: 131380 loss: 0.0023 lr: 0.02\n",
      "iteration: 131390 loss: 0.0022 lr: 0.02\n",
      "iteration: 131400 loss: 0.0020 lr: 0.02\n",
      "iteration: 131410 loss: 0.0022 lr: 0.02\n",
      "iteration: 131420 loss: 0.0019 lr: 0.02\n",
      "iteration: 131430 loss: 0.0029 lr: 0.02\n",
      "iteration: 131440 loss: 0.0031 lr: 0.02\n",
      "iteration: 131450 loss: 0.0029 lr: 0.02\n",
      "iteration: 131460 loss: 0.0024 lr: 0.02\n",
      "iteration: 131470 loss: 0.0020 lr: 0.02\n",
      "iteration: 131480 loss: 0.0020 lr: 0.02\n",
      "iteration: 131490 loss: 0.0021 lr: 0.02\n",
      "iteration: 131500 loss: 0.0031 lr: 0.02\n",
      "iteration: 131510 loss: 0.0028 lr: 0.02\n",
      "iteration: 131520 loss: 0.0027 lr: 0.02\n",
      "iteration: 131530 loss: 0.0021 lr: 0.02\n",
      "iteration: 131540 loss: 0.0021 lr: 0.02\n",
      "iteration: 131550 loss: 0.0029 lr: 0.02\n",
      "iteration: 131560 loss: 0.0024 lr: 0.02\n",
      "iteration: 131570 loss: 0.0024 lr: 0.02\n",
      "iteration: 131580 loss: 0.0029 lr: 0.02\n",
      "iteration: 131590 loss: 0.0031 lr: 0.02\n",
      "iteration: 131600 loss: 0.0036 lr: 0.02\n",
      "iteration: 131610 loss: 0.0028 lr: 0.02\n",
      "iteration: 131620 loss: 0.0019 lr: 0.02\n",
      "iteration: 131630 loss: 0.0022 lr: 0.02\n",
      "iteration: 131640 loss: 0.0022 lr: 0.02\n",
      "iteration: 131650 loss: 0.0023 lr: 0.02\n",
      "iteration: 131660 loss: 0.0022 lr: 0.02\n",
      "iteration: 131670 loss: 0.0027 lr: 0.02\n",
      "iteration: 131680 loss: 0.0023 lr: 0.02\n",
      "iteration: 131690 loss: 0.0027 lr: 0.02\n",
      "iteration: 131700 loss: 0.0025 lr: 0.02\n",
      "iteration: 131710 loss: 0.0020 lr: 0.02\n",
      "iteration: 131720 loss: 0.0028 lr: 0.02\n",
      "iteration: 131730 loss: 0.0026 lr: 0.02\n",
      "iteration: 131740 loss: 0.0027 lr: 0.02\n",
      "iteration: 131750 loss: 0.0028 lr: 0.02\n",
      "iteration: 131760 loss: 0.0025 lr: 0.02\n",
      "iteration: 131770 loss: 0.0027 lr: 0.02\n",
      "iteration: 131780 loss: 0.0026 lr: 0.02\n",
      "iteration: 131790 loss: 0.0035 lr: 0.02\n",
      "iteration: 131800 loss: 0.0028 lr: 0.02\n",
      "iteration: 131810 loss: 0.0028 lr: 0.02\n",
      "iteration: 131820 loss: 0.0037 lr: 0.02\n",
      "iteration: 131830 loss: 0.0022 lr: 0.02\n",
      "iteration: 131840 loss: 0.0027 lr: 0.02\n",
      "iteration: 131850 loss: 0.0026 lr: 0.02\n",
      "iteration: 131860 loss: 0.0021 lr: 0.02\n",
      "iteration: 131870 loss: 0.0027 lr: 0.02\n",
      "iteration: 131880 loss: 0.0027 lr: 0.02\n",
      "iteration: 131890 loss: 0.0027 lr: 0.02\n",
      "iteration: 131900 loss: 0.0024 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 131910 loss: 0.0022 lr: 0.02\n",
      "iteration: 131920 loss: 0.0028 lr: 0.02\n",
      "iteration: 131930 loss: 0.0020 lr: 0.02\n",
      "iteration: 131940 loss: 0.0029 lr: 0.02\n",
      "iteration: 131950 loss: 0.0021 lr: 0.02\n",
      "iteration: 131960 loss: 0.0024 lr: 0.02\n",
      "iteration: 131970 loss: 0.0020 lr: 0.02\n",
      "iteration: 131980 loss: 0.0020 lr: 0.02\n",
      "iteration: 131990 loss: 0.0021 lr: 0.02\n",
      "iteration: 132000 loss: 0.0023 lr: 0.02\n",
      "iteration: 132010 loss: 0.0024 lr: 0.02\n",
      "iteration: 132020 loss: 0.0025 lr: 0.02\n",
      "iteration: 132030 loss: 0.0028 lr: 0.02\n",
      "iteration: 132040 loss: 0.0031 lr: 0.02\n",
      "iteration: 132050 loss: 0.0024 lr: 0.02\n",
      "iteration: 132060 loss: 0.0026 lr: 0.02\n",
      "iteration: 132070 loss: 0.0023 lr: 0.02\n",
      "iteration: 132080 loss: 0.0028 lr: 0.02\n",
      "iteration: 132090 loss: 0.0023 lr: 0.02\n",
      "iteration: 132100 loss: 0.0024 lr: 0.02\n",
      "iteration: 132110 loss: 0.0025 lr: 0.02\n",
      "iteration: 132120 loss: 0.0017 lr: 0.02\n",
      "iteration: 132130 loss: 0.0020 lr: 0.02\n",
      "iteration: 132140 loss: 0.0021 lr: 0.02\n",
      "iteration: 132150 loss: 0.0031 lr: 0.02\n",
      "iteration: 132160 loss: 0.0034 lr: 0.02\n",
      "iteration: 132170 loss: 0.0029 lr: 0.02\n",
      "iteration: 132180 loss: 0.0022 lr: 0.02\n",
      "iteration: 132190 loss: 0.0025 lr: 0.02\n",
      "iteration: 132200 loss: 0.0033 lr: 0.02\n",
      "iteration: 132210 loss: 0.0025 lr: 0.02\n",
      "iteration: 132220 loss: 0.0028 lr: 0.02\n",
      "iteration: 132230 loss: 0.0024 lr: 0.02\n",
      "iteration: 132240 loss: 0.0023 lr: 0.02\n",
      "iteration: 132250 loss: 0.0025 lr: 0.02\n",
      "iteration: 132260 loss: 0.0022 lr: 0.02\n",
      "iteration: 132270 loss: 0.0028 lr: 0.02\n",
      "iteration: 132280 loss: 0.0025 lr: 0.02\n",
      "iteration: 132290 loss: 0.0020 lr: 0.02\n",
      "iteration: 132300 loss: 0.0027 lr: 0.02\n",
      "iteration: 132310 loss: 0.0022 lr: 0.02\n",
      "iteration: 132320 loss: 0.0029 lr: 0.02\n",
      "iteration: 132330 loss: 0.0024 lr: 0.02\n",
      "iteration: 132340 loss: 0.0026 lr: 0.02\n",
      "iteration: 132350 loss: 0.0023 lr: 0.02\n",
      "iteration: 132360 loss: 0.0028 lr: 0.02\n",
      "iteration: 132370 loss: 0.0020 lr: 0.02\n",
      "iteration: 132380 loss: 0.0025 lr: 0.02\n",
      "iteration: 132390 loss: 0.0024 lr: 0.02\n",
      "iteration: 132400 loss: 0.0023 lr: 0.02\n",
      "iteration: 132410 loss: 0.0021 lr: 0.02\n",
      "iteration: 132420 loss: 0.0021 lr: 0.02\n",
      "iteration: 132430 loss: 0.0023 lr: 0.02\n",
      "iteration: 132440 loss: 0.0019 lr: 0.02\n",
      "iteration: 132450 loss: 0.0024 lr: 0.02\n",
      "iteration: 132460 loss: 0.0026 lr: 0.02\n",
      "iteration: 132470 loss: 0.0023 lr: 0.02\n",
      "iteration: 132480 loss: 0.0027 lr: 0.02\n",
      "iteration: 132490 loss: 0.0027 lr: 0.02\n",
      "iteration: 132500 loss: 0.0025 lr: 0.02\n",
      "iteration: 132510 loss: 0.0031 lr: 0.02\n",
      "iteration: 132520 loss: 0.0024 lr: 0.02\n",
      "iteration: 132530 loss: 0.0025 lr: 0.02\n",
      "iteration: 132540 loss: 0.0029 lr: 0.02\n",
      "iteration: 132550 loss: 0.0023 lr: 0.02\n",
      "iteration: 132560 loss: 0.0027 lr: 0.02\n",
      "iteration: 132570 loss: 0.0024 lr: 0.02\n",
      "iteration: 132580 loss: 0.0020 lr: 0.02\n",
      "iteration: 132590 loss: 0.0025 lr: 0.02\n",
      "iteration: 132600 loss: 0.0021 lr: 0.02\n",
      "iteration: 132610 loss: 0.0026 lr: 0.02\n",
      "iteration: 132620 loss: 0.0021 lr: 0.02\n",
      "iteration: 132630 loss: 0.0026 lr: 0.02\n",
      "iteration: 132640 loss: 0.0018 lr: 0.02\n",
      "iteration: 132650 loss: 0.0024 lr: 0.02\n",
      "iteration: 132660 loss: 0.0024 lr: 0.02\n",
      "iteration: 132670 loss: 0.0032 lr: 0.02\n",
      "iteration: 132680 loss: 0.0028 lr: 0.02\n",
      "iteration: 132690 loss: 0.0021 lr: 0.02\n",
      "iteration: 132700 loss: 0.0024 lr: 0.02\n",
      "iteration: 132710 loss: 0.0026 lr: 0.02\n",
      "iteration: 132720 loss: 0.0035 lr: 0.02\n",
      "iteration: 132730 loss: 0.0021 lr: 0.02\n",
      "iteration: 132740 loss: 0.0024 lr: 0.02\n",
      "iteration: 132750 loss: 0.0023 lr: 0.02\n",
      "iteration: 132760 loss: 0.0028 lr: 0.02\n",
      "iteration: 132770 loss: 0.0030 lr: 0.02\n",
      "iteration: 132780 loss: 0.0029 lr: 0.02\n",
      "iteration: 132790 loss: 0.0019 lr: 0.02\n",
      "iteration: 132800 loss: 0.0029 lr: 0.02\n",
      "iteration: 132810 loss: 0.0024 lr: 0.02\n",
      "iteration: 132820 loss: 0.0019 lr: 0.02\n",
      "iteration: 132830 loss: 0.0020 lr: 0.02\n",
      "iteration: 132840 loss: 0.0028 lr: 0.02\n",
      "iteration: 132850 loss: 0.0017 lr: 0.02\n",
      "iteration: 132860 loss: 0.0027 lr: 0.02\n",
      "iteration: 132870 loss: 0.0023 lr: 0.02\n",
      "iteration: 132880 loss: 0.0028 lr: 0.02\n",
      "iteration: 132890 loss: 0.0019 lr: 0.02\n",
      "iteration: 132900 loss: 0.0025 lr: 0.02\n",
      "iteration: 132910 loss: 0.0030 lr: 0.02\n",
      "iteration: 132920 loss: 0.0025 lr: 0.02\n",
      "iteration: 132930 loss: 0.0028 lr: 0.02\n",
      "iteration: 132940 loss: 0.0023 lr: 0.02\n",
      "iteration: 132950 loss: 0.0023 lr: 0.02\n",
      "iteration: 132960 loss: 0.0023 lr: 0.02\n",
      "iteration: 132970 loss: 0.0029 lr: 0.02\n",
      "iteration: 132980 loss: 0.0034 lr: 0.02\n",
      "iteration: 132990 loss: 0.0023 lr: 0.02\n",
      "iteration: 133000 loss: 0.0029 lr: 0.02\n",
      "iteration: 133010 loss: 0.0029 lr: 0.02\n",
      "iteration: 133020 loss: 0.0021 lr: 0.02\n",
      "iteration: 133030 loss: 0.0019 lr: 0.02\n",
      "iteration: 133040 loss: 0.0029 lr: 0.02\n",
      "iteration: 133050 loss: 0.0024 lr: 0.02\n",
      "iteration: 133060 loss: 0.0024 lr: 0.02\n",
      "iteration: 133070 loss: 0.0019 lr: 0.02\n",
      "iteration: 133080 loss: 0.0023 lr: 0.02\n",
      "iteration: 133090 loss: 0.0020 lr: 0.02\n",
      "iteration: 133100 loss: 0.0025 lr: 0.02\n",
      "iteration: 133110 loss: 0.0026 lr: 0.02\n",
      "iteration: 133120 loss: 0.0023 lr: 0.02\n",
      "iteration: 133130 loss: 0.0030 lr: 0.02\n",
      "iteration: 133140 loss: 0.0022 lr: 0.02\n",
      "iteration: 133150 loss: 0.0024 lr: 0.02\n",
      "iteration: 133160 loss: 0.0024 lr: 0.02\n",
      "iteration: 133170 loss: 0.0026 lr: 0.02\n",
      "iteration: 133180 loss: 0.0025 lr: 0.02\n",
      "iteration: 133190 loss: 0.0020 lr: 0.02\n",
      "iteration: 133200 loss: 0.0022 lr: 0.02\n",
      "iteration: 133210 loss: 0.0029 lr: 0.02\n",
      "iteration: 133220 loss: 0.0025 lr: 0.02\n",
      "iteration: 133230 loss: 0.0021 lr: 0.02\n",
      "iteration: 133240 loss: 0.0027 lr: 0.02\n",
      "iteration: 133250 loss: 0.0027 lr: 0.02\n",
      "iteration: 133260 loss: 0.0026 lr: 0.02\n",
      "iteration: 133270 loss: 0.0025 lr: 0.02\n",
      "iteration: 133280 loss: 0.0020 lr: 0.02\n",
      "iteration: 133290 loss: 0.0021 lr: 0.02\n",
      "iteration: 133300 loss: 0.0030 lr: 0.02\n",
      "iteration: 133310 loss: 0.0023 lr: 0.02\n",
      "iteration: 133320 loss: 0.0023 lr: 0.02\n",
      "iteration: 133330 loss: 0.0026 lr: 0.02\n",
      "iteration: 133340 loss: 0.0018 lr: 0.02\n",
      "iteration: 133350 loss: 0.0022 lr: 0.02\n",
      "iteration: 133360 loss: 0.0022 lr: 0.02\n",
      "iteration: 133370 loss: 0.0026 lr: 0.02\n",
      "iteration: 133380 loss: 0.0025 lr: 0.02\n",
      "iteration: 133390 loss: 0.0024 lr: 0.02\n",
      "iteration: 133400 loss: 0.0023 lr: 0.02\n",
      "iteration: 133410 loss: 0.0024 lr: 0.02\n",
      "iteration: 133420 loss: 0.0028 lr: 0.02\n",
      "iteration: 133430 loss: 0.0022 lr: 0.02\n",
      "iteration: 133440 loss: 0.0020 lr: 0.02\n",
      "iteration: 133450 loss: 0.0031 lr: 0.02\n",
      "iteration: 133460 loss: 0.0018 lr: 0.02\n",
      "iteration: 133470 loss: 0.0022 lr: 0.02\n",
      "iteration: 133480 loss: 0.0024 lr: 0.02\n",
      "iteration: 133490 loss: 0.0030 lr: 0.02\n",
      "iteration: 133500 loss: 0.0024 lr: 0.02\n",
      "iteration: 133510 loss: 0.0024 lr: 0.02\n",
      "iteration: 133520 loss: 0.0026 lr: 0.02\n",
      "iteration: 133530 loss: 0.0025 lr: 0.02\n",
      "iteration: 133540 loss: 0.0028 lr: 0.02\n",
      "iteration: 133550 loss: 0.0024 lr: 0.02\n",
      "iteration: 133560 loss: 0.0034 lr: 0.02\n",
      "iteration: 133570 loss: 0.0024 lr: 0.02\n",
      "iteration: 133580 loss: 0.0023 lr: 0.02\n",
      "iteration: 133590 loss: 0.0024 lr: 0.02\n",
      "iteration: 133600 loss: 0.0023 lr: 0.02\n",
      "iteration: 133610 loss: 0.0023 lr: 0.02\n",
      "iteration: 133620 loss: 0.0021 lr: 0.02\n",
      "iteration: 133630 loss: 0.0026 lr: 0.02\n",
      "iteration: 133640 loss: 0.0023 lr: 0.02\n",
      "iteration: 133650 loss: 0.0019 lr: 0.02\n",
      "iteration: 133660 loss: 0.0024 lr: 0.02\n",
      "iteration: 133670 loss: 0.0024 lr: 0.02\n",
      "iteration: 133680 loss: 0.0024 lr: 0.02\n",
      "iteration: 133690 loss: 0.0030 lr: 0.02\n",
      "iteration: 133700 loss: 0.0023 lr: 0.02\n",
      "iteration: 133710 loss: 0.0020 lr: 0.02\n",
      "iteration: 133720 loss: 0.0027 lr: 0.02\n",
      "iteration: 133730 loss: 0.0023 lr: 0.02\n",
      "iteration: 133740 loss: 0.0018 lr: 0.02\n",
      "iteration: 133750 loss: 0.0032 lr: 0.02\n",
      "iteration: 133760 loss: 0.0023 lr: 0.02\n",
      "iteration: 133770 loss: 0.0022 lr: 0.02\n",
      "iteration: 133780 loss: 0.0023 lr: 0.02\n",
      "iteration: 133790 loss: 0.0025 lr: 0.02\n",
      "iteration: 133800 loss: 0.0024 lr: 0.02\n",
      "iteration: 133810 loss: 0.0021 lr: 0.02\n",
      "iteration: 133820 loss: 0.0021 lr: 0.02\n",
      "iteration: 133830 loss: 0.0021 lr: 0.02\n",
      "iteration: 133840 loss: 0.0023 lr: 0.02\n",
      "iteration: 133850 loss: 0.0025 lr: 0.02\n",
      "iteration: 133860 loss: 0.0027 lr: 0.02\n",
      "iteration: 133870 loss: 0.0023 lr: 0.02\n",
      "iteration: 133880 loss: 0.0020 lr: 0.02\n",
      "iteration: 133890 loss: 0.0031 lr: 0.02\n",
      "iteration: 133900 loss: 0.0021 lr: 0.02\n",
      "iteration: 133910 loss: 0.0025 lr: 0.02\n",
      "iteration: 133920 loss: 0.0023 lr: 0.02\n",
      "iteration: 133930 loss: 0.0024 lr: 0.02\n",
      "iteration: 133940 loss: 0.0024 lr: 0.02\n",
      "iteration: 133950 loss: 0.0021 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 133960 loss: 0.0021 lr: 0.02\n",
      "iteration: 133970 loss: 0.0030 lr: 0.02\n",
      "iteration: 133980 loss: 0.0019 lr: 0.02\n",
      "iteration: 133990 loss: 0.0021 lr: 0.02\n",
      "iteration: 134000 loss: 0.0030 lr: 0.02\n",
      "iteration: 134010 loss: 0.0032 lr: 0.02\n",
      "iteration: 134020 loss: 0.0021 lr: 0.02\n",
      "iteration: 134030 loss: 0.0020 lr: 0.02\n",
      "iteration: 134040 loss: 0.0021 lr: 0.02\n",
      "iteration: 134050 loss: 0.0027 lr: 0.02\n",
      "iteration: 134060 loss: 0.0026 lr: 0.02\n",
      "iteration: 134070 loss: 0.0022 lr: 0.02\n",
      "iteration: 134080 loss: 0.0027 lr: 0.02\n",
      "iteration: 134090 loss: 0.0022 lr: 0.02\n",
      "iteration: 134100 loss: 0.0023 lr: 0.02\n",
      "iteration: 134110 loss: 0.0023 lr: 0.02\n",
      "iteration: 134120 loss: 0.0025 lr: 0.02\n",
      "iteration: 134130 loss: 0.0025 lr: 0.02\n",
      "iteration: 134140 loss: 0.0018 lr: 0.02\n",
      "iteration: 134150 loss: 0.0026 lr: 0.02\n",
      "iteration: 134160 loss: 0.0036 lr: 0.02\n",
      "iteration: 134170 loss: 0.0026 lr: 0.02\n",
      "iteration: 134180 loss: 0.0031 lr: 0.02\n",
      "iteration: 134190 loss: 0.0026 lr: 0.02\n",
      "iteration: 134200 loss: 0.0022 lr: 0.02\n",
      "iteration: 134210 loss: 0.0026 lr: 0.02\n",
      "iteration: 134220 loss: 0.0031 lr: 0.02\n",
      "iteration: 134230 loss: 0.0030 lr: 0.02\n",
      "iteration: 134240 loss: 0.0022 lr: 0.02\n",
      "iteration: 134250 loss: 0.0021 lr: 0.02\n",
      "iteration: 134260 loss: 0.0022 lr: 0.02\n",
      "iteration: 134270 loss: 0.0024 lr: 0.02\n",
      "iteration: 134280 loss: 0.0030 lr: 0.02\n",
      "iteration: 134290 loss: 0.0028 lr: 0.02\n",
      "iteration: 134300 loss: 0.0018 lr: 0.02\n",
      "iteration: 134310 loss: 0.0026 lr: 0.02\n",
      "iteration: 134320 loss: 0.0024 lr: 0.02\n",
      "iteration: 134330 loss: 0.0024 lr: 0.02\n",
      "iteration: 134340 loss: 0.0027 lr: 0.02\n",
      "iteration: 134350 loss: 0.0022 lr: 0.02\n",
      "iteration: 134360 loss: 0.0029 lr: 0.02\n",
      "iteration: 134370 loss: 0.0024 lr: 0.02\n",
      "iteration: 134380 loss: 0.0022 lr: 0.02\n",
      "iteration: 134390 loss: 0.0025 lr: 0.02\n",
      "iteration: 134400 loss: 0.0028 lr: 0.02\n",
      "iteration: 134410 loss: 0.0032 lr: 0.02\n",
      "iteration: 134420 loss: 0.0019 lr: 0.02\n",
      "iteration: 134430 loss: 0.0027 lr: 0.02\n",
      "iteration: 134440 loss: 0.0023 lr: 0.02\n",
      "iteration: 134450 loss: 0.0030 lr: 0.02\n",
      "iteration: 134460 loss: 0.0030 lr: 0.02\n",
      "iteration: 134470 loss: 0.0024 lr: 0.02\n",
      "iteration: 134480 loss: 0.0024 lr: 0.02\n",
      "iteration: 134490 loss: 0.0019 lr: 0.02\n",
      "iteration: 134500 loss: 0.0021 lr: 0.02\n",
      "iteration: 134510 loss: 0.0027 lr: 0.02\n",
      "iteration: 134520 loss: 0.0025 lr: 0.02\n",
      "iteration: 134530 loss: 0.0028 lr: 0.02\n",
      "iteration: 134540 loss: 0.0024 lr: 0.02\n",
      "iteration: 134550 loss: 0.0025 lr: 0.02\n",
      "iteration: 134560 loss: 0.0024 lr: 0.02\n",
      "iteration: 134570 loss: 0.0032 lr: 0.02\n",
      "iteration: 134580 loss: 0.0022 lr: 0.02\n",
      "iteration: 134590 loss: 0.0023 lr: 0.02\n",
      "iteration: 134600 loss: 0.0023 lr: 0.02\n",
      "iteration: 134610 loss: 0.0026 lr: 0.02\n",
      "iteration: 134620 loss: 0.0024 lr: 0.02\n",
      "iteration: 134630 loss: 0.0023 lr: 0.02\n",
      "iteration: 134640 loss: 0.0022 lr: 0.02\n",
      "iteration: 134650 loss: 0.0021 lr: 0.02\n",
      "iteration: 134660 loss: 0.0019 lr: 0.02\n",
      "iteration: 134670 loss: 0.0029 lr: 0.02\n",
      "iteration: 134680 loss: 0.0020 lr: 0.02\n",
      "iteration: 134690 loss: 0.0025 lr: 0.02\n",
      "iteration: 134700 loss: 0.0022 lr: 0.02\n",
      "iteration: 134710 loss: 0.0029 lr: 0.02\n",
      "iteration: 134720 loss: 0.0022 lr: 0.02\n",
      "iteration: 134730 loss: 0.0022 lr: 0.02\n",
      "iteration: 134740 loss: 0.0020 lr: 0.02\n",
      "iteration: 134750 loss: 0.0030 lr: 0.02\n",
      "iteration: 134760 loss: 0.0030 lr: 0.02\n",
      "iteration: 134770 loss: 0.0027 lr: 0.02\n",
      "iteration: 134780 loss: 0.0023 lr: 0.02\n",
      "iteration: 134790 loss: 0.0020 lr: 0.02\n",
      "iteration: 134800 loss: 0.0022 lr: 0.02\n",
      "iteration: 134810 loss: 0.0022 lr: 0.02\n",
      "iteration: 134820 loss: 0.0025 lr: 0.02\n",
      "iteration: 134830 loss: 0.0020 lr: 0.02\n",
      "iteration: 134840 loss: 0.0027 lr: 0.02\n",
      "iteration: 134850 loss: 0.0019 lr: 0.02\n",
      "iteration: 134860 loss: 0.0022 lr: 0.02\n",
      "iteration: 134870 loss: 0.0026 lr: 0.02\n",
      "iteration: 134880 loss: 0.0025 lr: 0.02\n",
      "iteration: 134890 loss: 0.0024 lr: 0.02\n",
      "iteration: 134900 loss: 0.0019 lr: 0.02\n",
      "iteration: 134910 loss: 0.0017 lr: 0.02\n",
      "iteration: 134920 loss: 0.0023 lr: 0.02\n",
      "iteration: 134930 loss: 0.0020 lr: 0.02\n",
      "iteration: 134940 loss: 0.0033 lr: 0.02\n",
      "iteration: 134950 loss: 0.0027 lr: 0.02\n",
      "iteration: 134960 loss: 0.0028 lr: 0.02\n",
      "iteration: 134970 loss: 0.0021 lr: 0.02\n",
      "iteration: 134980 loss: 0.0020 lr: 0.02\n",
      "iteration: 134990 loss: 0.0020 lr: 0.02\n",
      "iteration: 135000 loss: 0.0018 lr: 0.02\n",
      "iteration: 135010 loss: 0.0031 lr: 0.02\n",
      "iteration: 135020 loss: 0.0022 lr: 0.02\n",
      "iteration: 135030 loss: 0.0023 lr: 0.02\n",
      "iteration: 135040 loss: 0.0021 lr: 0.02\n",
      "iteration: 135050 loss: 0.0021 lr: 0.02\n",
      "iteration: 135060 loss: 0.0019 lr: 0.02\n",
      "iteration: 135070 loss: 0.0027 lr: 0.02\n",
      "iteration: 135080 loss: 0.0025 lr: 0.02\n",
      "iteration: 135090 loss: 0.0024 lr: 0.02\n",
      "iteration: 135100 loss: 0.0018 lr: 0.02\n",
      "iteration: 135110 loss: 0.0026 lr: 0.02\n",
      "iteration: 135120 loss: 0.0031 lr: 0.02\n",
      "iteration: 135130 loss: 0.0025 lr: 0.02\n",
      "iteration: 135140 loss: 0.0025 lr: 0.02\n",
      "iteration: 135150 loss: 0.0021 lr: 0.02\n",
      "iteration: 135160 loss: 0.0030 lr: 0.02\n",
      "iteration: 135170 loss: 0.0024 lr: 0.02\n",
      "iteration: 135180 loss: 0.0021 lr: 0.02\n",
      "iteration: 135190 loss: 0.0024 lr: 0.02\n",
      "iteration: 135200 loss: 0.0021 lr: 0.02\n",
      "iteration: 135210 loss: 0.0026 lr: 0.02\n",
      "iteration: 135220 loss: 0.0030 lr: 0.02\n",
      "iteration: 135230 loss: 0.0025 lr: 0.02\n",
      "iteration: 135240 loss: 0.0027 lr: 0.02\n",
      "iteration: 135250 loss: 0.0030 lr: 0.02\n",
      "iteration: 135260 loss: 0.0025 lr: 0.02\n",
      "iteration: 135270 loss: 0.0022 lr: 0.02\n",
      "iteration: 135280 loss: 0.0024 lr: 0.02\n",
      "iteration: 135290 loss: 0.0025 lr: 0.02\n",
      "iteration: 135300 loss: 0.0024 lr: 0.02\n",
      "iteration: 135310 loss: 0.0024 lr: 0.02\n",
      "iteration: 135320 loss: 0.0033 lr: 0.02\n",
      "iteration: 135330 loss: 0.0021 lr: 0.02\n",
      "iteration: 135340 loss: 0.0020 lr: 0.02\n",
      "iteration: 135350 loss: 0.0027 lr: 0.02\n",
      "iteration: 135360 loss: 0.0024 lr: 0.02\n",
      "iteration: 135370 loss: 0.0023 lr: 0.02\n",
      "iteration: 135380 loss: 0.0031 lr: 0.02\n",
      "iteration: 135390 loss: 0.0038 lr: 0.02\n",
      "iteration: 135400 loss: 0.0023 lr: 0.02\n",
      "iteration: 135410 loss: 0.0024 lr: 0.02\n",
      "iteration: 135420 loss: 0.0025 lr: 0.02\n",
      "iteration: 135430 loss: 0.0022 lr: 0.02\n",
      "iteration: 135440 loss: 0.0023 lr: 0.02\n",
      "iteration: 135450 loss: 0.0023 lr: 0.02\n",
      "iteration: 135460 loss: 0.0020 lr: 0.02\n",
      "iteration: 135470 loss: 0.0022 lr: 0.02\n",
      "iteration: 135480 loss: 0.0032 lr: 0.02\n",
      "iteration: 135490 loss: 0.0027 lr: 0.02\n",
      "iteration: 135500 loss: 0.0030 lr: 0.02\n",
      "iteration: 135510 loss: 0.0019 lr: 0.02\n",
      "iteration: 135520 loss: 0.0025 lr: 0.02\n",
      "iteration: 135530 loss: 0.0023 lr: 0.02\n",
      "iteration: 135540 loss: 0.0029 lr: 0.02\n",
      "iteration: 135550 loss: 0.0025 lr: 0.02\n",
      "iteration: 135560 loss: 0.0029 lr: 0.02\n",
      "iteration: 135570 loss: 0.0028 lr: 0.02\n",
      "iteration: 135580 loss: 0.0022 lr: 0.02\n",
      "iteration: 135590 loss: 0.0027 lr: 0.02\n",
      "iteration: 135600 loss: 0.0030 lr: 0.02\n",
      "iteration: 135610 loss: 0.0031 lr: 0.02\n",
      "iteration: 135620 loss: 0.0022 lr: 0.02\n",
      "iteration: 135630 loss: 0.0028 lr: 0.02\n",
      "iteration: 135640 loss: 0.0030 lr: 0.02\n",
      "iteration: 135650 loss: 0.0026 lr: 0.02\n",
      "iteration: 135660 loss: 0.0023 lr: 0.02\n",
      "iteration: 135670 loss: 0.0029 lr: 0.02\n",
      "iteration: 135680 loss: 0.0024 lr: 0.02\n",
      "iteration: 135690 loss: 0.0027 lr: 0.02\n",
      "iteration: 135700 loss: 0.0018 lr: 0.02\n",
      "iteration: 135710 loss: 0.0025 lr: 0.02\n",
      "iteration: 135720 loss: 0.0028 lr: 0.02\n",
      "iteration: 135730 loss: 0.0029 lr: 0.02\n",
      "iteration: 135740 loss: 0.0025 lr: 0.02\n",
      "iteration: 135750 loss: 0.0026 lr: 0.02\n",
      "iteration: 135760 loss: 0.0026 lr: 0.02\n",
      "iteration: 135770 loss: 0.0022 lr: 0.02\n",
      "iteration: 135780 loss: 0.0023 lr: 0.02\n",
      "iteration: 135790 loss: 0.0025 lr: 0.02\n",
      "iteration: 135800 loss: 0.0023 lr: 0.02\n",
      "iteration: 135810 loss: 0.0024 lr: 0.02\n",
      "iteration: 135820 loss: 0.0020 lr: 0.02\n",
      "iteration: 135830 loss: 0.0022 lr: 0.02\n",
      "iteration: 135840 loss: 0.0021 lr: 0.02\n",
      "iteration: 135850 loss: 0.0025 lr: 0.02\n",
      "iteration: 135860 loss: 0.0021 lr: 0.02\n",
      "iteration: 135870 loss: 0.0024 lr: 0.02\n",
      "iteration: 135880 loss: 0.0031 lr: 0.02\n",
      "iteration: 135890 loss: 0.0022 lr: 0.02\n",
      "iteration: 135900 loss: 0.0029 lr: 0.02\n",
      "iteration: 135910 loss: 0.0031 lr: 0.02\n",
      "iteration: 135920 loss: 0.0020 lr: 0.02\n",
      "iteration: 135930 loss: 0.0024 lr: 0.02\n",
      "iteration: 135940 loss: 0.0026 lr: 0.02\n",
      "iteration: 135950 loss: 0.0022 lr: 0.02\n",
      "iteration: 135960 loss: 0.0031 lr: 0.02\n",
      "iteration: 135970 loss: 0.0024 lr: 0.02\n",
      "iteration: 135980 loss: 0.0026 lr: 0.02\n",
      "iteration: 135990 loss: 0.0027 lr: 0.02\n",
      "iteration: 136000 loss: 0.0021 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 136010 loss: 0.0032 lr: 0.02\n",
      "iteration: 136020 loss: 0.0021 lr: 0.02\n",
      "iteration: 136030 loss: 0.0024 lr: 0.02\n",
      "iteration: 136040 loss: 0.0028 lr: 0.02\n",
      "iteration: 136050 loss: 0.0023 lr: 0.02\n",
      "iteration: 136060 loss: 0.0026 lr: 0.02\n",
      "iteration: 136070 loss: 0.0024 lr: 0.02\n",
      "iteration: 136080 loss: 0.0025 lr: 0.02\n",
      "iteration: 136090 loss: 0.0035 lr: 0.02\n",
      "iteration: 136100 loss: 0.0030 lr: 0.02\n",
      "iteration: 136110 loss: 0.0027 lr: 0.02\n",
      "iteration: 136120 loss: 0.0020 lr: 0.02\n",
      "iteration: 136130 loss: 0.0024 lr: 0.02\n",
      "iteration: 136140 loss: 0.0024 lr: 0.02\n",
      "iteration: 136150 loss: 0.0019 lr: 0.02\n",
      "iteration: 136160 loss: 0.0018 lr: 0.02\n",
      "iteration: 136170 loss: 0.0024 lr: 0.02\n",
      "iteration: 136180 loss: 0.0023 lr: 0.02\n",
      "iteration: 136190 loss: 0.0015 lr: 0.02\n",
      "iteration: 136200 loss: 0.0022 lr: 0.02\n",
      "iteration: 136210 loss: 0.0023 lr: 0.02\n",
      "iteration: 136220 loss: 0.0022 lr: 0.02\n",
      "iteration: 136230 loss: 0.0019 lr: 0.02\n",
      "iteration: 136240 loss: 0.0024 lr: 0.02\n",
      "iteration: 136250 loss: 0.0020 lr: 0.02\n",
      "iteration: 136260 loss: 0.0017 lr: 0.02\n",
      "iteration: 136270 loss: 0.0017 lr: 0.02\n",
      "iteration: 136280 loss: 0.0028 lr: 0.02\n",
      "iteration: 136290 loss: 0.0028 lr: 0.02\n",
      "iteration: 136300 loss: 0.0023 lr: 0.02\n",
      "iteration: 136310 loss: 0.0024 lr: 0.02\n",
      "iteration: 136320 loss: 0.0024 lr: 0.02\n",
      "iteration: 136330 loss: 0.0024 lr: 0.02\n",
      "iteration: 136340 loss: 0.0021 lr: 0.02\n",
      "iteration: 136350 loss: 0.0023 lr: 0.02\n",
      "iteration: 136360 loss: 0.0021 lr: 0.02\n",
      "iteration: 136370 loss: 0.0019 lr: 0.02\n",
      "iteration: 136380 loss: 0.0029 lr: 0.02\n",
      "iteration: 136390 loss: 0.0031 lr: 0.02\n",
      "iteration: 136400 loss: 0.0027 lr: 0.02\n",
      "iteration: 136410 loss: 0.0030 lr: 0.02\n",
      "iteration: 136420 loss: 0.0028 lr: 0.02\n",
      "iteration: 136430 loss: 0.0023 lr: 0.02\n",
      "iteration: 136440 loss: 0.0023 lr: 0.02\n",
      "iteration: 136450 loss: 0.0023 lr: 0.02\n",
      "iteration: 136460 loss: 0.0024 lr: 0.02\n",
      "iteration: 136470 loss: 0.0030 lr: 0.02\n",
      "iteration: 136480 loss: 0.0024 lr: 0.02\n",
      "iteration: 136490 loss: 0.0021 lr: 0.02\n",
      "iteration: 136500 loss: 0.0019 lr: 0.02\n",
      "iteration: 136510 loss: 0.0022 lr: 0.02\n",
      "iteration: 136520 loss: 0.0022 lr: 0.02\n",
      "iteration: 136530 loss: 0.0025 lr: 0.02\n",
      "iteration: 136540 loss: 0.0022 lr: 0.02\n",
      "iteration: 136550 loss: 0.0024 lr: 0.02\n",
      "iteration: 136560 loss: 0.0025 lr: 0.02\n",
      "iteration: 136570 loss: 0.0021 lr: 0.02\n",
      "iteration: 136580 loss: 0.0019 lr: 0.02\n",
      "iteration: 136590 loss: 0.0024 lr: 0.02\n",
      "iteration: 136600 loss: 0.0026 lr: 0.02\n",
      "iteration: 136610 loss: 0.0021 lr: 0.02\n",
      "iteration: 136620 loss: 0.0026 lr: 0.02\n",
      "iteration: 136630 loss: 0.0021 lr: 0.02\n",
      "iteration: 136640 loss: 0.0022 lr: 0.02\n",
      "iteration: 136650 loss: 0.0023 lr: 0.02\n",
      "iteration: 136660 loss: 0.0023 lr: 0.02\n",
      "iteration: 136670 loss: 0.0024 lr: 0.02\n",
      "iteration: 136680 loss: 0.0027 lr: 0.02\n",
      "iteration: 136690 loss: 0.0020 lr: 0.02\n",
      "iteration: 136700 loss: 0.0030 lr: 0.02\n",
      "iteration: 136710 loss: 0.0029 lr: 0.02\n",
      "iteration: 136720 loss: 0.0023 lr: 0.02\n",
      "iteration: 136730 loss: 0.0019 lr: 0.02\n",
      "iteration: 136740 loss: 0.0026 lr: 0.02\n",
      "iteration: 136750 loss: 0.0026 lr: 0.02\n",
      "iteration: 136760 loss: 0.0034 lr: 0.02\n",
      "iteration: 136770 loss: 0.0031 lr: 0.02\n",
      "iteration: 136780 loss: 0.0023 lr: 0.02\n",
      "iteration: 136790 loss: 0.0026 lr: 0.02\n",
      "iteration: 136800 loss: 0.0019 lr: 0.02\n",
      "iteration: 136810 loss: 0.0018 lr: 0.02\n",
      "iteration: 136820 loss: 0.0024 lr: 0.02\n",
      "iteration: 136830 loss: 0.0017 lr: 0.02\n",
      "iteration: 136840 loss: 0.0039 lr: 0.02\n",
      "iteration: 136850 loss: 0.0026 lr: 0.02\n",
      "iteration: 136860 loss: 0.0025 lr: 0.02\n",
      "iteration: 136870 loss: 0.0024 lr: 0.02\n",
      "iteration: 136880 loss: 0.0027 lr: 0.02\n",
      "iteration: 136890 loss: 0.0015 lr: 0.02\n",
      "iteration: 136900 loss: 0.0029 lr: 0.02\n",
      "iteration: 136910 loss: 0.0031 lr: 0.02\n",
      "iteration: 136920 loss: 0.0018 lr: 0.02\n",
      "iteration: 136930 loss: 0.0034 lr: 0.02\n",
      "iteration: 136940 loss: 0.0022 lr: 0.02\n",
      "iteration: 136950 loss: 0.0038 lr: 0.02\n",
      "iteration: 136960 loss: 0.0026 lr: 0.02\n",
      "iteration: 136970 loss: 0.0016 lr: 0.02\n",
      "iteration: 136980 loss: 0.0020 lr: 0.02\n",
      "iteration: 136990 loss: 0.0029 lr: 0.02\n",
      "iteration: 137000 loss: 0.0021 lr: 0.02\n",
      "iteration: 137010 loss: 0.0022 lr: 0.02\n",
      "iteration: 137020 loss: 0.0026 lr: 0.02\n",
      "iteration: 137030 loss: 0.0018 lr: 0.02\n",
      "iteration: 137040 loss: 0.0027 lr: 0.02\n",
      "iteration: 137050 loss: 0.0022 lr: 0.02\n",
      "iteration: 137060 loss: 0.0019 lr: 0.02\n",
      "iteration: 137070 loss: 0.0018 lr: 0.02\n",
      "iteration: 137080 loss: 0.0024 lr: 0.02\n",
      "iteration: 137090 loss: 0.0030 lr: 0.02\n",
      "iteration: 137100 loss: 0.0034 lr: 0.02\n",
      "iteration: 137110 loss: 0.0025 lr: 0.02\n",
      "iteration: 137120 loss: 0.0021 lr: 0.02\n",
      "iteration: 137130 loss: 0.0027 lr: 0.02\n",
      "iteration: 137140 loss: 0.0036 lr: 0.02\n",
      "iteration: 137150 loss: 0.0021 lr: 0.02\n",
      "iteration: 137160 loss: 0.0024 lr: 0.02\n",
      "iteration: 137170 loss: 0.0024 lr: 0.02\n",
      "iteration: 137180 loss: 0.0033 lr: 0.02\n",
      "iteration: 137190 loss: 0.0021 lr: 0.02\n",
      "iteration: 137200 loss: 0.0022 lr: 0.02\n",
      "iteration: 137210 loss: 0.0018 lr: 0.02\n",
      "iteration: 137220 loss: 0.0023 lr: 0.02\n",
      "iteration: 137230 loss: 0.0023 lr: 0.02\n",
      "iteration: 137240 loss: 0.0029 lr: 0.02\n",
      "iteration: 137250 loss: 0.0020 lr: 0.02\n",
      "iteration: 137260 loss: 0.0034 lr: 0.02\n",
      "iteration: 137270 loss: 0.0023 lr: 0.02\n",
      "iteration: 137280 loss: 0.0022 lr: 0.02\n",
      "iteration: 137290 loss: 0.0026 lr: 0.02\n",
      "iteration: 137300 loss: 0.0032 lr: 0.02\n",
      "iteration: 137310 loss: 0.0029 lr: 0.02\n",
      "iteration: 137320 loss: 0.0027 lr: 0.02\n",
      "iteration: 137330 loss: 0.0025 lr: 0.02\n",
      "iteration: 137340 loss: 0.0022 lr: 0.02\n",
      "iteration: 137350 loss: 0.0030 lr: 0.02\n",
      "iteration: 137360 loss: 0.0026 lr: 0.02\n",
      "iteration: 137370 loss: 0.0023 lr: 0.02\n",
      "iteration: 137380 loss: 0.0019 lr: 0.02\n",
      "iteration: 137390 loss: 0.0027 lr: 0.02\n",
      "iteration: 137400 loss: 0.0025 lr: 0.02\n",
      "iteration: 137410 loss: 0.0026 lr: 0.02\n",
      "iteration: 137420 loss: 0.0021 lr: 0.02\n",
      "iteration: 137430 loss: 0.0021 lr: 0.02\n",
      "iteration: 137440 loss: 0.0034 lr: 0.02\n",
      "iteration: 137450 loss: 0.0025 lr: 0.02\n",
      "iteration: 137460 loss: 0.0024 lr: 0.02\n",
      "iteration: 137470 loss: 0.0022 lr: 0.02\n",
      "iteration: 137480 loss: 0.0021 lr: 0.02\n",
      "iteration: 137490 loss: 0.0022 lr: 0.02\n",
      "iteration: 137500 loss: 0.0023 lr: 0.02\n",
      "iteration: 137510 loss: 0.0025 lr: 0.02\n",
      "iteration: 137520 loss: 0.0027 lr: 0.02\n",
      "iteration: 137530 loss: 0.0024 lr: 0.02\n",
      "iteration: 137540 loss: 0.0025 lr: 0.02\n",
      "iteration: 137550 loss: 0.0024 lr: 0.02\n",
      "iteration: 137560 loss: 0.0038 lr: 0.02\n",
      "iteration: 137570 loss: 0.0022 lr: 0.02\n",
      "iteration: 137580 loss: 0.0021 lr: 0.02\n",
      "iteration: 137590 loss: 0.0026 lr: 0.02\n",
      "iteration: 137600 loss: 0.0034 lr: 0.02\n",
      "iteration: 137610 loss: 0.0020 lr: 0.02\n",
      "iteration: 137620 loss: 0.0030 lr: 0.02\n",
      "iteration: 137630 loss: 0.0023 lr: 0.02\n",
      "iteration: 137640 loss: 0.0024 lr: 0.02\n",
      "iteration: 137650 loss: 0.0028 lr: 0.02\n",
      "iteration: 137660 loss: 0.0022 lr: 0.02\n",
      "iteration: 137670 loss: 0.0024 lr: 0.02\n",
      "iteration: 137680 loss: 0.0021 lr: 0.02\n",
      "iteration: 137690 loss: 0.0028 lr: 0.02\n",
      "iteration: 137700 loss: 0.0020 lr: 0.02\n",
      "iteration: 137710 loss: 0.0020 lr: 0.02\n",
      "iteration: 137720 loss: 0.0023 lr: 0.02\n",
      "iteration: 137730 loss: 0.0023 lr: 0.02\n",
      "iteration: 137740 loss: 0.0022 lr: 0.02\n",
      "iteration: 137750 loss: 0.0019 lr: 0.02\n",
      "iteration: 137760 loss: 0.0026 lr: 0.02\n",
      "iteration: 137770 loss: 0.0020 lr: 0.02\n",
      "iteration: 137780 loss: 0.0021 lr: 0.02\n",
      "iteration: 137790 loss: 0.0024 lr: 0.02\n",
      "iteration: 137800 loss: 0.0030 lr: 0.02\n",
      "iteration: 137810 loss: 0.0023 lr: 0.02\n",
      "iteration: 137820 loss: 0.0025 lr: 0.02\n",
      "iteration: 137830 loss: 0.0024 lr: 0.02\n",
      "iteration: 137840 loss: 0.0018 lr: 0.02\n",
      "iteration: 137850 loss: 0.0021 lr: 0.02\n",
      "iteration: 137860 loss: 0.0021 lr: 0.02\n",
      "iteration: 137870 loss: 0.0024 lr: 0.02\n",
      "iteration: 137880 loss: 0.0024 lr: 0.02\n",
      "iteration: 137890 loss: 0.0022 lr: 0.02\n",
      "iteration: 137900 loss: 0.0025 lr: 0.02\n",
      "iteration: 137910 loss: 0.0020 lr: 0.02\n",
      "iteration: 137920 loss: 0.0023 lr: 0.02\n",
      "iteration: 137930 loss: 0.0024 lr: 0.02\n",
      "iteration: 137940 loss: 0.0025 lr: 0.02\n",
      "iteration: 137950 loss: 0.0029 lr: 0.02\n",
      "iteration: 137960 loss: 0.0020 lr: 0.02\n",
      "iteration: 137970 loss: 0.0024 lr: 0.02\n",
      "iteration: 137980 loss: 0.0018 lr: 0.02\n",
      "iteration: 137990 loss: 0.0030 lr: 0.02\n",
      "iteration: 138000 loss: 0.0035 lr: 0.02\n",
      "iteration: 138010 loss: 0.0023 lr: 0.02\n",
      "iteration: 138020 loss: 0.0025 lr: 0.02\n",
      "iteration: 138030 loss: 0.0027 lr: 0.02\n",
      "iteration: 138040 loss: 0.0022 lr: 0.02\n",
      "iteration: 138050 loss: 0.0031 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 138060 loss: 0.0022 lr: 0.02\n",
      "iteration: 138070 loss: 0.0026 lr: 0.02\n",
      "iteration: 138080 loss: 0.0024 lr: 0.02\n",
      "iteration: 138090 loss: 0.0020 lr: 0.02\n",
      "iteration: 138100 loss: 0.0022 lr: 0.02\n",
      "iteration: 138110 loss: 0.0023 lr: 0.02\n",
      "iteration: 138120 loss: 0.0022 lr: 0.02\n",
      "iteration: 138130 loss: 0.0033 lr: 0.02\n",
      "iteration: 138140 loss: 0.0027 lr: 0.02\n",
      "iteration: 138150 loss: 0.0024 lr: 0.02\n",
      "iteration: 138160 loss: 0.0026 lr: 0.02\n",
      "iteration: 138170 loss: 0.0020 lr: 0.02\n",
      "iteration: 138180 loss: 0.0021 lr: 0.02\n",
      "iteration: 138190 loss: 0.0026 lr: 0.02\n",
      "iteration: 138200 loss: 0.0026 lr: 0.02\n",
      "iteration: 138210 loss: 0.0022 lr: 0.02\n",
      "iteration: 138220 loss: 0.0022 lr: 0.02\n",
      "iteration: 138230 loss: 0.0022 lr: 0.02\n",
      "iteration: 138240 loss: 0.0027 lr: 0.02\n",
      "iteration: 138250 loss: 0.0020 lr: 0.02\n",
      "iteration: 138260 loss: 0.0018 lr: 0.02\n",
      "iteration: 138270 loss: 0.0022 lr: 0.02\n",
      "iteration: 138280 loss: 0.0027 lr: 0.02\n",
      "iteration: 138290 loss: 0.0024 lr: 0.02\n",
      "iteration: 138300 loss: 0.0021 lr: 0.02\n",
      "iteration: 138310 loss: 0.0023 lr: 0.02\n",
      "iteration: 138320 loss: 0.0021 lr: 0.02\n",
      "iteration: 138330 loss: 0.0035 lr: 0.02\n",
      "iteration: 138340 loss: 0.0022 lr: 0.02\n",
      "iteration: 138350 loss: 0.0027 lr: 0.02\n",
      "iteration: 138360 loss: 0.0028 lr: 0.02\n",
      "iteration: 138370 loss: 0.0029 lr: 0.02\n",
      "iteration: 138380 loss: 0.0024 lr: 0.02\n",
      "iteration: 138390 loss: 0.0024 lr: 0.02\n",
      "iteration: 138400 loss: 0.0025 lr: 0.02\n",
      "iteration: 138410 loss: 0.0020 lr: 0.02\n",
      "iteration: 138420 loss: 0.0027 lr: 0.02\n",
      "iteration: 138430 loss: 0.0032 lr: 0.02\n",
      "iteration: 138440 loss: 0.0027 lr: 0.02\n",
      "iteration: 138450 loss: 0.0031 lr: 0.02\n",
      "iteration: 138460 loss: 0.0018 lr: 0.02\n",
      "iteration: 138470 loss: 0.0021 lr: 0.02\n",
      "iteration: 138480 loss: 0.0023 lr: 0.02\n",
      "iteration: 138490 loss: 0.0026 lr: 0.02\n",
      "iteration: 138500 loss: 0.0021 lr: 0.02\n",
      "iteration: 138510 loss: 0.0035 lr: 0.02\n",
      "iteration: 138520 loss: 0.0027 lr: 0.02\n",
      "iteration: 138530 loss: 0.0021 lr: 0.02\n",
      "iteration: 138540 loss: 0.0024 lr: 0.02\n",
      "iteration: 138550 loss: 0.0021 lr: 0.02\n",
      "iteration: 138560 loss: 0.0025 lr: 0.02\n",
      "iteration: 138570 loss: 0.0027 lr: 0.02\n",
      "iteration: 138580 loss: 0.0023 lr: 0.02\n",
      "iteration: 138590 loss: 0.0019 lr: 0.02\n",
      "iteration: 138600 loss: 0.0018 lr: 0.02\n",
      "iteration: 138610 loss: 0.0020 lr: 0.02\n",
      "iteration: 138620 loss: 0.0022 lr: 0.02\n",
      "iteration: 138630 loss: 0.0025 lr: 0.02\n",
      "iteration: 138640 loss: 0.0032 lr: 0.02\n",
      "iteration: 138650 loss: 0.0025 lr: 0.02\n",
      "iteration: 138660 loss: 0.0022 lr: 0.02\n",
      "iteration: 138670 loss: 0.0030 lr: 0.02\n",
      "iteration: 138680 loss: 0.0019 lr: 0.02\n",
      "iteration: 138690 loss: 0.0018 lr: 0.02\n",
      "iteration: 138700 loss: 0.0026 lr: 0.02\n",
      "iteration: 138710 loss: 0.0026 lr: 0.02\n",
      "iteration: 138720 loss: 0.0024 lr: 0.02\n",
      "iteration: 138730 loss: 0.0025 lr: 0.02\n",
      "iteration: 138740 loss: 0.0020 lr: 0.02\n",
      "iteration: 138750 loss: 0.0029 lr: 0.02\n",
      "iteration: 138760 loss: 0.0032 lr: 0.02\n",
      "iteration: 138770 loss: 0.0022 lr: 0.02\n",
      "iteration: 138780 loss: 0.0021 lr: 0.02\n",
      "iteration: 138790 loss: 0.0031 lr: 0.02\n",
      "iteration: 138800 loss: 0.0017 lr: 0.02\n",
      "iteration: 138810 loss: 0.0023 lr: 0.02\n",
      "iteration: 138820 loss: 0.0022 lr: 0.02\n",
      "iteration: 138830 loss: 0.0015 lr: 0.02\n",
      "iteration: 138840 loss: 0.0026 lr: 0.02\n",
      "iteration: 138850 loss: 0.0021 lr: 0.02\n",
      "iteration: 138860 loss: 0.0019 lr: 0.02\n",
      "iteration: 138870 loss: 0.0026 lr: 0.02\n",
      "iteration: 138880 loss: 0.0024 lr: 0.02\n",
      "iteration: 138890 loss: 0.0022 lr: 0.02\n",
      "iteration: 138900 loss: 0.0022 lr: 0.02\n",
      "iteration: 138910 loss: 0.0029 lr: 0.02\n",
      "iteration: 138920 loss: 0.0028 lr: 0.02\n",
      "iteration: 138930 loss: 0.0026 lr: 0.02\n",
      "iteration: 138940 loss: 0.0021 lr: 0.02\n",
      "iteration: 138950 loss: 0.0032 lr: 0.02\n",
      "iteration: 138960 loss: 0.0020 lr: 0.02\n",
      "iteration: 138970 loss: 0.0023 lr: 0.02\n",
      "iteration: 138980 loss: 0.0019 lr: 0.02\n",
      "iteration: 138990 loss: 0.0021 lr: 0.02\n",
      "iteration: 139000 loss: 0.0025 lr: 0.02\n",
      "iteration: 139010 loss: 0.0022 lr: 0.02\n",
      "iteration: 139020 loss: 0.0031 lr: 0.02\n",
      "iteration: 139030 loss: 0.0021 lr: 0.02\n",
      "iteration: 139040 loss: 0.0022 lr: 0.02\n",
      "iteration: 139050 loss: 0.0020 lr: 0.02\n",
      "iteration: 139060 loss: 0.0028 lr: 0.02\n",
      "iteration: 139070 loss: 0.0025 lr: 0.02\n",
      "iteration: 139080 loss: 0.0023 lr: 0.02\n",
      "iteration: 139090 loss: 0.0031 lr: 0.02\n",
      "iteration: 139100 loss: 0.0026 lr: 0.02\n",
      "iteration: 139110 loss: 0.0024 lr: 0.02\n",
      "iteration: 139120 loss: 0.0023 lr: 0.02\n",
      "iteration: 139130 loss: 0.0021 lr: 0.02\n",
      "iteration: 139140 loss: 0.0016 lr: 0.02\n",
      "iteration: 139150 loss: 0.0029 lr: 0.02\n",
      "iteration: 139160 loss: 0.0023 lr: 0.02\n",
      "iteration: 139170 loss: 0.0026 lr: 0.02\n",
      "iteration: 139180 loss: 0.0027 lr: 0.02\n",
      "iteration: 139190 loss: 0.0021 lr: 0.02\n",
      "iteration: 139200 loss: 0.0022 lr: 0.02\n",
      "iteration: 139210 loss: 0.0021 lr: 0.02\n",
      "iteration: 139220 loss: 0.0030 lr: 0.02\n",
      "iteration: 139230 loss: 0.0026 lr: 0.02\n",
      "iteration: 139240 loss: 0.0029 lr: 0.02\n",
      "iteration: 139250 loss: 0.0025 lr: 0.02\n",
      "iteration: 139260 loss: 0.0017 lr: 0.02\n",
      "iteration: 139270 loss: 0.0022 lr: 0.02\n",
      "iteration: 139280 loss: 0.0022 lr: 0.02\n",
      "iteration: 139290 loss: 0.0022 lr: 0.02\n",
      "iteration: 139300 loss: 0.0023 lr: 0.02\n",
      "iteration: 139310 loss: 0.0027 lr: 0.02\n",
      "iteration: 139320 loss: 0.0024 lr: 0.02\n",
      "iteration: 139330 loss: 0.0021 lr: 0.02\n",
      "iteration: 139340 loss: 0.0023 lr: 0.02\n",
      "iteration: 139350 loss: 0.0031 lr: 0.02\n",
      "iteration: 139360 loss: 0.0024 lr: 0.02\n",
      "iteration: 139370 loss: 0.0024 lr: 0.02\n",
      "iteration: 139380 loss: 0.0024 lr: 0.02\n",
      "iteration: 139390 loss: 0.0027 lr: 0.02\n",
      "iteration: 139400 loss: 0.0021 lr: 0.02\n",
      "iteration: 139410 loss: 0.0023 lr: 0.02\n",
      "iteration: 139420 loss: 0.0019 lr: 0.02\n",
      "iteration: 139430 loss: 0.0028 lr: 0.02\n",
      "iteration: 139440 loss: 0.0024 lr: 0.02\n",
      "iteration: 139450 loss: 0.0025 lr: 0.02\n",
      "iteration: 139460 loss: 0.0022 lr: 0.02\n",
      "iteration: 139470 loss: 0.0023 lr: 0.02\n",
      "iteration: 139480 loss: 0.0021 lr: 0.02\n",
      "iteration: 139490 loss: 0.0022 lr: 0.02\n",
      "iteration: 139500 loss: 0.0025 lr: 0.02\n",
      "iteration: 139510 loss: 0.0027 lr: 0.02\n",
      "iteration: 139520 loss: 0.0021 lr: 0.02\n",
      "iteration: 139530 loss: 0.0022 lr: 0.02\n",
      "iteration: 139540 loss: 0.0029 lr: 0.02\n",
      "iteration: 139550 loss: 0.0036 lr: 0.02\n",
      "iteration: 139560 loss: 0.0023 lr: 0.02\n",
      "iteration: 139570 loss: 0.0024 lr: 0.02\n",
      "iteration: 139580 loss: 0.0029 lr: 0.02\n",
      "iteration: 139590 loss: 0.0023 lr: 0.02\n",
      "iteration: 139600 loss: 0.0031 lr: 0.02\n",
      "iteration: 139610 loss: 0.0027 lr: 0.02\n",
      "iteration: 139620 loss: 0.0022 lr: 0.02\n",
      "iteration: 139630 loss: 0.0022 lr: 0.02\n",
      "iteration: 139640 loss: 0.0022 lr: 0.02\n",
      "iteration: 139650 loss: 0.0023 lr: 0.02\n",
      "iteration: 139660 loss: 0.0023 lr: 0.02\n",
      "iteration: 139670 loss: 0.0021 lr: 0.02\n",
      "iteration: 139680 loss: 0.0022 lr: 0.02\n",
      "iteration: 139690 loss: 0.0027 lr: 0.02\n",
      "iteration: 139700 loss: 0.0023 lr: 0.02\n",
      "iteration: 139710 loss: 0.0035 lr: 0.02\n",
      "iteration: 139720 loss: 0.0026 lr: 0.02\n",
      "iteration: 139730 loss: 0.0024 lr: 0.02\n",
      "iteration: 139740 loss: 0.0022 lr: 0.02\n",
      "iteration: 139750 loss: 0.0031 lr: 0.02\n",
      "iteration: 139760 loss: 0.0028 lr: 0.02\n",
      "iteration: 139770 loss: 0.0023 lr: 0.02\n",
      "iteration: 139780 loss: 0.0019 lr: 0.02\n",
      "iteration: 139790 loss: 0.0023 lr: 0.02\n",
      "iteration: 139800 loss: 0.0020 lr: 0.02\n",
      "iteration: 139810 loss: 0.0014 lr: 0.02\n",
      "iteration: 139820 loss: 0.0023 lr: 0.02\n",
      "iteration: 139830 loss: 0.0024 lr: 0.02\n",
      "iteration: 139840 loss: 0.0020 lr: 0.02\n",
      "iteration: 139850 loss: 0.0025 lr: 0.02\n",
      "iteration: 139860 loss: 0.0017 lr: 0.02\n",
      "iteration: 139870 loss: 0.0025 lr: 0.02\n",
      "iteration: 139880 loss: 0.0031 lr: 0.02\n",
      "iteration: 139890 loss: 0.0027 lr: 0.02\n",
      "iteration: 139900 loss: 0.0021 lr: 0.02\n",
      "iteration: 139910 loss: 0.0025 lr: 0.02\n",
      "iteration: 139920 loss: 0.0017 lr: 0.02\n",
      "iteration: 139930 loss: 0.0015 lr: 0.02\n",
      "iteration: 139940 loss: 0.0024 lr: 0.02\n",
      "iteration: 139950 loss: 0.0022 lr: 0.02\n",
      "iteration: 139960 loss: 0.0024 lr: 0.02\n",
      "iteration: 139970 loss: 0.0020 lr: 0.02\n",
      "iteration: 139980 loss: 0.0029 lr: 0.02\n",
      "iteration: 139990 loss: 0.0028 lr: 0.02\n",
      "iteration: 140000 loss: 0.0026 lr: 0.02\n",
      "iteration: 140010 loss: 0.0027 lr: 0.02\n",
      "iteration: 140020 loss: 0.0026 lr: 0.02\n",
      "iteration: 140030 loss: 0.0023 lr: 0.02\n",
      "iteration: 140040 loss: 0.0025 lr: 0.02\n",
      "iteration: 140050 loss: 0.0024 lr: 0.02\n",
      "iteration: 140060 loss: 0.0018 lr: 0.02\n",
      "iteration: 140070 loss: 0.0022 lr: 0.02\n",
      "iteration: 140080 loss: 0.0021 lr: 0.02\n",
      "iteration: 140090 loss: 0.0021 lr: 0.02\n",
      "iteration: 140100 loss: 0.0030 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 140110 loss: 0.0036 lr: 0.02\n",
      "iteration: 140120 loss: 0.0025 lr: 0.02\n",
      "iteration: 140130 loss: 0.0032 lr: 0.02\n",
      "iteration: 140140 loss: 0.0025 lr: 0.02\n",
      "iteration: 140150 loss: 0.0017 lr: 0.02\n",
      "iteration: 140160 loss: 0.0027 lr: 0.02\n",
      "iteration: 140170 loss: 0.0016 lr: 0.02\n",
      "iteration: 140180 loss: 0.0021 lr: 0.02\n",
      "iteration: 140190 loss: 0.0018 lr: 0.02\n",
      "iteration: 140200 loss: 0.0022 lr: 0.02\n",
      "iteration: 140210 loss: 0.0026 lr: 0.02\n",
      "iteration: 140220 loss: 0.0020 lr: 0.02\n",
      "iteration: 140230 loss: 0.0024 lr: 0.02\n",
      "iteration: 140240 loss: 0.0025 lr: 0.02\n",
      "iteration: 140250 loss: 0.0023 lr: 0.02\n",
      "iteration: 140260 loss: 0.0030 lr: 0.02\n",
      "iteration: 140270 loss: 0.0027 lr: 0.02\n",
      "iteration: 140280 loss: 0.0022 lr: 0.02\n",
      "iteration: 140290 loss: 0.0025 lr: 0.02\n",
      "iteration: 140300 loss: 0.0022 lr: 0.02\n",
      "iteration: 140310 loss: 0.0020 lr: 0.02\n",
      "iteration: 140320 loss: 0.0021 lr: 0.02\n",
      "iteration: 140330 loss: 0.0023 lr: 0.02\n",
      "iteration: 140340 loss: 0.0022 lr: 0.02\n",
      "iteration: 140350 loss: 0.0026 lr: 0.02\n",
      "iteration: 140360 loss: 0.0023 lr: 0.02\n",
      "iteration: 140370 loss: 0.0021 lr: 0.02\n",
      "iteration: 140380 loss: 0.0024 lr: 0.02\n",
      "iteration: 140390 loss: 0.0028 lr: 0.02\n",
      "iteration: 140400 loss: 0.0024 lr: 0.02\n",
      "iteration: 140410 loss: 0.0027 lr: 0.02\n",
      "iteration: 140420 loss: 0.0023 lr: 0.02\n",
      "iteration: 140430 loss: 0.0027 lr: 0.02\n",
      "iteration: 140440 loss: 0.0025 lr: 0.02\n",
      "iteration: 140450 loss: 0.0020 lr: 0.02\n",
      "iteration: 140460 loss: 0.0027 lr: 0.02\n",
      "iteration: 140470 loss: 0.0029 lr: 0.02\n",
      "iteration: 140480 loss: 0.0027 lr: 0.02\n",
      "iteration: 140490 loss: 0.0024 lr: 0.02\n",
      "iteration: 140500 loss: 0.0019 lr: 0.02\n",
      "iteration: 140510 loss: 0.0023 lr: 0.02\n",
      "iteration: 140520 loss: 0.0021 lr: 0.02\n",
      "iteration: 140530 loss: 0.0015 lr: 0.02\n",
      "iteration: 140540 loss: 0.0020 lr: 0.02\n",
      "iteration: 140550 loss: 0.0025 lr: 0.02\n",
      "iteration: 140560 loss: 0.0026 lr: 0.02\n",
      "iteration: 140570 loss: 0.0023 lr: 0.02\n",
      "iteration: 140580 loss: 0.0022 lr: 0.02\n",
      "iteration: 140590 loss: 0.0023 lr: 0.02\n",
      "iteration: 140600 loss: 0.0024 lr: 0.02\n",
      "iteration: 140610 loss: 0.0026 lr: 0.02\n",
      "iteration: 140620 loss: 0.0023 lr: 0.02\n",
      "iteration: 140630 loss: 0.0024 lr: 0.02\n",
      "iteration: 140640 loss: 0.0024 lr: 0.02\n",
      "iteration: 140650 loss: 0.0023 lr: 0.02\n",
      "iteration: 140660 loss: 0.0023 lr: 0.02\n",
      "iteration: 140670 loss: 0.0026 lr: 0.02\n",
      "iteration: 140680 loss: 0.0022 lr: 0.02\n",
      "iteration: 140690 loss: 0.0029 lr: 0.02\n",
      "iteration: 140700 loss: 0.0023 lr: 0.02\n",
      "iteration: 140710 loss: 0.0028 lr: 0.02\n",
      "iteration: 140720 loss: 0.0023 lr: 0.02\n",
      "iteration: 140730 loss: 0.0023 lr: 0.02\n",
      "iteration: 140740 loss: 0.0020 lr: 0.02\n",
      "iteration: 140750 loss: 0.0022 lr: 0.02\n",
      "iteration: 140760 loss: 0.0035 lr: 0.02\n",
      "iteration: 140770 loss: 0.0021 lr: 0.02\n",
      "iteration: 140780 loss: 0.0021 lr: 0.02\n",
      "iteration: 140790 loss: 0.0026 lr: 0.02\n",
      "iteration: 140800 loss: 0.0027 lr: 0.02\n",
      "iteration: 140810 loss: 0.0030 lr: 0.02\n",
      "iteration: 140820 loss: 0.0024 lr: 0.02\n",
      "iteration: 140830 loss: 0.0024 lr: 0.02\n",
      "iteration: 140840 loss: 0.0026 lr: 0.02\n",
      "iteration: 140850 loss: 0.0019 lr: 0.02\n",
      "iteration: 140860 loss: 0.0026 lr: 0.02\n",
      "iteration: 140870 loss: 0.0025 lr: 0.02\n",
      "iteration: 140880 loss: 0.0025 lr: 0.02\n",
      "iteration: 140890 loss: 0.0025 lr: 0.02\n",
      "iteration: 140900 loss: 0.0025 lr: 0.02\n",
      "iteration: 140910 loss: 0.0022 lr: 0.02\n",
      "iteration: 140920 loss: 0.0021 lr: 0.02\n",
      "iteration: 140930 loss: 0.0029 lr: 0.02\n",
      "iteration: 140940 loss: 0.0024 lr: 0.02\n",
      "iteration: 140950 loss: 0.0020 lr: 0.02\n",
      "iteration: 140960 loss: 0.0022 lr: 0.02\n",
      "iteration: 140970 loss: 0.0021 lr: 0.02\n",
      "iteration: 140980 loss: 0.0022 lr: 0.02\n",
      "iteration: 140990 loss: 0.0021 lr: 0.02\n",
      "iteration: 141000 loss: 0.0021 lr: 0.02\n",
      "iteration: 141010 loss: 0.0024 lr: 0.02\n",
      "iteration: 141020 loss: 0.0021 lr: 0.02\n",
      "iteration: 141030 loss: 0.0026 lr: 0.02\n",
      "iteration: 141040 loss: 0.0025 lr: 0.02\n",
      "iteration: 141050 loss: 0.0027 lr: 0.02\n",
      "iteration: 141060 loss: 0.0016 lr: 0.02\n",
      "iteration: 141070 loss: 0.0024 lr: 0.02\n",
      "iteration: 141080 loss: 0.0020 lr: 0.02\n",
      "iteration: 141090 loss: 0.0020 lr: 0.02\n",
      "iteration: 141100 loss: 0.0019 lr: 0.02\n",
      "iteration: 141110 loss: 0.0027 lr: 0.02\n",
      "iteration: 141120 loss: 0.0024 lr: 0.02\n",
      "iteration: 141130 loss: 0.0018 lr: 0.02\n",
      "iteration: 141140 loss: 0.0024 lr: 0.02\n",
      "iteration: 141150 loss: 0.0021 lr: 0.02\n",
      "iteration: 141160 loss: 0.0020 lr: 0.02\n",
      "iteration: 141170 loss: 0.0021 lr: 0.02\n",
      "iteration: 141180 loss: 0.0028 lr: 0.02\n",
      "iteration: 141190 loss: 0.0019 lr: 0.02\n",
      "iteration: 141200 loss: 0.0022 lr: 0.02\n",
      "iteration: 141210 loss: 0.0025 lr: 0.02\n",
      "iteration: 141220 loss: 0.0019 lr: 0.02\n",
      "iteration: 141230 loss: 0.0032 lr: 0.02\n",
      "iteration: 141240 loss: 0.0030 lr: 0.02\n",
      "iteration: 141250 loss: 0.0026 lr: 0.02\n",
      "iteration: 141260 loss: 0.0028 lr: 0.02\n",
      "iteration: 141270 loss: 0.0027 lr: 0.02\n",
      "iteration: 141280 loss: 0.0028 lr: 0.02\n",
      "iteration: 141290 loss: 0.0029 lr: 0.02\n",
      "iteration: 141300 loss: 0.0027 lr: 0.02\n",
      "iteration: 141310 loss: 0.0026 lr: 0.02\n",
      "iteration: 141320 loss: 0.0024 lr: 0.02\n",
      "iteration: 141330 loss: 0.0021 lr: 0.02\n",
      "iteration: 141340 loss: 0.0025 lr: 0.02\n",
      "iteration: 141350 loss: 0.0025 lr: 0.02\n",
      "iteration: 141360 loss: 0.0032 lr: 0.02\n",
      "iteration: 141370 loss: 0.0023 lr: 0.02\n",
      "iteration: 141380 loss: 0.0019 lr: 0.02\n",
      "iteration: 141390 loss: 0.0027 lr: 0.02\n",
      "iteration: 141400 loss: 0.0021 lr: 0.02\n",
      "iteration: 141410 loss: 0.0020 lr: 0.02\n",
      "iteration: 141420 loss: 0.0027 lr: 0.02\n",
      "iteration: 141430 loss: 0.0024 lr: 0.02\n",
      "iteration: 141440 loss: 0.0021 lr: 0.02\n",
      "iteration: 141450 loss: 0.0025 lr: 0.02\n",
      "iteration: 141460 loss: 0.0022 lr: 0.02\n",
      "iteration: 141470 loss: 0.0031 lr: 0.02\n",
      "iteration: 141480 loss: 0.0025 lr: 0.02\n",
      "iteration: 141490 loss: 0.0024 lr: 0.02\n",
      "iteration: 141500 loss: 0.0025 lr: 0.02\n",
      "iteration: 141510 loss: 0.0021 lr: 0.02\n",
      "iteration: 141520 loss: 0.0022 lr: 0.02\n",
      "iteration: 141530 loss: 0.0019 lr: 0.02\n",
      "iteration: 141540 loss: 0.0023 lr: 0.02\n",
      "iteration: 141550 loss: 0.0022 lr: 0.02\n",
      "iteration: 141560 loss: 0.0020 lr: 0.02\n",
      "iteration: 141570 loss: 0.0030 lr: 0.02\n",
      "iteration: 141580 loss: 0.0027 lr: 0.02\n",
      "iteration: 141590 loss: 0.0022 lr: 0.02\n",
      "iteration: 141600 loss: 0.0018 lr: 0.02\n",
      "iteration: 141610 loss: 0.0024 lr: 0.02\n",
      "iteration: 141620 loss: 0.0033 lr: 0.02\n",
      "iteration: 141630 loss: 0.0027 lr: 0.02\n",
      "iteration: 141640 loss: 0.0024 lr: 0.02\n",
      "iteration: 141650 loss: 0.0021 lr: 0.02\n",
      "iteration: 141660 loss: 0.0018 lr: 0.02\n",
      "iteration: 141670 loss: 0.0026 lr: 0.02\n",
      "iteration: 141680 loss: 0.0026 lr: 0.02\n",
      "iteration: 141690 loss: 0.0027 lr: 0.02\n",
      "iteration: 141700 loss: 0.0019 lr: 0.02\n",
      "iteration: 141710 loss: 0.0018 lr: 0.02\n",
      "iteration: 141720 loss: 0.0017 lr: 0.02\n",
      "iteration: 141730 loss: 0.0014 lr: 0.02\n",
      "iteration: 141740 loss: 0.0019 lr: 0.02\n",
      "iteration: 141750 loss: 0.0019 lr: 0.02\n",
      "iteration: 141760 loss: 0.0024 lr: 0.02\n",
      "iteration: 141770 loss: 0.0030 lr: 0.02\n",
      "iteration: 141780 loss: 0.0029 lr: 0.02\n",
      "iteration: 141790 loss: 0.0019 lr: 0.02\n",
      "iteration: 141800 loss: 0.0022 lr: 0.02\n",
      "iteration: 141810 loss: 0.0025 lr: 0.02\n",
      "iteration: 141820 loss: 0.0017 lr: 0.02\n",
      "iteration: 141830 loss: 0.0035 lr: 0.02\n",
      "iteration: 141840 loss: 0.0021 lr: 0.02\n",
      "iteration: 141850 loss: 0.0021 lr: 0.02\n",
      "iteration: 141860 loss: 0.0023 lr: 0.02\n",
      "iteration: 141870 loss: 0.0024 lr: 0.02\n",
      "iteration: 141880 loss: 0.0022 lr: 0.02\n",
      "iteration: 141890 loss: 0.0026 lr: 0.02\n",
      "iteration: 141900 loss: 0.0021 lr: 0.02\n",
      "iteration: 141910 loss: 0.0020 lr: 0.02\n",
      "iteration: 141920 loss: 0.0022 lr: 0.02\n",
      "iteration: 141930 loss: 0.0026 lr: 0.02\n",
      "iteration: 141940 loss: 0.0024 lr: 0.02\n",
      "iteration: 141950 loss: 0.0025 lr: 0.02\n",
      "iteration: 141960 loss: 0.0028 lr: 0.02\n",
      "iteration: 141970 loss: 0.0025 lr: 0.02\n",
      "iteration: 141980 loss: 0.0021 lr: 0.02\n",
      "iteration: 141990 loss: 0.0021 lr: 0.02\n",
      "iteration: 142000 loss: 0.0025 lr: 0.02\n",
      "iteration: 142010 loss: 0.0024 lr: 0.02\n",
      "iteration: 142020 loss: 0.0021 lr: 0.02\n",
      "iteration: 142030 loss: 0.0022 lr: 0.02\n",
      "iteration: 142040 loss: 0.0023 lr: 0.02\n",
      "iteration: 142050 loss: 0.0030 lr: 0.02\n",
      "iteration: 142060 loss: 0.0023 lr: 0.02\n",
      "iteration: 142070 loss: 0.0021 lr: 0.02\n",
      "iteration: 142080 loss: 0.0026 lr: 0.02\n",
      "iteration: 142090 loss: 0.0026 lr: 0.02\n",
      "iteration: 142100 loss: 0.0024 lr: 0.02\n",
      "iteration: 142110 loss: 0.0023 lr: 0.02\n",
      "iteration: 142120 loss: 0.0024 lr: 0.02\n",
      "iteration: 142130 loss: 0.0021 lr: 0.02\n",
      "iteration: 142140 loss: 0.0029 lr: 0.02\n",
      "iteration: 142150 loss: 0.0020 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 142160 loss: 0.0022 lr: 0.02\n",
      "iteration: 142170 loss: 0.0024 lr: 0.02\n",
      "iteration: 142180 loss: 0.0028 lr: 0.02\n",
      "iteration: 142190 loss: 0.0022 lr: 0.02\n",
      "iteration: 142200 loss: 0.0027 lr: 0.02\n",
      "iteration: 142210 loss: 0.0031 lr: 0.02\n",
      "iteration: 142220 loss: 0.0019 lr: 0.02\n",
      "iteration: 142230 loss: 0.0020 lr: 0.02\n",
      "iteration: 142240 loss: 0.0023 lr: 0.02\n",
      "iteration: 142250 loss: 0.0026 lr: 0.02\n",
      "iteration: 142260 loss: 0.0021 lr: 0.02\n",
      "iteration: 142270 loss: 0.0021 lr: 0.02\n",
      "iteration: 142280 loss: 0.0029 lr: 0.02\n",
      "iteration: 142290 loss: 0.0019 lr: 0.02\n",
      "iteration: 142300 loss: 0.0024 lr: 0.02\n",
      "iteration: 142310 loss: 0.0026 lr: 0.02\n",
      "iteration: 142320 loss: 0.0023 lr: 0.02\n",
      "iteration: 142330 loss: 0.0019 lr: 0.02\n",
      "iteration: 142340 loss: 0.0028 lr: 0.02\n",
      "iteration: 142350 loss: 0.0017 lr: 0.02\n",
      "iteration: 142360 loss: 0.0025 lr: 0.02\n",
      "iteration: 142370 loss: 0.0026 lr: 0.02\n",
      "iteration: 142380 loss: 0.0027 lr: 0.02\n",
      "iteration: 142390 loss: 0.0017 lr: 0.02\n",
      "iteration: 142400 loss: 0.0020 lr: 0.02\n",
      "iteration: 142410 loss: 0.0025 lr: 0.02\n",
      "iteration: 142420 loss: 0.0027 lr: 0.02\n",
      "iteration: 142430 loss: 0.0017 lr: 0.02\n",
      "iteration: 142440 loss: 0.0025 lr: 0.02\n",
      "iteration: 142450 loss: 0.0019 lr: 0.02\n",
      "iteration: 142460 loss: 0.0021 lr: 0.02\n",
      "iteration: 142470 loss: 0.0022 lr: 0.02\n",
      "iteration: 142480 loss: 0.0021 lr: 0.02\n",
      "iteration: 142490 loss: 0.0023 lr: 0.02\n",
      "iteration: 142500 loss: 0.0030 lr: 0.02\n",
      "iteration: 142510 loss: 0.0026 lr: 0.02\n",
      "iteration: 142520 loss: 0.0017 lr: 0.02\n",
      "iteration: 142530 loss: 0.0019 lr: 0.02\n",
      "iteration: 142540 loss: 0.0021 lr: 0.02\n",
      "iteration: 142550 loss: 0.0021 lr: 0.02\n",
      "iteration: 142560 loss: 0.0023 lr: 0.02\n",
      "iteration: 142570 loss: 0.0022 lr: 0.02\n",
      "iteration: 142580 loss: 0.0029 lr: 0.02\n",
      "iteration: 142590 loss: 0.0018 lr: 0.02\n",
      "iteration: 142600 loss: 0.0018 lr: 0.02\n",
      "iteration: 142610 loss: 0.0023 lr: 0.02\n",
      "iteration: 142620 loss: 0.0030 lr: 0.02\n",
      "iteration: 142630 loss: 0.0023 lr: 0.02\n",
      "iteration: 142640 loss: 0.0023 lr: 0.02\n",
      "iteration: 142650 loss: 0.0023 lr: 0.02\n",
      "iteration: 142660 loss: 0.0021 lr: 0.02\n",
      "iteration: 142670 loss: 0.0023 lr: 0.02\n",
      "iteration: 142680 loss: 0.0015 lr: 0.02\n",
      "iteration: 142690 loss: 0.0025 lr: 0.02\n",
      "iteration: 142700 loss: 0.0020 lr: 0.02\n",
      "iteration: 142710 loss: 0.0024 lr: 0.02\n",
      "iteration: 142720 loss: 0.0026 lr: 0.02\n",
      "iteration: 142730 loss: 0.0031 lr: 0.02\n",
      "iteration: 142740 loss: 0.0020 lr: 0.02\n",
      "iteration: 142750 loss: 0.0022 lr: 0.02\n",
      "iteration: 142760 loss: 0.0018 lr: 0.02\n",
      "iteration: 142770 loss: 0.0021 lr: 0.02\n",
      "iteration: 142780 loss: 0.0021 lr: 0.02\n",
      "iteration: 142790 loss: 0.0029 lr: 0.02\n",
      "iteration: 142800 loss: 0.0018 lr: 0.02\n",
      "iteration: 142810 loss: 0.0025 lr: 0.02\n",
      "iteration: 142820 loss: 0.0023 lr: 0.02\n",
      "iteration: 142830 loss: 0.0019 lr: 0.02\n",
      "iteration: 142840 loss: 0.0030 lr: 0.02\n",
      "iteration: 142850 loss: 0.0030 lr: 0.02\n",
      "iteration: 142860 loss: 0.0024 lr: 0.02\n",
      "iteration: 142870 loss: 0.0020 lr: 0.02\n",
      "iteration: 142880 loss: 0.0020 lr: 0.02\n",
      "iteration: 142890 loss: 0.0034 lr: 0.02\n",
      "iteration: 142900 loss: 0.0024 lr: 0.02\n",
      "iteration: 142910 loss: 0.0026 lr: 0.02\n",
      "iteration: 142920 loss: 0.0020 lr: 0.02\n",
      "iteration: 142930 loss: 0.0025 lr: 0.02\n",
      "iteration: 142940 loss: 0.0023 lr: 0.02\n",
      "iteration: 142950 loss: 0.0018 lr: 0.02\n",
      "iteration: 142960 loss: 0.0030 lr: 0.02\n",
      "iteration: 142970 loss: 0.0019 lr: 0.02\n",
      "iteration: 142980 loss: 0.0023 lr: 0.02\n",
      "iteration: 142990 loss: 0.0023 lr: 0.02\n",
      "iteration: 143000 loss: 0.0021 lr: 0.02\n",
      "iteration: 143010 loss: 0.0021 lr: 0.02\n",
      "iteration: 143020 loss: 0.0030 lr: 0.02\n",
      "iteration: 143030 loss: 0.0023 lr: 0.02\n",
      "iteration: 143040 loss: 0.0018 lr: 0.02\n",
      "iteration: 143050 loss: 0.0021 lr: 0.02\n",
      "iteration: 143060 loss: 0.0029 lr: 0.02\n",
      "iteration: 143070 loss: 0.0022 lr: 0.02\n",
      "iteration: 143080 loss: 0.0024 lr: 0.02\n",
      "iteration: 143090 loss: 0.0020 lr: 0.02\n",
      "iteration: 143100 loss: 0.0028 lr: 0.02\n",
      "iteration: 143110 loss: 0.0023 lr: 0.02\n",
      "iteration: 143120 loss: 0.0024 lr: 0.02\n",
      "iteration: 143130 loss: 0.0021 lr: 0.02\n",
      "iteration: 143140 loss: 0.0024 lr: 0.02\n",
      "iteration: 143150 loss: 0.0023 lr: 0.02\n",
      "iteration: 143160 loss: 0.0020 lr: 0.02\n",
      "iteration: 143170 loss: 0.0023 lr: 0.02\n",
      "iteration: 143180 loss: 0.0026 lr: 0.02\n",
      "iteration: 143190 loss: 0.0021 lr: 0.02\n",
      "iteration: 143200 loss: 0.0025 lr: 0.02\n",
      "iteration: 143210 loss: 0.0022 lr: 0.02\n",
      "iteration: 143220 loss: 0.0024 lr: 0.02\n",
      "iteration: 143230 loss: 0.0019 lr: 0.02\n",
      "iteration: 143240 loss: 0.0019 lr: 0.02\n",
      "iteration: 143250 loss: 0.0024 lr: 0.02\n",
      "iteration: 143260 loss: 0.0026 lr: 0.02\n",
      "iteration: 143270 loss: 0.0022 lr: 0.02\n",
      "iteration: 143280 loss: 0.0024 lr: 0.02\n",
      "iteration: 143290 loss: 0.0019 lr: 0.02\n",
      "iteration: 143300 loss: 0.0021 lr: 0.02\n",
      "iteration: 143310 loss: 0.0023 lr: 0.02\n",
      "iteration: 143320 loss: 0.0026 lr: 0.02\n",
      "iteration: 143330 loss: 0.0022 lr: 0.02\n",
      "iteration: 143340 loss: 0.0030 lr: 0.02\n",
      "iteration: 143350 loss: 0.0021 lr: 0.02\n",
      "iteration: 143360 loss: 0.0024 lr: 0.02\n",
      "iteration: 143370 loss: 0.0021 lr: 0.02\n",
      "iteration: 143380 loss: 0.0032 lr: 0.02\n",
      "iteration: 143390 loss: 0.0023 lr: 0.02\n",
      "iteration: 143400 loss: 0.0027 lr: 0.02\n",
      "iteration: 143410 loss: 0.0026 lr: 0.02\n",
      "iteration: 143420 loss: 0.0016 lr: 0.02\n",
      "iteration: 143430 loss: 0.0027 lr: 0.02\n",
      "iteration: 143440 loss: 0.0029 lr: 0.02\n",
      "iteration: 143450 loss: 0.0022 lr: 0.02\n",
      "iteration: 143460 loss: 0.0027 lr: 0.02\n",
      "iteration: 143470 loss: 0.0023 lr: 0.02\n",
      "iteration: 143480 loss: 0.0025 lr: 0.02\n",
      "iteration: 143490 loss: 0.0030 lr: 0.02\n",
      "iteration: 143500 loss: 0.0028 lr: 0.02\n",
      "iteration: 143510 loss: 0.0018 lr: 0.02\n",
      "iteration: 143520 loss: 0.0022 lr: 0.02\n",
      "iteration: 143530 loss: 0.0029 lr: 0.02\n",
      "iteration: 143540 loss: 0.0026 lr: 0.02\n",
      "iteration: 143550 loss: 0.0029 lr: 0.02\n",
      "iteration: 143560 loss: 0.0023 lr: 0.02\n",
      "iteration: 143570 loss: 0.0024 lr: 0.02\n",
      "iteration: 143580 loss: 0.0029 lr: 0.02\n",
      "iteration: 143590 loss: 0.0017 lr: 0.02\n",
      "iteration: 143600 loss: 0.0022 lr: 0.02\n",
      "iteration: 143610 loss: 0.0021 lr: 0.02\n",
      "iteration: 143620 loss: 0.0025 lr: 0.02\n",
      "iteration: 143630 loss: 0.0030 lr: 0.02\n",
      "iteration: 143640 loss: 0.0021 lr: 0.02\n",
      "iteration: 143650 loss: 0.0024 lr: 0.02\n",
      "iteration: 143660 loss: 0.0026 lr: 0.02\n",
      "iteration: 143670 loss: 0.0025 lr: 0.02\n",
      "iteration: 143680 loss: 0.0023 lr: 0.02\n",
      "iteration: 143690 loss: 0.0017 lr: 0.02\n",
      "iteration: 143700 loss: 0.0022 lr: 0.02\n",
      "iteration: 143710 loss: 0.0027 lr: 0.02\n",
      "iteration: 143720 loss: 0.0025 lr: 0.02\n",
      "iteration: 143730 loss: 0.0020 lr: 0.02\n",
      "iteration: 143740 loss: 0.0021 lr: 0.02\n",
      "iteration: 143750 loss: 0.0020 lr: 0.02\n",
      "iteration: 143760 loss: 0.0020 lr: 0.02\n",
      "iteration: 143770 loss: 0.0022 lr: 0.02\n",
      "iteration: 143780 loss: 0.0024 lr: 0.02\n",
      "iteration: 143790 loss: 0.0028 lr: 0.02\n",
      "iteration: 143800 loss: 0.0021 lr: 0.02\n",
      "iteration: 143810 loss: 0.0020 lr: 0.02\n",
      "iteration: 143820 loss: 0.0022 lr: 0.02\n",
      "iteration: 143830 loss: 0.0023 lr: 0.02\n",
      "iteration: 143840 loss: 0.0026 lr: 0.02\n",
      "iteration: 143850 loss: 0.0022 lr: 0.02\n",
      "iteration: 143860 loss: 0.0024 lr: 0.02\n",
      "iteration: 143870 loss: 0.0027 lr: 0.02\n",
      "iteration: 143880 loss: 0.0022 lr: 0.02\n",
      "iteration: 143890 loss: 0.0023 lr: 0.02\n",
      "iteration: 143900 loss: 0.0018 lr: 0.02\n",
      "iteration: 143910 loss: 0.0023 lr: 0.02\n",
      "iteration: 143920 loss: 0.0026 lr: 0.02\n",
      "iteration: 143930 loss: 0.0020 lr: 0.02\n",
      "iteration: 143940 loss: 0.0021 lr: 0.02\n",
      "iteration: 143950 loss: 0.0024 lr: 0.02\n",
      "iteration: 143960 loss: 0.0029 lr: 0.02\n",
      "iteration: 143970 loss: 0.0023 lr: 0.02\n",
      "iteration: 143980 loss: 0.0022 lr: 0.02\n",
      "iteration: 143990 loss: 0.0030 lr: 0.02\n",
      "iteration: 144000 loss: 0.0020 lr: 0.02\n",
      "iteration: 144010 loss: 0.0017 lr: 0.02\n",
      "iteration: 144020 loss: 0.0017 lr: 0.02\n",
      "iteration: 144030 loss: 0.0026 lr: 0.02\n",
      "iteration: 144040 loss: 0.0018 lr: 0.02\n",
      "iteration: 144050 loss: 0.0028 lr: 0.02\n",
      "iteration: 144060 loss: 0.0027 lr: 0.02\n",
      "iteration: 144070 loss: 0.0022 lr: 0.02\n",
      "iteration: 144080 loss: 0.0024 lr: 0.02\n",
      "iteration: 144090 loss: 0.0032 lr: 0.02\n",
      "iteration: 144100 loss: 0.0027 lr: 0.02\n",
      "iteration: 144110 loss: 0.0022 lr: 0.02\n",
      "iteration: 144120 loss: 0.0027 lr: 0.02\n",
      "iteration: 144130 loss: 0.0025 lr: 0.02\n",
      "iteration: 144140 loss: 0.0023 lr: 0.02\n",
      "iteration: 144150 loss: 0.0027 lr: 0.02\n",
      "iteration: 144160 loss: 0.0026 lr: 0.02\n",
      "iteration: 144170 loss: 0.0022 lr: 0.02\n",
      "iteration: 144180 loss: 0.0020 lr: 0.02\n",
      "iteration: 144190 loss: 0.0022 lr: 0.02\n",
      "iteration: 144200 loss: 0.0025 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 144210 loss: 0.0019 lr: 0.02\n",
      "iteration: 144220 loss: 0.0026 lr: 0.02\n",
      "iteration: 144230 loss: 0.0028 lr: 0.02\n",
      "iteration: 144240 loss: 0.0027 lr: 0.02\n",
      "iteration: 144250 loss: 0.0020 lr: 0.02\n",
      "iteration: 144260 loss: 0.0022 lr: 0.02\n",
      "iteration: 144270 loss: 0.0027 lr: 0.02\n",
      "iteration: 144280 loss: 0.0029 lr: 0.02\n",
      "iteration: 144290 loss: 0.0025 lr: 0.02\n",
      "iteration: 144300 loss: 0.0019 lr: 0.02\n",
      "iteration: 144310 loss: 0.0025 lr: 0.02\n",
      "iteration: 144320 loss: 0.0033 lr: 0.02\n",
      "iteration: 144330 loss: 0.0024 lr: 0.02\n",
      "iteration: 144340 loss: 0.0020 lr: 0.02\n",
      "iteration: 144350 loss: 0.0018 lr: 0.02\n",
      "iteration: 144360 loss: 0.0020 lr: 0.02\n",
      "iteration: 144370 loss: 0.0023 lr: 0.02\n",
      "iteration: 144380 loss: 0.0020 lr: 0.02\n",
      "iteration: 144390 loss: 0.0021 lr: 0.02\n",
      "iteration: 144400 loss: 0.0017 lr: 0.02\n",
      "iteration: 144410 loss: 0.0021 lr: 0.02\n",
      "iteration: 144420 loss: 0.0021 lr: 0.02\n",
      "iteration: 144430 loss: 0.0017 lr: 0.02\n",
      "iteration: 144440 loss: 0.0019 lr: 0.02\n",
      "iteration: 144450 loss: 0.0020 lr: 0.02\n",
      "iteration: 144460 loss: 0.0019 lr: 0.02\n",
      "iteration: 144470 loss: 0.0017 lr: 0.02\n",
      "iteration: 144480 loss: 0.0023 lr: 0.02\n",
      "iteration: 144490 loss: 0.0017 lr: 0.02\n",
      "iteration: 144500 loss: 0.0020 lr: 0.02\n",
      "iteration: 144510 loss: 0.0019 lr: 0.02\n",
      "iteration: 144520 loss: 0.0036 lr: 0.02\n",
      "iteration: 144530 loss: 0.0026 lr: 0.02\n",
      "iteration: 144540 loss: 0.0023 lr: 0.02\n",
      "iteration: 144550 loss: 0.0017 lr: 0.02\n",
      "iteration: 144560 loss: 0.0022 lr: 0.02\n",
      "iteration: 144570 loss: 0.0024 lr: 0.02\n",
      "iteration: 144580 loss: 0.0016 lr: 0.02\n",
      "iteration: 144590 loss: 0.0022 lr: 0.02\n",
      "iteration: 144600 loss: 0.0029 lr: 0.02\n",
      "iteration: 144610 loss: 0.0025 lr: 0.02\n",
      "iteration: 144620 loss: 0.0018 lr: 0.02\n",
      "iteration: 144630 loss: 0.0020 lr: 0.02\n",
      "iteration: 144640 loss: 0.0017 lr: 0.02\n",
      "iteration: 144650 loss: 0.0028 lr: 0.02\n",
      "iteration: 144660 loss: 0.0027 lr: 0.02\n",
      "iteration: 144670 loss: 0.0020 lr: 0.02\n",
      "iteration: 144680 loss: 0.0020 lr: 0.02\n",
      "iteration: 144690 loss: 0.0025 lr: 0.02\n",
      "iteration: 144700 loss: 0.0020 lr: 0.02\n",
      "iteration: 144710 loss: 0.0028 lr: 0.02\n",
      "iteration: 144720 loss: 0.0029 lr: 0.02\n",
      "iteration: 144730 loss: 0.0028 lr: 0.02\n",
      "iteration: 144740 loss: 0.0029 lr: 0.02\n",
      "iteration: 144750 loss: 0.0019 lr: 0.02\n",
      "iteration: 144760 loss: 0.0021 lr: 0.02\n",
      "iteration: 144770 loss: 0.0028 lr: 0.02\n",
      "iteration: 144780 loss: 0.0024 lr: 0.02\n",
      "iteration: 144790 loss: 0.0026 lr: 0.02\n",
      "iteration: 144800 loss: 0.0034 lr: 0.02\n",
      "iteration: 144810 loss: 0.0025 lr: 0.02\n",
      "iteration: 144820 loss: 0.0026 lr: 0.02\n",
      "iteration: 144830 loss: 0.0021 lr: 0.02\n",
      "iteration: 144840 loss: 0.0024 lr: 0.02\n",
      "iteration: 144850 loss: 0.0022 lr: 0.02\n",
      "iteration: 144860 loss: 0.0028 lr: 0.02\n",
      "iteration: 144870 loss: 0.0027 lr: 0.02\n",
      "iteration: 144880 loss: 0.0027 lr: 0.02\n",
      "iteration: 144890 loss: 0.0018 lr: 0.02\n",
      "iteration: 144900 loss: 0.0027 lr: 0.02\n",
      "iteration: 144910 loss: 0.0025 lr: 0.02\n",
      "iteration: 144920 loss: 0.0025 lr: 0.02\n",
      "iteration: 144930 loss: 0.0026 lr: 0.02\n",
      "iteration: 144940 loss: 0.0017 lr: 0.02\n",
      "iteration: 144950 loss: 0.0021 lr: 0.02\n",
      "iteration: 144960 loss: 0.0019 lr: 0.02\n",
      "iteration: 144970 loss: 0.0021 lr: 0.02\n",
      "iteration: 144980 loss: 0.0028 lr: 0.02\n",
      "iteration: 144990 loss: 0.0022 lr: 0.02\n",
      "iteration: 145000 loss: 0.0026 lr: 0.02\n",
      "iteration: 145010 loss: 0.0026 lr: 0.02\n",
      "iteration: 145020 loss: 0.0019 lr: 0.02\n",
      "iteration: 145030 loss: 0.0031 lr: 0.02\n",
      "iteration: 145040 loss: 0.0028 lr: 0.02\n",
      "iteration: 145050 loss: 0.0027 lr: 0.02\n",
      "iteration: 145060 loss: 0.0023 lr: 0.02\n",
      "iteration: 145070 loss: 0.0024 lr: 0.02\n",
      "iteration: 145080 loss: 0.0023 lr: 0.02\n",
      "iteration: 145090 loss: 0.0020 lr: 0.02\n",
      "iteration: 145100 loss: 0.0020 lr: 0.02\n",
      "iteration: 145110 loss: 0.0021 lr: 0.02\n",
      "iteration: 145120 loss: 0.0023 lr: 0.02\n",
      "iteration: 145130 loss: 0.0021 lr: 0.02\n",
      "iteration: 145140 loss: 0.0023 lr: 0.02\n",
      "iteration: 145150 loss: 0.0019 lr: 0.02\n",
      "iteration: 145160 loss: 0.0031 lr: 0.02\n",
      "iteration: 145170 loss: 0.0025 lr: 0.02\n",
      "iteration: 145180 loss: 0.0021 lr: 0.02\n",
      "iteration: 145190 loss: 0.0023 lr: 0.02\n",
      "iteration: 145200 loss: 0.0022 lr: 0.02\n",
      "iteration: 145210 loss: 0.0018 lr: 0.02\n",
      "iteration: 145220 loss: 0.0027 lr: 0.02\n",
      "iteration: 145230 loss: 0.0024 lr: 0.02\n",
      "iteration: 145240 loss: 0.0022 lr: 0.02\n",
      "iteration: 145250 loss: 0.0026 lr: 0.02\n",
      "iteration: 145260 loss: 0.0024 lr: 0.02\n",
      "iteration: 145270 loss: 0.0027 lr: 0.02\n",
      "iteration: 145280 loss: 0.0026 lr: 0.02\n",
      "iteration: 145290 loss: 0.0021 lr: 0.02\n",
      "iteration: 145300 loss: 0.0024 lr: 0.02\n",
      "iteration: 145310 loss: 0.0022 lr: 0.02\n",
      "iteration: 145320 loss: 0.0019 lr: 0.02\n",
      "iteration: 145330 loss: 0.0022 lr: 0.02\n",
      "iteration: 145340 loss: 0.0026 lr: 0.02\n",
      "iteration: 145350 loss: 0.0022 lr: 0.02\n",
      "iteration: 145360 loss: 0.0019 lr: 0.02\n",
      "iteration: 145370 loss: 0.0018 lr: 0.02\n",
      "iteration: 145380 loss: 0.0026 lr: 0.02\n",
      "iteration: 145390 loss: 0.0026 lr: 0.02\n",
      "iteration: 145400 loss: 0.0019 lr: 0.02\n",
      "iteration: 145410 loss: 0.0022 lr: 0.02\n",
      "iteration: 145420 loss: 0.0026 lr: 0.02\n",
      "iteration: 145430 loss: 0.0029 lr: 0.02\n",
      "iteration: 145440 loss: 0.0034 lr: 0.02\n",
      "iteration: 145450 loss: 0.0025 lr: 0.02\n",
      "iteration: 145460 loss: 0.0024 lr: 0.02\n",
      "iteration: 145470 loss: 0.0020 lr: 0.02\n",
      "iteration: 145480 loss: 0.0025 lr: 0.02\n",
      "iteration: 145490 loss: 0.0023 lr: 0.02\n",
      "iteration: 145500 loss: 0.0025 lr: 0.02\n",
      "iteration: 145510 loss: 0.0027 lr: 0.02\n",
      "iteration: 145520 loss: 0.0023 lr: 0.02\n",
      "iteration: 145530 loss: 0.0027 lr: 0.02\n",
      "iteration: 145540 loss: 0.0018 lr: 0.02\n",
      "iteration: 145550 loss: 0.0019 lr: 0.02\n",
      "iteration: 145560 loss: 0.0028 lr: 0.02\n",
      "iteration: 145570 loss: 0.0021 lr: 0.02\n",
      "iteration: 145580 loss: 0.0023 lr: 0.02\n",
      "iteration: 145590 loss: 0.0021 lr: 0.02\n",
      "iteration: 145600 loss: 0.0026 lr: 0.02\n",
      "iteration: 145610 loss: 0.0023 lr: 0.02\n",
      "iteration: 145620 loss: 0.0028 lr: 0.02\n",
      "iteration: 145630 loss: 0.0022 lr: 0.02\n",
      "iteration: 145640 loss: 0.0029 lr: 0.02\n",
      "iteration: 145650 loss: 0.0024 lr: 0.02\n",
      "iteration: 145660 loss: 0.0020 lr: 0.02\n",
      "iteration: 145670 loss: 0.0023 lr: 0.02\n",
      "iteration: 145680 loss: 0.0024 lr: 0.02\n",
      "iteration: 145690 loss: 0.0021 lr: 0.02\n",
      "iteration: 145700 loss: 0.0018 lr: 0.02\n",
      "iteration: 145710 loss: 0.0024 lr: 0.02\n",
      "iteration: 145720 loss: 0.0025 lr: 0.02\n",
      "iteration: 145730 loss: 0.0024 lr: 0.02\n",
      "iteration: 145740 loss: 0.0027 lr: 0.02\n",
      "iteration: 145750 loss: 0.0026 lr: 0.02\n",
      "iteration: 145760 loss: 0.0023 lr: 0.02\n",
      "iteration: 145770 loss: 0.0023 lr: 0.02\n",
      "iteration: 145780 loss: 0.0025 lr: 0.02\n",
      "iteration: 145790 loss: 0.0029 lr: 0.02\n",
      "iteration: 145800 loss: 0.0018 lr: 0.02\n",
      "iteration: 145810 loss: 0.0022 lr: 0.02\n",
      "iteration: 145820 loss: 0.0025 lr: 0.02\n",
      "iteration: 145830 loss: 0.0021 lr: 0.02\n",
      "iteration: 145840 loss: 0.0021 lr: 0.02\n",
      "iteration: 145850 loss: 0.0025 lr: 0.02\n",
      "iteration: 145860 loss: 0.0023 lr: 0.02\n",
      "iteration: 145870 loss: 0.0027 lr: 0.02\n",
      "iteration: 145880 loss: 0.0016 lr: 0.02\n",
      "iteration: 145890 loss: 0.0021 lr: 0.02\n",
      "iteration: 145900 loss: 0.0028 lr: 0.02\n",
      "iteration: 145910 loss: 0.0027 lr: 0.02\n",
      "iteration: 145920 loss: 0.0025 lr: 0.02\n",
      "iteration: 145930 loss: 0.0019 lr: 0.02\n",
      "iteration: 145940 loss: 0.0019 lr: 0.02\n",
      "iteration: 145950 loss: 0.0026 lr: 0.02\n",
      "iteration: 145960 loss: 0.0022 lr: 0.02\n",
      "iteration: 145970 loss: 0.0019 lr: 0.02\n",
      "iteration: 145980 loss: 0.0025 lr: 0.02\n",
      "iteration: 145990 loss: 0.0016 lr: 0.02\n",
      "iteration: 146000 loss: 0.0030 lr: 0.02\n",
      "iteration: 146010 loss: 0.0025 lr: 0.02\n",
      "iteration: 146020 loss: 0.0026 lr: 0.02\n",
      "iteration: 146030 loss: 0.0018 lr: 0.02\n",
      "iteration: 146040 loss: 0.0020 lr: 0.02\n",
      "iteration: 146050 loss: 0.0022 lr: 0.02\n",
      "iteration: 146060 loss: 0.0022 lr: 0.02\n",
      "iteration: 146070 loss: 0.0031 lr: 0.02\n",
      "iteration: 146080 loss: 0.0024 lr: 0.02\n",
      "iteration: 146090 loss: 0.0019 lr: 0.02\n",
      "iteration: 146100 loss: 0.0023 lr: 0.02\n",
      "iteration: 146110 loss: 0.0020 lr: 0.02\n",
      "iteration: 146120 loss: 0.0031 lr: 0.02\n",
      "iteration: 146130 loss: 0.0023 lr: 0.02\n",
      "iteration: 146140 loss: 0.0025 lr: 0.02\n",
      "iteration: 146150 loss: 0.0019 lr: 0.02\n",
      "iteration: 146160 loss: 0.0025 lr: 0.02\n",
      "iteration: 146170 loss: 0.0024 lr: 0.02\n",
      "iteration: 146180 loss: 0.0019 lr: 0.02\n",
      "iteration: 146190 loss: 0.0021 lr: 0.02\n",
      "iteration: 146200 loss: 0.0026 lr: 0.02\n",
      "iteration: 146210 loss: 0.0033 lr: 0.02\n",
      "iteration: 146220 loss: 0.0023 lr: 0.02\n",
      "iteration: 146230 loss: 0.0018 lr: 0.02\n",
      "iteration: 146240 loss: 0.0022 lr: 0.02\n",
      "iteration: 146250 loss: 0.0022 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 146260 loss: 0.0019 lr: 0.02\n",
      "iteration: 146270 loss: 0.0028 lr: 0.02\n",
      "iteration: 146280 loss: 0.0026 lr: 0.02\n",
      "iteration: 146290 loss: 0.0026 lr: 0.02\n",
      "iteration: 146300 loss: 0.0019 lr: 0.02\n",
      "iteration: 146310 loss: 0.0028 lr: 0.02\n",
      "iteration: 146320 loss: 0.0023 lr: 0.02\n",
      "iteration: 146330 loss: 0.0030 lr: 0.02\n",
      "iteration: 146340 loss: 0.0043 lr: 0.02\n",
      "iteration: 146350 loss: 0.0022 lr: 0.02\n",
      "iteration: 146360 loss: 0.0026 lr: 0.02\n",
      "iteration: 146370 loss: 0.0025 lr: 0.02\n",
      "iteration: 146380 loss: 0.0027 lr: 0.02\n",
      "iteration: 146390 loss: 0.0023 lr: 0.02\n",
      "iteration: 146400 loss: 0.0027 lr: 0.02\n",
      "iteration: 146410 loss: 0.0025 lr: 0.02\n",
      "iteration: 146420 loss: 0.0022 lr: 0.02\n",
      "iteration: 146430 loss: 0.0025 lr: 0.02\n",
      "iteration: 146440 loss: 0.0024 lr: 0.02\n",
      "iteration: 146450 loss: 0.0027 lr: 0.02\n",
      "iteration: 146460 loss: 0.0021 lr: 0.02\n",
      "iteration: 146470 loss: 0.0030 lr: 0.02\n",
      "iteration: 146480 loss: 0.0024 lr: 0.02\n",
      "iteration: 146490 loss: 0.0022 lr: 0.02\n",
      "iteration: 146500 loss: 0.0022 lr: 0.02\n",
      "iteration: 146510 loss: 0.0025 lr: 0.02\n",
      "iteration: 146520 loss: 0.0022 lr: 0.02\n",
      "iteration: 146530 loss: 0.0031 lr: 0.02\n",
      "iteration: 146540 loss: 0.0021 lr: 0.02\n",
      "iteration: 146550 loss: 0.0018 lr: 0.02\n",
      "iteration: 146560 loss: 0.0023 lr: 0.02\n",
      "iteration: 146570 loss: 0.0021 lr: 0.02\n",
      "iteration: 146580 loss: 0.0022 lr: 0.02\n",
      "iteration: 146590 loss: 0.0024 lr: 0.02\n",
      "iteration: 146600 loss: 0.0020 lr: 0.02\n",
      "iteration: 146610 loss: 0.0028 lr: 0.02\n",
      "iteration: 146620 loss: 0.0021 lr: 0.02\n",
      "iteration: 146630 loss: 0.0022 lr: 0.02\n",
      "iteration: 146640 loss: 0.0023 lr: 0.02\n",
      "iteration: 146650 loss: 0.0022 lr: 0.02\n",
      "iteration: 146660 loss: 0.0023 lr: 0.02\n",
      "iteration: 146670 loss: 0.0019 lr: 0.02\n",
      "iteration: 146680 loss: 0.0020 lr: 0.02\n",
      "iteration: 146690 loss: 0.0029 lr: 0.02\n",
      "iteration: 146700 loss: 0.0021 lr: 0.02\n",
      "iteration: 146710 loss: 0.0027 lr: 0.02\n",
      "iteration: 146720 loss: 0.0022 lr: 0.02\n",
      "iteration: 146730 loss: 0.0023 lr: 0.02\n",
      "iteration: 146740 loss: 0.0019 lr: 0.02\n",
      "iteration: 146750 loss: 0.0014 lr: 0.02\n",
      "iteration: 146760 loss: 0.0019 lr: 0.02\n",
      "iteration: 146770 loss: 0.0025 lr: 0.02\n",
      "iteration: 146780 loss: 0.0016 lr: 0.02\n",
      "iteration: 146790 loss: 0.0039 lr: 0.02\n",
      "iteration: 146800 loss: 0.0022 lr: 0.02\n",
      "iteration: 146810 loss: 0.0023 lr: 0.02\n",
      "iteration: 146820 loss: 0.0019 lr: 0.02\n",
      "iteration: 146830 loss: 0.0025 lr: 0.02\n",
      "iteration: 146840 loss: 0.0018 lr: 0.02\n",
      "iteration: 146850 loss: 0.0023 lr: 0.02\n",
      "iteration: 146860 loss: 0.0024 lr: 0.02\n",
      "iteration: 146870 loss: 0.0023 lr: 0.02\n",
      "iteration: 146880 loss: 0.0026 lr: 0.02\n",
      "iteration: 146890 loss: 0.0026 lr: 0.02\n",
      "iteration: 146900 loss: 0.0022 lr: 0.02\n",
      "iteration: 146910 loss: 0.0024 lr: 0.02\n",
      "iteration: 146920 loss: 0.0022 lr: 0.02\n",
      "iteration: 146930 loss: 0.0016 lr: 0.02\n",
      "iteration: 146940 loss: 0.0029 lr: 0.02\n",
      "iteration: 146950 loss: 0.0024 lr: 0.02\n",
      "iteration: 146960 loss: 0.0021 lr: 0.02\n",
      "iteration: 146970 loss: 0.0021 lr: 0.02\n",
      "iteration: 146980 loss: 0.0025 lr: 0.02\n",
      "iteration: 146990 loss: 0.0030 lr: 0.02\n",
      "iteration: 147000 loss: 0.0019 lr: 0.02\n",
      "iteration: 147010 loss: 0.0030 lr: 0.02\n",
      "iteration: 147020 loss: 0.0022 lr: 0.02\n",
      "iteration: 147030 loss: 0.0019 lr: 0.02\n",
      "iteration: 147040 loss: 0.0029 lr: 0.02\n",
      "iteration: 147050 loss: 0.0025 lr: 0.02\n",
      "iteration: 147060 loss: 0.0025 lr: 0.02\n",
      "iteration: 147070 loss: 0.0020 lr: 0.02\n",
      "iteration: 147080 loss: 0.0023 lr: 0.02\n",
      "iteration: 147090 loss: 0.0022 lr: 0.02\n",
      "iteration: 147100 loss: 0.0030 lr: 0.02\n",
      "iteration: 147110 loss: 0.0021 lr: 0.02\n",
      "iteration: 147120 loss: 0.0023 lr: 0.02\n",
      "iteration: 147130 loss: 0.0028 lr: 0.02\n",
      "iteration: 147140 loss: 0.0027 lr: 0.02\n",
      "iteration: 147150 loss: 0.0022 lr: 0.02\n",
      "iteration: 147160 loss: 0.0021 lr: 0.02\n",
      "iteration: 147170 loss: 0.0026 lr: 0.02\n",
      "iteration: 147180 loss: 0.0026 lr: 0.02\n",
      "iteration: 147190 loss: 0.0018 lr: 0.02\n",
      "iteration: 147200 loss: 0.0030 lr: 0.02\n",
      "iteration: 147210 loss: 0.0021 lr: 0.02\n",
      "iteration: 147220 loss: 0.0022 lr: 0.02\n",
      "iteration: 147230 loss: 0.0023 lr: 0.02\n",
      "iteration: 147240 loss: 0.0032 lr: 0.02\n",
      "iteration: 147250 loss: 0.0024 lr: 0.02\n",
      "iteration: 147260 loss: 0.0019 lr: 0.02\n",
      "iteration: 147270 loss: 0.0018 lr: 0.02\n",
      "iteration: 147280 loss: 0.0033 lr: 0.02\n",
      "iteration: 147290 loss: 0.0027 lr: 0.02\n",
      "iteration: 147300 loss: 0.0020 lr: 0.02\n",
      "iteration: 147310 loss: 0.0025 lr: 0.02\n",
      "iteration: 147320 loss: 0.0018 lr: 0.02\n",
      "iteration: 147330 loss: 0.0020 lr: 0.02\n",
      "iteration: 147340 loss: 0.0020 lr: 0.02\n",
      "iteration: 147350 loss: 0.0027 lr: 0.02\n",
      "iteration: 147360 loss: 0.0028 lr: 0.02\n",
      "iteration: 147370 loss: 0.0025 lr: 0.02\n",
      "iteration: 147380 loss: 0.0020 lr: 0.02\n",
      "iteration: 147390 loss: 0.0031 lr: 0.02\n",
      "iteration: 147400 loss: 0.0020 lr: 0.02\n",
      "iteration: 147410 loss: 0.0020 lr: 0.02\n",
      "iteration: 147420 loss: 0.0017 lr: 0.02\n",
      "iteration: 147430 loss: 0.0020 lr: 0.02\n",
      "iteration: 147440 loss: 0.0022 lr: 0.02\n",
      "iteration: 147450 loss: 0.0026 lr: 0.02\n",
      "iteration: 147460 loss: 0.0023 lr: 0.02\n",
      "iteration: 147470 loss: 0.0026 lr: 0.02\n",
      "iteration: 147480 loss: 0.0030 lr: 0.02\n",
      "iteration: 147490 loss: 0.0022 lr: 0.02\n",
      "iteration: 147500 loss: 0.0028 lr: 0.02\n",
      "iteration: 147510 loss: 0.0020 lr: 0.02\n",
      "iteration: 147520 loss: 0.0022 lr: 0.02\n",
      "iteration: 147530 loss: 0.0020 lr: 0.02\n",
      "iteration: 147540 loss: 0.0021 lr: 0.02\n",
      "iteration: 147550 loss: 0.0020 lr: 0.02\n",
      "iteration: 147560 loss: 0.0028 lr: 0.02\n",
      "iteration: 147570 loss: 0.0022 lr: 0.02\n",
      "iteration: 147580 loss: 0.0023 lr: 0.02\n",
      "iteration: 147590 loss: 0.0021 lr: 0.02\n",
      "iteration: 147600 loss: 0.0020 lr: 0.02\n",
      "iteration: 147610 loss: 0.0021 lr: 0.02\n",
      "iteration: 147620 loss: 0.0023 lr: 0.02\n",
      "iteration: 147630 loss: 0.0027 lr: 0.02\n",
      "iteration: 147640 loss: 0.0026 lr: 0.02\n",
      "iteration: 147650 loss: 0.0021 lr: 0.02\n",
      "iteration: 147660 loss: 0.0023 lr: 0.02\n",
      "iteration: 147670 loss: 0.0023 lr: 0.02\n",
      "iteration: 147680 loss: 0.0021 lr: 0.02\n",
      "iteration: 147690 loss: 0.0020 lr: 0.02\n",
      "iteration: 147700 loss: 0.0022 lr: 0.02\n",
      "iteration: 147710 loss: 0.0020 lr: 0.02\n",
      "iteration: 147720 loss: 0.0023 lr: 0.02\n",
      "iteration: 147730 loss: 0.0026 lr: 0.02\n",
      "iteration: 147740 loss: 0.0022 lr: 0.02\n",
      "iteration: 147750 loss: 0.0023 lr: 0.02\n",
      "iteration: 147760 loss: 0.0020 lr: 0.02\n",
      "iteration: 147770 loss: 0.0033 lr: 0.02\n",
      "iteration: 147780 loss: 0.0021 lr: 0.02\n",
      "iteration: 147790 loss: 0.0020 lr: 0.02\n",
      "iteration: 147800 loss: 0.0020 lr: 0.02\n",
      "iteration: 147810 loss: 0.0028 lr: 0.02\n",
      "iteration: 147820 loss: 0.0021 lr: 0.02\n",
      "iteration: 147830 loss: 0.0017 lr: 0.02\n",
      "iteration: 147840 loss: 0.0020 lr: 0.02\n",
      "iteration: 147850 loss: 0.0020 lr: 0.02\n",
      "iteration: 147860 loss: 0.0017 lr: 0.02\n",
      "iteration: 147870 loss: 0.0025 lr: 0.02\n",
      "iteration: 147880 loss: 0.0019 lr: 0.02\n",
      "iteration: 147890 loss: 0.0024 lr: 0.02\n",
      "iteration: 147900 loss: 0.0022 lr: 0.02\n",
      "iteration: 147910 loss: 0.0019 lr: 0.02\n",
      "iteration: 147920 loss: 0.0019 lr: 0.02\n",
      "iteration: 147930 loss: 0.0027 lr: 0.02\n",
      "iteration: 147940 loss: 0.0025 lr: 0.02\n",
      "iteration: 147950 loss: 0.0027 lr: 0.02\n",
      "iteration: 147960 loss: 0.0022 lr: 0.02\n",
      "iteration: 147970 loss: 0.0029 lr: 0.02\n",
      "iteration: 147980 loss: 0.0016 lr: 0.02\n",
      "iteration: 147990 loss: 0.0024 lr: 0.02\n",
      "iteration: 148000 loss: 0.0028 lr: 0.02\n",
      "iteration: 148010 loss: 0.0021 lr: 0.02\n",
      "iteration: 148020 loss: 0.0024 lr: 0.02\n",
      "iteration: 148030 loss: 0.0028 lr: 0.02\n",
      "iteration: 148040 loss: 0.0018 lr: 0.02\n",
      "iteration: 148050 loss: 0.0022 lr: 0.02\n",
      "iteration: 148060 loss: 0.0017 lr: 0.02\n",
      "iteration: 148070 loss: 0.0034 lr: 0.02\n",
      "iteration: 148080 loss: 0.0021 lr: 0.02\n",
      "iteration: 148090 loss: 0.0028 lr: 0.02\n",
      "iteration: 148100 loss: 0.0022 lr: 0.02\n",
      "iteration: 148110 loss: 0.0016 lr: 0.02\n",
      "iteration: 148120 loss: 0.0028 lr: 0.02\n",
      "iteration: 148130 loss: 0.0024 lr: 0.02\n",
      "iteration: 148140 loss: 0.0021 lr: 0.02\n",
      "iteration: 148150 loss: 0.0024 lr: 0.02\n",
      "iteration: 148160 loss: 0.0027 lr: 0.02\n",
      "iteration: 148170 loss: 0.0025 lr: 0.02\n",
      "iteration: 148180 loss: 0.0020 lr: 0.02\n",
      "iteration: 148190 loss: 0.0019 lr: 0.02\n",
      "iteration: 148200 loss: 0.0021 lr: 0.02\n",
      "iteration: 148210 loss: 0.0024 lr: 0.02\n",
      "iteration: 148220 loss: 0.0021 lr: 0.02\n",
      "iteration: 148230 loss: 0.0023 lr: 0.02\n",
      "iteration: 148240 loss: 0.0023 lr: 0.02\n",
      "iteration: 148250 loss: 0.0026 lr: 0.02\n",
      "iteration: 148260 loss: 0.0021 lr: 0.02\n",
      "iteration: 148270 loss: 0.0020 lr: 0.02\n",
      "iteration: 148280 loss: 0.0020 lr: 0.02\n",
      "iteration: 148290 loss: 0.0028 lr: 0.02\n",
      "iteration: 148300 loss: 0.0023 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 148310 loss: 0.0024 lr: 0.02\n",
      "iteration: 148320 loss: 0.0022 lr: 0.02\n",
      "iteration: 148330 loss: 0.0023 lr: 0.02\n",
      "iteration: 148340 loss: 0.0025 lr: 0.02\n",
      "iteration: 148350 loss: 0.0025 lr: 0.02\n",
      "iteration: 148360 loss: 0.0021 lr: 0.02\n",
      "iteration: 148370 loss: 0.0022 lr: 0.02\n",
      "iteration: 148380 loss: 0.0021 lr: 0.02\n",
      "iteration: 148390 loss: 0.0017 lr: 0.02\n",
      "iteration: 148400 loss: 0.0026 lr: 0.02\n",
      "iteration: 148410 loss: 0.0022 lr: 0.02\n",
      "iteration: 148420 loss: 0.0020 lr: 0.02\n",
      "iteration: 148430 loss: 0.0025 lr: 0.02\n",
      "iteration: 148440 loss: 0.0030 lr: 0.02\n",
      "iteration: 148450 loss: 0.0022 lr: 0.02\n",
      "iteration: 148460 loss: 0.0029 lr: 0.02\n",
      "iteration: 148470 loss: 0.0025 lr: 0.02\n",
      "iteration: 148480 loss: 0.0024 lr: 0.02\n",
      "iteration: 148490 loss: 0.0024 lr: 0.02\n",
      "iteration: 148500 loss: 0.0031 lr: 0.02\n",
      "iteration: 148510 loss: 0.0027 lr: 0.02\n",
      "iteration: 148520 loss: 0.0023 lr: 0.02\n",
      "iteration: 148530 loss: 0.0022 lr: 0.02\n",
      "iteration: 148540 loss: 0.0021 lr: 0.02\n",
      "iteration: 148550 loss: 0.0027 lr: 0.02\n",
      "iteration: 148560 loss: 0.0024 lr: 0.02\n",
      "iteration: 148570 loss: 0.0024 lr: 0.02\n",
      "iteration: 148580 loss: 0.0023 lr: 0.02\n",
      "iteration: 148590 loss: 0.0021 lr: 0.02\n",
      "iteration: 148600 loss: 0.0041 lr: 0.02\n",
      "iteration: 148610 loss: 0.0031 lr: 0.02\n",
      "iteration: 148620 loss: 0.0023 lr: 0.02\n",
      "iteration: 148630 loss: 0.0027 lr: 0.02\n",
      "iteration: 148640 loss: 0.0021 lr: 0.02\n",
      "iteration: 148650 loss: 0.0020 lr: 0.02\n",
      "iteration: 148660 loss: 0.0025 lr: 0.02\n",
      "iteration: 148670 loss: 0.0020 lr: 0.02\n",
      "iteration: 148680 loss: 0.0033 lr: 0.02\n",
      "iteration: 148690 loss: 0.0026 lr: 0.02\n",
      "iteration: 148700 loss: 0.0025 lr: 0.02\n",
      "iteration: 148710 loss: 0.0019 lr: 0.02\n",
      "iteration: 148720 loss: 0.0028 lr: 0.02\n",
      "iteration: 148730 loss: 0.0014 lr: 0.02\n",
      "iteration: 148740 loss: 0.0024 lr: 0.02\n",
      "iteration: 148750 loss: 0.0022 lr: 0.02\n",
      "iteration: 148760 loss: 0.0021 lr: 0.02\n",
      "iteration: 148770 loss: 0.0020 lr: 0.02\n",
      "iteration: 148780 loss: 0.0026 lr: 0.02\n",
      "iteration: 148790 loss: 0.0023 lr: 0.02\n",
      "iteration: 148800 loss: 0.0026 lr: 0.02\n",
      "iteration: 148810 loss: 0.0020 lr: 0.02\n",
      "iteration: 148820 loss: 0.0019 lr: 0.02\n",
      "iteration: 148830 loss: 0.0020 lr: 0.02\n",
      "iteration: 148840 loss: 0.0021 lr: 0.02\n",
      "iteration: 148850 loss: 0.0023 lr: 0.02\n",
      "iteration: 148860 loss: 0.0032 lr: 0.02\n",
      "iteration: 148870 loss: 0.0033 lr: 0.02\n",
      "iteration: 148880 loss: 0.0024 lr: 0.02\n",
      "iteration: 148890 loss: 0.0022 lr: 0.02\n",
      "iteration: 148900 loss: 0.0023 lr: 0.02\n",
      "iteration: 148910 loss: 0.0037 lr: 0.02\n",
      "iteration: 148920 loss: 0.0024 lr: 0.02\n",
      "iteration: 148930 loss: 0.0026 lr: 0.02\n",
      "iteration: 148940 loss: 0.0017 lr: 0.02\n",
      "iteration: 148950 loss: 0.0021 lr: 0.02\n",
      "iteration: 148960 loss: 0.0019 lr: 0.02\n",
      "iteration: 148970 loss: 0.0023 lr: 0.02\n",
      "iteration: 148980 loss: 0.0028 lr: 0.02\n",
      "iteration: 148990 loss: 0.0032 lr: 0.02\n",
      "iteration: 149000 loss: 0.0025 lr: 0.02\n",
      "iteration: 149010 loss: 0.0025 lr: 0.02\n",
      "iteration: 149020 loss: 0.0022 lr: 0.02\n",
      "iteration: 149030 loss: 0.0022 lr: 0.02\n",
      "iteration: 149040 loss: 0.0019 lr: 0.02\n",
      "iteration: 149050 loss: 0.0022 lr: 0.02\n",
      "iteration: 149060 loss: 0.0024 lr: 0.02\n",
      "iteration: 149070 loss: 0.0026 lr: 0.02\n",
      "iteration: 149080 loss: 0.0018 lr: 0.02\n",
      "iteration: 149090 loss: 0.0024 lr: 0.02\n",
      "iteration: 149100 loss: 0.0026 lr: 0.02\n",
      "iteration: 149110 loss: 0.0022 lr: 0.02\n",
      "iteration: 149120 loss: 0.0021 lr: 0.02\n",
      "iteration: 149130 loss: 0.0022 lr: 0.02\n",
      "iteration: 149140 loss: 0.0023 lr: 0.02\n",
      "iteration: 149150 loss: 0.0021 lr: 0.02\n",
      "iteration: 149160 loss: 0.0021 lr: 0.02\n",
      "iteration: 149170 loss: 0.0024 lr: 0.02\n",
      "iteration: 149180 loss: 0.0024 lr: 0.02\n",
      "iteration: 149190 loss: 0.0018 lr: 0.02\n",
      "iteration: 149200 loss: 0.0025 lr: 0.02\n",
      "iteration: 149210 loss: 0.0021 lr: 0.02\n",
      "iteration: 149220 loss: 0.0020 lr: 0.02\n",
      "iteration: 149230 loss: 0.0020 lr: 0.02\n",
      "iteration: 149240 loss: 0.0019 lr: 0.02\n",
      "iteration: 149250 loss: 0.0024 lr: 0.02\n",
      "iteration: 149260 loss: 0.0018 lr: 0.02\n",
      "iteration: 149270 loss: 0.0023 lr: 0.02\n",
      "iteration: 149280 loss: 0.0021 lr: 0.02\n",
      "iteration: 149290 loss: 0.0029 lr: 0.02\n",
      "iteration: 149300 loss: 0.0027 lr: 0.02\n",
      "iteration: 149310 loss: 0.0026 lr: 0.02\n",
      "iteration: 149320 loss: 0.0019 lr: 0.02\n",
      "iteration: 149330 loss: 0.0022 lr: 0.02\n",
      "iteration: 149340 loss: 0.0023 lr: 0.02\n",
      "iteration: 149350 loss: 0.0022 lr: 0.02\n",
      "iteration: 149360 loss: 0.0022 lr: 0.02\n",
      "iteration: 149370 loss: 0.0028 lr: 0.02\n",
      "iteration: 149380 loss: 0.0016 lr: 0.02\n",
      "iteration: 149390 loss: 0.0030 lr: 0.02\n",
      "iteration: 149400 loss: 0.0023 lr: 0.02\n",
      "iteration: 149410 loss: 0.0018 lr: 0.02\n",
      "iteration: 149420 loss: 0.0017 lr: 0.02\n",
      "iteration: 149430 loss: 0.0022 lr: 0.02\n",
      "iteration: 149440 loss: 0.0030 lr: 0.02\n",
      "iteration: 149450 loss: 0.0019 lr: 0.02\n",
      "iteration: 149460 loss: 0.0019 lr: 0.02\n",
      "iteration: 149470 loss: 0.0021 lr: 0.02\n",
      "iteration: 149480 loss: 0.0026 lr: 0.02\n",
      "iteration: 149490 loss: 0.0024 lr: 0.02\n",
      "iteration: 149500 loss: 0.0023 lr: 0.02\n",
      "iteration: 149510 loss: 0.0026 lr: 0.02\n",
      "iteration: 149520 loss: 0.0019 lr: 0.02\n",
      "iteration: 149530 loss: 0.0024 lr: 0.02\n",
      "iteration: 149540 loss: 0.0034 lr: 0.02\n",
      "iteration: 149550 loss: 0.0021 lr: 0.02\n",
      "iteration: 149560 loss: 0.0019 lr: 0.02\n",
      "iteration: 149570 loss: 0.0026 lr: 0.02\n",
      "iteration: 149580 loss: 0.0020 lr: 0.02\n",
      "iteration: 149590 loss: 0.0023 lr: 0.02\n",
      "iteration: 149600 loss: 0.0023 lr: 0.02\n",
      "iteration: 149610 loss: 0.0017 lr: 0.02\n",
      "iteration: 149620 loss: 0.0020 lr: 0.02\n",
      "iteration: 149630 loss: 0.0019 lr: 0.02\n",
      "iteration: 149640 loss: 0.0024 lr: 0.02\n",
      "iteration: 149650 loss: 0.0020 lr: 0.02\n",
      "iteration: 149660 loss: 0.0021 lr: 0.02\n",
      "iteration: 149670 loss: 0.0020 lr: 0.02\n",
      "iteration: 149680 loss: 0.0032 lr: 0.02\n",
      "iteration: 149690 loss: 0.0020 lr: 0.02\n",
      "iteration: 149700 loss: 0.0023 lr: 0.02\n",
      "iteration: 149710 loss: 0.0021 lr: 0.02\n",
      "iteration: 149720 loss: 0.0022 lr: 0.02\n",
      "iteration: 149730 loss: 0.0023 lr: 0.02\n",
      "iteration: 149740 loss: 0.0018 lr: 0.02\n",
      "iteration: 149750 loss: 0.0020 lr: 0.02\n",
      "iteration: 149760 loss: 0.0025 lr: 0.02\n",
      "iteration: 149770 loss: 0.0024 lr: 0.02\n",
      "iteration: 149780 loss: 0.0024 lr: 0.02\n",
      "iteration: 149790 loss: 0.0024 lr: 0.02\n",
      "iteration: 149800 loss: 0.0017 lr: 0.02\n",
      "iteration: 149810 loss: 0.0021 lr: 0.02\n",
      "iteration: 149820 loss: 0.0031 lr: 0.02\n",
      "iteration: 149830 loss: 0.0027 lr: 0.02\n",
      "iteration: 149840 loss: 0.0019 lr: 0.02\n",
      "iteration: 149850 loss: 0.0032 lr: 0.02\n",
      "iteration: 149860 loss: 0.0025 lr: 0.02\n",
      "iteration: 149870 loss: 0.0024 lr: 0.02\n",
      "iteration: 149880 loss: 0.0024 lr: 0.02\n",
      "iteration: 149890 loss: 0.0031 lr: 0.02\n",
      "iteration: 149900 loss: 0.0031 lr: 0.02\n",
      "iteration: 149910 loss: 0.0024 lr: 0.02\n",
      "iteration: 149920 loss: 0.0022 lr: 0.02\n",
      "iteration: 149930 loss: 0.0026 lr: 0.02\n",
      "iteration: 149940 loss: 0.0021 lr: 0.02\n",
      "iteration: 149950 loss: 0.0023 lr: 0.02\n",
      "iteration: 149960 loss: 0.0032 lr: 0.02\n",
      "iteration: 149970 loss: 0.0018 lr: 0.02\n",
      "iteration: 149980 loss: 0.0022 lr: 0.02\n",
      "iteration: 149990 loss: 0.0023 lr: 0.02\n",
      "iteration: 150000 loss: 0.0022 lr: 0.02\n",
      "iteration: 150010 loss: 0.0031 lr: 0.02\n",
      "iteration: 150020 loss: 0.0024 lr: 0.02\n",
      "iteration: 150030 loss: 0.0027 lr: 0.02\n",
      "iteration: 150040 loss: 0.0030 lr: 0.02\n",
      "iteration: 150050 loss: 0.0025 lr: 0.02\n",
      "iteration: 150060 loss: 0.0021 lr: 0.02\n",
      "iteration: 150070 loss: 0.0018 lr: 0.02\n",
      "iteration: 150080 loss: 0.0029 lr: 0.02\n",
      "iteration: 150090 loss: 0.0026 lr: 0.02\n",
      "iteration: 150100 loss: 0.0016 lr: 0.02\n",
      "iteration: 150110 loss: 0.0021 lr: 0.02\n",
      "iteration: 150120 loss: 0.0026 lr: 0.02\n",
      "iteration: 150130 loss: 0.0021 lr: 0.02\n",
      "iteration: 150140 loss: 0.0024 lr: 0.02\n",
      "iteration: 150150 loss: 0.0025 lr: 0.02\n",
      "iteration: 150160 loss: 0.0025 lr: 0.02\n",
      "iteration: 150170 loss: 0.0026 lr: 0.02\n",
      "iteration: 150180 loss: 0.0027 lr: 0.02\n",
      "iteration: 150190 loss: 0.0025 lr: 0.02\n",
      "iteration: 150200 loss: 0.0024 lr: 0.02\n",
      "iteration: 150210 loss: 0.0019 lr: 0.02\n",
      "iteration: 150220 loss: 0.0019 lr: 0.02\n",
      "iteration: 150230 loss: 0.0025 lr: 0.02\n",
      "iteration: 150240 loss: 0.0025 lr: 0.02\n",
      "iteration: 150250 loss: 0.0017 lr: 0.02\n",
      "iteration: 150260 loss: 0.0019 lr: 0.02\n",
      "iteration: 150270 loss: 0.0019 lr: 0.02\n",
      "iteration: 150280 loss: 0.0021 lr: 0.02\n",
      "iteration: 150290 loss: 0.0021 lr: 0.02\n",
      "iteration: 150300 loss: 0.0019 lr: 0.02\n",
      "iteration: 150310 loss: 0.0015 lr: 0.02\n",
      "iteration: 150320 loss: 0.0029 lr: 0.02\n",
      "iteration: 150330 loss: 0.0023 lr: 0.02\n",
      "iteration: 150340 loss: 0.0023 lr: 0.02\n",
      "iteration: 150350 loss: 0.0040 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 150360 loss: 0.0028 lr: 0.02\n",
      "iteration: 150370 loss: 0.0020 lr: 0.02\n",
      "iteration: 150380 loss: 0.0024 lr: 0.02\n",
      "iteration: 150390 loss: 0.0019 lr: 0.02\n",
      "iteration: 150400 loss: 0.0023 lr: 0.02\n",
      "iteration: 150410 loss: 0.0024 lr: 0.02\n",
      "iteration: 150420 loss: 0.0026 lr: 0.02\n",
      "iteration: 150430 loss: 0.0024 lr: 0.02\n",
      "iteration: 150440 loss: 0.0019 lr: 0.02\n",
      "iteration: 150450 loss: 0.0023 lr: 0.02\n",
      "iteration: 150460 loss: 0.0018 lr: 0.02\n",
      "iteration: 150470 loss: 0.0022 lr: 0.02\n",
      "iteration: 150480 loss: 0.0021 lr: 0.02\n",
      "iteration: 150490 loss: 0.0020 lr: 0.02\n",
      "iteration: 150500 loss: 0.0021 lr: 0.02\n",
      "iteration: 150510 loss: 0.0020 lr: 0.02\n",
      "iteration: 150520 loss: 0.0026 lr: 0.02\n",
      "iteration: 150530 loss: 0.0023 lr: 0.02\n",
      "iteration: 150540 loss: 0.0020 lr: 0.02\n",
      "iteration: 150550 loss: 0.0021 lr: 0.02\n",
      "iteration: 150560 loss: 0.0022 lr: 0.02\n",
      "iteration: 150570 loss: 0.0026 lr: 0.02\n",
      "iteration: 150580 loss: 0.0021 lr: 0.02\n",
      "iteration: 150590 loss: 0.0022 lr: 0.02\n",
      "iteration: 150600 loss: 0.0027 lr: 0.02\n",
      "iteration: 150610 loss: 0.0019 lr: 0.02\n",
      "iteration: 150620 loss: 0.0016 lr: 0.02\n",
      "iteration: 150630 loss: 0.0026 lr: 0.02\n",
      "iteration: 150640 loss: 0.0021 lr: 0.02\n",
      "iteration: 150650 loss: 0.0018 lr: 0.02\n",
      "iteration: 150660 loss: 0.0020 lr: 0.02\n",
      "iteration: 150670 loss: 0.0020 lr: 0.02\n",
      "iteration: 150680 loss: 0.0016 lr: 0.02\n",
      "iteration: 150690 loss: 0.0023 lr: 0.02\n",
      "iteration: 150700 loss: 0.0023 lr: 0.02\n",
      "iteration: 150710 loss: 0.0025 lr: 0.02\n",
      "iteration: 150720 loss: 0.0032 lr: 0.02\n",
      "iteration: 150730 loss: 0.0024 lr: 0.02\n",
      "iteration: 150740 loss: 0.0019 lr: 0.02\n",
      "iteration: 150750 loss: 0.0020 lr: 0.02\n",
      "iteration: 150760 loss: 0.0021 lr: 0.02\n",
      "iteration: 150770 loss: 0.0023 lr: 0.02\n",
      "iteration: 150780 loss: 0.0027 lr: 0.02\n",
      "iteration: 150790 loss: 0.0022 lr: 0.02\n",
      "iteration: 150800 loss: 0.0019 lr: 0.02\n",
      "iteration: 150810 loss: 0.0019 lr: 0.02\n",
      "iteration: 150820 loss: 0.0027 lr: 0.02\n",
      "iteration: 150830 loss: 0.0020 lr: 0.02\n",
      "iteration: 150840 loss: 0.0023 lr: 0.02\n",
      "iteration: 150850 loss: 0.0020 lr: 0.02\n",
      "iteration: 150860 loss: 0.0022 lr: 0.02\n",
      "iteration: 150870 loss: 0.0024 lr: 0.02\n",
      "iteration: 150880 loss: 0.0025 lr: 0.02\n",
      "iteration: 150890 loss: 0.0027 lr: 0.02\n",
      "iteration: 150900 loss: 0.0024 lr: 0.02\n",
      "iteration: 150910 loss: 0.0026 lr: 0.02\n",
      "iteration: 150920 loss: 0.0020 lr: 0.02\n",
      "iteration: 150930 loss: 0.0021 lr: 0.02\n",
      "iteration: 150940 loss: 0.0029 lr: 0.02\n",
      "iteration: 150950 loss: 0.0023 lr: 0.02\n",
      "iteration: 150960 loss: 0.0024 lr: 0.02\n",
      "iteration: 150970 loss: 0.0021 lr: 0.02\n",
      "iteration: 150980 loss: 0.0025 lr: 0.02\n",
      "iteration: 150990 loss: 0.0020 lr: 0.02\n",
      "iteration: 151000 loss: 0.0017 lr: 0.02\n",
      "iteration: 151010 loss: 0.0025 lr: 0.02\n",
      "iteration: 151020 loss: 0.0024 lr: 0.02\n",
      "iteration: 151030 loss: 0.0025 lr: 0.02\n",
      "iteration: 151040 loss: 0.0022 lr: 0.02\n",
      "iteration: 151050 loss: 0.0032 lr: 0.02\n",
      "iteration: 151060 loss: 0.0030 lr: 0.02\n",
      "iteration: 151070 loss: 0.0024 lr: 0.02\n",
      "iteration: 151080 loss: 0.0022 lr: 0.02\n",
      "iteration: 151090 loss: 0.0017 lr: 0.02\n",
      "iteration: 151100 loss: 0.0020 lr: 0.02\n",
      "iteration: 151110 loss: 0.0024 lr: 0.02\n",
      "iteration: 151120 loss: 0.0023 lr: 0.02\n",
      "iteration: 151130 loss: 0.0026 lr: 0.02\n",
      "iteration: 151140 loss: 0.0021 lr: 0.02\n",
      "iteration: 151150 loss: 0.0019 lr: 0.02\n",
      "iteration: 151160 loss: 0.0049 lr: 0.02\n",
      "iteration: 151170 loss: 0.0016 lr: 0.02\n",
      "iteration: 151180 loss: 0.0021 lr: 0.02\n",
      "iteration: 151190 loss: 0.0017 lr: 0.02\n",
      "iteration: 151200 loss: 0.0024 lr: 0.02\n",
      "iteration: 151210 loss: 0.0029 lr: 0.02\n",
      "iteration: 151220 loss: 0.0021 lr: 0.02\n",
      "iteration: 151230 loss: 0.0027 lr: 0.02\n",
      "iteration: 151240 loss: 0.0024 lr: 0.02\n",
      "iteration: 151250 loss: 0.0018 lr: 0.02\n",
      "iteration: 151260 loss: 0.0024 lr: 0.02\n",
      "iteration: 151270 loss: 0.0021 lr: 0.02\n",
      "iteration: 151280 loss: 0.0020 lr: 0.02\n",
      "iteration: 151290 loss: 0.0016 lr: 0.02\n",
      "iteration: 151300 loss: 0.0023 lr: 0.02\n",
      "iteration: 151310 loss: 0.0021 lr: 0.02\n",
      "iteration: 151320 loss: 0.0021 lr: 0.02\n",
      "iteration: 151330 loss: 0.0022 lr: 0.02\n",
      "iteration: 151340 loss: 0.0022 lr: 0.02\n",
      "iteration: 151350 loss: 0.0027 lr: 0.02\n",
      "iteration: 151360 loss: 0.0026 lr: 0.02\n",
      "iteration: 151370 loss: 0.0021 lr: 0.02\n",
      "iteration: 151380 loss: 0.0018 lr: 0.02\n",
      "iteration: 151390 loss: 0.0021 lr: 0.02\n",
      "iteration: 151400 loss: 0.0027 lr: 0.02\n",
      "iteration: 151410 loss: 0.0027 lr: 0.02\n",
      "iteration: 151420 loss: 0.0035 lr: 0.02\n",
      "iteration: 151430 loss: 0.0032 lr: 0.02\n",
      "iteration: 151440 loss: 0.0030 lr: 0.02\n",
      "iteration: 151450 loss: 0.0024 lr: 0.02\n",
      "iteration: 151460 loss: 0.0026 lr: 0.02\n",
      "iteration: 151470 loss: 0.0021 lr: 0.02\n",
      "iteration: 151480 loss: 0.0024 lr: 0.02\n",
      "iteration: 151490 loss: 0.0018 lr: 0.02\n",
      "iteration: 151500 loss: 0.0020 lr: 0.02\n",
      "iteration: 151510 loss: 0.0020 lr: 0.02\n",
      "iteration: 151520 loss: 0.0018 lr: 0.02\n",
      "iteration: 151530 loss: 0.0023 lr: 0.02\n",
      "iteration: 151540 loss: 0.0017 lr: 0.02\n",
      "iteration: 151550 loss: 0.0022 lr: 0.02\n",
      "iteration: 151560 loss: 0.0030 lr: 0.02\n",
      "iteration: 151570 loss: 0.0019 lr: 0.02\n",
      "iteration: 151580 loss: 0.0022 lr: 0.02\n",
      "iteration: 151590 loss: 0.0022 lr: 0.02\n",
      "iteration: 151600 loss: 0.0023 lr: 0.02\n",
      "iteration: 151610 loss: 0.0022 lr: 0.02\n",
      "iteration: 151620 loss: 0.0025 lr: 0.02\n",
      "iteration: 151630 loss: 0.0026 lr: 0.02\n",
      "iteration: 151640 loss: 0.0030 lr: 0.02\n",
      "iteration: 151650 loss: 0.0017 lr: 0.02\n",
      "iteration: 151660 loss: 0.0022 lr: 0.02\n",
      "iteration: 151670 loss: 0.0020 lr: 0.02\n",
      "iteration: 151680 loss: 0.0020 lr: 0.02\n",
      "iteration: 151690 loss: 0.0021 lr: 0.02\n",
      "iteration: 151700 loss: 0.0030 lr: 0.02\n",
      "iteration: 151710 loss: 0.0019 lr: 0.02\n",
      "iteration: 151720 loss: 0.0026 lr: 0.02\n",
      "iteration: 151730 loss: 0.0022 lr: 0.02\n",
      "iteration: 151740 loss: 0.0019 lr: 0.02\n",
      "iteration: 151750 loss: 0.0019 lr: 0.02\n",
      "iteration: 151760 loss: 0.0023 lr: 0.02\n",
      "iteration: 151770 loss: 0.0024 lr: 0.02\n",
      "iteration: 151780 loss: 0.0021 lr: 0.02\n",
      "iteration: 151790 loss: 0.0029 lr: 0.02\n",
      "iteration: 151800 loss: 0.0022 lr: 0.02\n",
      "iteration: 151810 loss: 0.0021 lr: 0.02\n",
      "iteration: 151820 loss: 0.0024 lr: 0.02\n",
      "iteration: 151830 loss: 0.0021 lr: 0.02\n",
      "iteration: 151840 loss: 0.0026 lr: 0.02\n",
      "iteration: 151850 loss: 0.0024 lr: 0.02\n",
      "iteration: 151860 loss: 0.0027 lr: 0.02\n",
      "iteration: 151870 loss: 0.0018 lr: 0.02\n",
      "iteration: 151880 loss: 0.0023 lr: 0.02\n",
      "iteration: 151890 loss: 0.0022 lr: 0.02\n",
      "iteration: 151900 loss: 0.0027 lr: 0.02\n",
      "iteration: 151910 loss: 0.0028 lr: 0.02\n",
      "iteration: 151920 loss: 0.0017 lr: 0.02\n",
      "iteration: 151930 loss: 0.0026 lr: 0.02\n",
      "iteration: 151940 loss: 0.0020 lr: 0.02\n",
      "iteration: 151950 loss: 0.0022 lr: 0.02\n",
      "iteration: 151960 loss: 0.0021 lr: 0.02\n",
      "iteration: 151970 loss: 0.0025 lr: 0.02\n",
      "iteration: 151980 loss: 0.0017 lr: 0.02\n",
      "iteration: 151990 loss: 0.0020 lr: 0.02\n",
      "iteration: 152000 loss: 0.0023 lr: 0.02\n",
      "iteration: 152010 loss: 0.0020 lr: 0.02\n",
      "iteration: 152020 loss: 0.0024 lr: 0.02\n",
      "iteration: 152030 loss: 0.0023 lr: 0.02\n",
      "iteration: 152040 loss: 0.0017 lr: 0.02\n",
      "iteration: 152050 loss: 0.0030 lr: 0.02\n",
      "iteration: 152060 loss: 0.0032 lr: 0.02\n",
      "iteration: 152070 loss: 0.0023 lr: 0.02\n",
      "iteration: 152080 loss: 0.0022 lr: 0.02\n",
      "iteration: 152090 loss: 0.0020 lr: 0.02\n",
      "iteration: 152100 loss: 0.0019 lr: 0.02\n",
      "iteration: 152110 loss: 0.0023 lr: 0.02\n",
      "iteration: 152120 loss: 0.0023 lr: 0.02\n",
      "iteration: 152130 loss: 0.0022 lr: 0.02\n",
      "iteration: 152140 loss: 0.0025 lr: 0.02\n",
      "iteration: 152150 loss: 0.0022 lr: 0.02\n",
      "iteration: 152160 loss: 0.0027 lr: 0.02\n",
      "iteration: 152170 loss: 0.0026 lr: 0.02\n",
      "iteration: 152180 loss: 0.0023 lr: 0.02\n",
      "iteration: 152190 loss: 0.0022 lr: 0.02\n",
      "iteration: 152200 loss: 0.0027 lr: 0.02\n",
      "iteration: 152210 loss: 0.0024 lr: 0.02\n",
      "iteration: 152220 loss: 0.0025 lr: 0.02\n",
      "iteration: 152230 loss: 0.0022 lr: 0.02\n",
      "iteration: 152240 loss: 0.0022 lr: 0.02\n",
      "iteration: 152250 loss: 0.0027 lr: 0.02\n",
      "iteration: 152260 loss: 0.0025 lr: 0.02\n",
      "iteration: 152270 loss: 0.0019 lr: 0.02\n",
      "iteration: 152280 loss: 0.0022 lr: 0.02\n",
      "iteration: 152290 loss: 0.0019 lr: 0.02\n",
      "iteration: 152300 loss: 0.0030 lr: 0.02\n",
      "iteration: 152310 loss: 0.0023 lr: 0.02\n",
      "iteration: 152320 loss: 0.0022 lr: 0.02\n",
      "iteration: 152330 loss: 0.0023 lr: 0.02\n",
      "iteration: 152340 loss: 0.0021 lr: 0.02\n",
      "iteration: 152350 loss: 0.0025 lr: 0.02\n",
      "iteration: 152360 loss: 0.0022 lr: 0.02\n",
      "iteration: 152370 loss: 0.0022 lr: 0.02\n",
      "iteration: 152380 loss: 0.0029 lr: 0.02\n",
      "iteration: 152390 loss: 0.0020 lr: 0.02\n",
      "iteration: 152400 loss: 0.0035 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 152410 loss: 0.0025 lr: 0.02\n",
      "iteration: 152420 loss: 0.0026 lr: 0.02\n",
      "iteration: 152430 loss: 0.0021 lr: 0.02\n",
      "iteration: 152440 loss: 0.0017 lr: 0.02\n",
      "iteration: 152450 loss: 0.0019 lr: 0.02\n",
      "iteration: 152460 loss: 0.0022 lr: 0.02\n",
      "iteration: 152470 loss: 0.0027 lr: 0.02\n",
      "iteration: 152480 loss: 0.0026 lr: 0.02\n",
      "iteration: 152490 loss: 0.0020 lr: 0.02\n",
      "iteration: 152500 loss: 0.0020 lr: 0.02\n",
      "iteration: 152510 loss: 0.0022 lr: 0.02\n",
      "iteration: 152520 loss: 0.0019 lr: 0.02\n",
      "iteration: 152530 loss: 0.0024 lr: 0.02\n",
      "iteration: 152540 loss: 0.0028 lr: 0.02\n",
      "iteration: 152550 loss: 0.0029 lr: 0.02\n",
      "iteration: 152560 loss: 0.0036 lr: 0.02\n",
      "iteration: 152570 loss: 0.0021 lr: 0.02\n",
      "iteration: 152580 loss: 0.0024 lr: 0.02\n",
      "iteration: 152590 loss: 0.0025 lr: 0.02\n",
      "iteration: 152600 loss: 0.0025 lr: 0.02\n",
      "iteration: 152610 loss: 0.0031 lr: 0.02\n",
      "iteration: 152620 loss: 0.0020 lr: 0.02\n",
      "iteration: 152630 loss: 0.0021 lr: 0.02\n",
      "iteration: 152640 loss: 0.0024 lr: 0.02\n",
      "iteration: 152650 loss: 0.0023 lr: 0.02\n",
      "iteration: 152660 loss: 0.0022 lr: 0.02\n",
      "iteration: 152670 loss: 0.0025 lr: 0.02\n",
      "iteration: 152680 loss: 0.0027 lr: 0.02\n",
      "iteration: 152690 loss: 0.0021 lr: 0.02\n",
      "iteration: 152700 loss: 0.0020 lr: 0.02\n",
      "iteration: 152710 loss: 0.0021 lr: 0.02\n",
      "iteration: 152720 loss: 0.0030 lr: 0.02\n",
      "iteration: 152730 loss: 0.0022 lr: 0.02\n",
      "iteration: 152740 loss: 0.0027 lr: 0.02\n",
      "iteration: 152750 loss: 0.0024 lr: 0.02\n",
      "iteration: 152760 loss: 0.0023 lr: 0.02\n",
      "iteration: 152770 loss: 0.0023 lr: 0.02\n",
      "iteration: 152780 loss: 0.0019 lr: 0.02\n",
      "iteration: 152790 loss: 0.0022 lr: 0.02\n",
      "iteration: 152800 loss: 0.0024 lr: 0.02\n",
      "iteration: 152810 loss: 0.0024 lr: 0.02\n",
      "iteration: 152820 loss: 0.0018 lr: 0.02\n",
      "iteration: 152830 loss: 0.0018 lr: 0.02\n",
      "iteration: 152840 loss: 0.0020 lr: 0.02\n",
      "iteration: 152850 loss: 0.0028 lr: 0.02\n",
      "iteration: 152860 loss: 0.0025 lr: 0.02\n",
      "iteration: 152870 loss: 0.0021 lr: 0.02\n",
      "iteration: 152880 loss: 0.0025 lr: 0.02\n",
      "iteration: 152890 loss: 0.0028 lr: 0.02\n",
      "iteration: 152900 loss: 0.0026 lr: 0.02\n",
      "iteration: 152910 loss: 0.0024 lr: 0.02\n",
      "iteration: 152920 loss: 0.0023 lr: 0.02\n",
      "iteration: 152930 loss: 0.0024 lr: 0.02\n",
      "iteration: 152940 loss: 0.0028 lr: 0.02\n",
      "iteration: 152950 loss: 0.0028 lr: 0.02\n",
      "iteration: 152960 loss: 0.0018 lr: 0.02\n",
      "iteration: 152970 loss: 0.0021 lr: 0.02\n",
      "iteration: 152980 loss: 0.0020 lr: 0.02\n",
      "iteration: 152990 loss: 0.0023 lr: 0.02\n",
      "iteration: 153000 loss: 0.0038 lr: 0.02\n",
      "iteration: 153010 loss: 0.0027 lr: 0.02\n",
      "iteration: 153020 loss: 0.0025 lr: 0.02\n",
      "iteration: 153030 loss: 0.0017 lr: 0.02\n",
      "iteration: 153040 loss: 0.0022 lr: 0.02\n",
      "iteration: 153050 loss: 0.0027 lr: 0.02\n",
      "iteration: 153060 loss: 0.0023 lr: 0.02\n",
      "iteration: 153070 loss: 0.0022 lr: 0.02\n",
      "iteration: 153080 loss: 0.0027 lr: 0.02\n",
      "iteration: 153090 loss: 0.0030 lr: 0.02\n",
      "iteration: 153100 loss: 0.0028 lr: 0.02\n",
      "iteration: 153110 loss: 0.0025 lr: 0.02\n",
      "iteration: 153120 loss: 0.0015 lr: 0.02\n",
      "iteration: 153130 loss: 0.0019 lr: 0.02\n",
      "iteration: 153140 loss: 0.0024 lr: 0.02\n",
      "iteration: 153150 loss: 0.0024 lr: 0.02\n",
      "iteration: 153160 loss: 0.0021 lr: 0.02\n",
      "iteration: 153170 loss: 0.0021 lr: 0.02\n",
      "iteration: 153180 loss: 0.0022 lr: 0.02\n",
      "iteration: 153190 loss: 0.0020 lr: 0.02\n",
      "iteration: 153200 loss: 0.0020 lr: 0.02\n",
      "iteration: 153210 loss: 0.0027 lr: 0.02\n",
      "iteration: 153220 loss: 0.0022 lr: 0.02\n",
      "iteration: 153230 loss: 0.0018 lr: 0.02\n",
      "iteration: 153240 loss: 0.0026 lr: 0.02\n",
      "iteration: 153250 loss: 0.0026 lr: 0.02\n",
      "iteration: 153260 loss: 0.0029 lr: 0.02\n",
      "iteration: 153270 loss: 0.0020 lr: 0.02\n",
      "iteration: 153280 loss: 0.0021 lr: 0.02\n",
      "iteration: 153290 loss: 0.0021 lr: 0.02\n",
      "iteration: 153300 loss: 0.0020 lr: 0.02\n",
      "iteration: 153310 loss: 0.0020 lr: 0.02\n",
      "iteration: 153320 loss: 0.0031 lr: 0.02\n",
      "iteration: 153330 loss: 0.0020 lr: 0.02\n",
      "iteration: 153340 loss: 0.0028 lr: 0.02\n",
      "iteration: 153350 loss: 0.0019 lr: 0.02\n",
      "iteration: 153360 loss: 0.0019 lr: 0.02\n",
      "iteration: 153370 loss: 0.0022 lr: 0.02\n",
      "iteration: 153380 loss: 0.0020 lr: 0.02\n",
      "iteration: 153390 loss: 0.0021 lr: 0.02\n",
      "iteration: 153400 loss: 0.0019 lr: 0.02\n",
      "iteration: 153410 loss: 0.0020 lr: 0.02\n",
      "iteration: 153420 loss: 0.0018 lr: 0.02\n",
      "iteration: 153430 loss: 0.0023 lr: 0.02\n",
      "iteration: 153440 loss: 0.0019 lr: 0.02\n",
      "iteration: 153450 loss: 0.0026 lr: 0.02\n",
      "iteration: 153460 loss: 0.0022 lr: 0.02\n",
      "iteration: 153470 loss: 0.0021 lr: 0.02\n",
      "iteration: 153480 loss: 0.0020 lr: 0.02\n",
      "iteration: 153490 loss: 0.0014 lr: 0.02\n",
      "iteration: 153500 loss: 0.0024 lr: 0.02\n",
      "iteration: 153510 loss: 0.0030 lr: 0.02\n",
      "iteration: 153520 loss: 0.0024 lr: 0.02\n",
      "iteration: 153530 loss: 0.0021 lr: 0.02\n",
      "iteration: 153540 loss: 0.0024 lr: 0.02\n",
      "iteration: 153550 loss: 0.0028 lr: 0.02\n",
      "iteration: 153560 loss: 0.0022 lr: 0.02\n",
      "iteration: 153570 loss: 0.0024 lr: 0.02\n",
      "iteration: 153580 loss: 0.0018 lr: 0.02\n",
      "iteration: 153590 loss: 0.0022 lr: 0.02\n",
      "iteration: 153600 loss: 0.0020 lr: 0.02\n",
      "iteration: 153610 loss: 0.0020 lr: 0.02\n",
      "iteration: 153620 loss: 0.0019 lr: 0.02\n",
      "iteration: 153630 loss: 0.0015 lr: 0.02\n",
      "iteration: 153640 loss: 0.0019 lr: 0.02\n",
      "iteration: 153650 loss: 0.0020 lr: 0.02\n",
      "iteration: 153660 loss: 0.0020 lr: 0.02\n",
      "iteration: 153670 loss: 0.0029 lr: 0.02\n",
      "iteration: 153680 loss: 0.0022 lr: 0.02\n",
      "iteration: 153690 loss: 0.0021 lr: 0.02\n",
      "iteration: 153700 loss: 0.0026 lr: 0.02\n",
      "iteration: 153710 loss: 0.0024 lr: 0.02\n",
      "iteration: 153720 loss: 0.0027 lr: 0.02\n",
      "iteration: 153730 loss: 0.0028 lr: 0.02\n",
      "iteration: 153740 loss: 0.0025 lr: 0.02\n",
      "iteration: 153750 loss: 0.0028 lr: 0.02\n",
      "iteration: 153760 loss: 0.0024 lr: 0.02\n",
      "iteration: 153770 loss: 0.0021 lr: 0.02\n",
      "iteration: 153780 loss: 0.0020 lr: 0.02\n",
      "iteration: 153790 loss: 0.0018 lr: 0.02\n",
      "iteration: 153800 loss: 0.0028 lr: 0.02\n",
      "iteration: 153810 loss: 0.0030 lr: 0.02\n",
      "iteration: 153820 loss: 0.0023 lr: 0.02\n",
      "iteration: 153830 loss: 0.0025 lr: 0.02\n",
      "iteration: 153840 loss: 0.0022 lr: 0.02\n",
      "iteration: 153850 loss: 0.0026 lr: 0.02\n",
      "iteration: 153860 loss: 0.0027 lr: 0.02\n",
      "iteration: 153870 loss: 0.0025 lr: 0.02\n",
      "iteration: 153880 loss: 0.0022 lr: 0.02\n",
      "iteration: 153890 loss: 0.0027 lr: 0.02\n",
      "iteration: 153900 loss: 0.0022 lr: 0.02\n",
      "iteration: 153910 loss: 0.0023 lr: 0.02\n",
      "iteration: 153920 loss: 0.0020 lr: 0.02\n",
      "iteration: 153930 loss: 0.0024 lr: 0.02\n",
      "iteration: 153940 loss: 0.0023 lr: 0.02\n",
      "iteration: 153950 loss: 0.0027 lr: 0.02\n",
      "iteration: 153960 loss: 0.0020 lr: 0.02\n",
      "iteration: 153970 loss: 0.0029 lr: 0.02\n",
      "iteration: 153980 loss: 0.0020 lr: 0.02\n",
      "iteration: 153990 loss: 0.0015 lr: 0.02\n",
      "iteration: 154000 loss: 0.0021 lr: 0.02\n",
      "iteration: 154010 loss: 0.0018 lr: 0.02\n",
      "iteration: 154020 loss: 0.0024 lr: 0.02\n",
      "iteration: 154030 loss: 0.0026 lr: 0.02\n",
      "iteration: 154040 loss: 0.0018 lr: 0.02\n",
      "iteration: 154050 loss: 0.0025 lr: 0.02\n",
      "iteration: 154060 loss: 0.0030 lr: 0.02\n",
      "iteration: 154070 loss: 0.0022 lr: 0.02\n",
      "iteration: 154080 loss: 0.0023 lr: 0.02\n",
      "iteration: 154090 loss: 0.0025 lr: 0.02\n",
      "iteration: 154100 loss: 0.0023 lr: 0.02\n",
      "iteration: 154110 loss: 0.0031 lr: 0.02\n",
      "iteration: 154120 loss: 0.0026 lr: 0.02\n",
      "iteration: 154130 loss: 0.0025 lr: 0.02\n",
      "iteration: 154140 loss: 0.0026 lr: 0.02\n",
      "iteration: 154150 loss: 0.0022 lr: 0.02\n",
      "iteration: 154160 loss: 0.0019 lr: 0.02\n",
      "iteration: 154170 loss: 0.0024 lr: 0.02\n",
      "iteration: 154180 loss: 0.0021 lr: 0.02\n",
      "iteration: 154190 loss: 0.0017 lr: 0.02\n",
      "iteration: 154200 loss: 0.0020 lr: 0.02\n",
      "iteration: 154210 loss: 0.0018 lr: 0.02\n",
      "iteration: 154220 loss: 0.0025 lr: 0.02\n",
      "iteration: 154230 loss: 0.0025 lr: 0.02\n",
      "iteration: 154240 loss: 0.0023 lr: 0.02\n",
      "iteration: 154250 loss: 0.0021 lr: 0.02\n",
      "iteration: 154260 loss: 0.0021 lr: 0.02\n",
      "iteration: 154270 loss: 0.0035 lr: 0.02\n",
      "iteration: 154280 loss: 0.0020 lr: 0.02\n",
      "iteration: 154290 loss: 0.0029 lr: 0.02\n",
      "iteration: 154300 loss: 0.0017 lr: 0.02\n",
      "iteration: 154310 loss: 0.0029 lr: 0.02\n",
      "iteration: 154320 loss: 0.0021 lr: 0.02\n",
      "iteration: 154330 loss: 0.0020 lr: 0.02\n",
      "iteration: 154340 loss: 0.0025 lr: 0.02\n",
      "iteration: 154350 loss: 0.0038 lr: 0.02\n",
      "iteration: 154360 loss: 0.0023 lr: 0.02\n",
      "iteration: 154370 loss: 0.0023 lr: 0.02\n",
      "iteration: 154380 loss: 0.0023 lr: 0.02\n",
      "iteration: 154390 loss: 0.0021 lr: 0.02\n",
      "iteration: 154400 loss: 0.0025 lr: 0.02\n",
      "iteration: 154410 loss: 0.0017 lr: 0.02\n",
      "iteration: 154420 loss: 0.0022 lr: 0.02\n",
      "iteration: 154430 loss: 0.0021 lr: 0.02\n",
      "iteration: 154440 loss: 0.0021 lr: 0.02\n",
      "iteration: 154450 loss: 0.0021 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 154460 loss: 0.0025 lr: 0.02\n",
      "iteration: 154470 loss: 0.0025 lr: 0.02\n",
      "iteration: 154480 loss: 0.0025 lr: 0.02\n",
      "iteration: 154490 loss: 0.0029 lr: 0.02\n",
      "iteration: 154500 loss: 0.0025 lr: 0.02\n",
      "iteration: 154510 loss: 0.0025 lr: 0.02\n",
      "iteration: 154520 loss: 0.0031 lr: 0.02\n",
      "iteration: 154530 loss: 0.0025 lr: 0.02\n",
      "iteration: 154540 loss: 0.0024 lr: 0.02\n",
      "iteration: 154550 loss: 0.0027 lr: 0.02\n",
      "iteration: 154560 loss: 0.0022 lr: 0.02\n",
      "iteration: 154570 loss: 0.0027 lr: 0.02\n",
      "iteration: 154580 loss: 0.0019 lr: 0.02\n",
      "iteration: 154590 loss: 0.0023 lr: 0.02\n",
      "iteration: 154600 loss: 0.0043 lr: 0.02\n",
      "iteration: 154610 loss: 0.0027 lr: 0.02\n",
      "iteration: 154620 loss: 0.0025 lr: 0.02\n",
      "iteration: 154630 loss: 0.0024 lr: 0.02\n",
      "iteration: 154640 loss: 0.0025 lr: 0.02\n",
      "iteration: 154650 loss: 0.0019 lr: 0.02\n",
      "iteration: 154660 loss: 0.0025 lr: 0.02\n",
      "iteration: 154670 loss: 0.0024 lr: 0.02\n",
      "iteration: 154680 loss: 0.0022 lr: 0.02\n",
      "iteration: 154690 loss: 0.0024 lr: 0.02\n",
      "iteration: 154700 loss: 0.0018 lr: 0.02\n",
      "iteration: 154710 loss: 0.0026 lr: 0.02\n",
      "iteration: 154720 loss: 0.0025 lr: 0.02\n",
      "iteration: 154730 loss: 0.0018 lr: 0.02\n",
      "iteration: 154740 loss: 0.0020 lr: 0.02\n",
      "iteration: 154750 loss: 0.0025 lr: 0.02\n",
      "iteration: 154760 loss: 0.0031 lr: 0.02\n",
      "iteration: 154770 loss: 0.0025 lr: 0.02\n",
      "iteration: 154780 loss: 0.0028 lr: 0.02\n",
      "iteration: 154790 loss: 0.0024 lr: 0.02\n",
      "iteration: 154800 loss: 0.0019 lr: 0.02\n",
      "iteration: 154810 loss: 0.0025 lr: 0.02\n",
      "iteration: 154820 loss: 0.0021 lr: 0.02\n",
      "iteration: 154830 loss: 0.0029 lr: 0.02\n",
      "iteration: 154840 loss: 0.0024 lr: 0.02\n",
      "iteration: 154850 loss: 0.0022 lr: 0.02\n",
      "iteration: 154860 loss: 0.0022 lr: 0.02\n",
      "iteration: 154870 loss: 0.0020 lr: 0.02\n",
      "iteration: 154880 loss: 0.0022 lr: 0.02\n",
      "iteration: 154890 loss: 0.0021 lr: 0.02\n",
      "iteration: 154900 loss: 0.0021 lr: 0.02\n",
      "iteration: 154910 loss: 0.0020 lr: 0.02\n",
      "iteration: 154920 loss: 0.0022 lr: 0.02\n",
      "iteration: 154930 loss: 0.0021 lr: 0.02\n",
      "iteration: 154940 loss: 0.0022 lr: 0.02\n",
      "iteration: 154950 loss: 0.0027 lr: 0.02\n",
      "iteration: 154960 loss: 0.0021 lr: 0.02\n",
      "iteration: 154970 loss: 0.0019 lr: 0.02\n",
      "iteration: 154980 loss: 0.0024 lr: 0.02\n",
      "iteration: 154990 loss: 0.0026 lr: 0.02\n",
      "iteration: 155000 loss: 0.0022 lr: 0.02\n",
      "iteration: 155010 loss: 0.0026 lr: 0.02\n",
      "iteration: 155020 loss: 0.0025 lr: 0.02\n",
      "iteration: 155030 loss: 0.0023 lr: 0.02\n",
      "iteration: 155040 loss: 0.0021 lr: 0.02\n",
      "iteration: 155050 loss: 0.0021 lr: 0.02\n",
      "iteration: 155060 loss: 0.0023 lr: 0.02\n",
      "iteration: 155070 loss: 0.0024 lr: 0.02\n",
      "iteration: 155080 loss: 0.0023 lr: 0.02\n",
      "iteration: 155090 loss: 0.0019 lr: 0.02\n",
      "iteration: 155100 loss: 0.0027 lr: 0.02\n",
      "iteration: 155110 loss: 0.0026 lr: 0.02\n",
      "iteration: 155120 loss: 0.0023 lr: 0.02\n",
      "iteration: 155130 loss: 0.0024 lr: 0.02\n",
      "iteration: 155140 loss: 0.0019 lr: 0.02\n",
      "iteration: 155150 loss: 0.0026 lr: 0.02\n",
      "iteration: 155160 loss: 0.0019 lr: 0.02\n",
      "iteration: 155170 loss: 0.0025 lr: 0.02\n",
      "iteration: 155180 loss: 0.0024 lr: 0.02\n",
      "iteration: 155190 loss: 0.0015 lr: 0.02\n",
      "iteration: 155200 loss: 0.0025 lr: 0.02\n",
      "iteration: 155210 loss: 0.0020 lr: 0.02\n",
      "iteration: 155220 loss: 0.0020 lr: 0.02\n",
      "iteration: 155230 loss: 0.0020 lr: 0.02\n",
      "iteration: 155240 loss: 0.0019 lr: 0.02\n",
      "iteration: 155250 loss: 0.0024 lr: 0.02\n",
      "iteration: 155260 loss: 0.0018 lr: 0.02\n",
      "iteration: 155270 loss: 0.0015 lr: 0.02\n",
      "iteration: 155280 loss: 0.0022 lr: 0.02\n",
      "iteration: 155290 loss: 0.0021 lr: 0.02\n",
      "iteration: 155300 loss: 0.0028 lr: 0.02\n",
      "iteration: 155310 loss: 0.0023 lr: 0.02\n",
      "iteration: 155320 loss: 0.0021 lr: 0.02\n",
      "iteration: 155330 loss: 0.0023 lr: 0.02\n",
      "iteration: 155340 loss: 0.0023 lr: 0.02\n",
      "iteration: 155350 loss: 0.0023 lr: 0.02\n",
      "iteration: 155360 loss: 0.0022 lr: 0.02\n",
      "iteration: 155370 loss: 0.0022 lr: 0.02\n",
      "iteration: 155380 loss: 0.0021 lr: 0.02\n",
      "iteration: 155390 loss: 0.0028 lr: 0.02\n",
      "iteration: 155400 loss: 0.0021 lr: 0.02\n",
      "iteration: 155410 loss: 0.0026 lr: 0.02\n",
      "iteration: 155420 loss: 0.0021 lr: 0.02\n",
      "iteration: 155430 loss: 0.0019 lr: 0.02\n",
      "iteration: 155440 loss: 0.0030 lr: 0.02\n",
      "iteration: 155450 loss: 0.0028 lr: 0.02\n",
      "iteration: 155460 loss: 0.0025 lr: 0.02\n",
      "iteration: 155470 loss: 0.0022 lr: 0.02\n",
      "iteration: 155480 loss: 0.0018 lr: 0.02\n",
      "iteration: 155490 loss: 0.0022 lr: 0.02\n",
      "iteration: 155500 loss: 0.0022 lr: 0.02\n",
      "iteration: 155510 loss: 0.0029 lr: 0.02\n",
      "iteration: 155520 loss: 0.0022 lr: 0.02\n",
      "iteration: 155530 loss: 0.0017 lr: 0.02\n",
      "iteration: 155540 loss: 0.0018 lr: 0.02\n",
      "iteration: 155550 loss: 0.0019 lr: 0.02\n",
      "iteration: 155560 loss: 0.0021 lr: 0.02\n",
      "iteration: 155570 loss: 0.0018 lr: 0.02\n",
      "iteration: 155580 loss: 0.0024 lr: 0.02\n",
      "iteration: 155590 loss: 0.0021 lr: 0.02\n",
      "iteration: 155600 loss: 0.0019 lr: 0.02\n",
      "iteration: 155610 loss: 0.0020 lr: 0.02\n",
      "iteration: 155620 loss: 0.0019 lr: 0.02\n",
      "iteration: 155630 loss: 0.0020 lr: 0.02\n",
      "iteration: 155640 loss: 0.0021 lr: 0.02\n",
      "iteration: 155650 loss: 0.0023 lr: 0.02\n",
      "iteration: 155660 loss: 0.0024 lr: 0.02\n",
      "iteration: 155670 loss: 0.0023 lr: 0.02\n",
      "iteration: 155680 loss: 0.0024 lr: 0.02\n",
      "iteration: 155690 loss: 0.0028 lr: 0.02\n",
      "iteration: 155700 loss: 0.0021 lr: 0.02\n",
      "iteration: 155710 loss: 0.0022 lr: 0.02\n",
      "iteration: 155720 loss: 0.0023 lr: 0.02\n",
      "iteration: 155730 loss: 0.0023 lr: 0.02\n",
      "iteration: 155740 loss: 0.0022 lr: 0.02\n",
      "iteration: 155750 loss: 0.0026 lr: 0.02\n",
      "iteration: 155760 loss: 0.0020 lr: 0.02\n",
      "iteration: 155770 loss: 0.0024 lr: 0.02\n",
      "iteration: 155780 loss: 0.0023 lr: 0.02\n",
      "iteration: 155790 loss: 0.0021 lr: 0.02\n",
      "iteration: 155800 loss: 0.0023 lr: 0.02\n",
      "iteration: 155810 loss: 0.0016 lr: 0.02\n",
      "iteration: 155820 loss: 0.0029 lr: 0.02\n",
      "iteration: 155830 loss: 0.0020 lr: 0.02\n",
      "iteration: 155840 loss: 0.0017 lr: 0.02\n",
      "iteration: 155850 loss: 0.0026 lr: 0.02\n",
      "iteration: 155860 loss: 0.0021 lr: 0.02\n",
      "iteration: 155870 loss: 0.0019 lr: 0.02\n",
      "iteration: 155880 loss: 0.0023 lr: 0.02\n",
      "iteration: 155890 loss: 0.0026 lr: 0.02\n",
      "iteration: 155900 loss: 0.0020 lr: 0.02\n",
      "iteration: 155910 loss: 0.0025 lr: 0.02\n",
      "iteration: 155920 loss: 0.0026 lr: 0.02\n",
      "iteration: 155930 loss: 0.0018 lr: 0.02\n",
      "iteration: 155940 loss: 0.0020 lr: 0.02\n",
      "iteration: 155950 loss: 0.0030 lr: 0.02\n",
      "iteration: 155960 loss: 0.0021 lr: 0.02\n",
      "iteration: 155970 loss: 0.0026 lr: 0.02\n",
      "iteration: 155980 loss: 0.0020 lr: 0.02\n",
      "iteration: 155990 loss: 0.0022 lr: 0.02\n",
      "iteration: 156000 loss: 0.0020 lr: 0.02\n",
      "iteration: 156010 loss: 0.0025 lr: 0.02\n",
      "iteration: 156020 loss: 0.0019 lr: 0.02\n",
      "iteration: 156030 loss: 0.0021 lr: 0.02\n",
      "iteration: 156040 loss: 0.0022 lr: 0.02\n",
      "iteration: 156050 loss: 0.0022 lr: 0.02\n",
      "iteration: 156060 loss: 0.0022 lr: 0.02\n",
      "iteration: 156070 loss: 0.0020 lr: 0.02\n",
      "iteration: 156080 loss: 0.0026 lr: 0.02\n",
      "iteration: 156090 loss: 0.0021 lr: 0.02\n",
      "iteration: 156100 loss: 0.0024 lr: 0.02\n",
      "iteration: 156110 loss: 0.0026 lr: 0.02\n",
      "iteration: 156120 loss: 0.0020 lr: 0.02\n",
      "iteration: 156130 loss: 0.0022 lr: 0.02\n",
      "iteration: 156140 loss: 0.0024 lr: 0.02\n",
      "iteration: 156150 loss: 0.0025 lr: 0.02\n",
      "iteration: 156160 loss: 0.0014 lr: 0.02\n",
      "iteration: 156170 loss: 0.0026 lr: 0.02\n",
      "iteration: 156180 loss: 0.0030 lr: 0.02\n",
      "iteration: 156190 loss: 0.0020 lr: 0.02\n",
      "iteration: 156200 loss: 0.0024 lr: 0.02\n",
      "iteration: 156210 loss: 0.0020 lr: 0.02\n",
      "iteration: 156220 loss: 0.0025 lr: 0.02\n",
      "iteration: 156230 loss: 0.0023 lr: 0.02\n",
      "iteration: 156240 loss: 0.0025 lr: 0.02\n",
      "iteration: 156250 loss: 0.0027 lr: 0.02\n",
      "iteration: 156260 loss: 0.0026 lr: 0.02\n",
      "iteration: 156270 loss: 0.0022 lr: 0.02\n",
      "iteration: 156280 loss: 0.0020 lr: 0.02\n",
      "iteration: 156290 loss: 0.0019 lr: 0.02\n",
      "iteration: 156300 loss: 0.0018 lr: 0.02\n",
      "iteration: 156310 loss: 0.0021 lr: 0.02\n",
      "iteration: 156320 loss: 0.0024 lr: 0.02\n",
      "iteration: 156330 loss: 0.0023 lr: 0.02\n",
      "iteration: 156340 loss: 0.0020 lr: 0.02\n",
      "iteration: 156350 loss: 0.0021 lr: 0.02\n",
      "iteration: 156360 loss: 0.0025 lr: 0.02\n",
      "iteration: 156370 loss: 0.0023 lr: 0.02\n",
      "iteration: 156380 loss: 0.0019 lr: 0.02\n",
      "iteration: 156390 loss: 0.0024 lr: 0.02\n",
      "iteration: 156400 loss: 0.0021 lr: 0.02\n",
      "iteration: 156410 loss: 0.0020 lr: 0.02\n",
      "iteration: 156420 loss: 0.0020 lr: 0.02\n",
      "iteration: 156430 loss: 0.0024 lr: 0.02\n",
      "iteration: 156440 loss: 0.0023 lr: 0.02\n",
      "iteration: 156450 loss: 0.0026 lr: 0.02\n",
      "iteration: 156460 loss: 0.0022 lr: 0.02\n",
      "iteration: 156470 loss: 0.0028 lr: 0.02\n",
      "iteration: 156480 loss: 0.0015 lr: 0.02\n",
      "iteration: 156490 loss: 0.0024 lr: 0.02\n",
      "iteration: 156500 loss: 0.0019 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 156510 loss: 0.0020 lr: 0.02\n",
      "iteration: 156520 loss: 0.0019 lr: 0.02\n",
      "iteration: 156530 loss: 0.0020 lr: 0.02\n",
      "iteration: 156540 loss: 0.0024 lr: 0.02\n",
      "iteration: 156550 loss: 0.0022 lr: 0.02\n",
      "iteration: 156560 loss: 0.0023 lr: 0.02\n",
      "iteration: 156570 loss: 0.0021 lr: 0.02\n",
      "iteration: 156580 loss: 0.0018 lr: 0.02\n",
      "iteration: 156590 loss: 0.0023 lr: 0.02\n",
      "iteration: 156600 loss: 0.0025 lr: 0.02\n",
      "iteration: 156610 loss: 0.0021 lr: 0.02\n",
      "iteration: 156620 loss: 0.0016 lr: 0.02\n",
      "iteration: 156630 loss: 0.0022 lr: 0.02\n",
      "iteration: 156640 loss: 0.0022 lr: 0.02\n",
      "iteration: 156650 loss: 0.0023 lr: 0.02\n",
      "iteration: 156660 loss: 0.0019 lr: 0.02\n",
      "iteration: 156670 loss: 0.0026 lr: 0.02\n",
      "iteration: 156680 loss: 0.0019 lr: 0.02\n",
      "iteration: 156690 loss: 0.0019 lr: 0.02\n",
      "iteration: 156700 loss: 0.0022 lr: 0.02\n",
      "iteration: 156710 loss: 0.0023 lr: 0.02\n",
      "iteration: 156720 loss: 0.0021 lr: 0.02\n",
      "iteration: 156730 loss: 0.0023 lr: 0.02\n",
      "iteration: 156740 loss: 0.0017 lr: 0.02\n",
      "iteration: 156750 loss: 0.0025 lr: 0.02\n",
      "iteration: 156760 loss: 0.0023 lr: 0.02\n",
      "iteration: 156770 loss: 0.0019 lr: 0.02\n",
      "iteration: 156780 loss: 0.0017 lr: 0.02\n",
      "iteration: 156790 loss: 0.0017 lr: 0.02\n",
      "iteration: 156800 loss: 0.0028 lr: 0.02\n",
      "iteration: 156810 loss: 0.0022 lr: 0.02\n",
      "iteration: 156820 loss: 0.0021 lr: 0.02\n",
      "iteration: 156830 loss: 0.0017 lr: 0.02\n",
      "iteration: 156840 loss: 0.0022 lr: 0.02\n",
      "iteration: 156850 loss: 0.0026 lr: 0.02\n",
      "iteration: 156860 loss: 0.0020 lr: 0.02\n",
      "iteration: 156870 loss: 0.0022 lr: 0.02\n",
      "iteration: 156880 loss: 0.0023 lr: 0.02\n",
      "iteration: 156890 loss: 0.0019 lr: 0.02\n",
      "iteration: 156900 loss: 0.0024 lr: 0.02\n",
      "iteration: 156910 loss: 0.0023 lr: 0.02\n",
      "iteration: 156920 loss: 0.0026 lr: 0.02\n",
      "iteration: 156930 loss: 0.0027 lr: 0.02\n",
      "iteration: 156940 loss: 0.0018 lr: 0.02\n",
      "iteration: 156950 loss: 0.0019 lr: 0.02\n",
      "iteration: 156960 loss: 0.0016 lr: 0.02\n",
      "iteration: 156970 loss: 0.0023 lr: 0.02\n",
      "iteration: 156980 loss: 0.0025 lr: 0.02\n",
      "iteration: 156990 loss: 0.0025 lr: 0.02\n",
      "iteration: 157000 loss: 0.0019 lr: 0.02\n",
      "iteration: 157010 loss: 0.0023 lr: 0.02\n",
      "iteration: 157020 loss: 0.0018 lr: 0.02\n",
      "iteration: 157030 loss: 0.0026 lr: 0.02\n",
      "iteration: 157040 loss: 0.0022 lr: 0.02\n",
      "iteration: 157050 loss: 0.0026 lr: 0.02\n",
      "iteration: 157060 loss: 0.0023 lr: 0.02\n",
      "iteration: 157070 loss: 0.0029 lr: 0.02\n",
      "iteration: 157080 loss: 0.0022 lr: 0.02\n",
      "iteration: 157090 loss: 0.0018 lr: 0.02\n",
      "iteration: 157100 loss: 0.0019 lr: 0.02\n",
      "iteration: 157110 loss: 0.0023 lr: 0.02\n",
      "iteration: 157120 loss: 0.0030 lr: 0.02\n",
      "iteration: 157130 loss: 0.0021 lr: 0.02\n",
      "iteration: 157140 loss: 0.0022 lr: 0.02\n",
      "iteration: 157150 loss: 0.0023 lr: 0.02\n",
      "iteration: 157160 loss: 0.0023 lr: 0.02\n",
      "iteration: 157170 loss: 0.0017 lr: 0.02\n",
      "iteration: 157180 loss: 0.0016 lr: 0.02\n",
      "iteration: 157190 loss: 0.0017 lr: 0.02\n",
      "iteration: 157200 loss: 0.0031 lr: 0.02\n",
      "iteration: 157210 loss: 0.0017 lr: 0.02\n",
      "iteration: 157220 loss: 0.0018 lr: 0.02\n",
      "iteration: 157230 loss: 0.0022 lr: 0.02\n",
      "iteration: 157240 loss: 0.0021 lr: 0.02\n",
      "iteration: 157250 loss: 0.0018 lr: 0.02\n",
      "iteration: 157260 loss: 0.0022 lr: 0.02\n",
      "iteration: 157270 loss: 0.0023 lr: 0.02\n",
      "iteration: 157280 loss: 0.0023 lr: 0.02\n",
      "iteration: 157290 loss: 0.0026 lr: 0.02\n",
      "iteration: 157300 loss: 0.0019 lr: 0.02\n",
      "iteration: 157310 loss: 0.0021 lr: 0.02\n",
      "iteration: 157320 loss: 0.0034 lr: 0.02\n",
      "iteration: 157330 loss: 0.0023 lr: 0.02\n",
      "iteration: 157340 loss: 0.0024 lr: 0.02\n",
      "iteration: 157350 loss: 0.0026 lr: 0.02\n",
      "iteration: 157360 loss: 0.0026 lr: 0.02\n",
      "iteration: 157370 loss: 0.0019 lr: 0.02\n",
      "iteration: 157380 loss: 0.0024 lr: 0.02\n",
      "iteration: 157390 loss: 0.0020 lr: 0.02\n",
      "iteration: 157400 loss: 0.0015 lr: 0.02\n",
      "iteration: 157410 loss: 0.0020 lr: 0.02\n",
      "iteration: 157420 loss: 0.0021 lr: 0.02\n",
      "iteration: 157430 loss: 0.0022 lr: 0.02\n",
      "iteration: 157440 loss: 0.0025 lr: 0.02\n",
      "iteration: 157450 loss: 0.0020 lr: 0.02\n",
      "iteration: 157460 loss: 0.0023 lr: 0.02\n",
      "iteration: 157470 loss: 0.0016 lr: 0.02\n",
      "iteration: 157480 loss: 0.0018 lr: 0.02\n",
      "iteration: 157490 loss: 0.0024 lr: 0.02\n",
      "iteration: 157500 loss: 0.0024 lr: 0.02\n",
      "iteration: 157510 loss: 0.0020 lr: 0.02\n",
      "iteration: 157520 loss: 0.0021 lr: 0.02\n",
      "iteration: 157530 loss: 0.0018 lr: 0.02\n",
      "iteration: 157540 loss: 0.0017 lr: 0.02\n",
      "iteration: 157550 loss: 0.0020 lr: 0.02\n",
      "iteration: 157560 loss: 0.0023 lr: 0.02\n",
      "iteration: 157570 loss: 0.0021 lr: 0.02\n",
      "iteration: 157580 loss: 0.0022 lr: 0.02\n",
      "iteration: 157590 loss: 0.0022 lr: 0.02\n",
      "iteration: 157600 loss: 0.0027 lr: 0.02\n",
      "iteration: 157610 loss: 0.0028 lr: 0.02\n",
      "iteration: 157620 loss: 0.0020 lr: 0.02\n",
      "iteration: 157630 loss: 0.0026 lr: 0.02\n",
      "iteration: 157640 loss: 0.0027 lr: 0.02\n",
      "iteration: 157650 loss: 0.0021 lr: 0.02\n",
      "iteration: 157660 loss: 0.0021 lr: 0.02\n",
      "iteration: 157670 loss: 0.0022 lr: 0.02\n",
      "iteration: 157680 loss: 0.0021 lr: 0.02\n",
      "iteration: 157690 loss: 0.0018 lr: 0.02\n",
      "iteration: 157700 loss: 0.0021 lr: 0.02\n",
      "iteration: 157710 loss: 0.0019 lr: 0.02\n",
      "iteration: 157720 loss: 0.0019 lr: 0.02\n",
      "iteration: 157730 loss: 0.0021 lr: 0.02\n",
      "iteration: 157740 loss: 0.0018 lr: 0.02\n",
      "iteration: 157750 loss: 0.0021 lr: 0.02\n",
      "iteration: 157760 loss: 0.0025 lr: 0.02\n",
      "iteration: 157770 loss: 0.0025 lr: 0.02\n",
      "iteration: 157780 loss: 0.0022 lr: 0.02\n",
      "iteration: 157790 loss: 0.0021 lr: 0.02\n",
      "iteration: 157800 loss: 0.0026 lr: 0.02\n",
      "iteration: 157810 loss: 0.0020 lr: 0.02\n",
      "iteration: 157820 loss: 0.0020 lr: 0.02\n",
      "iteration: 157830 loss: 0.0023 lr: 0.02\n",
      "iteration: 157840 loss: 0.0019 lr: 0.02\n",
      "iteration: 157850 loss: 0.0022 lr: 0.02\n",
      "iteration: 157860 loss: 0.0023 lr: 0.02\n",
      "iteration: 157870 loss: 0.0021 lr: 0.02\n",
      "iteration: 157880 loss: 0.0031 lr: 0.02\n",
      "iteration: 157890 loss: 0.0016 lr: 0.02\n",
      "iteration: 157900 loss: 0.0019 lr: 0.02\n",
      "iteration: 157910 loss: 0.0021 lr: 0.02\n",
      "iteration: 157920 loss: 0.0029 lr: 0.02\n",
      "iteration: 157930 loss: 0.0026 lr: 0.02\n",
      "iteration: 157940 loss: 0.0028 lr: 0.02\n",
      "iteration: 157950 loss: 0.0022 lr: 0.02\n",
      "iteration: 157960 loss: 0.0034 lr: 0.02\n",
      "iteration: 157970 loss: 0.0033 lr: 0.02\n",
      "iteration: 157980 loss: 0.0021 lr: 0.02\n",
      "iteration: 157990 loss: 0.0027 lr: 0.02\n",
      "iteration: 158000 loss: 0.0021 lr: 0.02\n",
      "iteration: 158010 loss: 0.0029 lr: 0.02\n",
      "iteration: 158020 loss: 0.0015 lr: 0.02\n",
      "iteration: 158030 loss: 0.0020 lr: 0.02\n",
      "iteration: 158040 loss: 0.0029 lr: 0.02\n",
      "iteration: 158050 loss: 0.0026 lr: 0.02\n",
      "iteration: 158060 loss: 0.0023 lr: 0.02\n",
      "iteration: 158070 loss: 0.0027 lr: 0.02\n",
      "iteration: 158080 loss: 0.0025 lr: 0.02\n",
      "iteration: 158090 loss: 0.0025 lr: 0.02\n",
      "iteration: 158100 loss: 0.0023 lr: 0.02\n",
      "iteration: 158110 loss: 0.0023 lr: 0.02\n",
      "iteration: 158120 loss: 0.0024 lr: 0.02\n",
      "iteration: 158130 loss: 0.0022 lr: 0.02\n",
      "iteration: 158140 loss: 0.0022 lr: 0.02\n",
      "iteration: 158150 loss: 0.0022 lr: 0.02\n",
      "iteration: 158160 loss: 0.0026 lr: 0.02\n",
      "iteration: 158170 loss: 0.0029 lr: 0.02\n",
      "iteration: 158180 loss: 0.0021 lr: 0.02\n",
      "iteration: 158190 loss: 0.0017 lr: 0.02\n",
      "iteration: 158200 loss: 0.0018 lr: 0.02\n",
      "iteration: 158210 loss: 0.0019 lr: 0.02\n",
      "iteration: 158220 loss: 0.0024 lr: 0.02\n",
      "iteration: 158230 loss: 0.0022 lr: 0.02\n",
      "iteration: 158240 loss: 0.0020 lr: 0.02\n",
      "iteration: 158250 loss: 0.0018 lr: 0.02\n",
      "iteration: 158260 loss: 0.0023 lr: 0.02\n",
      "iteration: 158270 loss: 0.0019 lr: 0.02\n",
      "iteration: 158280 loss: 0.0026 lr: 0.02\n",
      "iteration: 158290 loss: 0.0022 lr: 0.02\n",
      "iteration: 158300 loss: 0.0019 lr: 0.02\n",
      "iteration: 158310 loss: 0.0016 lr: 0.02\n",
      "iteration: 158320 loss: 0.0026 lr: 0.02\n",
      "iteration: 158330 loss: 0.0025 lr: 0.02\n",
      "iteration: 158340 loss: 0.0025 lr: 0.02\n",
      "iteration: 158350 loss: 0.0019 lr: 0.02\n",
      "iteration: 158360 loss: 0.0023 lr: 0.02\n",
      "iteration: 158370 loss: 0.0025 lr: 0.02\n",
      "iteration: 158380 loss: 0.0019 lr: 0.02\n",
      "iteration: 158390 loss: 0.0017 lr: 0.02\n",
      "iteration: 158400 loss: 0.0017 lr: 0.02\n",
      "iteration: 158410 loss: 0.0022 lr: 0.02\n",
      "iteration: 158420 loss: 0.0029 lr: 0.02\n",
      "iteration: 158430 loss: 0.0028 lr: 0.02\n",
      "iteration: 158440 loss: 0.0019 lr: 0.02\n",
      "iteration: 158450 loss: 0.0019 lr: 0.02\n",
      "iteration: 158460 loss: 0.0027 lr: 0.02\n",
      "iteration: 158470 loss: 0.0031 lr: 0.02\n",
      "iteration: 158480 loss: 0.0020 lr: 0.02\n",
      "iteration: 158490 loss: 0.0016 lr: 0.02\n",
      "iteration: 158500 loss: 0.0018 lr: 0.02\n",
      "iteration: 158510 loss: 0.0017 lr: 0.02\n",
      "iteration: 158520 loss: 0.0032 lr: 0.02\n",
      "iteration: 158530 loss: 0.0023 lr: 0.02\n",
      "iteration: 158540 loss: 0.0021 lr: 0.02\n",
      "iteration: 158550 loss: 0.0021 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 158560 loss: 0.0017 lr: 0.02\n",
      "iteration: 158570 loss: 0.0025 lr: 0.02\n",
      "iteration: 158580 loss: 0.0024 lr: 0.02\n",
      "iteration: 158590 loss: 0.0020 lr: 0.02\n",
      "iteration: 158600 loss: 0.0021 lr: 0.02\n",
      "iteration: 158610 loss: 0.0027 lr: 0.02\n",
      "iteration: 158620 loss: 0.0026 lr: 0.02\n",
      "iteration: 158630 loss: 0.0026 lr: 0.02\n",
      "iteration: 158640 loss: 0.0019 lr: 0.02\n",
      "iteration: 158650 loss: 0.0027 lr: 0.02\n",
      "iteration: 158660 loss: 0.0026 lr: 0.02\n",
      "iteration: 158670 loss: 0.0022 lr: 0.02\n",
      "iteration: 158680 loss: 0.0023 lr: 0.02\n",
      "iteration: 158690 loss: 0.0026 lr: 0.02\n",
      "iteration: 158700 loss: 0.0025 lr: 0.02\n",
      "iteration: 158710 loss: 0.0021 lr: 0.02\n",
      "iteration: 158720 loss: 0.0019 lr: 0.02\n",
      "iteration: 158730 loss: 0.0027 lr: 0.02\n",
      "iteration: 158740 loss: 0.0019 lr: 0.02\n",
      "iteration: 158750 loss: 0.0022 lr: 0.02\n",
      "iteration: 158760 loss: 0.0018 lr: 0.02\n",
      "iteration: 158770 loss: 0.0023 lr: 0.02\n",
      "iteration: 158780 loss: 0.0021 lr: 0.02\n",
      "iteration: 158790 loss: 0.0024 lr: 0.02\n",
      "iteration: 158800 loss: 0.0026 lr: 0.02\n",
      "iteration: 158810 loss: 0.0023 lr: 0.02\n",
      "iteration: 158820 loss: 0.0026 lr: 0.02\n",
      "iteration: 158830 loss: 0.0029 lr: 0.02\n",
      "iteration: 158840 loss: 0.0027 lr: 0.02\n",
      "iteration: 158850 loss: 0.0022 lr: 0.02\n",
      "iteration: 158860 loss: 0.0020 lr: 0.02\n",
      "iteration: 158870 loss: 0.0019 lr: 0.02\n",
      "iteration: 158880 loss: 0.0023 lr: 0.02\n",
      "iteration: 158890 loss: 0.0022 lr: 0.02\n",
      "iteration: 158900 loss: 0.0020 lr: 0.02\n",
      "iteration: 158910 loss: 0.0020 lr: 0.02\n",
      "iteration: 158920 loss: 0.0023 lr: 0.02\n",
      "iteration: 158930 loss: 0.0026 lr: 0.02\n",
      "iteration: 158940 loss: 0.0025 lr: 0.02\n",
      "iteration: 158950 loss: 0.0023 lr: 0.02\n",
      "iteration: 158960 loss: 0.0023 lr: 0.02\n",
      "iteration: 158970 loss: 0.0024 lr: 0.02\n",
      "iteration: 158980 loss: 0.0026 lr: 0.02\n",
      "iteration: 158990 loss: 0.0023 lr: 0.02\n",
      "iteration: 159000 loss: 0.0026 lr: 0.02\n",
      "iteration: 159010 loss: 0.0027 lr: 0.02\n",
      "iteration: 159020 loss: 0.0023 lr: 0.02\n",
      "iteration: 159030 loss: 0.0020 lr: 0.02\n",
      "iteration: 159040 loss: 0.0024 lr: 0.02\n",
      "iteration: 159050 loss: 0.0015 lr: 0.02\n",
      "iteration: 159060 loss: 0.0018 lr: 0.02\n",
      "iteration: 159070 loss: 0.0019 lr: 0.02\n",
      "iteration: 159080 loss: 0.0021 lr: 0.02\n",
      "iteration: 159090 loss: 0.0023 lr: 0.02\n",
      "iteration: 159100 loss: 0.0029 lr: 0.02\n",
      "iteration: 159110 loss: 0.0018 lr: 0.02\n",
      "iteration: 159120 loss: 0.0022 lr: 0.02\n",
      "iteration: 159130 loss: 0.0021 lr: 0.02\n",
      "iteration: 159140 loss: 0.0019 lr: 0.02\n",
      "iteration: 159150 loss: 0.0020 lr: 0.02\n",
      "iteration: 159160 loss: 0.0021 lr: 0.02\n",
      "iteration: 159170 loss: 0.0020 lr: 0.02\n",
      "iteration: 159180 loss: 0.0018 lr: 0.02\n",
      "iteration: 159190 loss: 0.0025 lr: 0.02\n",
      "iteration: 159200 loss: 0.0018 lr: 0.02\n",
      "iteration: 159210 loss: 0.0022 lr: 0.02\n",
      "iteration: 159220 loss: 0.0021 lr: 0.02\n",
      "iteration: 159230 loss: 0.0023 lr: 0.02\n",
      "iteration: 159240 loss: 0.0020 lr: 0.02\n",
      "iteration: 159250 loss: 0.0023 lr: 0.02\n",
      "iteration: 159260 loss: 0.0028 lr: 0.02\n",
      "iteration: 159270 loss: 0.0022 lr: 0.02\n",
      "iteration: 159280 loss: 0.0022 lr: 0.02\n",
      "iteration: 159290 loss: 0.0025 lr: 0.02\n",
      "iteration: 159300 loss: 0.0022 lr: 0.02\n",
      "iteration: 159310 loss: 0.0022 lr: 0.02\n",
      "iteration: 159320 loss: 0.0020 lr: 0.02\n",
      "iteration: 159330 loss: 0.0029 lr: 0.02\n",
      "iteration: 159340 loss: 0.0024 lr: 0.02\n",
      "iteration: 159350 loss: 0.0027 lr: 0.02\n",
      "iteration: 159360 loss: 0.0023 lr: 0.02\n",
      "iteration: 159370 loss: 0.0029 lr: 0.02\n",
      "iteration: 159380 loss: 0.0021 lr: 0.02\n",
      "iteration: 159390 loss: 0.0027 lr: 0.02\n",
      "iteration: 159400 loss: 0.0019 lr: 0.02\n",
      "iteration: 159410 loss: 0.0023 lr: 0.02\n",
      "iteration: 159420 loss: 0.0025 lr: 0.02\n",
      "iteration: 159430 loss: 0.0020 lr: 0.02\n",
      "iteration: 159440 loss: 0.0023 lr: 0.02\n",
      "iteration: 159450 loss: 0.0017 lr: 0.02\n",
      "iteration: 159460 loss: 0.0021 lr: 0.02\n",
      "iteration: 159470 loss: 0.0034 lr: 0.02\n",
      "iteration: 159480 loss: 0.0022 lr: 0.02\n",
      "iteration: 159490 loss: 0.0019 lr: 0.02\n",
      "iteration: 159500 loss: 0.0024 lr: 0.02\n",
      "iteration: 159510 loss: 0.0020 lr: 0.02\n",
      "iteration: 159520 loss: 0.0021 lr: 0.02\n",
      "iteration: 159530 loss: 0.0020 lr: 0.02\n",
      "iteration: 159540 loss: 0.0017 lr: 0.02\n",
      "iteration: 159550 loss: 0.0016 lr: 0.02\n",
      "iteration: 159560 loss: 0.0021 lr: 0.02\n",
      "iteration: 159570 loss: 0.0025 lr: 0.02\n",
      "iteration: 159580 loss: 0.0026 lr: 0.02\n",
      "iteration: 159590 loss: 0.0026 lr: 0.02\n",
      "iteration: 159600 loss: 0.0023 lr: 0.02\n",
      "iteration: 159610 loss: 0.0020 lr: 0.02\n",
      "iteration: 159620 loss: 0.0019 lr: 0.02\n",
      "iteration: 159630 loss: 0.0018 lr: 0.02\n",
      "iteration: 159640 loss: 0.0023 lr: 0.02\n",
      "iteration: 159650 loss: 0.0021 lr: 0.02\n",
      "iteration: 159660 loss: 0.0020 lr: 0.02\n",
      "iteration: 159670 loss: 0.0023 lr: 0.02\n",
      "iteration: 159680 loss: 0.0017 lr: 0.02\n",
      "iteration: 159690 loss: 0.0024 lr: 0.02\n",
      "iteration: 159700 loss: 0.0020 lr: 0.02\n",
      "iteration: 159710 loss: 0.0023 lr: 0.02\n",
      "iteration: 159720 loss: 0.0020 lr: 0.02\n",
      "iteration: 159730 loss: 0.0026 lr: 0.02\n",
      "iteration: 159740 loss: 0.0023 lr: 0.02\n",
      "iteration: 159750 loss: 0.0019 lr: 0.02\n",
      "iteration: 159760 loss: 0.0027 lr: 0.02\n",
      "iteration: 159770 loss: 0.0032 lr: 0.02\n",
      "iteration: 159780 loss: 0.0020 lr: 0.02\n",
      "iteration: 159790 loss: 0.0025 lr: 0.02\n",
      "iteration: 159800 loss: 0.0025 lr: 0.02\n",
      "iteration: 159810 loss: 0.0021 lr: 0.02\n",
      "iteration: 159820 loss: 0.0019 lr: 0.02\n",
      "iteration: 159830 loss: 0.0025 lr: 0.02\n",
      "iteration: 159840 loss: 0.0025 lr: 0.02\n",
      "iteration: 159850 loss: 0.0018 lr: 0.02\n",
      "iteration: 159860 loss: 0.0022 lr: 0.02\n",
      "iteration: 159870 loss: 0.0021 lr: 0.02\n",
      "iteration: 159880 loss: 0.0026 lr: 0.02\n",
      "iteration: 159890 loss: 0.0021 lr: 0.02\n",
      "iteration: 159900 loss: 0.0018 lr: 0.02\n",
      "iteration: 159910 loss: 0.0019 lr: 0.02\n",
      "iteration: 159920 loss: 0.0026 lr: 0.02\n",
      "iteration: 159930 loss: 0.0022 lr: 0.02\n",
      "iteration: 159940 loss: 0.0023 lr: 0.02\n",
      "iteration: 159950 loss: 0.0022 lr: 0.02\n",
      "iteration: 159960 loss: 0.0024 lr: 0.02\n",
      "iteration: 159970 loss: 0.0023 lr: 0.02\n",
      "iteration: 159980 loss: 0.0023 lr: 0.02\n",
      "iteration: 159990 loss: 0.0021 lr: 0.02\n",
      "iteration: 160000 loss: 0.0021 lr: 0.02\n",
      "iteration: 160010 loss: 0.0024 lr: 0.02\n",
      "iteration: 160020 loss: 0.0024 lr: 0.02\n",
      "iteration: 160030 loss: 0.0027 lr: 0.02\n",
      "iteration: 160040 loss: 0.0023 lr: 0.02\n",
      "iteration: 160050 loss: 0.0026 lr: 0.02\n",
      "iteration: 160060 loss: 0.0029 lr: 0.02\n",
      "iteration: 160070 loss: 0.0020 lr: 0.02\n",
      "iteration: 160080 loss: 0.0019 lr: 0.02\n",
      "iteration: 160090 loss: 0.0019 lr: 0.02\n",
      "iteration: 160100 loss: 0.0020 lr: 0.02\n",
      "iteration: 160110 loss: 0.0022 lr: 0.02\n",
      "iteration: 160120 loss: 0.0019 lr: 0.02\n",
      "iteration: 160130 loss: 0.0028 lr: 0.02\n",
      "iteration: 160140 loss: 0.0022 lr: 0.02\n",
      "iteration: 160150 loss: 0.0023 lr: 0.02\n",
      "iteration: 160160 loss: 0.0025 lr: 0.02\n",
      "iteration: 160170 loss: 0.0025 lr: 0.02\n",
      "iteration: 160180 loss: 0.0019 lr: 0.02\n",
      "iteration: 160190 loss: 0.0024 lr: 0.02\n",
      "iteration: 160200 loss: 0.0029 lr: 0.02\n",
      "iteration: 160210 loss: 0.0025 lr: 0.02\n",
      "iteration: 160220 loss: 0.0019 lr: 0.02\n",
      "iteration: 160230 loss: 0.0023 lr: 0.02\n",
      "iteration: 160240 loss: 0.0020 lr: 0.02\n",
      "iteration: 160250 loss: 0.0020 lr: 0.02\n",
      "iteration: 160260 loss: 0.0016 lr: 0.02\n",
      "iteration: 160270 loss: 0.0023 lr: 0.02\n",
      "iteration: 160280 loss: 0.0022 lr: 0.02\n",
      "iteration: 160290 loss: 0.0025 lr: 0.02\n",
      "iteration: 160300 loss: 0.0018 lr: 0.02\n",
      "iteration: 160310 loss: 0.0022 lr: 0.02\n",
      "iteration: 160320 loss: 0.0024 lr: 0.02\n",
      "iteration: 160330 loss: 0.0022 lr: 0.02\n",
      "iteration: 160340 loss: 0.0018 lr: 0.02\n",
      "iteration: 160350 loss: 0.0019 lr: 0.02\n",
      "iteration: 160360 loss: 0.0024 lr: 0.02\n",
      "iteration: 160370 loss: 0.0022 lr: 0.02\n",
      "iteration: 160380 loss: 0.0023 lr: 0.02\n",
      "iteration: 160390 loss: 0.0022 lr: 0.02\n",
      "iteration: 160400 loss: 0.0024 lr: 0.02\n",
      "iteration: 160410 loss: 0.0019 lr: 0.02\n",
      "iteration: 160420 loss: 0.0018 lr: 0.02\n",
      "iteration: 160430 loss: 0.0019 lr: 0.02\n",
      "iteration: 160440 loss: 0.0022 lr: 0.02\n",
      "iteration: 160450 loss: 0.0020 lr: 0.02\n",
      "iteration: 160460 loss: 0.0022 lr: 0.02\n",
      "iteration: 160470 loss: 0.0021 lr: 0.02\n",
      "iteration: 160480 loss: 0.0023 lr: 0.02\n",
      "iteration: 160490 loss: 0.0022 lr: 0.02\n",
      "iteration: 160500 loss: 0.0020 lr: 0.02\n",
      "iteration: 160510 loss: 0.0019 lr: 0.02\n",
      "iteration: 160520 loss: 0.0031 lr: 0.02\n",
      "iteration: 160530 loss: 0.0024 lr: 0.02\n",
      "iteration: 160540 loss: 0.0021 lr: 0.02\n",
      "iteration: 160550 loss: 0.0029 lr: 0.02\n",
      "iteration: 160560 loss: 0.0019 lr: 0.02\n",
      "iteration: 160570 loss: 0.0025 lr: 0.02\n",
      "iteration: 160580 loss: 0.0021 lr: 0.02\n",
      "iteration: 160590 loss: 0.0025 lr: 0.02\n",
      "iteration: 160600 loss: 0.0018 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 160610 loss: 0.0025 lr: 0.02\n",
      "iteration: 160620 loss: 0.0019 lr: 0.02\n",
      "iteration: 160630 loss: 0.0017 lr: 0.02\n",
      "iteration: 160640 loss: 0.0026 lr: 0.02\n",
      "iteration: 160650 loss: 0.0027 lr: 0.02\n",
      "iteration: 160660 loss: 0.0017 lr: 0.02\n",
      "iteration: 160670 loss: 0.0035 lr: 0.02\n",
      "iteration: 160680 loss: 0.0030 lr: 0.02\n",
      "iteration: 160690 loss: 0.0022 lr: 0.02\n",
      "iteration: 160700 loss: 0.0022 lr: 0.02\n",
      "iteration: 160710 loss: 0.0020 lr: 0.02\n",
      "iteration: 160720 loss: 0.0021 lr: 0.02\n",
      "iteration: 160730 loss: 0.0033 lr: 0.02\n",
      "iteration: 160740 loss: 0.0020 lr: 0.02\n",
      "iteration: 160750 loss: 0.0021 lr: 0.02\n",
      "iteration: 160760 loss: 0.0034 lr: 0.02\n",
      "iteration: 160770 loss: 0.0022 lr: 0.02\n",
      "iteration: 160780 loss: 0.0024 lr: 0.02\n",
      "iteration: 160790 loss: 0.0031 lr: 0.02\n",
      "iteration: 160800 loss: 0.0021 lr: 0.02\n",
      "iteration: 160810 loss: 0.0025 lr: 0.02\n",
      "iteration: 160820 loss: 0.0022 lr: 0.02\n",
      "iteration: 160830 loss: 0.0022 lr: 0.02\n",
      "iteration: 160840 loss: 0.0027 lr: 0.02\n",
      "iteration: 160850 loss: 0.0018 lr: 0.02\n",
      "iteration: 160860 loss: 0.0026 lr: 0.02\n",
      "iteration: 160870 loss: 0.0025 lr: 0.02\n",
      "iteration: 160880 loss: 0.0018 lr: 0.02\n",
      "iteration: 160890 loss: 0.0027 lr: 0.02\n",
      "iteration: 160900 loss: 0.0020 lr: 0.02\n",
      "iteration: 160910 loss: 0.0016 lr: 0.02\n",
      "iteration: 160920 loss: 0.0022 lr: 0.02\n",
      "iteration: 160930 loss: 0.0028 lr: 0.02\n",
      "iteration: 160940 loss: 0.0024 lr: 0.02\n",
      "iteration: 160950 loss: 0.0019 lr: 0.02\n",
      "iteration: 160960 loss: 0.0022 lr: 0.02\n",
      "iteration: 160970 loss: 0.0021 lr: 0.02\n",
      "iteration: 160980 loss: 0.0022 lr: 0.02\n",
      "iteration: 160990 loss: 0.0026 lr: 0.02\n",
      "iteration: 161000 loss: 0.0026 lr: 0.02\n",
      "iteration: 161010 loss: 0.0024 lr: 0.02\n",
      "iteration: 161020 loss: 0.0023 lr: 0.02\n",
      "iteration: 161030 loss: 0.0026 lr: 0.02\n",
      "iteration: 161040 loss: 0.0029 lr: 0.02\n",
      "iteration: 161050 loss: 0.0027 lr: 0.02\n",
      "iteration: 161060 loss: 0.0020 lr: 0.02\n",
      "iteration: 161070 loss: 0.0021 lr: 0.02\n",
      "iteration: 161080 loss: 0.0022 lr: 0.02\n",
      "iteration: 161090 loss: 0.0017 lr: 0.02\n",
      "iteration: 161100 loss: 0.0019 lr: 0.02\n",
      "iteration: 161110 loss: 0.0026 lr: 0.02\n",
      "iteration: 161120 loss: 0.0019 lr: 0.02\n",
      "iteration: 161130 loss: 0.0024 lr: 0.02\n",
      "iteration: 161140 loss: 0.0020 lr: 0.02\n",
      "iteration: 161150 loss: 0.0015 lr: 0.02\n",
      "iteration: 161160 loss: 0.0023 lr: 0.02\n",
      "iteration: 161170 loss: 0.0018 lr: 0.02\n",
      "iteration: 161180 loss: 0.0016 lr: 0.02\n",
      "iteration: 161190 loss: 0.0022 lr: 0.02\n",
      "iteration: 161200 loss: 0.0022 lr: 0.02\n",
      "iteration: 161210 loss: 0.0025 lr: 0.02\n",
      "iteration: 161220 loss: 0.0024 lr: 0.02\n",
      "iteration: 161230 loss: 0.0025 lr: 0.02\n",
      "iteration: 161240 loss: 0.0023 lr: 0.02\n",
      "iteration: 161250 loss: 0.0016 lr: 0.02\n",
      "iteration: 161260 loss: 0.0033 lr: 0.02\n",
      "iteration: 161270 loss: 0.0021 lr: 0.02\n",
      "iteration: 161280 loss: 0.0023 lr: 0.02\n",
      "iteration: 161290 loss: 0.0026 lr: 0.02\n",
      "iteration: 161300 loss: 0.0023 lr: 0.02\n",
      "iteration: 161310 loss: 0.0021 lr: 0.02\n",
      "iteration: 161320 loss: 0.0019 lr: 0.02\n",
      "iteration: 161330 loss: 0.0019 lr: 0.02\n",
      "iteration: 161340 loss: 0.0023 lr: 0.02\n",
      "iteration: 161350 loss: 0.0021 lr: 0.02\n",
      "iteration: 161360 loss: 0.0024 lr: 0.02\n",
      "iteration: 161370 loss: 0.0018 lr: 0.02\n",
      "iteration: 161380 loss: 0.0022 lr: 0.02\n",
      "iteration: 161390 loss: 0.0016 lr: 0.02\n",
      "iteration: 161400 loss: 0.0025 lr: 0.02\n",
      "iteration: 161410 loss: 0.0025 lr: 0.02\n",
      "iteration: 161420 loss: 0.0023 lr: 0.02\n",
      "iteration: 161430 loss: 0.0019 lr: 0.02\n",
      "iteration: 161440 loss: 0.0022 lr: 0.02\n",
      "iteration: 161450 loss: 0.0027 lr: 0.02\n",
      "iteration: 161460 loss: 0.0030 lr: 0.02\n",
      "iteration: 161470 loss: 0.0023 lr: 0.02\n",
      "iteration: 161480 loss: 0.0018 lr: 0.02\n",
      "iteration: 161490 loss: 0.0025 lr: 0.02\n",
      "iteration: 161500 loss: 0.0024 lr: 0.02\n",
      "iteration: 161510 loss: 0.0022 lr: 0.02\n",
      "iteration: 161520 loss: 0.0021 lr: 0.02\n",
      "iteration: 161530 loss: 0.0019 lr: 0.02\n",
      "iteration: 161540 loss: 0.0022 lr: 0.02\n",
      "iteration: 161550 loss: 0.0020 lr: 0.02\n",
      "iteration: 161560 loss: 0.0028 lr: 0.02\n",
      "iteration: 161570 loss: 0.0022 lr: 0.02\n",
      "iteration: 161580 loss: 0.0016 lr: 0.02\n",
      "iteration: 161590 loss: 0.0021 lr: 0.02\n",
      "iteration: 161600 loss: 0.0020 lr: 0.02\n",
      "iteration: 161610 loss: 0.0020 lr: 0.02\n",
      "iteration: 161620 loss: 0.0019 lr: 0.02\n",
      "iteration: 161630 loss: 0.0025 lr: 0.02\n",
      "iteration: 161640 loss: 0.0028 lr: 0.02\n",
      "iteration: 161650 loss: 0.0023 lr: 0.02\n",
      "iteration: 161660 loss: 0.0026 lr: 0.02\n",
      "iteration: 161670 loss: 0.0023 lr: 0.02\n",
      "iteration: 161680 loss: 0.0026 lr: 0.02\n",
      "iteration: 161690 loss: 0.0020 lr: 0.02\n",
      "iteration: 161700 loss: 0.0027 lr: 0.02\n",
      "iteration: 161710 loss: 0.0023 lr: 0.02\n",
      "iteration: 161720 loss: 0.0022 lr: 0.02\n",
      "iteration: 161730 loss: 0.0018 lr: 0.02\n",
      "iteration: 161740 loss: 0.0020 lr: 0.02\n",
      "iteration: 161750 loss: 0.0017 lr: 0.02\n",
      "iteration: 161760 loss: 0.0023 lr: 0.02\n",
      "iteration: 161770 loss: 0.0023 lr: 0.02\n",
      "iteration: 161780 loss: 0.0019 lr: 0.02\n",
      "iteration: 161790 loss: 0.0021 lr: 0.02\n",
      "iteration: 161800 loss: 0.0018 lr: 0.02\n",
      "iteration: 161810 loss: 0.0024 lr: 0.02\n",
      "iteration: 161820 loss: 0.0021 lr: 0.02\n",
      "iteration: 161830 loss: 0.0018 lr: 0.02\n",
      "iteration: 161840 loss: 0.0028 lr: 0.02\n",
      "iteration: 161850 loss: 0.0018 lr: 0.02\n",
      "iteration: 161860 loss: 0.0023 lr: 0.02\n",
      "iteration: 161870 loss: 0.0027 lr: 0.02\n",
      "iteration: 161880 loss: 0.0019 lr: 0.02\n",
      "iteration: 161890 loss: 0.0027 lr: 0.02\n",
      "iteration: 161900 loss: 0.0021 lr: 0.02\n",
      "iteration: 161910 loss: 0.0024 lr: 0.02\n",
      "iteration: 161920 loss: 0.0030 lr: 0.02\n",
      "iteration: 161930 loss: 0.0020 lr: 0.02\n",
      "iteration: 161940 loss: 0.0024 lr: 0.02\n",
      "iteration: 161950 loss: 0.0023 lr: 0.02\n",
      "iteration: 161960 loss: 0.0020 lr: 0.02\n",
      "iteration: 161970 loss: 0.0018 lr: 0.02\n",
      "iteration: 161980 loss: 0.0019 lr: 0.02\n",
      "iteration: 161990 loss: 0.0027 lr: 0.02\n",
      "iteration: 162000 loss: 0.0028 lr: 0.02\n",
      "iteration: 162010 loss: 0.0029 lr: 0.02\n",
      "iteration: 162020 loss: 0.0019 lr: 0.02\n",
      "iteration: 162030 loss: 0.0019 lr: 0.02\n",
      "iteration: 162040 loss: 0.0022 lr: 0.02\n",
      "iteration: 162050 loss: 0.0023 lr: 0.02\n",
      "iteration: 162060 loss: 0.0022 lr: 0.02\n",
      "iteration: 162070 loss: 0.0017 lr: 0.02\n",
      "iteration: 162080 loss: 0.0023 lr: 0.02\n",
      "iteration: 162090 loss: 0.0027 lr: 0.02\n",
      "iteration: 162100 loss: 0.0025 lr: 0.02\n",
      "iteration: 162110 loss: 0.0022 lr: 0.02\n",
      "iteration: 162120 loss: 0.0018 lr: 0.02\n",
      "iteration: 162130 loss: 0.0022 lr: 0.02\n",
      "iteration: 162140 loss: 0.0040 lr: 0.02\n",
      "iteration: 162150 loss: 0.0018 lr: 0.02\n",
      "iteration: 162160 loss: 0.0017 lr: 0.02\n",
      "iteration: 162170 loss: 0.0023 lr: 0.02\n",
      "iteration: 162180 loss: 0.0023 lr: 0.02\n",
      "iteration: 162190 loss: 0.0023 lr: 0.02\n",
      "iteration: 162200 loss: 0.0017 lr: 0.02\n",
      "iteration: 162210 loss: 0.0024 lr: 0.02\n",
      "iteration: 162220 loss: 0.0027 lr: 0.02\n",
      "iteration: 162230 loss: 0.0027 lr: 0.02\n",
      "iteration: 162240 loss: 0.0020 lr: 0.02\n",
      "iteration: 162250 loss: 0.0024 lr: 0.02\n",
      "iteration: 162260 loss: 0.0018 lr: 0.02\n",
      "iteration: 162270 loss: 0.0028 lr: 0.02\n",
      "iteration: 162280 loss: 0.0021 lr: 0.02\n",
      "iteration: 162290 loss: 0.0019 lr: 0.02\n",
      "iteration: 162300 loss: 0.0024 lr: 0.02\n",
      "iteration: 162310 loss: 0.0020 lr: 0.02\n",
      "iteration: 162320 loss: 0.0019 lr: 0.02\n",
      "iteration: 162330 loss: 0.0021 lr: 0.02\n",
      "iteration: 162340 loss: 0.0017 lr: 0.02\n",
      "iteration: 162350 loss: 0.0023 lr: 0.02\n",
      "iteration: 162360 loss: 0.0019 lr: 0.02\n",
      "iteration: 162370 loss: 0.0024 lr: 0.02\n",
      "iteration: 162380 loss: 0.0021 lr: 0.02\n",
      "iteration: 162390 loss: 0.0029 lr: 0.02\n",
      "iteration: 162400 loss: 0.0020 lr: 0.02\n",
      "iteration: 162410 loss: 0.0020 lr: 0.02\n",
      "iteration: 162420 loss: 0.0018 lr: 0.02\n",
      "iteration: 162430 loss: 0.0022 lr: 0.02\n",
      "iteration: 162440 loss: 0.0024 lr: 0.02\n",
      "iteration: 162450 loss: 0.0021 lr: 0.02\n",
      "iteration: 162460 loss: 0.0019 lr: 0.02\n",
      "iteration: 162470 loss: 0.0021 lr: 0.02\n",
      "iteration: 162480 loss: 0.0024 lr: 0.02\n",
      "iteration: 162490 loss: 0.0024 lr: 0.02\n",
      "iteration: 162500 loss: 0.0017 lr: 0.02\n",
      "iteration: 162510 loss: 0.0023 lr: 0.02\n",
      "iteration: 162520 loss: 0.0024 lr: 0.02\n",
      "iteration: 162530 loss: 0.0022 lr: 0.02\n",
      "iteration: 162540 loss: 0.0019 lr: 0.02\n",
      "iteration: 162550 loss: 0.0024 lr: 0.02\n",
      "iteration: 162560 loss: 0.0029 lr: 0.02\n",
      "iteration: 162570 loss: 0.0018 lr: 0.02\n",
      "iteration: 162580 loss: 0.0019 lr: 0.02\n",
      "iteration: 162590 loss: 0.0025 lr: 0.02\n",
      "iteration: 162600 loss: 0.0020 lr: 0.02\n",
      "iteration: 162610 loss: 0.0017 lr: 0.02\n",
      "iteration: 162620 loss: 0.0021 lr: 0.02\n",
      "iteration: 162630 loss: 0.0020 lr: 0.02\n",
      "iteration: 162640 loss: 0.0017 lr: 0.02\n",
      "iteration: 162650 loss: 0.0017 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 162660 loss: 0.0026 lr: 0.02\n",
      "iteration: 162670 loss: 0.0020 lr: 0.02\n",
      "iteration: 162680 loss: 0.0021 lr: 0.02\n",
      "iteration: 162690 loss: 0.0023 lr: 0.02\n",
      "iteration: 162700 loss: 0.0022 lr: 0.02\n",
      "iteration: 162710 loss: 0.0016 lr: 0.02\n",
      "iteration: 162720 loss: 0.0019 lr: 0.02\n",
      "iteration: 162730 loss: 0.0021 lr: 0.02\n",
      "iteration: 162740 loss: 0.0021 lr: 0.02\n",
      "iteration: 162750 loss: 0.0022 lr: 0.02\n",
      "iteration: 162760 loss: 0.0021 lr: 0.02\n",
      "iteration: 162770 loss: 0.0023 lr: 0.02\n",
      "iteration: 162780 loss: 0.0023 lr: 0.02\n",
      "iteration: 162790 loss: 0.0025 lr: 0.02\n",
      "iteration: 162800 loss: 0.0021 lr: 0.02\n",
      "iteration: 162810 loss: 0.0017 lr: 0.02\n",
      "iteration: 162820 loss: 0.0016 lr: 0.02\n",
      "iteration: 162830 loss: 0.0022 lr: 0.02\n",
      "iteration: 162840 loss: 0.0021 lr: 0.02\n",
      "iteration: 162850 loss: 0.0022 lr: 0.02\n",
      "iteration: 162860 loss: 0.0029 lr: 0.02\n",
      "iteration: 162870 loss: 0.0022 lr: 0.02\n",
      "iteration: 162880 loss: 0.0017 lr: 0.02\n",
      "iteration: 162890 loss: 0.0021 lr: 0.02\n",
      "iteration: 162900 loss: 0.0021 lr: 0.02\n",
      "iteration: 162910 loss: 0.0025 lr: 0.02\n",
      "iteration: 162920 loss: 0.0020 lr: 0.02\n",
      "iteration: 162930 loss: 0.0018 lr: 0.02\n",
      "iteration: 162940 loss: 0.0021 lr: 0.02\n",
      "iteration: 162950 loss: 0.0024 lr: 0.02\n",
      "iteration: 162960 loss: 0.0020 lr: 0.02\n",
      "iteration: 162970 loss: 0.0022 lr: 0.02\n",
      "iteration: 162980 loss: 0.0016 lr: 0.02\n",
      "iteration: 162990 loss: 0.0018 lr: 0.02\n",
      "iteration: 163000 loss: 0.0021 lr: 0.02\n",
      "iteration: 163010 loss: 0.0021 lr: 0.02\n",
      "iteration: 163020 loss: 0.0019 lr: 0.02\n",
      "iteration: 163030 loss: 0.0022 lr: 0.02\n",
      "iteration: 163040 loss: 0.0018 lr: 0.02\n",
      "iteration: 163050 loss: 0.0024 lr: 0.02\n",
      "iteration: 163060 loss: 0.0024 lr: 0.02\n",
      "iteration: 163070 loss: 0.0018 lr: 0.02\n",
      "iteration: 163080 loss: 0.0023 lr: 0.02\n",
      "iteration: 163090 loss: 0.0020 lr: 0.02\n",
      "iteration: 163100 loss: 0.0021 lr: 0.02\n",
      "iteration: 163110 loss: 0.0028 lr: 0.02\n",
      "iteration: 163120 loss: 0.0020 lr: 0.02\n",
      "iteration: 163130 loss: 0.0018 lr: 0.02\n",
      "iteration: 163140 loss: 0.0028 lr: 0.02\n",
      "iteration: 163150 loss: 0.0023 lr: 0.02\n",
      "iteration: 163160 loss: 0.0022 lr: 0.02\n",
      "iteration: 163170 loss: 0.0024 lr: 0.02\n",
      "iteration: 163180 loss: 0.0017 lr: 0.02\n",
      "iteration: 163190 loss: 0.0026 lr: 0.02\n",
      "iteration: 163200 loss: 0.0022 lr: 0.02\n",
      "iteration: 163210 loss: 0.0027 lr: 0.02\n",
      "iteration: 163220 loss: 0.0023 lr: 0.02\n",
      "iteration: 163230 loss: 0.0021 lr: 0.02\n",
      "iteration: 163240 loss: 0.0027 lr: 0.02\n",
      "iteration: 163250 loss: 0.0018 lr: 0.02\n",
      "iteration: 163260 loss: 0.0021 lr: 0.02\n",
      "iteration: 163270 loss: 0.0020 lr: 0.02\n",
      "iteration: 163280 loss: 0.0022 lr: 0.02\n",
      "iteration: 163290 loss: 0.0022 lr: 0.02\n",
      "iteration: 163300 loss: 0.0019 lr: 0.02\n",
      "iteration: 163310 loss: 0.0018 lr: 0.02\n",
      "iteration: 163320 loss: 0.0019 lr: 0.02\n",
      "iteration: 163330 loss: 0.0026 lr: 0.02\n",
      "iteration: 163340 loss: 0.0021 lr: 0.02\n",
      "iteration: 163350 loss: 0.0015 lr: 0.02\n",
      "iteration: 163360 loss: 0.0023 lr: 0.02\n",
      "iteration: 163370 loss: 0.0020 lr: 0.02\n",
      "iteration: 163380 loss: 0.0026 lr: 0.02\n",
      "iteration: 163390 loss: 0.0024 lr: 0.02\n",
      "iteration: 163400 loss: 0.0018 lr: 0.02\n",
      "iteration: 163410 loss: 0.0020 lr: 0.02\n",
      "iteration: 163420 loss: 0.0024 lr: 0.02\n",
      "iteration: 163430 loss: 0.0021 lr: 0.02\n",
      "iteration: 163440 loss: 0.0026 lr: 0.02\n",
      "iteration: 163450 loss: 0.0021 lr: 0.02\n",
      "iteration: 163460 loss: 0.0026 lr: 0.02\n",
      "iteration: 163470 loss: 0.0023 lr: 0.02\n",
      "iteration: 163480 loss: 0.0023 lr: 0.02\n",
      "iteration: 163490 loss: 0.0023 lr: 0.02\n",
      "iteration: 163500 loss: 0.0016 lr: 0.02\n",
      "iteration: 163510 loss: 0.0018 lr: 0.02\n",
      "iteration: 163520 loss: 0.0019 lr: 0.02\n",
      "iteration: 163530 loss: 0.0022 lr: 0.02\n",
      "iteration: 163540 loss: 0.0024 lr: 0.02\n",
      "iteration: 163550 loss: 0.0026 lr: 0.02\n",
      "iteration: 163560 loss: 0.0024 lr: 0.02\n",
      "iteration: 163570 loss: 0.0020 lr: 0.02\n",
      "iteration: 163580 loss: 0.0021 lr: 0.02\n",
      "iteration: 163590 loss: 0.0019 lr: 0.02\n",
      "iteration: 163600 loss: 0.0024 lr: 0.02\n",
      "iteration: 163610 loss: 0.0035 lr: 0.02\n",
      "iteration: 163620 loss: 0.0022 lr: 0.02\n",
      "iteration: 163630 loss: 0.0029 lr: 0.02\n",
      "iteration: 163640 loss: 0.0025 lr: 0.02\n",
      "iteration: 163650 loss: 0.0023 lr: 0.02\n",
      "iteration: 163660 loss: 0.0023 lr: 0.02\n",
      "iteration: 163670 loss: 0.0025 lr: 0.02\n",
      "iteration: 163680 loss: 0.0021 lr: 0.02\n",
      "iteration: 163690 loss: 0.0022 lr: 0.02\n",
      "iteration: 163700 loss: 0.0018 lr: 0.02\n",
      "iteration: 163710 loss: 0.0019 lr: 0.02\n",
      "iteration: 163720 loss: 0.0022 lr: 0.02\n",
      "iteration: 163730 loss: 0.0018 lr: 0.02\n",
      "iteration: 163740 loss: 0.0022 lr: 0.02\n",
      "iteration: 163750 loss: 0.0019 lr: 0.02\n",
      "iteration: 163760 loss: 0.0023 lr: 0.02\n",
      "iteration: 163770 loss: 0.0019 lr: 0.02\n",
      "iteration: 163780 loss: 0.0016 lr: 0.02\n",
      "iteration: 163790 loss: 0.0015 lr: 0.02\n",
      "iteration: 163800 loss: 0.0027 lr: 0.02\n",
      "iteration: 163810 loss: 0.0025 lr: 0.02\n",
      "iteration: 163820 loss: 0.0022 lr: 0.02\n",
      "iteration: 163830 loss: 0.0018 lr: 0.02\n",
      "iteration: 163840 loss: 0.0022 lr: 0.02\n",
      "iteration: 163850 loss: 0.0033 lr: 0.02\n",
      "iteration: 163860 loss: 0.0026 lr: 0.02\n",
      "iteration: 163870 loss: 0.0025 lr: 0.02\n",
      "iteration: 163880 loss: 0.0023 lr: 0.02\n",
      "iteration: 163890 loss: 0.0026 lr: 0.02\n",
      "iteration: 163900 loss: 0.0020 lr: 0.02\n",
      "iteration: 163910 loss: 0.0026 lr: 0.02\n",
      "iteration: 163920 loss: 0.0021 lr: 0.02\n",
      "iteration: 163930 loss: 0.0025 lr: 0.02\n",
      "iteration: 163940 loss: 0.0018 lr: 0.02\n",
      "iteration: 163950 loss: 0.0020 lr: 0.02\n",
      "iteration: 163960 loss: 0.0023 lr: 0.02\n",
      "iteration: 163970 loss: 0.0015 lr: 0.02\n",
      "iteration: 163980 loss: 0.0029 lr: 0.02\n",
      "iteration: 163990 loss: 0.0019 lr: 0.02\n",
      "iteration: 164000 loss: 0.0019 lr: 0.02\n",
      "iteration: 164010 loss: 0.0024 lr: 0.02\n",
      "iteration: 164020 loss: 0.0018 lr: 0.02\n",
      "iteration: 164030 loss: 0.0022 lr: 0.02\n",
      "iteration: 164040 loss: 0.0018 lr: 0.02\n",
      "iteration: 164050 loss: 0.0025 lr: 0.02\n",
      "iteration: 164060 loss: 0.0024 lr: 0.02\n",
      "iteration: 164070 loss: 0.0032 lr: 0.02\n",
      "iteration: 164080 loss: 0.0016 lr: 0.02\n",
      "iteration: 164090 loss: 0.0025 lr: 0.02\n",
      "iteration: 164100 loss: 0.0023 lr: 0.02\n",
      "iteration: 164110 loss: 0.0027 lr: 0.02\n",
      "iteration: 164120 loss: 0.0027 lr: 0.02\n",
      "iteration: 164130 loss: 0.0025 lr: 0.02\n",
      "iteration: 164140 loss: 0.0020 lr: 0.02\n",
      "iteration: 164150 loss: 0.0022 lr: 0.02\n",
      "iteration: 164160 loss: 0.0019 lr: 0.02\n",
      "iteration: 164170 loss: 0.0024 lr: 0.02\n",
      "iteration: 164180 loss: 0.0039 lr: 0.02\n",
      "iteration: 164190 loss: 0.0022 lr: 0.02\n",
      "iteration: 164200 loss: 0.0021 lr: 0.02\n",
      "iteration: 164210 loss: 0.0028 lr: 0.02\n",
      "iteration: 164220 loss: 0.0019 lr: 0.02\n",
      "iteration: 164230 loss: 0.0021 lr: 0.02\n",
      "iteration: 164240 loss: 0.0020 lr: 0.02\n",
      "iteration: 164250 loss: 0.0020 lr: 0.02\n",
      "iteration: 164260 loss: 0.0019 lr: 0.02\n",
      "iteration: 164270 loss: 0.0025 lr: 0.02\n",
      "iteration: 164280 loss: 0.0032 lr: 0.02\n",
      "iteration: 164290 loss: 0.0019 lr: 0.02\n",
      "iteration: 164300 loss: 0.0020 lr: 0.02\n",
      "iteration: 164310 loss: 0.0018 lr: 0.02\n",
      "iteration: 164320 loss: 0.0023 lr: 0.02\n",
      "iteration: 164330 loss: 0.0020 lr: 0.02\n",
      "iteration: 164340 loss: 0.0026 lr: 0.02\n",
      "iteration: 164350 loss: 0.0017 lr: 0.02\n",
      "iteration: 164360 loss: 0.0022 lr: 0.02\n",
      "iteration: 164370 loss: 0.0023 lr: 0.02\n",
      "iteration: 164380 loss: 0.0019 lr: 0.02\n",
      "iteration: 164390 loss: 0.0017 lr: 0.02\n",
      "iteration: 164400 loss: 0.0021 lr: 0.02\n",
      "iteration: 164410 loss: 0.0027 lr: 0.02\n",
      "iteration: 164420 loss: 0.0022 lr: 0.02\n",
      "iteration: 164430 loss: 0.0027 lr: 0.02\n",
      "iteration: 164440 loss: 0.0031 lr: 0.02\n",
      "iteration: 164450 loss: 0.0025 lr: 0.02\n",
      "iteration: 164460 loss: 0.0031 lr: 0.02\n",
      "iteration: 164470 loss: 0.0023 lr: 0.02\n",
      "iteration: 164480 loss: 0.0019 lr: 0.02\n",
      "iteration: 164490 loss: 0.0020 lr: 0.02\n",
      "iteration: 164500 loss: 0.0026 lr: 0.02\n",
      "iteration: 164510 loss: 0.0025 lr: 0.02\n",
      "iteration: 164520 loss: 0.0034 lr: 0.02\n",
      "iteration: 164530 loss: 0.0029 lr: 0.02\n",
      "iteration: 164540 loss: 0.0026 lr: 0.02\n",
      "iteration: 164550 loss: 0.0025 lr: 0.02\n",
      "iteration: 164560 loss: 0.0022 lr: 0.02\n",
      "iteration: 164570 loss: 0.0025 lr: 0.02\n",
      "iteration: 164580 loss: 0.0026 lr: 0.02\n",
      "iteration: 164590 loss: 0.0030 lr: 0.02\n",
      "iteration: 164600 loss: 0.0021 lr: 0.02\n",
      "iteration: 164610 loss: 0.0024 lr: 0.02\n",
      "iteration: 164620 loss: 0.0024 lr: 0.02\n",
      "iteration: 164630 loss: 0.0020 lr: 0.02\n",
      "iteration: 164640 loss: 0.0018 lr: 0.02\n",
      "iteration: 164650 loss: 0.0025 lr: 0.02\n",
      "iteration: 164660 loss: 0.0026 lr: 0.02\n",
      "iteration: 164670 loss: 0.0018 lr: 0.02\n",
      "iteration: 164680 loss: 0.0018 lr: 0.02\n",
      "iteration: 164690 loss: 0.0018 lr: 0.02\n",
      "iteration: 164700 loss: 0.0021 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 164710 loss: 0.0025 lr: 0.02\n",
      "iteration: 164720 loss: 0.0021 lr: 0.02\n",
      "iteration: 164730 loss: 0.0019 lr: 0.02\n",
      "iteration: 164740 loss: 0.0021 lr: 0.02\n",
      "iteration: 164750 loss: 0.0027 lr: 0.02\n",
      "iteration: 164760 loss: 0.0019 lr: 0.02\n",
      "iteration: 164770 loss: 0.0018 lr: 0.02\n",
      "iteration: 164780 loss: 0.0017 lr: 0.02\n",
      "iteration: 164790 loss: 0.0029 lr: 0.02\n",
      "iteration: 164800 loss: 0.0020 lr: 0.02\n",
      "iteration: 164810 loss: 0.0018 lr: 0.02\n",
      "iteration: 164820 loss: 0.0017 lr: 0.02\n",
      "iteration: 164830 loss: 0.0027 lr: 0.02\n",
      "iteration: 164840 loss: 0.0025 lr: 0.02\n",
      "iteration: 164850 loss: 0.0019 lr: 0.02\n",
      "iteration: 164860 loss: 0.0021 lr: 0.02\n",
      "iteration: 164870 loss: 0.0026 lr: 0.02\n",
      "iteration: 164880 loss: 0.0032 lr: 0.02\n",
      "iteration: 164890 loss: 0.0025 lr: 0.02\n",
      "iteration: 164900 loss: 0.0023 lr: 0.02\n",
      "iteration: 164910 loss: 0.0020 lr: 0.02\n",
      "iteration: 164920 loss: 0.0024 lr: 0.02\n",
      "iteration: 164930 loss: 0.0022 lr: 0.02\n",
      "iteration: 164940 loss: 0.0023 lr: 0.02\n",
      "iteration: 164950 loss: 0.0021 lr: 0.02\n",
      "iteration: 164960 loss: 0.0016 lr: 0.02\n",
      "iteration: 164970 loss: 0.0021 lr: 0.02\n",
      "iteration: 164980 loss: 0.0023 lr: 0.02\n",
      "iteration: 164990 loss: 0.0025 lr: 0.02\n",
      "iteration: 165000 loss: 0.0026 lr: 0.02\n",
      "iteration: 165010 loss: 0.0022 lr: 0.02\n",
      "iteration: 165020 loss: 0.0021 lr: 0.02\n",
      "iteration: 165030 loss: 0.0023 lr: 0.02\n",
      "iteration: 165040 loss: 0.0021 lr: 0.02\n",
      "iteration: 165050 loss: 0.0025 lr: 0.02\n",
      "iteration: 165060 loss: 0.0026 lr: 0.02\n",
      "iteration: 165070 loss: 0.0027 lr: 0.02\n",
      "iteration: 165080 loss: 0.0020 lr: 0.02\n",
      "iteration: 165090 loss: 0.0024 lr: 0.02\n",
      "iteration: 165100 loss: 0.0020 lr: 0.02\n",
      "iteration: 165110 loss: 0.0026 lr: 0.02\n",
      "iteration: 165120 loss: 0.0017 lr: 0.02\n",
      "iteration: 165130 loss: 0.0021 lr: 0.02\n",
      "iteration: 165140 loss: 0.0026 lr: 0.02\n",
      "iteration: 165150 loss: 0.0019 lr: 0.02\n",
      "iteration: 165160 loss: 0.0027 lr: 0.02\n",
      "iteration: 165170 loss: 0.0021 lr: 0.02\n",
      "iteration: 165180 loss: 0.0020 lr: 0.02\n",
      "iteration: 165190 loss: 0.0024 lr: 0.02\n",
      "iteration: 165200 loss: 0.0019 lr: 0.02\n",
      "iteration: 165210 loss: 0.0021 lr: 0.02\n",
      "iteration: 165220 loss: 0.0020 lr: 0.02\n",
      "iteration: 165230 loss: 0.0027 lr: 0.02\n",
      "iteration: 165240 loss: 0.0025 lr: 0.02\n",
      "iteration: 165250 loss: 0.0018 lr: 0.02\n",
      "iteration: 165260 loss: 0.0017 lr: 0.02\n",
      "iteration: 165270 loss: 0.0021 lr: 0.02\n",
      "iteration: 165280 loss: 0.0015 lr: 0.02\n",
      "iteration: 165290 loss: 0.0021 lr: 0.02\n",
      "iteration: 165300 loss: 0.0030 lr: 0.02\n",
      "iteration: 165310 loss: 0.0017 lr: 0.02\n",
      "iteration: 165320 loss: 0.0022 lr: 0.02\n",
      "iteration: 165330 loss: 0.0023 lr: 0.02\n",
      "iteration: 165340 loss: 0.0019 lr: 0.02\n",
      "iteration: 165350 loss: 0.0017 lr: 0.02\n",
      "iteration: 165360 loss: 0.0016 lr: 0.02\n",
      "iteration: 165370 loss: 0.0025 lr: 0.02\n",
      "iteration: 165380 loss: 0.0022 lr: 0.02\n",
      "iteration: 165390 loss: 0.0022 lr: 0.02\n",
      "iteration: 165400 loss: 0.0021 lr: 0.02\n",
      "iteration: 165410 loss: 0.0016 lr: 0.02\n",
      "iteration: 165420 loss: 0.0033 lr: 0.02\n",
      "iteration: 165430 loss: 0.0019 lr: 0.02\n",
      "iteration: 165440 loss: 0.0022 lr: 0.02\n",
      "iteration: 165450 loss: 0.0022 lr: 0.02\n",
      "iteration: 165460 loss: 0.0018 lr: 0.02\n",
      "iteration: 165470 loss: 0.0021 lr: 0.02\n",
      "iteration: 165480 loss: 0.0023 lr: 0.02\n",
      "iteration: 165490 loss: 0.0019 lr: 0.02\n",
      "iteration: 165500 loss: 0.0021 lr: 0.02\n",
      "iteration: 165510 loss: 0.0024 lr: 0.02\n",
      "iteration: 165520 loss: 0.0027 lr: 0.02\n",
      "iteration: 165530 loss: 0.0022 lr: 0.02\n",
      "iteration: 165540 loss: 0.0017 lr: 0.02\n",
      "iteration: 165550 loss: 0.0021 lr: 0.02\n",
      "iteration: 165560 loss: 0.0020 lr: 0.02\n",
      "iteration: 165570 loss: 0.0025 lr: 0.02\n",
      "iteration: 165580 loss: 0.0017 lr: 0.02\n",
      "iteration: 165590 loss: 0.0040 lr: 0.02\n",
      "iteration: 165600 loss: 0.0022 lr: 0.02\n",
      "iteration: 165610 loss: 0.0022 lr: 0.02\n",
      "iteration: 165620 loss: 0.0019 lr: 0.02\n",
      "iteration: 165630 loss: 0.0020 lr: 0.02\n",
      "iteration: 165640 loss: 0.0015 lr: 0.02\n",
      "iteration: 165650 loss: 0.0018 lr: 0.02\n",
      "iteration: 165660 loss: 0.0015 lr: 0.02\n",
      "iteration: 165670 loss: 0.0020 lr: 0.02\n",
      "iteration: 165680 loss: 0.0037 lr: 0.02\n",
      "iteration: 165690 loss: 0.0022 lr: 0.02\n",
      "iteration: 165700 loss: 0.0026 lr: 0.02\n",
      "iteration: 165710 loss: 0.0022 lr: 0.02\n",
      "iteration: 165720 loss: 0.0023 lr: 0.02\n",
      "iteration: 165730 loss: 0.0028 lr: 0.02\n",
      "iteration: 165740 loss: 0.0029 lr: 0.02\n",
      "iteration: 165750 loss: 0.0019 lr: 0.02\n",
      "iteration: 165760 loss: 0.0021 lr: 0.02\n",
      "iteration: 165770 loss: 0.0021 lr: 0.02\n",
      "iteration: 165780 loss: 0.0022 lr: 0.02\n",
      "iteration: 165790 loss: 0.0017 lr: 0.02\n",
      "iteration: 165800 loss: 0.0021 lr: 0.02\n",
      "iteration: 165810 loss: 0.0019 lr: 0.02\n",
      "iteration: 165820 loss: 0.0017 lr: 0.02\n",
      "iteration: 165830 loss: 0.0023 lr: 0.02\n",
      "iteration: 165840 loss: 0.0020 lr: 0.02\n",
      "iteration: 165850 loss: 0.0023 lr: 0.02\n",
      "iteration: 165860 loss: 0.0024 lr: 0.02\n",
      "iteration: 165870 loss: 0.0027 lr: 0.02\n",
      "iteration: 165880 loss: 0.0024 lr: 0.02\n",
      "iteration: 165890 loss: 0.0015 lr: 0.02\n",
      "iteration: 165900 loss: 0.0019 lr: 0.02\n",
      "iteration: 165910 loss: 0.0019 lr: 0.02\n",
      "iteration: 165920 loss: 0.0025 lr: 0.02\n",
      "iteration: 165930 loss: 0.0022 lr: 0.02\n",
      "iteration: 165940 loss: 0.0027 lr: 0.02\n",
      "iteration: 165950 loss: 0.0022 lr: 0.02\n",
      "iteration: 165960 loss: 0.0022 lr: 0.02\n",
      "iteration: 165970 loss: 0.0026 lr: 0.02\n",
      "iteration: 165980 loss: 0.0016 lr: 0.02\n",
      "iteration: 165990 loss: 0.0019 lr: 0.02\n",
      "iteration: 166000 loss: 0.0024 lr: 0.02\n",
      "iteration: 166010 loss: 0.0023 lr: 0.02\n",
      "iteration: 166020 loss: 0.0023 lr: 0.02\n",
      "iteration: 166030 loss: 0.0022 lr: 0.02\n",
      "iteration: 166040 loss: 0.0022 lr: 0.02\n",
      "iteration: 166050 loss: 0.0029 lr: 0.02\n",
      "iteration: 166060 loss: 0.0022 lr: 0.02\n",
      "iteration: 166070 loss: 0.0019 lr: 0.02\n",
      "iteration: 166080 loss: 0.0017 lr: 0.02\n",
      "iteration: 166090 loss: 0.0024 lr: 0.02\n",
      "iteration: 166100 loss: 0.0019 lr: 0.02\n",
      "iteration: 166110 loss: 0.0022 lr: 0.02\n",
      "iteration: 166120 loss: 0.0028 lr: 0.02\n",
      "iteration: 166130 loss: 0.0030 lr: 0.02\n",
      "iteration: 166140 loss: 0.0017 lr: 0.02\n",
      "iteration: 166150 loss: 0.0032 lr: 0.02\n",
      "iteration: 166160 loss: 0.0024 lr: 0.02\n",
      "iteration: 166170 loss: 0.0024 lr: 0.02\n",
      "iteration: 166180 loss: 0.0022 lr: 0.02\n",
      "iteration: 166190 loss: 0.0024 lr: 0.02\n",
      "iteration: 166200 loss: 0.0021 lr: 0.02\n",
      "iteration: 166210 loss: 0.0016 lr: 0.02\n",
      "iteration: 166220 loss: 0.0024 lr: 0.02\n",
      "iteration: 166230 loss: 0.0023 lr: 0.02\n",
      "iteration: 166240 loss: 0.0024 lr: 0.02\n",
      "iteration: 166250 loss: 0.0020 lr: 0.02\n",
      "iteration: 166260 loss: 0.0018 lr: 0.02\n",
      "iteration: 166270 loss: 0.0022 lr: 0.02\n",
      "iteration: 166280 loss: 0.0017 lr: 0.02\n",
      "iteration: 166290 loss: 0.0023 lr: 0.02\n",
      "iteration: 166300 loss: 0.0021 lr: 0.02\n",
      "iteration: 166310 loss: 0.0020 lr: 0.02\n",
      "iteration: 166320 loss: 0.0020 lr: 0.02\n",
      "iteration: 166330 loss: 0.0025 lr: 0.02\n",
      "iteration: 166340 loss: 0.0024 lr: 0.02\n",
      "iteration: 166350 loss: 0.0022 lr: 0.02\n",
      "iteration: 166360 loss: 0.0023 lr: 0.02\n",
      "iteration: 166370 loss: 0.0015 lr: 0.02\n",
      "iteration: 166380 loss: 0.0021 lr: 0.02\n",
      "iteration: 166390 loss: 0.0022 lr: 0.02\n",
      "iteration: 166400 loss: 0.0021 lr: 0.02\n",
      "iteration: 166410 loss: 0.0027 lr: 0.02\n",
      "iteration: 166420 loss: 0.0026 lr: 0.02\n",
      "iteration: 166430 loss: 0.0022 lr: 0.02\n",
      "iteration: 166440 loss: 0.0015 lr: 0.02\n",
      "iteration: 166450 loss: 0.0021 lr: 0.02\n",
      "iteration: 166460 loss: 0.0025 lr: 0.02\n",
      "iteration: 166470 loss: 0.0026 lr: 0.02\n",
      "iteration: 166480 loss: 0.0023 lr: 0.02\n",
      "iteration: 166490 loss: 0.0024 lr: 0.02\n",
      "iteration: 166500 loss: 0.0024 lr: 0.02\n",
      "iteration: 166510 loss: 0.0023 lr: 0.02\n",
      "iteration: 166520 loss: 0.0020 lr: 0.02\n",
      "iteration: 166530 loss: 0.0022 lr: 0.02\n",
      "iteration: 166540 loss: 0.0019 lr: 0.02\n",
      "iteration: 166550 loss: 0.0030 lr: 0.02\n",
      "iteration: 166560 loss: 0.0024 lr: 0.02\n",
      "iteration: 166570 loss: 0.0030 lr: 0.02\n",
      "iteration: 166580 loss: 0.0023 lr: 0.02\n",
      "iteration: 166590 loss: 0.0020 lr: 0.02\n",
      "iteration: 166600 loss: 0.0022 lr: 0.02\n",
      "iteration: 166610 loss: 0.0025 lr: 0.02\n",
      "iteration: 166620 loss: 0.0030 lr: 0.02\n",
      "iteration: 166630 loss: 0.0021 lr: 0.02\n",
      "iteration: 166640 loss: 0.0024 lr: 0.02\n",
      "iteration: 166650 loss: 0.0026 lr: 0.02\n",
      "iteration: 166660 loss: 0.0018 lr: 0.02\n",
      "iteration: 166670 loss: 0.0019 lr: 0.02\n",
      "iteration: 166680 loss: 0.0018 lr: 0.02\n",
      "iteration: 166690 loss: 0.0021 lr: 0.02\n",
      "iteration: 166700 loss: 0.0021 lr: 0.02\n",
      "iteration: 166710 loss: 0.0015 lr: 0.02\n",
      "iteration: 166720 loss: 0.0020 lr: 0.02\n",
      "iteration: 166730 loss: 0.0021 lr: 0.02\n",
      "iteration: 166740 loss: 0.0023 lr: 0.02\n",
      "iteration: 166750 loss: 0.0023 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 166760 loss: 0.0024 lr: 0.02\n",
      "iteration: 166770 loss: 0.0018 lr: 0.02\n",
      "iteration: 166780 loss: 0.0023 lr: 0.02\n",
      "iteration: 166790 loss: 0.0017 lr: 0.02\n",
      "iteration: 166800 loss: 0.0019 lr: 0.02\n",
      "iteration: 166810 loss: 0.0024 lr: 0.02\n",
      "iteration: 166820 loss: 0.0017 lr: 0.02\n",
      "iteration: 166830 loss: 0.0023 lr: 0.02\n",
      "iteration: 166840 loss: 0.0021 lr: 0.02\n",
      "iteration: 166850 loss: 0.0022 lr: 0.02\n",
      "iteration: 166860 loss: 0.0021 lr: 0.02\n",
      "iteration: 166870 loss: 0.0025 lr: 0.02\n",
      "iteration: 166880 loss: 0.0018 lr: 0.02\n",
      "iteration: 166890 loss: 0.0021 lr: 0.02\n",
      "iteration: 166900 loss: 0.0025 lr: 0.02\n",
      "iteration: 166910 loss: 0.0020 lr: 0.02\n",
      "iteration: 166920 loss: 0.0018 lr: 0.02\n",
      "iteration: 166930 loss: 0.0022 lr: 0.02\n",
      "iteration: 166940 loss: 0.0018 lr: 0.02\n",
      "iteration: 166950 loss: 0.0019 lr: 0.02\n",
      "iteration: 166960 loss: 0.0024 lr: 0.02\n",
      "iteration: 166970 loss: 0.0021 lr: 0.02\n",
      "iteration: 166980 loss: 0.0025 lr: 0.02\n",
      "iteration: 166990 loss: 0.0021 lr: 0.02\n",
      "iteration: 167000 loss: 0.0027 lr: 0.02\n",
      "iteration: 167010 loss: 0.0015 lr: 0.02\n",
      "iteration: 167020 loss: 0.0020 lr: 0.02\n",
      "iteration: 167030 loss: 0.0016 lr: 0.02\n",
      "iteration: 167040 loss: 0.0018 lr: 0.02\n",
      "iteration: 167050 loss: 0.0023 lr: 0.02\n",
      "iteration: 167060 loss: 0.0019 lr: 0.02\n",
      "iteration: 167070 loss: 0.0018 lr: 0.02\n",
      "iteration: 167080 loss: 0.0024 lr: 0.02\n",
      "iteration: 167090 loss: 0.0021 lr: 0.02\n",
      "iteration: 167100 loss: 0.0021 lr: 0.02\n",
      "iteration: 167110 loss: 0.0022 lr: 0.02\n",
      "iteration: 167120 loss: 0.0034 lr: 0.02\n",
      "iteration: 167130 loss: 0.0028 lr: 0.02\n",
      "iteration: 167140 loss: 0.0027 lr: 0.02\n",
      "iteration: 167150 loss: 0.0022 lr: 0.02\n",
      "iteration: 167160 loss: 0.0024 lr: 0.02\n",
      "iteration: 167170 loss: 0.0027 lr: 0.02\n",
      "iteration: 167180 loss: 0.0024 lr: 0.02\n",
      "iteration: 167190 loss: 0.0019 lr: 0.02\n",
      "iteration: 167200 loss: 0.0022 lr: 0.02\n",
      "iteration: 167210 loss: 0.0026 lr: 0.02\n",
      "iteration: 167220 loss: 0.0021 lr: 0.02\n",
      "iteration: 167230 loss: 0.0021 lr: 0.02\n",
      "iteration: 167240 loss: 0.0020 lr: 0.02\n",
      "iteration: 167250 loss: 0.0018 lr: 0.02\n",
      "iteration: 167260 loss: 0.0025 lr: 0.02\n",
      "iteration: 167270 loss: 0.0021 lr: 0.02\n",
      "iteration: 167280 loss: 0.0022 lr: 0.02\n",
      "iteration: 167290 loss: 0.0017 lr: 0.02\n",
      "iteration: 167300 loss: 0.0021 lr: 0.02\n",
      "iteration: 167310 loss: 0.0020 lr: 0.02\n",
      "iteration: 167320 loss: 0.0023 lr: 0.02\n",
      "iteration: 167330 loss: 0.0021 lr: 0.02\n",
      "iteration: 167340 loss: 0.0022 lr: 0.02\n",
      "iteration: 167350 loss: 0.0020 lr: 0.02\n",
      "iteration: 167360 loss: 0.0025 lr: 0.02\n",
      "iteration: 167370 loss: 0.0018 lr: 0.02\n",
      "iteration: 167380 loss: 0.0022 lr: 0.02\n",
      "iteration: 167390 loss: 0.0022 lr: 0.02\n",
      "iteration: 167400 loss: 0.0023 lr: 0.02\n",
      "iteration: 167410 loss: 0.0017 lr: 0.02\n",
      "iteration: 167420 loss: 0.0020 lr: 0.02\n",
      "iteration: 167430 loss: 0.0015 lr: 0.02\n",
      "iteration: 167440 loss: 0.0021 lr: 0.02\n",
      "iteration: 167450 loss: 0.0018 lr: 0.02\n",
      "iteration: 167460 loss: 0.0021 lr: 0.02\n",
      "iteration: 167470 loss: 0.0028 lr: 0.02\n",
      "iteration: 167480 loss: 0.0026 lr: 0.02\n",
      "iteration: 167490 loss: 0.0023 lr: 0.02\n",
      "iteration: 167500 loss: 0.0022 lr: 0.02\n",
      "iteration: 167510 loss: 0.0021 lr: 0.02\n",
      "iteration: 167520 loss: 0.0023 lr: 0.02\n",
      "iteration: 167530 loss: 0.0023 lr: 0.02\n",
      "iteration: 167540 loss: 0.0022 lr: 0.02\n",
      "iteration: 167550 loss: 0.0029 lr: 0.02\n",
      "iteration: 167560 loss: 0.0026 lr: 0.02\n",
      "iteration: 167570 loss: 0.0024 lr: 0.02\n",
      "iteration: 167580 loss: 0.0018 lr: 0.02\n",
      "iteration: 167590 loss: 0.0025 lr: 0.02\n",
      "iteration: 167600 loss: 0.0017 lr: 0.02\n",
      "iteration: 167610 loss: 0.0018 lr: 0.02\n",
      "iteration: 167620 loss: 0.0025 lr: 0.02\n",
      "iteration: 167630 loss: 0.0021 lr: 0.02\n",
      "iteration: 167640 loss: 0.0024 lr: 0.02\n",
      "iteration: 167650 loss: 0.0017 lr: 0.02\n",
      "iteration: 167660 loss: 0.0022 lr: 0.02\n",
      "iteration: 167670 loss: 0.0021 lr: 0.02\n",
      "iteration: 167680 loss: 0.0020 lr: 0.02\n",
      "iteration: 167690 loss: 0.0022 lr: 0.02\n",
      "iteration: 167700 loss: 0.0025 lr: 0.02\n",
      "iteration: 167710 loss: 0.0025 lr: 0.02\n",
      "iteration: 167720 loss: 0.0023 lr: 0.02\n",
      "iteration: 167730 loss: 0.0023 lr: 0.02\n",
      "iteration: 167740 loss: 0.0022 lr: 0.02\n",
      "iteration: 167750 loss: 0.0019 lr: 0.02\n",
      "iteration: 167760 loss: 0.0022 lr: 0.02\n",
      "iteration: 167770 loss: 0.0023 lr: 0.02\n",
      "iteration: 167780 loss: 0.0021 lr: 0.02\n",
      "iteration: 167790 loss: 0.0016 lr: 0.02\n",
      "iteration: 167800 loss: 0.0021 lr: 0.02\n",
      "iteration: 167810 loss: 0.0020 lr: 0.02\n",
      "iteration: 167820 loss: 0.0022 lr: 0.02\n",
      "iteration: 167830 loss: 0.0027 lr: 0.02\n",
      "iteration: 167840 loss: 0.0020 lr: 0.02\n",
      "iteration: 167850 loss: 0.0022 lr: 0.02\n",
      "iteration: 167860 loss: 0.0020 lr: 0.02\n",
      "iteration: 167870 loss: 0.0025 lr: 0.02\n",
      "iteration: 167880 loss: 0.0019 lr: 0.02\n",
      "iteration: 167890 loss: 0.0018 lr: 0.02\n",
      "iteration: 167900 loss: 0.0017 lr: 0.02\n",
      "iteration: 167910 loss: 0.0019 lr: 0.02\n",
      "iteration: 167920 loss: 0.0017 lr: 0.02\n",
      "iteration: 167930 loss: 0.0016 lr: 0.02\n",
      "iteration: 167940 loss: 0.0021 lr: 0.02\n",
      "iteration: 167950 loss: 0.0020 lr: 0.02\n",
      "iteration: 167960 loss: 0.0021 lr: 0.02\n",
      "iteration: 167970 loss: 0.0018 lr: 0.02\n",
      "iteration: 167980 loss: 0.0020 lr: 0.02\n",
      "iteration: 167990 loss: 0.0016 lr: 0.02\n",
      "iteration: 168000 loss: 0.0019 lr: 0.02\n",
      "iteration: 168010 loss: 0.0018 lr: 0.02\n",
      "iteration: 168020 loss: 0.0023 lr: 0.02\n",
      "iteration: 168030 loss: 0.0016 lr: 0.02\n",
      "iteration: 168040 loss: 0.0017 lr: 0.02\n",
      "iteration: 168050 loss: 0.0023 lr: 0.02\n",
      "iteration: 168060 loss: 0.0027 lr: 0.02\n",
      "iteration: 168070 loss: 0.0020 lr: 0.02\n",
      "iteration: 168080 loss: 0.0019 lr: 0.02\n",
      "iteration: 168090 loss: 0.0022 lr: 0.02\n",
      "iteration: 168100 loss: 0.0022 lr: 0.02\n",
      "iteration: 168110 loss: 0.0022 lr: 0.02\n",
      "iteration: 168120 loss: 0.0020 lr: 0.02\n",
      "iteration: 168130 loss: 0.0018 lr: 0.02\n",
      "iteration: 168140 loss: 0.0018 lr: 0.02\n",
      "iteration: 168150 loss: 0.0018 lr: 0.02\n",
      "iteration: 168160 loss: 0.0021 lr: 0.02\n",
      "iteration: 168170 loss: 0.0016 lr: 0.02\n",
      "iteration: 168180 loss: 0.0017 lr: 0.02\n",
      "iteration: 168190 loss: 0.0020 lr: 0.02\n",
      "iteration: 168200 loss: 0.0021 lr: 0.02\n",
      "iteration: 168210 loss: 0.0021 lr: 0.02\n",
      "iteration: 168220 loss: 0.0019 lr: 0.02\n",
      "iteration: 168230 loss: 0.0017 lr: 0.02\n",
      "iteration: 168240 loss: 0.0019 lr: 0.02\n",
      "iteration: 168250 loss: 0.0025 lr: 0.02\n",
      "iteration: 168260 loss: 0.0026 lr: 0.02\n",
      "iteration: 168270 loss: 0.0024 lr: 0.02\n",
      "iteration: 168280 loss: 0.0023 lr: 0.02\n",
      "iteration: 168290 loss: 0.0026 lr: 0.02\n",
      "iteration: 168300 loss: 0.0028 lr: 0.02\n",
      "iteration: 168310 loss: 0.0020 lr: 0.02\n",
      "iteration: 168320 loss: 0.0024 lr: 0.02\n",
      "iteration: 168330 loss: 0.0023 lr: 0.02\n",
      "iteration: 168340 loss: 0.0025 lr: 0.02\n",
      "iteration: 168350 loss: 0.0017 lr: 0.02\n",
      "iteration: 168360 loss: 0.0017 lr: 0.02\n",
      "iteration: 168370 loss: 0.0024 lr: 0.02\n",
      "iteration: 168380 loss: 0.0031 lr: 0.02\n",
      "iteration: 168390 loss: 0.0025 lr: 0.02\n",
      "iteration: 168400 loss: 0.0021 lr: 0.02\n",
      "iteration: 168410 loss: 0.0019 lr: 0.02\n",
      "iteration: 168420 loss: 0.0025 lr: 0.02\n",
      "iteration: 168430 loss: 0.0021 lr: 0.02\n",
      "iteration: 168440 loss: 0.0030 lr: 0.02\n",
      "iteration: 168450 loss: 0.0029 lr: 0.02\n",
      "iteration: 168460 loss: 0.0021 lr: 0.02\n",
      "iteration: 168470 loss: 0.0018 lr: 0.02\n",
      "iteration: 168480 loss: 0.0024 lr: 0.02\n",
      "iteration: 168490 loss: 0.0020 lr: 0.02\n",
      "iteration: 168500 loss: 0.0026 lr: 0.02\n",
      "iteration: 168510 loss: 0.0019 lr: 0.02\n",
      "iteration: 168520 loss: 0.0023 lr: 0.02\n",
      "iteration: 168530 loss: 0.0019 lr: 0.02\n",
      "iteration: 168540 loss: 0.0027 lr: 0.02\n",
      "iteration: 168550 loss: 0.0025 lr: 0.02\n",
      "iteration: 168560 loss: 0.0021 lr: 0.02\n",
      "iteration: 168570 loss: 0.0021 lr: 0.02\n",
      "iteration: 168580 loss: 0.0018 lr: 0.02\n",
      "iteration: 168590 loss: 0.0022 lr: 0.02\n",
      "iteration: 168600 loss: 0.0015 lr: 0.02\n",
      "iteration: 168610 loss: 0.0024 lr: 0.02\n",
      "iteration: 168620 loss: 0.0023 lr: 0.02\n",
      "iteration: 168630 loss: 0.0017 lr: 0.02\n",
      "iteration: 168640 loss: 0.0019 lr: 0.02\n",
      "iteration: 168650 loss: 0.0018 lr: 0.02\n",
      "iteration: 168660 loss: 0.0019 lr: 0.02\n",
      "iteration: 168670 loss: 0.0023 lr: 0.02\n",
      "iteration: 168680 loss: 0.0023 lr: 0.02\n",
      "iteration: 168690 loss: 0.0023 lr: 0.02\n",
      "iteration: 168700 loss: 0.0024 lr: 0.02\n",
      "iteration: 168710 loss: 0.0019 lr: 0.02\n",
      "iteration: 168720 loss: 0.0020 lr: 0.02\n",
      "iteration: 168730 loss: 0.0022 lr: 0.02\n",
      "iteration: 168740 loss: 0.0033 lr: 0.02\n",
      "iteration: 168750 loss: 0.0023 lr: 0.02\n",
      "iteration: 168760 loss: 0.0024 lr: 0.02\n",
      "iteration: 168770 loss: 0.0024 lr: 0.02\n",
      "iteration: 168780 loss: 0.0020 lr: 0.02\n",
      "iteration: 168790 loss: 0.0022 lr: 0.02\n",
      "iteration: 168800 loss: 0.0022 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 168810 loss: 0.0021 lr: 0.02\n",
      "iteration: 168820 loss: 0.0022 lr: 0.02\n",
      "iteration: 168830 loss: 0.0020 lr: 0.02\n",
      "iteration: 168840 loss: 0.0029 lr: 0.02\n",
      "iteration: 168850 loss: 0.0017 lr: 0.02\n",
      "iteration: 168860 loss: 0.0017 lr: 0.02\n",
      "iteration: 168870 loss: 0.0023 lr: 0.02\n",
      "iteration: 168880 loss: 0.0020 lr: 0.02\n",
      "iteration: 168890 loss: 0.0017 lr: 0.02\n",
      "iteration: 168900 loss: 0.0022 lr: 0.02\n",
      "iteration: 168910 loss: 0.0021 lr: 0.02\n",
      "iteration: 168920 loss: 0.0018 lr: 0.02\n",
      "iteration: 168930 loss: 0.0021 lr: 0.02\n",
      "iteration: 168940 loss: 0.0019 lr: 0.02\n",
      "iteration: 168950 loss: 0.0026 lr: 0.02\n",
      "iteration: 168960 loss: 0.0020 lr: 0.02\n",
      "iteration: 168970 loss: 0.0024 lr: 0.02\n",
      "iteration: 168980 loss: 0.0024 lr: 0.02\n",
      "iteration: 168990 loss: 0.0019 lr: 0.02\n",
      "iteration: 169000 loss: 0.0019 lr: 0.02\n",
      "iteration: 169010 loss: 0.0020 lr: 0.02\n",
      "iteration: 169020 loss: 0.0019 lr: 0.02\n",
      "iteration: 169030 loss: 0.0023 lr: 0.02\n",
      "iteration: 169040 loss: 0.0021 lr: 0.02\n",
      "iteration: 169050 loss: 0.0019 lr: 0.02\n",
      "iteration: 169060 loss: 0.0017 lr: 0.02\n",
      "iteration: 169070 loss: 0.0026 lr: 0.02\n",
      "iteration: 169080 loss: 0.0026 lr: 0.02\n",
      "iteration: 169090 loss: 0.0022 lr: 0.02\n",
      "iteration: 169100 loss: 0.0019 lr: 0.02\n",
      "iteration: 169110 loss: 0.0019 lr: 0.02\n",
      "iteration: 169120 loss: 0.0019 lr: 0.02\n",
      "iteration: 169130 loss: 0.0018 lr: 0.02\n",
      "iteration: 169140 loss: 0.0016 lr: 0.02\n",
      "iteration: 169150 loss: 0.0023 lr: 0.02\n",
      "iteration: 169160 loss: 0.0019 lr: 0.02\n",
      "iteration: 169170 loss: 0.0031 lr: 0.02\n",
      "iteration: 169180 loss: 0.0022 lr: 0.02\n",
      "iteration: 169190 loss: 0.0018 lr: 0.02\n",
      "iteration: 169200 loss: 0.0026 lr: 0.02\n",
      "iteration: 169210 loss: 0.0021 lr: 0.02\n",
      "iteration: 169220 loss: 0.0021 lr: 0.02\n",
      "iteration: 169230 loss: 0.0024 lr: 0.02\n",
      "iteration: 169240 loss: 0.0023 lr: 0.02\n",
      "iteration: 169250 loss: 0.0019 lr: 0.02\n",
      "iteration: 169260 loss: 0.0024 lr: 0.02\n",
      "iteration: 169270 loss: 0.0014 lr: 0.02\n",
      "iteration: 169280 loss: 0.0017 lr: 0.02\n",
      "iteration: 169290 loss: 0.0021 lr: 0.02\n",
      "iteration: 169300 loss: 0.0024 lr: 0.02\n",
      "iteration: 169310 loss: 0.0023 lr: 0.02\n",
      "iteration: 169320 loss: 0.0013 lr: 0.02\n",
      "iteration: 169330 loss: 0.0019 lr: 0.02\n",
      "iteration: 169340 loss: 0.0023 lr: 0.02\n",
      "iteration: 169350 loss: 0.0020 lr: 0.02\n",
      "iteration: 169360 loss: 0.0018 lr: 0.02\n",
      "iteration: 169370 loss: 0.0023 lr: 0.02\n",
      "iteration: 169380 loss: 0.0023 lr: 0.02\n",
      "iteration: 169390 loss: 0.0025 lr: 0.02\n",
      "iteration: 169400 loss: 0.0019 lr: 0.02\n",
      "iteration: 169410 loss: 0.0024 lr: 0.02\n",
      "iteration: 169420 loss: 0.0031 lr: 0.02\n",
      "iteration: 169430 loss: 0.0022 lr: 0.02\n",
      "iteration: 169440 loss: 0.0018 lr: 0.02\n",
      "iteration: 169450 loss: 0.0020 lr: 0.02\n",
      "iteration: 169460 loss: 0.0017 lr: 0.02\n",
      "iteration: 169470 loss: 0.0019 lr: 0.02\n",
      "iteration: 169480 loss: 0.0022 lr: 0.02\n",
      "iteration: 169490 loss: 0.0022 lr: 0.02\n",
      "iteration: 169500 loss: 0.0018 lr: 0.02\n",
      "iteration: 169510 loss: 0.0023 lr: 0.02\n",
      "iteration: 169520 loss: 0.0020 lr: 0.02\n",
      "iteration: 169530 loss: 0.0025 lr: 0.02\n",
      "iteration: 169540 loss: 0.0018 lr: 0.02\n",
      "iteration: 169550 loss: 0.0018 lr: 0.02\n",
      "iteration: 169560 loss: 0.0020 lr: 0.02\n",
      "iteration: 169570 loss: 0.0026 lr: 0.02\n",
      "iteration: 169580 loss: 0.0027 lr: 0.02\n",
      "iteration: 169590 loss: 0.0019 lr: 0.02\n",
      "iteration: 169600 loss: 0.0020 lr: 0.02\n",
      "iteration: 169610 loss: 0.0023 lr: 0.02\n",
      "iteration: 169620 loss: 0.0025 lr: 0.02\n",
      "iteration: 169630 loss: 0.0023 lr: 0.02\n",
      "iteration: 169640 loss: 0.0021 lr: 0.02\n",
      "iteration: 169650 loss: 0.0022 lr: 0.02\n",
      "iteration: 169660 loss: 0.0020 lr: 0.02\n",
      "iteration: 169670 loss: 0.0029 lr: 0.02\n",
      "iteration: 169680 loss: 0.0020 lr: 0.02\n",
      "iteration: 169690 loss: 0.0028 lr: 0.02\n",
      "iteration: 169700 loss: 0.0025 lr: 0.02\n",
      "iteration: 169710 loss: 0.0021 lr: 0.02\n",
      "iteration: 169720 loss: 0.0023 lr: 0.02\n",
      "iteration: 169730 loss: 0.0017 lr: 0.02\n",
      "iteration: 169740 loss: 0.0022 lr: 0.02\n",
      "iteration: 169750 loss: 0.0022 lr: 0.02\n",
      "iteration: 169760 loss: 0.0019 lr: 0.02\n",
      "iteration: 169770 loss: 0.0018 lr: 0.02\n",
      "iteration: 169780 loss: 0.0020 lr: 0.02\n",
      "iteration: 169790 loss: 0.0022 lr: 0.02\n",
      "iteration: 169800 loss: 0.0019 lr: 0.02\n",
      "iteration: 169810 loss: 0.0024 lr: 0.02\n",
      "iteration: 169820 loss: 0.0022 lr: 0.02\n",
      "iteration: 169830 loss: 0.0024 lr: 0.02\n",
      "iteration: 169840 loss: 0.0023 lr: 0.02\n",
      "iteration: 169850 loss: 0.0028 lr: 0.02\n",
      "iteration: 169860 loss: 0.0025 lr: 0.02\n",
      "iteration: 169870 loss: 0.0022 lr: 0.02\n",
      "iteration: 169880 loss: 0.0019 lr: 0.02\n",
      "iteration: 169890 loss: 0.0024 lr: 0.02\n",
      "iteration: 169900 loss: 0.0018 lr: 0.02\n",
      "iteration: 169910 loss: 0.0016 lr: 0.02\n",
      "iteration: 169920 loss: 0.0022 lr: 0.02\n",
      "iteration: 169930 loss: 0.0031 lr: 0.02\n",
      "iteration: 169940 loss: 0.0025 lr: 0.02\n",
      "iteration: 169950 loss: 0.0018 lr: 0.02\n",
      "iteration: 169960 loss: 0.0025 lr: 0.02\n",
      "iteration: 169970 loss: 0.0014 lr: 0.02\n",
      "iteration: 169980 loss: 0.0025 lr: 0.02\n",
      "iteration: 169990 loss: 0.0028 lr: 0.02\n",
      "iteration: 170000 loss: 0.0030 lr: 0.02\n",
      "iteration: 170010 loss: 0.0019 lr: 0.02\n",
      "iteration: 170020 loss: 0.0023 lr: 0.02\n",
      "iteration: 170030 loss: 0.0023 lr: 0.02\n",
      "iteration: 170040 loss: 0.0027 lr: 0.02\n",
      "iteration: 170050 loss: 0.0018 lr: 0.02\n",
      "iteration: 170060 loss: 0.0025 lr: 0.02\n",
      "iteration: 170070 loss: 0.0017 lr: 0.02\n",
      "iteration: 170080 loss: 0.0021 lr: 0.02\n",
      "iteration: 170090 loss: 0.0024 lr: 0.02\n",
      "iteration: 170100 loss: 0.0029 lr: 0.02\n",
      "iteration: 170110 loss: 0.0021 lr: 0.02\n",
      "iteration: 170120 loss: 0.0020 lr: 0.02\n",
      "iteration: 170130 loss: 0.0022 lr: 0.02\n",
      "iteration: 170140 loss: 0.0017 lr: 0.02\n",
      "iteration: 170150 loss: 0.0019 lr: 0.02\n",
      "iteration: 170160 loss: 0.0025 lr: 0.02\n",
      "iteration: 170170 loss: 0.0019 lr: 0.02\n",
      "iteration: 170180 loss: 0.0021 lr: 0.02\n",
      "iteration: 170190 loss: 0.0024 lr: 0.02\n",
      "iteration: 170200 loss: 0.0021 lr: 0.02\n",
      "iteration: 170210 loss: 0.0019 lr: 0.02\n",
      "iteration: 170220 loss: 0.0026 lr: 0.02\n",
      "iteration: 170230 loss: 0.0024 lr: 0.02\n",
      "iteration: 170240 loss: 0.0019 lr: 0.02\n",
      "iteration: 170250 loss: 0.0020 lr: 0.02\n",
      "iteration: 170260 loss: 0.0019 lr: 0.02\n",
      "iteration: 170270 loss: 0.0023 lr: 0.02\n",
      "iteration: 170280 loss: 0.0022 lr: 0.02\n",
      "iteration: 170290 loss: 0.0029 lr: 0.02\n",
      "iteration: 170300 loss: 0.0022 lr: 0.02\n",
      "iteration: 170310 loss: 0.0019 lr: 0.02\n",
      "iteration: 170320 loss: 0.0019 lr: 0.02\n",
      "iteration: 170330 loss: 0.0026 lr: 0.02\n",
      "iteration: 170340 loss: 0.0024 lr: 0.02\n",
      "iteration: 170350 loss: 0.0025 lr: 0.02\n",
      "iteration: 170360 loss: 0.0020 lr: 0.02\n",
      "iteration: 170370 loss: 0.0028 lr: 0.02\n",
      "iteration: 170380 loss: 0.0014 lr: 0.02\n",
      "iteration: 170390 loss: 0.0022 lr: 0.02\n",
      "iteration: 170400 loss: 0.0028 lr: 0.02\n",
      "iteration: 170410 loss: 0.0020 lr: 0.02\n",
      "iteration: 170420 loss: 0.0026 lr: 0.02\n",
      "iteration: 170430 loss: 0.0017 lr: 0.02\n",
      "iteration: 170440 loss: 0.0021 lr: 0.02\n",
      "iteration: 170450 loss: 0.0031 lr: 0.02\n",
      "iteration: 170460 loss: 0.0032 lr: 0.02\n",
      "iteration: 170470 loss: 0.0018 lr: 0.02\n",
      "iteration: 170480 loss: 0.0017 lr: 0.02\n",
      "iteration: 170490 loss: 0.0016 lr: 0.02\n",
      "iteration: 170500 loss: 0.0021 lr: 0.02\n",
      "iteration: 170510 loss: 0.0022 lr: 0.02\n",
      "iteration: 170520 loss: 0.0021 lr: 0.02\n",
      "iteration: 170530 loss: 0.0023 lr: 0.02\n",
      "iteration: 170540 loss: 0.0021 lr: 0.02\n",
      "iteration: 170550 loss: 0.0017 lr: 0.02\n",
      "iteration: 170560 loss: 0.0024 lr: 0.02\n",
      "iteration: 170570 loss: 0.0022 lr: 0.02\n",
      "iteration: 170580 loss: 0.0021 lr: 0.02\n",
      "iteration: 170590 loss: 0.0028 lr: 0.02\n",
      "iteration: 170600 loss: 0.0024 lr: 0.02\n",
      "iteration: 170610 loss: 0.0021 lr: 0.02\n",
      "iteration: 170620 loss: 0.0022 lr: 0.02\n",
      "iteration: 170630 loss: 0.0025 lr: 0.02\n",
      "iteration: 170640 loss: 0.0023 lr: 0.02\n",
      "iteration: 170650 loss: 0.0020 lr: 0.02\n",
      "iteration: 170660 loss: 0.0026 lr: 0.02\n",
      "iteration: 170670 loss: 0.0021 lr: 0.02\n",
      "iteration: 170680 loss: 0.0025 lr: 0.02\n",
      "iteration: 170690 loss: 0.0021 lr: 0.02\n",
      "iteration: 170700 loss: 0.0022 lr: 0.02\n",
      "iteration: 170710 loss: 0.0021 lr: 0.02\n",
      "iteration: 170720 loss: 0.0023 lr: 0.02\n",
      "iteration: 170730 loss: 0.0022 lr: 0.02\n",
      "iteration: 170740 loss: 0.0025 lr: 0.02\n",
      "iteration: 170750 loss: 0.0021 lr: 0.02\n",
      "iteration: 170760 loss: 0.0028 lr: 0.02\n",
      "iteration: 170770 loss: 0.0019 lr: 0.02\n",
      "iteration: 170780 loss: 0.0020 lr: 0.02\n",
      "iteration: 170790 loss: 0.0020 lr: 0.02\n",
      "iteration: 170800 loss: 0.0022 lr: 0.02\n",
      "iteration: 170810 loss: 0.0020 lr: 0.02\n",
      "iteration: 170820 loss: 0.0022 lr: 0.02\n",
      "iteration: 170830 loss: 0.0030 lr: 0.02\n",
      "iteration: 170840 loss: 0.0016 lr: 0.02\n",
      "iteration: 170850 loss: 0.0018 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 170860 loss: 0.0020 lr: 0.02\n",
      "iteration: 170870 loss: 0.0021 lr: 0.02\n",
      "iteration: 170880 loss: 0.0019 lr: 0.02\n",
      "iteration: 170890 loss: 0.0019 lr: 0.02\n",
      "iteration: 170900 loss: 0.0024 lr: 0.02\n",
      "iteration: 170910 loss: 0.0027 lr: 0.02\n",
      "iteration: 170920 loss: 0.0027 lr: 0.02\n",
      "iteration: 170930 loss: 0.0014 lr: 0.02\n",
      "iteration: 170940 loss: 0.0027 lr: 0.02\n",
      "iteration: 170950 loss: 0.0025 lr: 0.02\n",
      "iteration: 170960 loss: 0.0030 lr: 0.02\n",
      "iteration: 170970 loss: 0.0018 lr: 0.02\n",
      "iteration: 170980 loss: 0.0026 lr: 0.02\n",
      "iteration: 170990 loss: 0.0020 lr: 0.02\n",
      "iteration: 171000 loss: 0.0021 lr: 0.02\n",
      "iteration: 171010 loss: 0.0016 lr: 0.02\n",
      "iteration: 171020 loss: 0.0021 lr: 0.02\n",
      "iteration: 171030 loss: 0.0018 lr: 0.02\n",
      "iteration: 171040 loss: 0.0025 lr: 0.02\n",
      "iteration: 171050 loss: 0.0025 lr: 0.02\n",
      "iteration: 171060 loss: 0.0022 lr: 0.02\n",
      "iteration: 171070 loss: 0.0026 lr: 0.02\n",
      "iteration: 171080 loss: 0.0018 lr: 0.02\n",
      "iteration: 171090 loss: 0.0019 lr: 0.02\n",
      "iteration: 171100 loss: 0.0016 lr: 0.02\n",
      "iteration: 171110 loss: 0.0024 lr: 0.02\n",
      "iteration: 171120 loss: 0.0022 lr: 0.02\n",
      "iteration: 171130 loss: 0.0015 lr: 0.02\n",
      "iteration: 171140 loss: 0.0019 lr: 0.02\n",
      "iteration: 171150 loss: 0.0022 lr: 0.02\n",
      "iteration: 171160 loss: 0.0021 lr: 0.02\n",
      "iteration: 171170 loss: 0.0022 lr: 0.02\n",
      "iteration: 171180 loss: 0.0020 lr: 0.02\n",
      "iteration: 171190 loss: 0.0026 lr: 0.02\n",
      "iteration: 171200 loss: 0.0022 lr: 0.02\n",
      "iteration: 171210 loss: 0.0019 lr: 0.02\n",
      "iteration: 171220 loss: 0.0018 lr: 0.02\n",
      "iteration: 171230 loss: 0.0022 lr: 0.02\n",
      "iteration: 171240 loss: 0.0019 lr: 0.02\n",
      "iteration: 171250 loss: 0.0018 lr: 0.02\n",
      "iteration: 171260 loss: 0.0027 lr: 0.02\n",
      "iteration: 171270 loss: 0.0022 lr: 0.02\n",
      "iteration: 171280 loss: 0.0022 lr: 0.02\n",
      "iteration: 171290 loss: 0.0021 lr: 0.02\n",
      "iteration: 171300 loss: 0.0018 lr: 0.02\n",
      "iteration: 171310 loss: 0.0022 lr: 0.02\n",
      "iteration: 171320 loss: 0.0016 lr: 0.02\n",
      "iteration: 171330 loss: 0.0017 lr: 0.02\n",
      "iteration: 171340 loss: 0.0020 lr: 0.02\n",
      "iteration: 171350 loss: 0.0026 lr: 0.02\n",
      "iteration: 171360 loss: 0.0025 lr: 0.02\n",
      "iteration: 171370 loss: 0.0024 lr: 0.02\n",
      "iteration: 171380 loss: 0.0019 lr: 0.02\n",
      "iteration: 171390 loss: 0.0026 lr: 0.02\n",
      "iteration: 171400 loss: 0.0021 lr: 0.02\n",
      "iteration: 171410 loss: 0.0022 lr: 0.02\n",
      "iteration: 171420 loss: 0.0017 lr: 0.02\n",
      "iteration: 171430 loss: 0.0019 lr: 0.02\n",
      "iteration: 171440 loss: 0.0037 lr: 0.02\n",
      "iteration: 171450 loss: 0.0020 lr: 0.02\n",
      "iteration: 171460 loss: 0.0019 lr: 0.02\n",
      "iteration: 171470 loss: 0.0023 lr: 0.02\n",
      "iteration: 171480 loss: 0.0021 lr: 0.02\n",
      "iteration: 171490 loss: 0.0023 lr: 0.02\n",
      "iteration: 171500 loss: 0.0024 lr: 0.02\n",
      "iteration: 171510 loss: 0.0020 lr: 0.02\n",
      "iteration: 171520 loss: 0.0021 lr: 0.02\n",
      "iteration: 171530 loss: 0.0020 lr: 0.02\n",
      "iteration: 171540 loss: 0.0019 lr: 0.02\n",
      "iteration: 171550 loss: 0.0025 lr: 0.02\n",
      "iteration: 171560 loss: 0.0023 lr: 0.02\n",
      "iteration: 171570 loss: 0.0021 lr: 0.02\n",
      "iteration: 171580 loss: 0.0021 lr: 0.02\n",
      "iteration: 171590 loss: 0.0021 lr: 0.02\n",
      "iteration: 171600 loss: 0.0024 lr: 0.02\n",
      "iteration: 171610 loss: 0.0027 lr: 0.02\n",
      "iteration: 171620 loss: 0.0019 lr: 0.02\n",
      "iteration: 171630 loss: 0.0021 lr: 0.02\n",
      "iteration: 171640 loss: 0.0028 lr: 0.02\n",
      "iteration: 171650 loss: 0.0017 lr: 0.02\n",
      "iteration: 171660 loss: 0.0020 lr: 0.02\n",
      "iteration: 171670 loss: 0.0017 lr: 0.02\n",
      "iteration: 171680 loss: 0.0021 lr: 0.02\n",
      "iteration: 171690 loss: 0.0020 lr: 0.02\n",
      "iteration: 171700 loss: 0.0023 lr: 0.02\n",
      "iteration: 171710 loss: 0.0028 lr: 0.02\n",
      "iteration: 171720 loss: 0.0019 lr: 0.02\n",
      "iteration: 171730 loss: 0.0019 lr: 0.02\n",
      "iteration: 171740 loss: 0.0018 lr: 0.02\n",
      "iteration: 171750 loss: 0.0021 lr: 0.02\n",
      "iteration: 171760 loss: 0.0015 lr: 0.02\n",
      "iteration: 171770 loss: 0.0016 lr: 0.02\n",
      "iteration: 171780 loss: 0.0020 lr: 0.02\n",
      "iteration: 171790 loss: 0.0022 lr: 0.02\n",
      "iteration: 171800 loss: 0.0029 lr: 0.02\n",
      "iteration: 171810 loss: 0.0020 lr: 0.02\n",
      "iteration: 171820 loss: 0.0019 lr: 0.02\n",
      "iteration: 171830 loss: 0.0022 lr: 0.02\n",
      "iteration: 171840 loss: 0.0019 lr: 0.02\n",
      "iteration: 171850 loss: 0.0021 lr: 0.02\n",
      "iteration: 171860 loss: 0.0026 lr: 0.02\n",
      "iteration: 171870 loss: 0.0020 lr: 0.02\n",
      "iteration: 171880 loss: 0.0018 lr: 0.02\n",
      "iteration: 171890 loss: 0.0028 lr: 0.02\n",
      "iteration: 171900 loss: 0.0021 lr: 0.02\n",
      "iteration: 171910 loss: 0.0021 lr: 0.02\n",
      "iteration: 171920 loss: 0.0022 lr: 0.02\n",
      "iteration: 171930 loss: 0.0021 lr: 0.02\n",
      "iteration: 171940 loss: 0.0021 lr: 0.02\n",
      "iteration: 171950 loss: 0.0022 lr: 0.02\n",
      "iteration: 171960 loss: 0.0020 lr: 0.02\n",
      "iteration: 171970 loss: 0.0021 lr: 0.02\n",
      "iteration: 171980 loss: 0.0027 lr: 0.02\n",
      "iteration: 171990 loss: 0.0026 lr: 0.02\n",
      "iteration: 172000 loss: 0.0015 lr: 0.02\n",
      "iteration: 172010 loss: 0.0022 lr: 0.02\n",
      "iteration: 172020 loss: 0.0018 lr: 0.02\n",
      "iteration: 172030 loss: 0.0018 lr: 0.02\n",
      "iteration: 172040 loss: 0.0020 lr: 0.02\n",
      "iteration: 172050 loss: 0.0022 lr: 0.02\n",
      "iteration: 172060 loss: 0.0025 lr: 0.02\n",
      "iteration: 172070 loss: 0.0020 lr: 0.02\n",
      "iteration: 172080 loss: 0.0025 lr: 0.02\n",
      "iteration: 172090 loss: 0.0024 lr: 0.02\n",
      "iteration: 172100 loss: 0.0023 lr: 0.02\n",
      "iteration: 172110 loss: 0.0021 lr: 0.02\n",
      "iteration: 172120 loss: 0.0019 lr: 0.02\n",
      "iteration: 172130 loss: 0.0023 lr: 0.02\n",
      "iteration: 172140 loss: 0.0018 lr: 0.02\n",
      "iteration: 172150 loss: 0.0017 lr: 0.02\n",
      "iteration: 172160 loss: 0.0015 lr: 0.02\n",
      "iteration: 172170 loss: 0.0019 lr: 0.02\n",
      "iteration: 172180 loss: 0.0019 lr: 0.02\n",
      "iteration: 172190 loss: 0.0023 lr: 0.02\n",
      "iteration: 172200 loss: 0.0020 lr: 0.02\n",
      "iteration: 172210 loss: 0.0021 lr: 0.02\n",
      "iteration: 172220 loss: 0.0017 lr: 0.02\n",
      "iteration: 172230 loss: 0.0018 lr: 0.02\n",
      "iteration: 172240 loss: 0.0014 lr: 0.02\n",
      "iteration: 172250 loss: 0.0021 lr: 0.02\n",
      "iteration: 172260 loss: 0.0024 lr: 0.02\n",
      "iteration: 172270 loss: 0.0019 lr: 0.02\n",
      "iteration: 172280 loss: 0.0029 lr: 0.02\n",
      "iteration: 172290 loss: 0.0021 lr: 0.02\n",
      "iteration: 172300 loss: 0.0018 lr: 0.02\n",
      "iteration: 172310 loss: 0.0022 lr: 0.02\n",
      "iteration: 172320 loss: 0.0026 lr: 0.02\n",
      "iteration: 172330 loss: 0.0022 lr: 0.02\n",
      "iteration: 172340 loss: 0.0026 lr: 0.02\n",
      "iteration: 172350 loss: 0.0021 lr: 0.02\n",
      "iteration: 172360 loss: 0.0016 lr: 0.02\n",
      "iteration: 172370 loss: 0.0023 lr: 0.02\n",
      "iteration: 172380 loss: 0.0023 lr: 0.02\n",
      "iteration: 172390 loss: 0.0019 lr: 0.02\n",
      "iteration: 172400 loss: 0.0023 lr: 0.02\n",
      "iteration: 172410 loss: 0.0016 lr: 0.02\n",
      "iteration: 172420 loss: 0.0026 lr: 0.02\n",
      "iteration: 172430 loss: 0.0019 lr: 0.02\n",
      "iteration: 172440 loss: 0.0026 lr: 0.02\n",
      "iteration: 172450 loss: 0.0019 lr: 0.02\n",
      "iteration: 172460 loss: 0.0020 lr: 0.02\n",
      "iteration: 172470 loss: 0.0020 lr: 0.02\n",
      "iteration: 172480 loss: 0.0019 lr: 0.02\n",
      "iteration: 172490 loss: 0.0018 lr: 0.02\n",
      "iteration: 172500 loss: 0.0018 lr: 0.02\n",
      "iteration: 172510 loss: 0.0013 lr: 0.02\n",
      "iteration: 172520 loss: 0.0022 lr: 0.02\n",
      "iteration: 172530 loss: 0.0024 lr: 0.02\n",
      "iteration: 172540 loss: 0.0023 lr: 0.02\n",
      "iteration: 172550 loss: 0.0025 lr: 0.02\n",
      "iteration: 172560 loss: 0.0026 lr: 0.02\n",
      "iteration: 172570 loss: 0.0022 lr: 0.02\n",
      "iteration: 172580 loss: 0.0028 lr: 0.02\n",
      "iteration: 172590 loss: 0.0020 lr: 0.02\n",
      "iteration: 172600 loss: 0.0018 lr: 0.02\n",
      "iteration: 172610 loss: 0.0023 lr: 0.02\n",
      "iteration: 172620 loss: 0.0020 lr: 0.02\n",
      "iteration: 172630 loss: 0.0026 lr: 0.02\n",
      "iteration: 172640 loss: 0.0028 lr: 0.02\n",
      "iteration: 172650 loss: 0.0021 lr: 0.02\n",
      "iteration: 172660 loss: 0.0016 lr: 0.02\n",
      "iteration: 172670 loss: 0.0020 lr: 0.02\n",
      "iteration: 172680 loss: 0.0019 lr: 0.02\n",
      "iteration: 172690 loss: 0.0023 lr: 0.02\n",
      "iteration: 172700 loss: 0.0022 lr: 0.02\n",
      "iteration: 172710 loss: 0.0019 lr: 0.02\n",
      "iteration: 172720 loss: 0.0023 lr: 0.02\n",
      "iteration: 172730 loss: 0.0013 lr: 0.02\n",
      "iteration: 172740 loss: 0.0022 lr: 0.02\n",
      "iteration: 172750 loss: 0.0022 lr: 0.02\n",
      "iteration: 172760 loss: 0.0025 lr: 0.02\n",
      "iteration: 172770 loss: 0.0035 lr: 0.02\n",
      "iteration: 172780 loss: 0.0037 lr: 0.02\n",
      "iteration: 172790 loss: 0.0024 lr: 0.02\n",
      "iteration: 172800 loss: 0.0023 lr: 0.02\n",
      "iteration: 172810 loss: 0.0025 lr: 0.02\n",
      "iteration: 172820 loss: 0.0028 lr: 0.02\n",
      "iteration: 172830 loss: 0.0021 lr: 0.02\n",
      "iteration: 172840 loss: 0.0021 lr: 0.02\n",
      "iteration: 172850 loss: 0.0023 lr: 0.02\n",
      "iteration: 172860 loss: 0.0021 lr: 0.02\n",
      "iteration: 172870 loss: 0.0017 lr: 0.02\n",
      "iteration: 172880 loss: 0.0018 lr: 0.02\n",
      "iteration: 172890 loss: 0.0021 lr: 0.02\n",
      "iteration: 172900 loss: 0.0022 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 172910 loss: 0.0022 lr: 0.02\n",
      "iteration: 172920 loss: 0.0020 lr: 0.02\n",
      "iteration: 172930 loss: 0.0022 lr: 0.02\n",
      "iteration: 172940 loss: 0.0023 lr: 0.02\n",
      "iteration: 172950 loss: 0.0018 lr: 0.02\n",
      "iteration: 172960 loss: 0.0018 lr: 0.02\n",
      "iteration: 172970 loss: 0.0021 lr: 0.02\n",
      "iteration: 172980 loss: 0.0029 lr: 0.02\n",
      "iteration: 172990 loss: 0.0015 lr: 0.02\n",
      "iteration: 173000 loss: 0.0020 lr: 0.02\n",
      "iteration: 173010 loss: 0.0029 lr: 0.02\n",
      "iteration: 173020 loss: 0.0020 lr: 0.02\n",
      "iteration: 173030 loss: 0.0023 lr: 0.02\n",
      "iteration: 173040 loss: 0.0019 lr: 0.02\n",
      "iteration: 173050 loss: 0.0029 lr: 0.02\n",
      "iteration: 173060 loss: 0.0024 lr: 0.02\n",
      "iteration: 173070 loss: 0.0025 lr: 0.02\n",
      "iteration: 173080 loss: 0.0025 lr: 0.02\n",
      "iteration: 173090 loss: 0.0026 lr: 0.02\n",
      "iteration: 173100 loss: 0.0024 lr: 0.02\n",
      "iteration: 173110 loss: 0.0026 lr: 0.02\n",
      "iteration: 173120 loss: 0.0025 lr: 0.02\n",
      "iteration: 173130 loss: 0.0031 lr: 0.02\n",
      "iteration: 173140 loss: 0.0018 lr: 0.02\n",
      "iteration: 173150 loss: 0.0022 lr: 0.02\n",
      "iteration: 173160 loss: 0.0019 lr: 0.02\n",
      "iteration: 173170 loss: 0.0020 lr: 0.02\n",
      "iteration: 173180 loss: 0.0024 lr: 0.02\n",
      "iteration: 173190 loss: 0.0024 lr: 0.02\n",
      "iteration: 173200 loss: 0.0018 lr: 0.02\n",
      "iteration: 173210 loss: 0.0021 lr: 0.02\n",
      "iteration: 173220 loss: 0.0027 lr: 0.02\n",
      "iteration: 173230 loss: 0.0023 lr: 0.02\n",
      "iteration: 173240 loss: 0.0021 lr: 0.02\n",
      "iteration: 173250 loss: 0.0026 lr: 0.02\n",
      "iteration: 173260 loss: 0.0026 lr: 0.02\n",
      "iteration: 173270 loss: 0.0021 lr: 0.02\n",
      "iteration: 173280 loss: 0.0020 lr: 0.02\n",
      "iteration: 173290 loss: 0.0023 lr: 0.02\n",
      "iteration: 173300 loss: 0.0023 lr: 0.02\n",
      "iteration: 173310 loss: 0.0021 lr: 0.02\n",
      "iteration: 173320 loss: 0.0022 lr: 0.02\n",
      "iteration: 173330 loss: 0.0016 lr: 0.02\n",
      "iteration: 173340 loss: 0.0019 lr: 0.02\n",
      "iteration: 173350 loss: 0.0034 lr: 0.02\n",
      "iteration: 173360 loss: 0.0020 lr: 0.02\n",
      "iteration: 173370 loss: 0.0020 lr: 0.02\n",
      "iteration: 173380 loss: 0.0022 lr: 0.02\n",
      "iteration: 173390 loss: 0.0023 lr: 0.02\n",
      "iteration: 173400 loss: 0.0020 lr: 0.02\n",
      "iteration: 173410 loss: 0.0021 lr: 0.02\n",
      "iteration: 173420 loss: 0.0024 lr: 0.02\n",
      "iteration: 173430 loss: 0.0019 lr: 0.02\n",
      "iteration: 173440 loss: 0.0023 lr: 0.02\n",
      "iteration: 173450 loss: 0.0027 lr: 0.02\n",
      "iteration: 173460 loss: 0.0018 lr: 0.02\n",
      "iteration: 173470 loss: 0.0024 lr: 0.02\n",
      "iteration: 173480 loss: 0.0019 lr: 0.02\n",
      "iteration: 173490 loss: 0.0021 lr: 0.02\n",
      "iteration: 173500 loss: 0.0026 lr: 0.02\n",
      "iteration: 173510 loss: 0.0017 lr: 0.02\n",
      "iteration: 173520 loss: 0.0020 lr: 0.02\n",
      "iteration: 173530 loss: 0.0029 lr: 0.02\n",
      "iteration: 173540 loss: 0.0033 lr: 0.02\n",
      "iteration: 173550 loss: 0.0020 lr: 0.02\n",
      "iteration: 173560 loss: 0.0022 lr: 0.02\n",
      "iteration: 173570 loss: 0.0018 lr: 0.02\n",
      "iteration: 173580 loss: 0.0019 lr: 0.02\n",
      "iteration: 173590 loss: 0.0021 lr: 0.02\n",
      "iteration: 173600 loss: 0.0016 lr: 0.02\n",
      "iteration: 173610 loss: 0.0023 lr: 0.02\n",
      "iteration: 173620 loss: 0.0026 lr: 0.02\n",
      "iteration: 173630 loss: 0.0019 lr: 0.02\n",
      "iteration: 173640 loss: 0.0023 lr: 0.02\n",
      "iteration: 173650 loss: 0.0021 lr: 0.02\n",
      "iteration: 173660 loss: 0.0021 lr: 0.02\n",
      "iteration: 173670 loss: 0.0026 lr: 0.02\n",
      "iteration: 173680 loss: 0.0025 lr: 0.02\n",
      "iteration: 173690 loss: 0.0018 lr: 0.02\n",
      "iteration: 173700 loss: 0.0030 lr: 0.02\n",
      "iteration: 173710 loss: 0.0020 lr: 0.02\n",
      "iteration: 173720 loss: 0.0020 lr: 0.02\n",
      "iteration: 173730 loss: 0.0022 lr: 0.02\n",
      "iteration: 173740 loss: 0.0026 lr: 0.02\n",
      "iteration: 173750 loss: 0.0026 lr: 0.02\n",
      "iteration: 173760 loss: 0.0018 lr: 0.02\n",
      "iteration: 173770 loss: 0.0019 lr: 0.02\n",
      "iteration: 173780 loss: 0.0020 lr: 0.02\n",
      "iteration: 173790 loss: 0.0024 lr: 0.02\n",
      "iteration: 173800 loss: 0.0021 lr: 0.02\n",
      "iteration: 173810 loss: 0.0023 lr: 0.02\n",
      "iteration: 173820 loss: 0.0018 lr: 0.02\n",
      "iteration: 173830 loss: 0.0017 lr: 0.02\n",
      "iteration: 173840 loss: 0.0016 lr: 0.02\n",
      "iteration: 173850 loss: 0.0022 lr: 0.02\n",
      "iteration: 173860 loss: 0.0028 lr: 0.02\n",
      "iteration: 173870 loss: 0.0023 lr: 0.02\n",
      "iteration: 173880 loss: 0.0017 lr: 0.02\n",
      "iteration: 173890 loss: 0.0026 lr: 0.02\n",
      "iteration: 173900 loss: 0.0019 lr: 0.02\n",
      "iteration: 173910 loss: 0.0018 lr: 0.02\n",
      "iteration: 173920 loss: 0.0019 lr: 0.02\n",
      "iteration: 173930 loss: 0.0019 lr: 0.02\n",
      "iteration: 173940 loss: 0.0019 lr: 0.02\n",
      "iteration: 173950 loss: 0.0017 lr: 0.02\n",
      "iteration: 173960 loss: 0.0027 lr: 0.02\n",
      "iteration: 173970 loss: 0.0013 lr: 0.02\n",
      "iteration: 173980 loss: 0.0021 lr: 0.02\n",
      "iteration: 173990 loss: 0.0019 lr: 0.02\n",
      "iteration: 174000 loss: 0.0020 lr: 0.02\n",
      "iteration: 174010 loss: 0.0025 lr: 0.02\n",
      "iteration: 174020 loss: 0.0019 lr: 0.02\n",
      "iteration: 174030 loss: 0.0020 lr: 0.02\n",
      "iteration: 174040 loss: 0.0021 lr: 0.02\n",
      "iteration: 174050 loss: 0.0032 lr: 0.02\n",
      "iteration: 174060 loss: 0.0022 lr: 0.02\n",
      "iteration: 174070 loss: 0.0017 lr: 0.02\n",
      "iteration: 174080 loss: 0.0025 lr: 0.02\n",
      "iteration: 174090 loss: 0.0031 lr: 0.02\n",
      "iteration: 174100 loss: 0.0024 lr: 0.02\n",
      "iteration: 174110 loss: 0.0024 lr: 0.02\n",
      "iteration: 174120 loss: 0.0023 lr: 0.02\n",
      "iteration: 174130 loss: 0.0025 lr: 0.02\n",
      "iteration: 174140 loss: 0.0022 lr: 0.02\n",
      "iteration: 174150 loss: 0.0020 lr: 0.02\n",
      "iteration: 174160 loss: 0.0024 lr: 0.02\n",
      "iteration: 174170 loss: 0.0023 lr: 0.02\n",
      "iteration: 174180 loss: 0.0034 lr: 0.02\n",
      "iteration: 174190 loss: 0.0015 lr: 0.02\n",
      "iteration: 174200 loss: 0.0021 lr: 0.02\n",
      "iteration: 174210 loss: 0.0019 lr: 0.02\n",
      "iteration: 174220 loss: 0.0020 lr: 0.02\n",
      "iteration: 174230 loss: 0.0022 lr: 0.02\n",
      "iteration: 174240 loss: 0.0025 lr: 0.02\n",
      "iteration: 174250 loss: 0.0033 lr: 0.02\n",
      "iteration: 174260 loss: 0.0025 lr: 0.02\n",
      "iteration: 174270 loss: 0.0028 lr: 0.02\n",
      "iteration: 174280 loss: 0.0016 lr: 0.02\n",
      "iteration: 174290 loss: 0.0021 lr: 0.02\n",
      "iteration: 174300 loss: 0.0017 lr: 0.02\n",
      "iteration: 174310 loss: 0.0021 lr: 0.02\n",
      "iteration: 174320 loss: 0.0019 lr: 0.02\n",
      "iteration: 174330 loss: 0.0021 lr: 0.02\n",
      "iteration: 174340 loss: 0.0015 lr: 0.02\n",
      "iteration: 174350 loss: 0.0021 lr: 0.02\n",
      "iteration: 174360 loss: 0.0017 lr: 0.02\n",
      "iteration: 174370 loss: 0.0020 lr: 0.02\n",
      "iteration: 174380 loss: 0.0017 lr: 0.02\n",
      "iteration: 174390 loss: 0.0022 lr: 0.02\n",
      "iteration: 174400 loss: 0.0023 lr: 0.02\n",
      "iteration: 174410 loss: 0.0019 lr: 0.02\n",
      "iteration: 174420 loss: 0.0015 lr: 0.02\n",
      "iteration: 174430 loss: 0.0022 lr: 0.02\n",
      "iteration: 174440 loss: 0.0020 lr: 0.02\n",
      "iteration: 174450 loss: 0.0020 lr: 0.02\n",
      "iteration: 174460 loss: 0.0023 lr: 0.02\n",
      "iteration: 174470 loss: 0.0024 lr: 0.02\n",
      "iteration: 174480 loss: 0.0025 lr: 0.02\n",
      "iteration: 174490 loss: 0.0019 lr: 0.02\n",
      "iteration: 174500 loss: 0.0024 lr: 0.02\n",
      "iteration: 174510 loss: 0.0020 lr: 0.02\n",
      "iteration: 174520 loss: 0.0019 lr: 0.02\n",
      "iteration: 174530 loss: 0.0018 lr: 0.02\n",
      "iteration: 174540 loss: 0.0023 lr: 0.02\n",
      "iteration: 174550 loss: 0.0018 lr: 0.02\n",
      "iteration: 174560 loss: 0.0020 lr: 0.02\n",
      "iteration: 174570 loss: 0.0016 lr: 0.02\n",
      "iteration: 174580 loss: 0.0019 lr: 0.02\n",
      "iteration: 174590 loss: 0.0017 lr: 0.02\n",
      "iteration: 174600 loss: 0.0023 lr: 0.02\n",
      "iteration: 174610 loss: 0.0022 lr: 0.02\n",
      "iteration: 174620 loss: 0.0021 lr: 0.02\n",
      "iteration: 174630 loss: 0.0019 lr: 0.02\n",
      "iteration: 174640 loss: 0.0021 lr: 0.02\n",
      "iteration: 174650 loss: 0.0023 lr: 0.02\n",
      "iteration: 174660 loss: 0.0030 lr: 0.02\n",
      "iteration: 174670 loss: 0.0022 lr: 0.02\n",
      "iteration: 174680 loss: 0.0022 lr: 0.02\n",
      "iteration: 174690 loss: 0.0024 lr: 0.02\n",
      "iteration: 174700 loss: 0.0020 lr: 0.02\n",
      "iteration: 174710 loss: 0.0022 lr: 0.02\n",
      "iteration: 174720 loss: 0.0021 lr: 0.02\n",
      "iteration: 174730 loss: 0.0022 lr: 0.02\n",
      "iteration: 174740 loss: 0.0021 lr: 0.02\n",
      "iteration: 174750 loss: 0.0019 lr: 0.02\n",
      "iteration: 174760 loss: 0.0026 lr: 0.02\n",
      "iteration: 174770 loss: 0.0021 lr: 0.02\n",
      "iteration: 174780 loss: 0.0018 lr: 0.02\n",
      "iteration: 174790 loss: 0.0028 lr: 0.02\n",
      "iteration: 174800 loss: 0.0023 lr: 0.02\n",
      "iteration: 174810 loss: 0.0022 lr: 0.02\n",
      "iteration: 174820 loss: 0.0023 lr: 0.02\n",
      "iteration: 174830 loss: 0.0016 lr: 0.02\n",
      "iteration: 174840 loss: 0.0019 lr: 0.02\n",
      "iteration: 174850 loss: 0.0018 lr: 0.02\n",
      "iteration: 174860 loss: 0.0018 lr: 0.02\n",
      "iteration: 174870 loss: 0.0022 lr: 0.02\n",
      "iteration: 174880 loss: 0.0025 lr: 0.02\n",
      "iteration: 174890 loss: 0.0022 lr: 0.02\n",
      "iteration: 174900 loss: 0.0021 lr: 0.02\n",
      "iteration: 174910 loss: 0.0019 lr: 0.02\n",
      "iteration: 174920 loss: 0.0016 lr: 0.02\n",
      "iteration: 174930 loss: 0.0030 lr: 0.02\n",
      "iteration: 174940 loss: 0.0020 lr: 0.02\n",
      "iteration: 174950 loss: 0.0018 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 174960 loss: 0.0022 lr: 0.02\n",
      "iteration: 174970 loss: 0.0020 lr: 0.02\n",
      "iteration: 174980 loss: 0.0020 lr: 0.02\n",
      "iteration: 174990 loss: 0.0024 lr: 0.02\n",
      "iteration: 175000 loss: 0.0021 lr: 0.02\n",
      "iteration: 175010 loss: 0.0024 lr: 0.02\n",
      "iteration: 175020 loss: 0.0029 lr: 0.02\n",
      "iteration: 175030 loss: 0.0021 lr: 0.02\n",
      "iteration: 175040 loss: 0.0018 lr: 0.02\n",
      "iteration: 175050 loss: 0.0020 lr: 0.02\n",
      "iteration: 175060 loss: 0.0019 lr: 0.02\n",
      "iteration: 175070 loss: 0.0025 lr: 0.02\n",
      "iteration: 175080 loss: 0.0023 lr: 0.02\n",
      "iteration: 175090 loss: 0.0021 lr: 0.02\n",
      "iteration: 175100 loss: 0.0020 lr: 0.02\n",
      "iteration: 175110 loss: 0.0020 lr: 0.02\n",
      "iteration: 175120 loss: 0.0023 lr: 0.02\n",
      "iteration: 175130 loss: 0.0021 lr: 0.02\n",
      "iteration: 175140 loss: 0.0025 lr: 0.02\n",
      "iteration: 175150 loss: 0.0023 lr: 0.02\n",
      "iteration: 175160 loss: 0.0023 lr: 0.02\n",
      "iteration: 175170 loss: 0.0020 lr: 0.02\n",
      "iteration: 175180 loss: 0.0020 lr: 0.02\n",
      "iteration: 175190 loss: 0.0022 lr: 0.02\n",
      "iteration: 175200 loss: 0.0018 lr: 0.02\n",
      "iteration: 175210 loss: 0.0017 lr: 0.02\n",
      "iteration: 175220 loss: 0.0022 lr: 0.02\n",
      "iteration: 175230 loss: 0.0021 lr: 0.02\n",
      "iteration: 175240 loss: 0.0026 lr: 0.02\n",
      "iteration: 175250 loss: 0.0020 lr: 0.02\n",
      "iteration: 175260 loss: 0.0019 lr: 0.02\n",
      "iteration: 175270 loss: 0.0018 lr: 0.02\n",
      "iteration: 175280 loss: 0.0019 lr: 0.02\n",
      "iteration: 175290 loss: 0.0018 lr: 0.02\n",
      "iteration: 175300 loss: 0.0022 lr: 0.02\n",
      "iteration: 175310 loss: 0.0016 lr: 0.02\n",
      "iteration: 175320 loss: 0.0018 lr: 0.02\n",
      "iteration: 175330 loss: 0.0024 lr: 0.02\n",
      "iteration: 175340 loss: 0.0020 lr: 0.02\n",
      "iteration: 175350 loss: 0.0028 lr: 0.02\n",
      "iteration: 175360 loss: 0.0022 lr: 0.02\n",
      "iteration: 175370 loss: 0.0023 lr: 0.02\n",
      "iteration: 175380 loss: 0.0021 lr: 0.02\n",
      "iteration: 175390 loss: 0.0016 lr: 0.02\n",
      "iteration: 175400 loss: 0.0016 lr: 0.02\n",
      "iteration: 175410 loss: 0.0021 lr: 0.02\n",
      "iteration: 175420 loss: 0.0024 lr: 0.02\n",
      "iteration: 175430 loss: 0.0024 lr: 0.02\n",
      "iteration: 175440 loss: 0.0022 lr: 0.02\n",
      "iteration: 175450 loss: 0.0017 lr: 0.02\n",
      "iteration: 175460 loss: 0.0019 lr: 0.02\n",
      "iteration: 175470 loss: 0.0018 lr: 0.02\n",
      "iteration: 175480 loss: 0.0018 lr: 0.02\n",
      "iteration: 175490 loss: 0.0028 lr: 0.02\n",
      "iteration: 175500 loss: 0.0020 lr: 0.02\n",
      "iteration: 175510 loss: 0.0024 lr: 0.02\n",
      "iteration: 175520 loss: 0.0024 lr: 0.02\n",
      "iteration: 175530 loss: 0.0020 lr: 0.02\n",
      "iteration: 175540 loss: 0.0018 lr: 0.02\n",
      "iteration: 175550 loss: 0.0021 lr: 0.02\n",
      "iteration: 175560 loss: 0.0028 lr: 0.02\n",
      "iteration: 175570 loss: 0.0026 lr: 0.02\n",
      "iteration: 175580 loss: 0.0028 lr: 0.02\n",
      "iteration: 175590 loss: 0.0020 lr: 0.02\n",
      "iteration: 175600 loss: 0.0026 lr: 0.02\n",
      "iteration: 175610 loss: 0.0019 lr: 0.02\n",
      "iteration: 175620 loss: 0.0022 lr: 0.02\n",
      "iteration: 175630 loss: 0.0018 lr: 0.02\n",
      "iteration: 175640 loss: 0.0025 lr: 0.02\n",
      "iteration: 175650 loss: 0.0016 lr: 0.02\n",
      "iteration: 175660 loss: 0.0017 lr: 0.02\n",
      "iteration: 175670 loss: 0.0020 lr: 0.02\n",
      "iteration: 175680 loss: 0.0016 lr: 0.02\n",
      "iteration: 175690 loss: 0.0020 lr: 0.02\n",
      "iteration: 175700 loss: 0.0022 lr: 0.02\n",
      "iteration: 175710 loss: 0.0022 lr: 0.02\n",
      "iteration: 175720 loss: 0.0023 lr: 0.02\n",
      "iteration: 175730 loss: 0.0017 lr: 0.02\n",
      "iteration: 175740 loss: 0.0018 lr: 0.02\n",
      "iteration: 175750 loss: 0.0025 lr: 0.02\n",
      "iteration: 175760 loss: 0.0021 lr: 0.02\n",
      "iteration: 175770 loss: 0.0031 lr: 0.02\n",
      "iteration: 175780 loss: 0.0020 lr: 0.02\n",
      "iteration: 175790 loss: 0.0022 lr: 0.02\n",
      "iteration: 175800 loss: 0.0016 lr: 0.02\n",
      "iteration: 175810 loss: 0.0019 lr: 0.02\n",
      "iteration: 175820 loss: 0.0023 lr: 0.02\n",
      "iteration: 175830 loss: 0.0025 lr: 0.02\n",
      "iteration: 175840 loss: 0.0018 lr: 0.02\n",
      "iteration: 175850 loss: 0.0023 lr: 0.02\n",
      "iteration: 175860 loss: 0.0032 lr: 0.02\n",
      "iteration: 175870 loss: 0.0028 lr: 0.02\n",
      "iteration: 175880 loss: 0.0022 lr: 0.02\n",
      "iteration: 175890 loss: 0.0017 lr: 0.02\n",
      "iteration: 175900 loss: 0.0024 lr: 0.02\n",
      "iteration: 175910 loss: 0.0029 lr: 0.02\n",
      "iteration: 175920 loss: 0.0022 lr: 0.02\n",
      "iteration: 175930 loss: 0.0025 lr: 0.02\n",
      "iteration: 175940 loss: 0.0023 lr: 0.02\n",
      "iteration: 175950 loss: 0.0018 lr: 0.02\n",
      "iteration: 175960 loss: 0.0024 lr: 0.02\n",
      "iteration: 175970 loss: 0.0028 lr: 0.02\n",
      "iteration: 175980 loss: 0.0022 lr: 0.02\n",
      "iteration: 175990 loss: 0.0016 lr: 0.02\n",
      "iteration: 176000 loss: 0.0017 lr: 0.02\n",
      "iteration: 176010 loss: 0.0028 lr: 0.02\n",
      "iteration: 176020 loss: 0.0020 lr: 0.02\n",
      "iteration: 176030 loss: 0.0023 lr: 0.02\n",
      "iteration: 176040 loss: 0.0020 lr: 0.02\n",
      "iteration: 176050 loss: 0.0021 lr: 0.02\n",
      "iteration: 176060 loss: 0.0023 lr: 0.02\n",
      "iteration: 176070 loss: 0.0021 lr: 0.02\n",
      "iteration: 176080 loss: 0.0021 lr: 0.02\n",
      "iteration: 176090 loss: 0.0022 lr: 0.02\n",
      "iteration: 176100 loss: 0.0021 lr: 0.02\n",
      "iteration: 176110 loss: 0.0021 lr: 0.02\n",
      "iteration: 176120 loss: 0.0019 lr: 0.02\n",
      "iteration: 176130 loss: 0.0020 lr: 0.02\n",
      "iteration: 176140 loss: 0.0018 lr: 0.02\n",
      "iteration: 176150 loss: 0.0020 lr: 0.02\n",
      "iteration: 176160 loss: 0.0025 lr: 0.02\n",
      "iteration: 176170 loss: 0.0022 lr: 0.02\n",
      "iteration: 176180 loss: 0.0022 lr: 0.02\n",
      "iteration: 176190 loss: 0.0016 lr: 0.02\n",
      "iteration: 176200 loss: 0.0018 lr: 0.02\n",
      "iteration: 176210 loss: 0.0019 lr: 0.02\n",
      "iteration: 176220 loss: 0.0020 lr: 0.02\n",
      "iteration: 176230 loss: 0.0018 lr: 0.02\n",
      "iteration: 176240 loss: 0.0020 lr: 0.02\n",
      "iteration: 176250 loss: 0.0022 lr: 0.02\n",
      "iteration: 176260 loss: 0.0024 lr: 0.02\n",
      "iteration: 176270 loss: 0.0022 lr: 0.02\n",
      "iteration: 176280 loss: 0.0017 lr: 0.02\n",
      "iteration: 176290 loss: 0.0023 lr: 0.02\n",
      "iteration: 176300 loss: 0.0023 lr: 0.02\n",
      "iteration: 176310 loss: 0.0023 lr: 0.02\n",
      "iteration: 176320 loss: 0.0018 lr: 0.02\n",
      "iteration: 176330 loss: 0.0028 lr: 0.02\n",
      "iteration: 176340 loss: 0.0021 lr: 0.02\n",
      "iteration: 176350 loss: 0.0028 lr: 0.02\n",
      "iteration: 176360 loss: 0.0022 lr: 0.02\n",
      "iteration: 176370 loss: 0.0020 lr: 0.02\n",
      "iteration: 176380 loss: 0.0021 lr: 0.02\n",
      "iteration: 176390 loss: 0.0018 lr: 0.02\n",
      "iteration: 176400 loss: 0.0028 lr: 0.02\n",
      "iteration: 176410 loss: 0.0023 lr: 0.02\n",
      "iteration: 176420 loss: 0.0027 lr: 0.02\n",
      "iteration: 176430 loss: 0.0024 lr: 0.02\n",
      "iteration: 176440 loss: 0.0019 lr: 0.02\n",
      "iteration: 176450 loss: 0.0025 lr: 0.02\n",
      "iteration: 176460 loss: 0.0021 lr: 0.02\n",
      "iteration: 176470 loss: 0.0025 lr: 0.02\n",
      "iteration: 176480 loss: 0.0023 lr: 0.02\n",
      "iteration: 176490 loss: 0.0017 lr: 0.02\n",
      "iteration: 176500 loss: 0.0016 lr: 0.02\n",
      "iteration: 176510 loss: 0.0023 lr: 0.02\n",
      "iteration: 176520 loss: 0.0020 lr: 0.02\n",
      "iteration: 176530 loss: 0.0017 lr: 0.02\n",
      "iteration: 176540 loss: 0.0019 lr: 0.02\n",
      "iteration: 176550 loss: 0.0018 lr: 0.02\n",
      "iteration: 176560 loss: 0.0023 lr: 0.02\n",
      "iteration: 176570 loss: 0.0024 lr: 0.02\n",
      "iteration: 176580 loss: 0.0024 lr: 0.02\n",
      "iteration: 176590 loss: 0.0023 lr: 0.02\n",
      "iteration: 176600 loss: 0.0026 lr: 0.02\n",
      "iteration: 176610 loss: 0.0023 lr: 0.02\n",
      "iteration: 176620 loss: 0.0018 lr: 0.02\n",
      "iteration: 176630 loss: 0.0018 lr: 0.02\n",
      "iteration: 176640 loss: 0.0022 lr: 0.02\n",
      "iteration: 176650 loss: 0.0021 lr: 0.02\n",
      "iteration: 176660 loss: 0.0020 lr: 0.02\n",
      "iteration: 176670 loss: 0.0019 lr: 0.02\n",
      "iteration: 176680 loss: 0.0018 lr: 0.02\n",
      "iteration: 176690 loss: 0.0016 lr: 0.02\n",
      "iteration: 176700 loss: 0.0023 lr: 0.02\n",
      "iteration: 176710 loss: 0.0022 lr: 0.02\n",
      "iteration: 176720 loss: 0.0022 lr: 0.02\n",
      "iteration: 176730 loss: 0.0024 lr: 0.02\n",
      "iteration: 176740 loss: 0.0021 lr: 0.02\n",
      "iteration: 176750 loss: 0.0024 lr: 0.02\n",
      "iteration: 176760 loss: 0.0033 lr: 0.02\n",
      "iteration: 176770 loss: 0.0025 lr: 0.02\n",
      "iteration: 176780 loss: 0.0017 lr: 0.02\n",
      "iteration: 176790 loss: 0.0018 lr: 0.02\n",
      "iteration: 176800 loss: 0.0027 lr: 0.02\n",
      "iteration: 176810 loss: 0.0015 lr: 0.02\n",
      "iteration: 176820 loss: 0.0022 lr: 0.02\n",
      "iteration: 176830 loss: 0.0019 lr: 0.02\n",
      "iteration: 176840 loss: 0.0022 lr: 0.02\n",
      "iteration: 176850 loss: 0.0017 lr: 0.02\n",
      "iteration: 176860 loss: 0.0029 lr: 0.02\n",
      "iteration: 176870 loss: 0.0025 lr: 0.02\n",
      "iteration: 176880 loss: 0.0026 lr: 0.02\n",
      "iteration: 176890 loss: 0.0020 lr: 0.02\n",
      "iteration: 176900 loss: 0.0021 lr: 0.02\n",
      "iteration: 176910 loss: 0.0028 lr: 0.02\n",
      "iteration: 176920 loss: 0.0024 lr: 0.02\n",
      "iteration: 176930 loss: 0.0022 lr: 0.02\n",
      "iteration: 176940 loss: 0.0015 lr: 0.02\n",
      "iteration: 176950 loss: 0.0023 lr: 0.02\n",
      "iteration: 176960 loss: 0.0025 lr: 0.02\n",
      "iteration: 176970 loss: 0.0021 lr: 0.02\n",
      "iteration: 176980 loss: 0.0016 lr: 0.02\n",
      "iteration: 176990 loss: 0.0018 lr: 0.02\n",
      "iteration: 177000 loss: 0.0017 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 177010 loss: 0.0025 lr: 0.02\n",
      "iteration: 177020 loss: 0.0034 lr: 0.02\n",
      "iteration: 177030 loss: 0.0019 lr: 0.02\n",
      "iteration: 177040 loss: 0.0027 lr: 0.02\n",
      "iteration: 177050 loss: 0.0019 lr: 0.02\n",
      "iteration: 177060 loss: 0.0017 lr: 0.02\n",
      "iteration: 177070 loss: 0.0021 lr: 0.02\n",
      "iteration: 177080 loss: 0.0019 lr: 0.02\n",
      "iteration: 177090 loss: 0.0018 lr: 0.02\n",
      "iteration: 177100 loss: 0.0023 lr: 0.02\n",
      "iteration: 177110 loss: 0.0016 lr: 0.02\n",
      "iteration: 177120 loss: 0.0024 lr: 0.02\n",
      "iteration: 177130 loss: 0.0019 lr: 0.02\n",
      "iteration: 177140 loss: 0.0020 lr: 0.02\n",
      "iteration: 177150 loss: 0.0014 lr: 0.02\n",
      "iteration: 177160 loss: 0.0020 lr: 0.02\n",
      "iteration: 177170 loss: 0.0026 lr: 0.02\n",
      "iteration: 177180 loss: 0.0021 lr: 0.02\n",
      "iteration: 177190 loss: 0.0027 lr: 0.02\n",
      "iteration: 177200 loss: 0.0019 lr: 0.02\n",
      "iteration: 177210 loss: 0.0016 lr: 0.02\n",
      "iteration: 177220 loss: 0.0019 lr: 0.02\n",
      "iteration: 177230 loss: 0.0028 lr: 0.02\n",
      "iteration: 177240 loss: 0.0025 lr: 0.02\n",
      "iteration: 177250 loss: 0.0027 lr: 0.02\n",
      "iteration: 177260 loss: 0.0021 lr: 0.02\n",
      "iteration: 177270 loss: 0.0020 lr: 0.02\n",
      "iteration: 177280 loss: 0.0021 lr: 0.02\n",
      "iteration: 177290 loss: 0.0020 lr: 0.02\n",
      "iteration: 177300 loss: 0.0026 lr: 0.02\n",
      "iteration: 177310 loss: 0.0017 lr: 0.02\n",
      "iteration: 177320 loss: 0.0019 lr: 0.02\n",
      "iteration: 177330 loss: 0.0024 lr: 0.02\n",
      "iteration: 177340 loss: 0.0024 lr: 0.02\n",
      "iteration: 177350 loss: 0.0018 lr: 0.02\n",
      "iteration: 177360 loss: 0.0019 lr: 0.02\n",
      "iteration: 177370 loss: 0.0026 lr: 0.02\n",
      "iteration: 177380 loss: 0.0023 lr: 0.02\n",
      "iteration: 177390 loss: 0.0020 lr: 0.02\n",
      "iteration: 177400 loss: 0.0022 lr: 0.02\n",
      "iteration: 177410 loss: 0.0021 lr: 0.02\n",
      "iteration: 177420 loss: 0.0019 lr: 0.02\n",
      "iteration: 177430 loss: 0.0022 lr: 0.02\n",
      "iteration: 177440 loss: 0.0027 lr: 0.02\n",
      "iteration: 177450 loss: 0.0023 lr: 0.02\n",
      "iteration: 177460 loss: 0.0019 lr: 0.02\n",
      "iteration: 177470 loss: 0.0019 lr: 0.02\n",
      "iteration: 177480 loss: 0.0024 lr: 0.02\n",
      "iteration: 177490 loss: 0.0018 lr: 0.02\n",
      "iteration: 177500 loss: 0.0021 lr: 0.02\n",
      "iteration: 177510 loss: 0.0034 lr: 0.02\n",
      "iteration: 177520 loss: 0.0024 lr: 0.02\n",
      "iteration: 177530 loss: 0.0021 lr: 0.02\n",
      "iteration: 177540 loss: 0.0022 lr: 0.02\n",
      "iteration: 177550 loss: 0.0020 lr: 0.02\n",
      "iteration: 177560 loss: 0.0023 lr: 0.02\n",
      "iteration: 177570 loss: 0.0021 lr: 0.02\n",
      "iteration: 177580 loss: 0.0021 lr: 0.02\n",
      "iteration: 177590 loss: 0.0021 lr: 0.02\n",
      "iteration: 177600 loss: 0.0016 lr: 0.02\n",
      "iteration: 177610 loss: 0.0022 lr: 0.02\n",
      "iteration: 177620 loss: 0.0024 lr: 0.02\n",
      "iteration: 177630 loss: 0.0027 lr: 0.02\n",
      "iteration: 177640 loss: 0.0018 lr: 0.02\n",
      "iteration: 177650 loss: 0.0024 lr: 0.02\n",
      "iteration: 177660 loss: 0.0031 lr: 0.02\n",
      "iteration: 177670 loss: 0.0019 lr: 0.02\n",
      "iteration: 177680 loss: 0.0020 lr: 0.02\n",
      "iteration: 177690 loss: 0.0018 lr: 0.02\n",
      "iteration: 177700 loss: 0.0015 lr: 0.02\n",
      "iteration: 177710 loss: 0.0020 lr: 0.02\n",
      "iteration: 177720 loss: 0.0031 lr: 0.02\n",
      "iteration: 177730 loss: 0.0024 lr: 0.02\n",
      "iteration: 177740 loss: 0.0021 lr: 0.02\n",
      "iteration: 177750 loss: 0.0019 lr: 0.02\n",
      "iteration: 177760 loss: 0.0017 lr: 0.02\n",
      "iteration: 177770 loss: 0.0018 lr: 0.02\n",
      "iteration: 177780 loss: 0.0018 lr: 0.02\n",
      "iteration: 177790 loss: 0.0020 lr: 0.02\n",
      "iteration: 177800 loss: 0.0019 lr: 0.02\n",
      "iteration: 177810 loss: 0.0026 lr: 0.02\n",
      "iteration: 177820 loss: 0.0019 lr: 0.02\n",
      "iteration: 177830 loss: 0.0018 lr: 0.02\n",
      "iteration: 177840 loss: 0.0020 lr: 0.02\n",
      "iteration: 177850 loss: 0.0016 lr: 0.02\n",
      "iteration: 177860 loss: 0.0017 lr: 0.02\n",
      "iteration: 177870 loss: 0.0028 lr: 0.02\n",
      "iteration: 177880 loss: 0.0023 lr: 0.02\n",
      "iteration: 177890 loss: 0.0023 lr: 0.02\n",
      "iteration: 177900 loss: 0.0019 lr: 0.02\n",
      "iteration: 177910 loss: 0.0022 lr: 0.02\n",
      "iteration: 177920 loss: 0.0029 lr: 0.02\n",
      "iteration: 177930 loss: 0.0022 lr: 0.02\n",
      "iteration: 177940 loss: 0.0024 lr: 0.02\n",
      "iteration: 177950 loss: 0.0021 lr: 0.02\n",
      "iteration: 177960 loss: 0.0022 lr: 0.02\n",
      "iteration: 177970 loss: 0.0023 lr: 0.02\n",
      "iteration: 177980 loss: 0.0025 lr: 0.02\n",
      "iteration: 177990 loss: 0.0018 lr: 0.02\n",
      "iteration: 178000 loss: 0.0027 lr: 0.02\n",
      "iteration: 178010 loss: 0.0028 lr: 0.02\n",
      "iteration: 178020 loss: 0.0021 lr: 0.02\n",
      "iteration: 178030 loss: 0.0021 lr: 0.02\n",
      "iteration: 178040 loss: 0.0032 lr: 0.02\n",
      "iteration: 178050 loss: 0.0022 lr: 0.02\n",
      "iteration: 178060 loss: 0.0024 lr: 0.02\n",
      "iteration: 178070 loss: 0.0019 lr: 0.02\n",
      "iteration: 178080 loss: 0.0024 lr: 0.02\n",
      "iteration: 178090 loss: 0.0034 lr: 0.02\n",
      "iteration: 178100 loss: 0.0021 lr: 0.02\n",
      "iteration: 178110 loss: 0.0022 lr: 0.02\n",
      "iteration: 178120 loss: 0.0018 lr: 0.02\n",
      "iteration: 178130 loss: 0.0019 lr: 0.02\n",
      "iteration: 178140 loss: 0.0024 lr: 0.02\n",
      "iteration: 178150 loss: 0.0022 lr: 0.02\n",
      "iteration: 178160 loss: 0.0020 lr: 0.02\n",
      "iteration: 178170 loss: 0.0022 lr: 0.02\n",
      "iteration: 178180 loss: 0.0023 lr: 0.02\n",
      "iteration: 178190 loss: 0.0018 lr: 0.02\n",
      "iteration: 178200 loss: 0.0017 lr: 0.02\n",
      "iteration: 178210 loss: 0.0022 lr: 0.02\n",
      "iteration: 178220 loss: 0.0023 lr: 0.02\n",
      "iteration: 178230 loss: 0.0020 lr: 0.02\n",
      "iteration: 178240 loss: 0.0022 lr: 0.02\n",
      "iteration: 178250 loss: 0.0021 lr: 0.02\n",
      "iteration: 178260 loss: 0.0019 lr: 0.02\n",
      "iteration: 178270 loss: 0.0020 lr: 0.02\n",
      "iteration: 178280 loss: 0.0025 lr: 0.02\n",
      "iteration: 178290 loss: 0.0018 lr: 0.02\n",
      "iteration: 178300 loss: 0.0020 lr: 0.02\n",
      "iteration: 178310 loss: 0.0027 lr: 0.02\n",
      "iteration: 178320 loss: 0.0014 lr: 0.02\n",
      "iteration: 178330 loss: 0.0026 lr: 0.02\n",
      "iteration: 178340 loss: 0.0018 lr: 0.02\n",
      "iteration: 178350 loss: 0.0016 lr: 0.02\n",
      "iteration: 178360 loss: 0.0022 lr: 0.02\n",
      "iteration: 178370 loss: 0.0020 lr: 0.02\n",
      "iteration: 178380 loss: 0.0021 lr: 0.02\n",
      "iteration: 178390 loss: 0.0015 lr: 0.02\n",
      "iteration: 178400 loss: 0.0023 lr: 0.02\n",
      "iteration: 178410 loss: 0.0023 lr: 0.02\n",
      "iteration: 178420 loss: 0.0019 lr: 0.02\n",
      "iteration: 178430 loss: 0.0019 lr: 0.02\n",
      "iteration: 178440 loss: 0.0018 lr: 0.02\n",
      "iteration: 178450 loss: 0.0016 lr: 0.02\n",
      "iteration: 178460 loss: 0.0021 lr: 0.02\n",
      "iteration: 178470 loss: 0.0020 lr: 0.02\n",
      "iteration: 178480 loss: 0.0025 lr: 0.02\n",
      "iteration: 178490 loss: 0.0022 lr: 0.02\n",
      "iteration: 178500 loss: 0.0016 lr: 0.02\n",
      "iteration: 178510 loss: 0.0031 lr: 0.02\n",
      "iteration: 178520 loss: 0.0023 lr: 0.02\n",
      "iteration: 178530 loss: 0.0024 lr: 0.02\n",
      "iteration: 178540 loss: 0.0019 lr: 0.02\n",
      "iteration: 178550 loss: 0.0029 lr: 0.02\n",
      "iteration: 178560 loss: 0.0023 lr: 0.02\n",
      "iteration: 178570 loss: 0.0016 lr: 0.02\n",
      "iteration: 178580 loss: 0.0019 lr: 0.02\n",
      "iteration: 178590 loss: 0.0026 lr: 0.02\n",
      "iteration: 178600 loss: 0.0021 lr: 0.02\n",
      "iteration: 178610 loss: 0.0017 lr: 0.02\n",
      "iteration: 178620 loss: 0.0022 lr: 0.02\n",
      "iteration: 178630 loss: 0.0020 lr: 0.02\n",
      "iteration: 178640 loss: 0.0028 lr: 0.02\n",
      "iteration: 178650 loss: 0.0017 lr: 0.02\n",
      "iteration: 178660 loss: 0.0028 lr: 0.02\n",
      "iteration: 178670 loss: 0.0021 lr: 0.02\n",
      "iteration: 178680 loss: 0.0019 lr: 0.02\n",
      "iteration: 178690 loss: 0.0022 lr: 0.02\n",
      "iteration: 178700 loss: 0.0024 lr: 0.02\n",
      "iteration: 178710 loss: 0.0024 lr: 0.02\n",
      "iteration: 178720 loss: 0.0022 lr: 0.02\n",
      "iteration: 178730 loss: 0.0019 lr: 0.02\n",
      "iteration: 178740 loss: 0.0016 lr: 0.02\n",
      "iteration: 178750 loss: 0.0020 lr: 0.02\n",
      "iteration: 178760 loss: 0.0024 lr: 0.02\n",
      "iteration: 178770 loss: 0.0018 lr: 0.02\n",
      "iteration: 178780 loss: 0.0019 lr: 0.02\n",
      "iteration: 178790 loss: 0.0020 lr: 0.02\n",
      "iteration: 178800 loss: 0.0017 lr: 0.02\n",
      "iteration: 178810 loss: 0.0018 lr: 0.02\n",
      "iteration: 178820 loss: 0.0021 lr: 0.02\n",
      "iteration: 178830 loss: 0.0017 lr: 0.02\n",
      "iteration: 178840 loss: 0.0029 lr: 0.02\n",
      "iteration: 178850 loss: 0.0019 lr: 0.02\n",
      "iteration: 178860 loss: 0.0020 lr: 0.02\n",
      "iteration: 178870 loss: 0.0019 lr: 0.02\n",
      "iteration: 178880 loss: 0.0023 lr: 0.02\n",
      "iteration: 178890 loss: 0.0015 lr: 0.02\n",
      "iteration: 178900 loss: 0.0026 lr: 0.02\n",
      "iteration: 178910 loss: 0.0017 lr: 0.02\n",
      "iteration: 178920 loss: 0.0024 lr: 0.02\n",
      "iteration: 178930 loss: 0.0019 lr: 0.02\n",
      "iteration: 178940 loss: 0.0019 lr: 0.02\n",
      "iteration: 178950 loss: 0.0020 lr: 0.02\n",
      "iteration: 178960 loss: 0.0020 lr: 0.02\n",
      "iteration: 178970 loss: 0.0016 lr: 0.02\n",
      "iteration: 178980 loss: 0.0025 lr: 0.02\n",
      "iteration: 178990 loss: 0.0022 lr: 0.02\n",
      "iteration: 179000 loss: 0.0018 lr: 0.02\n",
      "iteration: 179010 loss: 0.0023 lr: 0.02\n",
      "iteration: 179020 loss: 0.0034 lr: 0.02\n",
      "iteration: 179030 loss: 0.0017 lr: 0.02\n",
      "iteration: 179040 loss: 0.0018 lr: 0.02\n",
      "iteration: 179050 loss: 0.0014 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 179060 loss: 0.0018 lr: 0.02\n",
      "iteration: 179070 loss: 0.0027 lr: 0.02\n",
      "iteration: 179080 loss: 0.0023 lr: 0.02\n",
      "iteration: 179090 loss: 0.0021 lr: 0.02\n",
      "iteration: 179100 loss: 0.0020 lr: 0.02\n",
      "iteration: 179110 loss: 0.0027 lr: 0.02\n",
      "iteration: 179120 loss: 0.0016 lr: 0.02\n",
      "iteration: 179130 loss: 0.0026 lr: 0.02\n",
      "iteration: 179140 loss: 0.0023 lr: 0.02\n",
      "iteration: 179150 loss: 0.0023 lr: 0.02\n",
      "iteration: 179160 loss: 0.0026 lr: 0.02\n",
      "iteration: 179170 loss: 0.0018 lr: 0.02\n",
      "iteration: 179180 loss: 0.0021 lr: 0.02\n",
      "iteration: 179190 loss: 0.0014 lr: 0.02\n",
      "iteration: 179200 loss: 0.0025 lr: 0.02\n",
      "iteration: 179210 loss: 0.0022 lr: 0.02\n",
      "iteration: 179220 loss: 0.0019 lr: 0.02\n",
      "iteration: 179230 loss: 0.0021 lr: 0.02\n",
      "iteration: 179240 loss: 0.0023 lr: 0.02\n",
      "iteration: 179250 loss: 0.0021 lr: 0.02\n",
      "iteration: 179260 loss: 0.0025 lr: 0.02\n",
      "iteration: 179270 loss: 0.0017 lr: 0.02\n",
      "iteration: 179280 loss: 0.0019 lr: 0.02\n",
      "iteration: 179290 loss: 0.0018 lr: 0.02\n",
      "iteration: 179300 loss: 0.0022 lr: 0.02\n",
      "iteration: 179310 loss: 0.0019 lr: 0.02\n",
      "iteration: 179320 loss: 0.0017 lr: 0.02\n",
      "iteration: 179330 loss: 0.0022 lr: 0.02\n",
      "iteration: 179340 loss: 0.0020 lr: 0.02\n",
      "iteration: 179350 loss: 0.0026 lr: 0.02\n",
      "iteration: 179360 loss: 0.0013 lr: 0.02\n",
      "iteration: 179370 loss: 0.0023 lr: 0.02\n",
      "iteration: 179380 loss: 0.0016 lr: 0.02\n",
      "iteration: 179390 loss: 0.0017 lr: 0.02\n",
      "iteration: 179400 loss: 0.0022 lr: 0.02\n",
      "iteration: 179410 loss: 0.0018 lr: 0.02\n",
      "iteration: 179420 loss: 0.0014 lr: 0.02\n",
      "iteration: 179430 loss: 0.0016 lr: 0.02\n",
      "iteration: 179440 loss: 0.0022 lr: 0.02\n",
      "iteration: 179450 loss: 0.0015 lr: 0.02\n",
      "iteration: 179460 loss: 0.0027 lr: 0.02\n",
      "iteration: 179470 loss: 0.0019 lr: 0.02\n",
      "iteration: 179480 loss: 0.0027 lr: 0.02\n",
      "iteration: 179490 loss: 0.0024 lr: 0.02\n",
      "iteration: 179500 loss: 0.0018 lr: 0.02\n",
      "iteration: 179510 loss: 0.0021 lr: 0.02\n",
      "iteration: 179520 loss: 0.0017 lr: 0.02\n",
      "iteration: 179530 loss: 0.0018 lr: 0.02\n",
      "iteration: 179540 loss: 0.0020 lr: 0.02\n",
      "iteration: 179550 loss: 0.0028 lr: 0.02\n",
      "iteration: 179560 loss: 0.0021 lr: 0.02\n",
      "iteration: 179570 loss: 0.0020 lr: 0.02\n",
      "iteration: 179580 loss: 0.0021 lr: 0.02\n",
      "iteration: 179590 loss: 0.0023 lr: 0.02\n",
      "iteration: 179600 loss: 0.0021 lr: 0.02\n",
      "iteration: 179610 loss: 0.0021 lr: 0.02\n",
      "iteration: 179620 loss: 0.0022 lr: 0.02\n",
      "iteration: 179630 loss: 0.0017 lr: 0.02\n",
      "iteration: 179640 loss: 0.0020 lr: 0.02\n",
      "iteration: 179650 loss: 0.0019 lr: 0.02\n",
      "iteration: 179660 loss: 0.0022 lr: 0.02\n",
      "iteration: 179670 loss: 0.0020 lr: 0.02\n",
      "iteration: 179680 loss: 0.0020 lr: 0.02\n",
      "iteration: 179690 loss: 0.0025 lr: 0.02\n",
      "iteration: 179700 loss: 0.0022 lr: 0.02\n",
      "iteration: 179710 loss: 0.0027 lr: 0.02\n",
      "iteration: 179720 loss: 0.0026 lr: 0.02\n",
      "iteration: 179730 loss: 0.0025 lr: 0.02\n",
      "iteration: 179740 loss: 0.0021 lr: 0.02\n",
      "iteration: 179750 loss: 0.0021 lr: 0.02\n",
      "iteration: 179760 loss: 0.0021 lr: 0.02\n",
      "iteration: 179770 loss: 0.0019 lr: 0.02\n",
      "iteration: 179780 loss: 0.0022 lr: 0.02\n",
      "iteration: 179790 loss: 0.0019 lr: 0.02\n",
      "iteration: 179800 loss: 0.0021 lr: 0.02\n",
      "iteration: 179810 loss: 0.0037 lr: 0.02\n",
      "iteration: 179820 loss: 0.0023 lr: 0.02\n",
      "iteration: 179830 loss: 0.0025 lr: 0.02\n",
      "iteration: 179840 loss: 0.0022 lr: 0.02\n",
      "iteration: 179850 loss: 0.0034 lr: 0.02\n",
      "iteration: 179860 loss: 0.0028 lr: 0.02\n",
      "iteration: 179870 loss: 0.0026 lr: 0.02\n",
      "iteration: 179880 loss: 0.0023 lr: 0.02\n",
      "iteration: 179890 loss: 0.0025 lr: 0.02\n",
      "iteration: 179900 loss: 0.0023 lr: 0.02\n",
      "iteration: 179910 loss: 0.0025 lr: 0.02\n",
      "iteration: 179920 loss: 0.0027 lr: 0.02\n",
      "iteration: 179930 loss: 0.0018 lr: 0.02\n",
      "iteration: 179940 loss: 0.0023 lr: 0.02\n",
      "iteration: 179950 loss: 0.0019 lr: 0.02\n",
      "iteration: 179960 loss: 0.0021 lr: 0.02\n",
      "iteration: 179970 loss: 0.0017 lr: 0.02\n",
      "iteration: 179980 loss: 0.0025 lr: 0.02\n",
      "iteration: 179990 loss: 0.0028 lr: 0.02\n",
      "iteration: 180000 loss: 0.0021 lr: 0.02\n",
      "iteration: 180010 loss: 0.0027 lr: 0.02\n",
      "iteration: 180020 loss: 0.0021 lr: 0.02\n",
      "iteration: 180030 loss: 0.0023 lr: 0.02\n",
      "iteration: 180040 loss: 0.0021 lr: 0.02\n",
      "iteration: 180050 loss: 0.0019 lr: 0.02\n",
      "iteration: 180060 loss: 0.0015 lr: 0.02\n",
      "iteration: 180070 loss: 0.0016 lr: 0.02\n",
      "iteration: 180080 loss: 0.0024 lr: 0.02\n",
      "iteration: 180090 loss: 0.0020 lr: 0.02\n",
      "iteration: 180100 loss: 0.0021 lr: 0.02\n",
      "iteration: 180110 loss: 0.0023 lr: 0.02\n",
      "iteration: 180120 loss: 0.0020 lr: 0.02\n",
      "iteration: 180130 loss: 0.0021 lr: 0.02\n",
      "iteration: 180140 loss: 0.0021 lr: 0.02\n",
      "iteration: 180150 loss: 0.0024 lr: 0.02\n",
      "iteration: 180160 loss: 0.0016 lr: 0.02\n",
      "iteration: 180170 loss: 0.0019 lr: 0.02\n",
      "iteration: 180180 loss: 0.0022 lr: 0.02\n",
      "iteration: 180190 loss: 0.0023 lr: 0.02\n",
      "iteration: 180200 loss: 0.0025 lr: 0.02\n",
      "iteration: 180210 loss: 0.0021 lr: 0.02\n",
      "iteration: 180220 loss: 0.0032 lr: 0.02\n",
      "iteration: 180230 loss: 0.0024 lr: 0.02\n",
      "iteration: 180240 loss: 0.0025 lr: 0.02\n",
      "iteration: 180250 loss: 0.0026 lr: 0.02\n",
      "iteration: 180260 loss: 0.0017 lr: 0.02\n",
      "iteration: 180270 loss: 0.0022 lr: 0.02\n",
      "iteration: 180280 loss: 0.0018 lr: 0.02\n",
      "iteration: 180290 loss: 0.0022 lr: 0.02\n",
      "iteration: 180300 loss: 0.0017 lr: 0.02\n",
      "iteration: 180310 loss: 0.0020 lr: 0.02\n",
      "iteration: 180320 loss: 0.0018 lr: 0.02\n",
      "iteration: 180330 loss: 0.0015 lr: 0.02\n",
      "iteration: 180340 loss: 0.0018 lr: 0.02\n",
      "iteration: 180350 loss: 0.0020 lr: 0.02\n",
      "iteration: 180360 loss: 0.0015 lr: 0.02\n",
      "iteration: 180370 loss: 0.0016 lr: 0.02\n",
      "iteration: 180380 loss: 0.0020 lr: 0.02\n",
      "iteration: 180390 loss: 0.0026 lr: 0.02\n",
      "iteration: 180400 loss: 0.0020 lr: 0.02\n",
      "iteration: 180410 loss: 0.0023 lr: 0.02\n",
      "iteration: 180420 loss: 0.0021 lr: 0.02\n",
      "iteration: 180430 loss: 0.0020 lr: 0.02\n",
      "iteration: 180440 loss: 0.0019 lr: 0.02\n",
      "iteration: 180450 loss: 0.0016 lr: 0.02\n",
      "iteration: 180460 loss: 0.0015 lr: 0.02\n",
      "iteration: 180470 loss: 0.0026 lr: 0.02\n",
      "iteration: 180480 loss: 0.0020 lr: 0.02\n",
      "iteration: 180490 loss: 0.0025 lr: 0.02\n",
      "iteration: 180500 loss: 0.0014 lr: 0.02\n",
      "iteration: 180510 loss: 0.0017 lr: 0.02\n",
      "iteration: 180520 loss: 0.0017 lr: 0.02\n",
      "iteration: 180530 loss: 0.0018 lr: 0.02\n",
      "iteration: 180540 loss: 0.0022 lr: 0.02\n",
      "iteration: 180550 loss: 0.0021 lr: 0.02\n",
      "iteration: 180560 loss: 0.0025 lr: 0.02\n",
      "iteration: 180570 loss: 0.0020 lr: 0.02\n",
      "iteration: 180580 loss: 0.0025 lr: 0.02\n",
      "iteration: 180590 loss: 0.0020 lr: 0.02\n",
      "iteration: 180600 loss: 0.0026 lr: 0.02\n",
      "iteration: 180610 loss: 0.0020 lr: 0.02\n",
      "iteration: 180620 loss: 0.0029 lr: 0.02\n",
      "iteration: 180630 loss: 0.0028 lr: 0.02\n",
      "iteration: 180640 loss: 0.0020 lr: 0.02\n",
      "iteration: 180650 loss: 0.0021 lr: 0.02\n",
      "iteration: 180660 loss: 0.0020 lr: 0.02\n",
      "iteration: 180670 loss: 0.0020 lr: 0.02\n",
      "iteration: 180680 loss: 0.0021 lr: 0.02\n",
      "iteration: 180690 loss: 0.0030 lr: 0.02\n",
      "iteration: 180700 loss: 0.0022 lr: 0.02\n",
      "iteration: 180710 loss: 0.0023 lr: 0.02\n",
      "iteration: 180720 loss: 0.0023 lr: 0.02\n",
      "iteration: 180730 loss: 0.0019 lr: 0.02\n",
      "iteration: 180740 loss: 0.0029 lr: 0.02\n",
      "iteration: 180750 loss: 0.0019 lr: 0.02\n",
      "iteration: 180760 loss: 0.0020 lr: 0.02\n",
      "iteration: 180770 loss: 0.0021 lr: 0.02\n",
      "iteration: 180780 loss: 0.0024 lr: 0.02\n",
      "iteration: 180790 loss: 0.0021 lr: 0.02\n",
      "iteration: 180800 loss: 0.0018 lr: 0.02\n",
      "iteration: 180810 loss: 0.0018 lr: 0.02\n",
      "iteration: 180820 loss: 0.0020 lr: 0.02\n",
      "iteration: 180830 loss: 0.0020 lr: 0.02\n",
      "iteration: 180840 loss: 0.0014 lr: 0.02\n",
      "iteration: 180850 loss: 0.0024 lr: 0.02\n",
      "iteration: 180860 loss: 0.0022 lr: 0.02\n",
      "iteration: 180870 loss: 0.0018 lr: 0.02\n",
      "iteration: 180880 loss: 0.0023 lr: 0.02\n",
      "iteration: 180890 loss: 0.0025 lr: 0.02\n",
      "iteration: 180900 loss: 0.0026 lr: 0.02\n",
      "iteration: 180910 loss: 0.0022 lr: 0.02\n",
      "iteration: 180920 loss: 0.0026 lr: 0.02\n",
      "iteration: 180930 loss: 0.0034 lr: 0.02\n",
      "iteration: 180940 loss: 0.0028 lr: 0.02\n",
      "iteration: 180950 loss: 0.0020 lr: 0.02\n",
      "iteration: 180960 loss: 0.0021 lr: 0.02\n",
      "iteration: 180970 loss: 0.0024 lr: 0.02\n",
      "iteration: 180980 loss: 0.0024 lr: 0.02\n",
      "iteration: 180990 loss: 0.0018 lr: 0.02\n",
      "iteration: 181000 loss: 0.0023 lr: 0.02\n",
      "iteration: 181010 loss: 0.0022 lr: 0.02\n",
      "iteration: 181020 loss: 0.0021 lr: 0.02\n",
      "iteration: 181030 loss: 0.0023 lr: 0.02\n",
      "iteration: 181040 loss: 0.0020 lr: 0.02\n",
      "iteration: 181050 loss: 0.0019 lr: 0.02\n",
      "iteration: 181060 loss: 0.0024 lr: 0.02\n",
      "iteration: 181070 loss: 0.0017 lr: 0.02\n",
      "iteration: 181080 loss: 0.0020 lr: 0.02\n",
      "iteration: 181090 loss: 0.0020 lr: 0.02\n",
      "iteration: 181100 loss: 0.0023 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 181110 loss: 0.0020 lr: 0.02\n",
      "iteration: 181120 loss: 0.0023 lr: 0.02\n",
      "iteration: 181130 loss: 0.0026 lr: 0.02\n",
      "iteration: 181140 loss: 0.0020 lr: 0.02\n",
      "iteration: 181150 loss: 0.0024 lr: 0.02\n",
      "iteration: 181160 loss: 0.0019 lr: 0.02\n",
      "iteration: 181170 loss: 0.0020 lr: 0.02\n",
      "iteration: 181180 loss: 0.0020 lr: 0.02\n",
      "iteration: 181190 loss: 0.0018 lr: 0.02\n",
      "iteration: 181200 loss: 0.0018 lr: 0.02\n",
      "iteration: 181210 loss: 0.0020 lr: 0.02\n",
      "iteration: 181220 loss: 0.0020 lr: 0.02\n",
      "iteration: 181230 loss: 0.0019 lr: 0.02\n",
      "iteration: 181240 loss: 0.0017 lr: 0.02\n",
      "iteration: 181250 loss: 0.0021 lr: 0.02\n",
      "iteration: 181260 loss: 0.0025 lr: 0.02\n",
      "iteration: 181270 loss: 0.0018 lr: 0.02\n",
      "iteration: 181280 loss: 0.0020 lr: 0.02\n",
      "iteration: 181290 loss: 0.0018 lr: 0.02\n",
      "iteration: 181300 loss: 0.0031 lr: 0.02\n",
      "iteration: 181310 loss: 0.0028 lr: 0.02\n",
      "iteration: 181320 loss: 0.0019 lr: 0.02\n",
      "iteration: 181330 loss: 0.0027 lr: 0.02\n",
      "iteration: 181340 loss: 0.0022 lr: 0.02\n",
      "iteration: 181350 loss: 0.0020 lr: 0.02\n",
      "iteration: 181360 loss: 0.0023 lr: 0.02\n",
      "iteration: 181370 loss: 0.0017 lr: 0.02\n",
      "iteration: 181380 loss: 0.0021 lr: 0.02\n",
      "iteration: 181390 loss: 0.0021 lr: 0.02\n",
      "iteration: 181400 loss: 0.0029 lr: 0.02\n",
      "iteration: 181410 loss: 0.0019 lr: 0.02\n",
      "iteration: 181420 loss: 0.0019 lr: 0.02\n",
      "iteration: 181430 loss: 0.0023 lr: 0.02\n",
      "iteration: 181440 loss: 0.0022 lr: 0.02\n",
      "iteration: 181450 loss: 0.0026 lr: 0.02\n",
      "iteration: 181460 loss: 0.0019 lr: 0.02\n",
      "iteration: 181470 loss: 0.0024 lr: 0.02\n",
      "iteration: 181480 loss: 0.0027 lr: 0.02\n",
      "iteration: 181490 loss: 0.0024 lr: 0.02\n",
      "iteration: 181500 loss: 0.0018 lr: 0.02\n",
      "iteration: 181510 loss: 0.0024 lr: 0.02\n",
      "iteration: 181520 loss: 0.0019 lr: 0.02\n",
      "iteration: 181530 loss: 0.0019 lr: 0.02\n",
      "iteration: 181540 loss: 0.0019 lr: 0.02\n",
      "iteration: 181550 loss: 0.0027 lr: 0.02\n",
      "iteration: 181560 loss: 0.0028 lr: 0.02\n",
      "iteration: 181570 loss: 0.0023 lr: 0.02\n",
      "iteration: 181580 loss: 0.0025 lr: 0.02\n",
      "iteration: 181590 loss: 0.0016 lr: 0.02\n",
      "iteration: 181600 loss: 0.0019 lr: 0.02\n",
      "iteration: 181610 loss: 0.0029 lr: 0.02\n",
      "iteration: 181620 loss: 0.0024 lr: 0.02\n",
      "iteration: 181630 loss: 0.0027 lr: 0.02\n",
      "iteration: 181640 loss: 0.0019 lr: 0.02\n",
      "iteration: 181650 loss: 0.0021 lr: 0.02\n",
      "iteration: 181660 loss: 0.0028 lr: 0.02\n",
      "iteration: 181670 loss: 0.0018 lr: 0.02\n",
      "iteration: 181680 loss: 0.0023 lr: 0.02\n",
      "iteration: 181690 loss: 0.0020 lr: 0.02\n",
      "iteration: 181700 loss: 0.0020 lr: 0.02\n",
      "iteration: 181710 loss: 0.0024 lr: 0.02\n",
      "iteration: 181720 loss: 0.0021 lr: 0.02\n",
      "iteration: 181730 loss: 0.0019 lr: 0.02\n",
      "iteration: 181740 loss: 0.0019 lr: 0.02\n",
      "iteration: 181750 loss: 0.0020 lr: 0.02\n",
      "iteration: 181760 loss: 0.0020 lr: 0.02\n",
      "iteration: 181770 loss: 0.0018 lr: 0.02\n",
      "iteration: 181780 loss: 0.0020 lr: 0.02\n",
      "iteration: 181790 loss: 0.0019 lr: 0.02\n",
      "iteration: 181800 loss: 0.0029 lr: 0.02\n",
      "iteration: 181810 loss: 0.0022 lr: 0.02\n",
      "iteration: 181820 loss: 0.0022 lr: 0.02\n",
      "iteration: 181830 loss: 0.0024 lr: 0.02\n",
      "iteration: 181840 loss: 0.0022 lr: 0.02\n",
      "iteration: 181850 loss: 0.0017 lr: 0.02\n",
      "iteration: 181860 loss: 0.0026 lr: 0.02\n",
      "iteration: 181870 loss: 0.0016 lr: 0.02\n",
      "iteration: 181880 loss: 0.0020 lr: 0.02\n",
      "iteration: 181890 loss: 0.0021 lr: 0.02\n",
      "iteration: 181900 loss: 0.0021 lr: 0.02\n",
      "iteration: 181910 loss: 0.0022 lr: 0.02\n",
      "iteration: 181920 loss: 0.0018 lr: 0.02\n",
      "iteration: 181930 loss: 0.0017 lr: 0.02\n",
      "iteration: 181940 loss: 0.0026 lr: 0.02\n",
      "iteration: 181950 loss: 0.0023 lr: 0.02\n",
      "iteration: 181960 loss: 0.0018 lr: 0.02\n",
      "iteration: 181970 loss: 0.0019 lr: 0.02\n",
      "iteration: 181980 loss: 0.0019 lr: 0.02\n",
      "iteration: 181990 loss: 0.0020 lr: 0.02\n",
      "iteration: 182000 loss: 0.0019 lr: 0.02\n",
      "iteration: 182010 loss: 0.0026 lr: 0.02\n",
      "iteration: 182020 loss: 0.0024 lr: 0.02\n",
      "iteration: 182030 loss: 0.0020 lr: 0.02\n",
      "iteration: 182040 loss: 0.0016 lr: 0.02\n",
      "iteration: 182050 loss: 0.0025 lr: 0.02\n",
      "iteration: 182060 loss: 0.0020 lr: 0.02\n",
      "iteration: 182070 loss: 0.0019 lr: 0.02\n",
      "iteration: 182080 loss: 0.0019 lr: 0.02\n",
      "iteration: 182090 loss: 0.0021 lr: 0.02\n",
      "iteration: 182100 loss: 0.0023 lr: 0.02\n",
      "iteration: 182110 loss: 0.0022 lr: 0.02\n",
      "iteration: 182120 loss: 0.0028 lr: 0.02\n",
      "iteration: 182130 loss: 0.0026 lr: 0.02\n",
      "iteration: 182140 loss: 0.0023 lr: 0.02\n",
      "iteration: 182150 loss: 0.0024 lr: 0.02\n",
      "iteration: 182160 loss: 0.0028 lr: 0.02\n",
      "iteration: 182170 loss: 0.0022 lr: 0.02\n",
      "iteration: 182180 loss: 0.0020 lr: 0.02\n",
      "iteration: 182190 loss: 0.0018 lr: 0.02\n",
      "iteration: 182200 loss: 0.0023 lr: 0.02\n",
      "iteration: 182210 loss: 0.0020 lr: 0.02\n",
      "iteration: 182220 loss: 0.0016 lr: 0.02\n",
      "iteration: 182230 loss: 0.0023 lr: 0.02\n",
      "iteration: 182240 loss: 0.0019 lr: 0.02\n",
      "iteration: 182250 loss: 0.0029 lr: 0.02\n",
      "iteration: 182260 loss: 0.0023 lr: 0.02\n",
      "iteration: 182270 loss: 0.0025 lr: 0.02\n",
      "iteration: 182280 loss: 0.0022 lr: 0.02\n",
      "iteration: 182290 loss: 0.0021 lr: 0.02\n",
      "iteration: 182300 loss: 0.0019 lr: 0.02\n",
      "iteration: 182310 loss: 0.0017 lr: 0.02\n",
      "iteration: 182320 loss: 0.0018 lr: 0.02\n",
      "iteration: 182330 loss: 0.0019 lr: 0.02\n",
      "iteration: 182340 loss: 0.0024 lr: 0.02\n",
      "iteration: 182350 loss: 0.0020 lr: 0.02\n",
      "iteration: 182360 loss: 0.0023 lr: 0.02\n",
      "iteration: 182370 loss: 0.0020 lr: 0.02\n",
      "iteration: 182380 loss: 0.0023 lr: 0.02\n",
      "iteration: 182390 loss: 0.0019 lr: 0.02\n",
      "iteration: 182400 loss: 0.0025 lr: 0.02\n",
      "iteration: 182410 loss: 0.0018 lr: 0.02\n",
      "iteration: 182420 loss: 0.0026 lr: 0.02\n",
      "iteration: 182430 loss: 0.0028 lr: 0.02\n",
      "iteration: 182440 loss: 0.0024 lr: 0.02\n",
      "iteration: 182450 loss: 0.0016 lr: 0.02\n",
      "iteration: 182460 loss: 0.0020 lr: 0.02\n",
      "iteration: 182470 loss: 0.0022 lr: 0.02\n",
      "iteration: 182480 loss: 0.0019 lr: 0.02\n",
      "iteration: 182490 loss: 0.0022 lr: 0.02\n",
      "iteration: 182500 loss: 0.0021 lr: 0.02\n",
      "iteration: 182510 loss: 0.0017 lr: 0.02\n",
      "iteration: 182520 loss: 0.0018 lr: 0.02\n",
      "iteration: 182530 loss: 0.0024 lr: 0.02\n",
      "iteration: 182540 loss: 0.0024 lr: 0.02\n",
      "iteration: 182550 loss: 0.0021 lr: 0.02\n",
      "iteration: 182560 loss: 0.0019 lr: 0.02\n",
      "iteration: 182570 loss: 0.0018 lr: 0.02\n",
      "iteration: 182580 loss: 0.0020 lr: 0.02\n",
      "iteration: 182590 loss: 0.0025 lr: 0.02\n",
      "iteration: 182600 loss: 0.0027 lr: 0.02\n",
      "iteration: 182610 loss: 0.0029 lr: 0.02\n",
      "iteration: 182620 loss: 0.0018 lr: 0.02\n",
      "iteration: 182630 loss: 0.0022 lr: 0.02\n",
      "iteration: 182640 loss: 0.0020 lr: 0.02\n",
      "iteration: 182650 loss: 0.0019 lr: 0.02\n",
      "iteration: 182660 loss: 0.0016 lr: 0.02\n",
      "iteration: 182670 loss: 0.0022 lr: 0.02\n",
      "iteration: 182680 loss: 0.0022 lr: 0.02\n",
      "iteration: 182690 loss: 0.0025 lr: 0.02\n",
      "iteration: 182700 loss: 0.0017 lr: 0.02\n",
      "iteration: 182710 loss: 0.0022 lr: 0.02\n",
      "iteration: 182720 loss: 0.0029 lr: 0.02\n",
      "iteration: 182730 loss: 0.0018 lr: 0.02\n",
      "iteration: 182740 loss: 0.0016 lr: 0.02\n",
      "iteration: 182750 loss: 0.0022 lr: 0.02\n",
      "iteration: 182760 loss: 0.0019 lr: 0.02\n",
      "iteration: 182770 loss: 0.0023 lr: 0.02\n",
      "iteration: 182780 loss: 0.0021 lr: 0.02\n",
      "iteration: 182790 loss: 0.0018 lr: 0.02\n",
      "iteration: 182800 loss: 0.0018 lr: 0.02\n",
      "iteration: 182810 loss: 0.0022 lr: 0.02\n",
      "iteration: 182820 loss: 0.0021 lr: 0.02\n",
      "iteration: 182830 loss: 0.0018 lr: 0.02\n",
      "iteration: 182840 loss: 0.0020 lr: 0.02\n",
      "iteration: 182850 loss: 0.0021 lr: 0.02\n",
      "iteration: 182860 loss: 0.0022 lr: 0.02\n",
      "iteration: 182870 loss: 0.0021 lr: 0.02\n",
      "iteration: 182880 loss: 0.0022 lr: 0.02\n",
      "iteration: 182890 loss: 0.0017 lr: 0.02\n",
      "iteration: 182900 loss: 0.0019 lr: 0.02\n",
      "iteration: 182910 loss: 0.0023 lr: 0.02\n",
      "iteration: 182920 loss: 0.0019 lr: 0.02\n",
      "iteration: 182930 loss: 0.0022 lr: 0.02\n",
      "iteration: 182940 loss: 0.0019 lr: 0.02\n",
      "iteration: 182950 loss: 0.0020 lr: 0.02\n",
      "iteration: 182960 loss: 0.0021 lr: 0.02\n",
      "iteration: 182970 loss: 0.0026 lr: 0.02\n",
      "iteration: 182980 loss: 0.0021 lr: 0.02\n",
      "iteration: 182990 loss: 0.0016 lr: 0.02\n",
      "iteration: 183000 loss: 0.0020 lr: 0.02\n",
      "iteration: 183010 loss: 0.0016 lr: 0.02\n",
      "iteration: 183020 loss: 0.0019 lr: 0.02\n",
      "iteration: 183030 loss: 0.0019 lr: 0.02\n",
      "iteration: 183040 loss: 0.0020 lr: 0.02\n",
      "iteration: 183050 loss: 0.0019 lr: 0.02\n",
      "iteration: 183060 loss: 0.0022 lr: 0.02\n",
      "iteration: 183070 loss: 0.0019 lr: 0.02\n",
      "iteration: 183080 loss: 0.0019 lr: 0.02\n",
      "iteration: 183090 loss: 0.0021 lr: 0.02\n",
      "iteration: 183100 loss: 0.0025 lr: 0.02\n",
      "iteration: 183110 loss: 0.0020 lr: 0.02\n",
      "iteration: 183120 loss: 0.0024 lr: 0.02\n",
      "iteration: 183130 loss: 0.0020 lr: 0.02\n",
      "iteration: 183140 loss: 0.0018 lr: 0.02\n",
      "iteration: 183150 loss: 0.0019 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 183160 loss: 0.0017 lr: 0.02\n",
      "iteration: 183170 loss: 0.0024 lr: 0.02\n",
      "iteration: 183180 loss: 0.0015 lr: 0.02\n",
      "iteration: 183190 loss: 0.0025 lr: 0.02\n",
      "iteration: 183200 loss: 0.0023 lr: 0.02\n",
      "iteration: 183210 loss: 0.0019 lr: 0.02\n",
      "iteration: 183220 loss: 0.0018 lr: 0.02\n",
      "iteration: 183230 loss: 0.0022 lr: 0.02\n",
      "iteration: 183240 loss: 0.0021 lr: 0.02\n",
      "iteration: 183250 loss: 0.0020 lr: 0.02\n",
      "iteration: 183260 loss: 0.0020 lr: 0.02\n",
      "iteration: 183270 loss: 0.0018 lr: 0.02\n",
      "iteration: 183280 loss: 0.0017 lr: 0.02\n",
      "iteration: 183290 loss: 0.0019 lr: 0.02\n",
      "iteration: 183300 loss: 0.0025 lr: 0.02\n",
      "iteration: 183310 loss: 0.0018 lr: 0.02\n",
      "iteration: 183320 loss: 0.0023 lr: 0.02\n",
      "iteration: 183330 loss: 0.0023 lr: 0.02\n",
      "iteration: 183340 loss: 0.0016 lr: 0.02\n",
      "iteration: 183350 loss: 0.0019 lr: 0.02\n",
      "iteration: 183360 loss: 0.0015 lr: 0.02\n",
      "iteration: 183370 loss: 0.0017 lr: 0.02\n",
      "iteration: 183380 loss: 0.0018 lr: 0.02\n",
      "iteration: 183390 loss: 0.0030 lr: 0.02\n",
      "iteration: 183400 loss: 0.0015 lr: 0.02\n",
      "iteration: 183410 loss: 0.0017 lr: 0.02\n",
      "iteration: 183420 loss: 0.0018 lr: 0.02\n",
      "iteration: 183430 loss: 0.0018 lr: 0.02\n",
      "iteration: 183440 loss: 0.0022 lr: 0.02\n",
      "iteration: 183450 loss: 0.0020 lr: 0.02\n",
      "iteration: 183460 loss: 0.0019 lr: 0.02\n",
      "iteration: 183470 loss: 0.0019 lr: 0.02\n",
      "iteration: 183480 loss: 0.0024 lr: 0.02\n",
      "iteration: 183490 loss: 0.0018 lr: 0.02\n",
      "iteration: 183500 loss: 0.0018 lr: 0.02\n",
      "iteration: 183510 loss: 0.0028 lr: 0.02\n",
      "iteration: 183520 loss: 0.0024 lr: 0.02\n",
      "iteration: 183530 loss: 0.0018 lr: 0.02\n",
      "iteration: 183540 loss: 0.0021 lr: 0.02\n",
      "iteration: 183550 loss: 0.0016 lr: 0.02\n",
      "iteration: 183560 loss: 0.0034 lr: 0.02\n",
      "iteration: 183570 loss: 0.0019 lr: 0.02\n",
      "iteration: 183580 loss: 0.0026 lr: 0.02\n",
      "iteration: 183590 loss: 0.0024 lr: 0.02\n",
      "iteration: 183600 loss: 0.0014 lr: 0.02\n",
      "iteration: 183610 loss: 0.0024 lr: 0.02\n",
      "iteration: 183620 loss: 0.0018 lr: 0.02\n",
      "iteration: 183630 loss: 0.0021 lr: 0.02\n",
      "iteration: 183640 loss: 0.0018 lr: 0.02\n",
      "iteration: 183650 loss: 0.0019 lr: 0.02\n",
      "iteration: 183660 loss: 0.0019 lr: 0.02\n",
      "iteration: 183670 loss: 0.0023 lr: 0.02\n",
      "iteration: 183680 loss: 0.0019 lr: 0.02\n",
      "iteration: 183690 loss: 0.0023 lr: 0.02\n",
      "iteration: 183700 loss: 0.0026 lr: 0.02\n",
      "iteration: 183710 loss: 0.0019 lr: 0.02\n",
      "iteration: 183720 loss: 0.0015 lr: 0.02\n",
      "iteration: 183730 loss: 0.0022 lr: 0.02\n",
      "iteration: 183740 loss: 0.0020 lr: 0.02\n",
      "iteration: 183750 loss: 0.0025 lr: 0.02\n",
      "iteration: 183760 loss: 0.0017 lr: 0.02\n",
      "iteration: 183770 loss: 0.0018 lr: 0.02\n",
      "iteration: 183780 loss: 0.0015 lr: 0.02\n",
      "iteration: 183790 loss: 0.0021 lr: 0.02\n",
      "iteration: 183800 loss: 0.0028 lr: 0.02\n",
      "iteration: 183810 loss: 0.0016 lr: 0.02\n",
      "iteration: 183820 loss: 0.0017 lr: 0.02\n",
      "iteration: 183830 loss: 0.0020 lr: 0.02\n",
      "iteration: 183840 loss: 0.0017 lr: 0.02\n",
      "iteration: 183850 loss: 0.0019 lr: 0.02\n",
      "iteration: 183860 loss: 0.0020 lr: 0.02\n",
      "iteration: 183870 loss: 0.0019 lr: 0.02\n",
      "iteration: 183880 loss: 0.0026 lr: 0.02\n",
      "iteration: 183890 loss: 0.0020 lr: 0.02\n",
      "iteration: 183900 loss: 0.0022 lr: 0.02\n",
      "iteration: 183910 loss: 0.0019 lr: 0.02\n",
      "iteration: 183920 loss: 0.0021 lr: 0.02\n",
      "iteration: 183930 loss: 0.0027 lr: 0.02\n",
      "iteration: 183940 loss: 0.0022 lr: 0.02\n",
      "iteration: 183950 loss: 0.0018 lr: 0.02\n",
      "iteration: 183960 loss: 0.0033 lr: 0.02\n",
      "iteration: 183970 loss: 0.0018 lr: 0.02\n",
      "iteration: 183980 loss: 0.0024 lr: 0.02\n",
      "iteration: 183990 loss: 0.0023 lr: 0.02\n",
      "iteration: 184000 loss: 0.0025 lr: 0.02\n",
      "iteration: 184010 loss: 0.0017 lr: 0.02\n",
      "iteration: 184020 loss: 0.0022 lr: 0.02\n",
      "iteration: 184030 loss: 0.0027 lr: 0.02\n",
      "iteration: 184040 loss: 0.0019 lr: 0.02\n",
      "iteration: 184050 loss: 0.0022 lr: 0.02\n",
      "iteration: 184060 loss: 0.0016 lr: 0.02\n",
      "iteration: 184070 loss: 0.0019 lr: 0.02\n",
      "iteration: 184080 loss: 0.0016 lr: 0.02\n",
      "iteration: 184090 loss: 0.0025 lr: 0.02\n",
      "iteration: 184100 loss: 0.0019 lr: 0.02\n",
      "iteration: 184110 loss: 0.0016 lr: 0.02\n",
      "iteration: 184120 loss: 0.0016 lr: 0.02\n",
      "iteration: 184130 loss: 0.0022 lr: 0.02\n",
      "iteration: 184140 loss: 0.0017 lr: 0.02\n",
      "iteration: 184150 loss: 0.0019 lr: 0.02\n",
      "iteration: 184160 loss: 0.0017 lr: 0.02\n",
      "iteration: 184170 loss: 0.0015 lr: 0.02\n",
      "iteration: 184180 loss: 0.0022 lr: 0.02\n",
      "iteration: 184190 loss: 0.0017 lr: 0.02\n",
      "iteration: 184200 loss: 0.0018 lr: 0.02\n",
      "iteration: 184210 loss: 0.0018 lr: 0.02\n",
      "iteration: 184220 loss: 0.0019 lr: 0.02\n",
      "iteration: 184230 loss: 0.0019 lr: 0.02\n",
      "iteration: 184240 loss: 0.0021 lr: 0.02\n",
      "iteration: 184250 loss: 0.0029 lr: 0.02\n",
      "iteration: 184260 loss: 0.0020 lr: 0.02\n",
      "iteration: 184270 loss: 0.0022 lr: 0.02\n",
      "iteration: 184280 loss: 0.0028 lr: 0.02\n",
      "iteration: 184290 loss: 0.0024 lr: 0.02\n",
      "iteration: 184300 loss: 0.0021 lr: 0.02\n",
      "iteration: 184310 loss: 0.0023 lr: 0.02\n",
      "iteration: 184320 loss: 0.0016 lr: 0.02\n",
      "iteration: 184330 loss: 0.0019 lr: 0.02\n",
      "iteration: 184340 loss: 0.0022 lr: 0.02\n",
      "iteration: 184350 loss: 0.0021 lr: 0.02\n",
      "iteration: 184360 loss: 0.0028 lr: 0.02\n",
      "iteration: 184370 loss: 0.0018 lr: 0.02\n",
      "iteration: 184380 loss: 0.0022 lr: 0.02\n",
      "iteration: 184390 loss: 0.0020 lr: 0.02\n",
      "iteration: 184400 loss: 0.0017 lr: 0.02\n",
      "iteration: 184410 loss: 0.0026 lr: 0.02\n",
      "iteration: 184420 loss: 0.0016 lr: 0.02\n",
      "iteration: 184430 loss: 0.0016 lr: 0.02\n",
      "iteration: 184440 loss: 0.0020 lr: 0.02\n",
      "iteration: 184450 loss: 0.0023 lr: 0.02\n",
      "iteration: 184460 loss: 0.0015 lr: 0.02\n",
      "iteration: 184470 loss: 0.0017 lr: 0.02\n",
      "iteration: 184480 loss: 0.0021 lr: 0.02\n",
      "iteration: 184490 loss: 0.0021 lr: 0.02\n",
      "iteration: 184500 loss: 0.0020 lr: 0.02\n",
      "iteration: 184510 loss: 0.0019 lr: 0.02\n",
      "iteration: 184520 loss: 0.0017 lr: 0.02\n",
      "iteration: 184530 loss: 0.0018 lr: 0.02\n",
      "iteration: 184540 loss: 0.0022 lr: 0.02\n",
      "iteration: 184550 loss: 0.0021 lr: 0.02\n",
      "iteration: 184560 loss: 0.0020 lr: 0.02\n",
      "iteration: 184570 loss: 0.0023 lr: 0.02\n",
      "iteration: 184580 loss: 0.0019 lr: 0.02\n",
      "iteration: 184590 loss: 0.0014 lr: 0.02\n",
      "iteration: 184600 loss: 0.0021 lr: 0.02\n",
      "iteration: 184610 loss: 0.0016 lr: 0.02\n",
      "iteration: 184620 loss: 0.0025 lr: 0.02\n",
      "iteration: 184630 loss: 0.0020 lr: 0.02\n",
      "iteration: 184640 loss: 0.0019 lr: 0.02\n",
      "iteration: 184650 loss: 0.0017 lr: 0.02\n",
      "iteration: 184660 loss: 0.0026 lr: 0.02\n",
      "iteration: 184670 loss: 0.0028 lr: 0.02\n",
      "iteration: 184680 loss: 0.0021 lr: 0.02\n",
      "iteration: 184690 loss: 0.0019 lr: 0.02\n",
      "iteration: 184700 loss: 0.0017 lr: 0.02\n",
      "iteration: 184710 loss: 0.0025 lr: 0.02\n",
      "iteration: 184720 loss: 0.0029 lr: 0.02\n",
      "iteration: 184730 loss: 0.0017 lr: 0.02\n",
      "iteration: 184740 loss: 0.0023 lr: 0.02\n",
      "iteration: 184750 loss: 0.0025 lr: 0.02\n",
      "iteration: 184760 loss: 0.0024 lr: 0.02\n",
      "iteration: 184770 loss: 0.0015 lr: 0.02\n",
      "iteration: 184780 loss: 0.0024 lr: 0.02\n",
      "iteration: 184790 loss: 0.0019 lr: 0.02\n",
      "iteration: 184800 loss: 0.0026 lr: 0.02\n",
      "iteration: 184810 loss: 0.0017 lr: 0.02\n",
      "iteration: 184820 loss: 0.0017 lr: 0.02\n",
      "iteration: 184830 loss: 0.0015 lr: 0.02\n",
      "iteration: 184840 loss: 0.0018 lr: 0.02\n",
      "iteration: 184850 loss: 0.0022 lr: 0.02\n",
      "iteration: 184860 loss: 0.0016 lr: 0.02\n",
      "iteration: 184870 loss: 0.0016 lr: 0.02\n",
      "iteration: 184880 loss: 0.0016 lr: 0.02\n",
      "iteration: 184890 loss: 0.0020 lr: 0.02\n",
      "iteration: 184900 loss: 0.0017 lr: 0.02\n",
      "iteration: 184910 loss: 0.0018 lr: 0.02\n",
      "iteration: 184920 loss: 0.0026 lr: 0.02\n",
      "iteration: 184930 loss: 0.0017 lr: 0.02\n",
      "iteration: 184940 loss: 0.0024 lr: 0.02\n",
      "iteration: 184950 loss: 0.0026 lr: 0.02\n",
      "iteration: 184960 loss: 0.0026 lr: 0.02\n",
      "iteration: 184970 loss: 0.0025 lr: 0.02\n",
      "iteration: 184980 loss: 0.0022 lr: 0.02\n",
      "iteration: 184990 loss: 0.0016 lr: 0.02\n",
      "iteration: 185000 loss: 0.0016 lr: 0.02\n",
      "iteration: 185010 loss: 0.0024 lr: 0.02\n",
      "iteration: 185020 loss: 0.0020 lr: 0.02\n",
      "iteration: 185030 loss: 0.0018 lr: 0.02\n",
      "iteration: 185040 loss: 0.0019 lr: 0.02\n",
      "iteration: 185050 loss: 0.0020 lr: 0.02\n",
      "iteration: 185060 loss: 0.0023 lr: 0.02\n",
      "iteration: 185070 loss: 0.0024 lr: 0.02\n",
      "iteration: 185080 loss: 0.0023 lr: 0.02\n",
      "iteration: 185090 loss: 0.0015 lr: 0.02\n",
      "iteration: 185100 loss: 0.0025 lr: 0.02\n",
      "iteration: 185110 loss: 0.0017 lr: 0.02\n",
      "iteration: 185120 loss: 0.0019 lr: 0.02\n",
      "iteration: 185130 loss: 0.0017 lr: 0.02\n",
      "iteration: 185140 loss: 0.0029 lr: 0.02\n",
      "iteration: 185150 loss: 0.0020 lr: 0.02\n",
      "iteration: 185160 loss: 0.0019 lr: 0.02\n",
      "iteration: 185170 loss: 0.0019 lr: 0.02\n",
      "iteration: 185180 loss: 0.0019 lr: 0.02\n",
      "iteration: 185190 loss: 0.0022 lr: 0.02\n",
      "iteration: 185200 loss: 0.0022 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 185210 loss: 0.0021 lr: 0.02\n",
      "iteration: 185220 loss: 0.0022 lr: 0.02\n",
      "iteration: 185230 loss: 0.0024 lr: 0.02\n",
      "iteration: 185240 loss: 0.0021 lr: 0.02\n",
      "iteration: 185250 loss: 0.0022 lr: 0.02\n",
      "iteration: 185260 loss: 0.0024 lr: 0.02\n",
      "iteration: 185270 loss: 0.0015 lr: 0.02\n",
      "iteration: 185280 loss: 0.0017 lr: 0.02\n",
      "iteration: 185290 loss: 0.0025 lr: 0.02\n",
      "iteration: 185300 loss: 0.0018 lr: 0.02\n",
      "iteration: 185310 loss: 0.0021 lr: 0.02\n",
      "iteration: 185320 loss: 0.0016 lr: 0.02\n",
      "iteration: 185330 loss: 0.0019 lr: 0.02\n",
      "iteration: 185340 loss: 0.0021 lr: 0.02\n",
      "iteration: 185350 loss: 0.0017 lr: 0.02\n",
      "iteration: 185360 loss: 0.0018 lr: 0.02\n",
      "iteration: 185370 loss: 0.0024 lr: 0.02\n",
      "iteration: 185380 loss: 0.0022 lr: 0.02\n",
      "iteration: 185390 loss: 0.0017 lr: 0.02\n",
      "iteration: 185400 loss: 0.0020 lr: 0.02\n",
      "iteration: 185410 loss: 0.0022 lr: 0.02\n",
      "iteration: 185420 loss: 0.0021 lr: 0.02\n",
      "iteration: 185430 loss: 0.0020 lr: 0.02\n",
      "iteration: 185440 loss: 0.0022 lr: 0.02\n",
      "iteration: 185450 loss: 0.0019 lr: 0.02\n",
      "iteration: 185460 loss: 0.0024 lr: 0.02\n",
      "iteration: 185470 loss: 0.0019 lr: 0.02\n",
      "iteration: 185480 loss: 0.0028 lr: 0.02\n",
      "iteration: 185490 loss: 0.0018 lr: 0.02\n",
      "iteration: 185500 loss: 0.0018 lr: 0.02\n",
      "iteration: 185510 loss: 0.0020 lr: 0.02\n",
      "iteration: 185520 loss: 0.0020 lr: 0.02\n",
      "iteration: 185530 loss: 0.0022 lr: 0.02\n",
      "iteration: 185540 loss: 0.0020 lr: 0.02\n",
      "iteration: 185550 loss: 0.0022 lr: 0.02\n",
      "iteration: 185560 loss: 0.0018 lr: 0.02\n",
      "iteration: 185570 loss: 0.0029 lr: 0.02\n",
      "iteration: 185580 loss: 0.0021 lr: 0.02\n",
      "iteration: 185590 loss: 0.0018 lr: 0.02\n",
      "iteration: 185600 loss: 0.0018 lr: 0.02\n",
      "iteration: 185610 loss: 0.0022 lr: 0.02\n",
      "iteration: 185620 loss: 0.0024 lr: 0.02\n",
      "iteration: 185630 loss: 0.0024 lr: 0.02\n",
      "iteration: 185640 loss: 0.0014 lr: 0.02\n",
      "iteration: 185650 loss: 0.0024 lr: 0.02\n",
      "iteration: 185660 loss: 0.0022 lr: 0.02\n",
      "iteration: 185670 loss: 0.0021 lr: 0.02\n",
      "iteration: 185680 loss: 0.0021 lr: 0.02\n",
      "iteration: 185690 loss: 0.0019 lr: 0.02\n",
      "iteration: 185700 loss: 0.0020 lr: 0.02\n",
      "iteration: 185710 loss: 0.0022 lr: 0.02\n",
      "iteration: 185720 loss: 0.0015 lr: 0.02\n",
      "iteration: 185730 loss: 0.0014 lr: 0.02\n",
      "iteration: 185740 loss: 0.0024 lr: 0.02\n",
      "iteration: 185750 loss: 0.0021 lr: 0.02\n",
      "iteration: 185760 loss: 0.0021 lr: 0.02\n",
      "iteration: 185770 loss: 0.0019 lr: 0.02\n",
      "iteration: 185780 loss: 0.0019 lr: 0.02\n",
      "iteration: 185790 loss: 0.0037 lr: 0.02\n",
      "iteration: 185800 loss: 0.0023 lr: 0.02\n",
      "iteration: 185810 loss: 0.0019 lr: 0.02\n",
      "iteration: 185820 loss: 0.0019 lr: 0.02\n",
      "iteration: 185830 loss: 0.0023 lr: 0.02\n",
      "iteration: 185840 loss: 0.0016 lr: 0.02\n",
      "iteration: 185850 loss: 0.0019 lr: 0.02\n",
      "iteration: 185860 loss: 0.0022 lr: 0.02\n",
      "iteration: 185870 loss: 0.0018 lr: 0.02\n",
      "iteration: 185880 loss: 0.0022 lr: 0.02\n",
      "iteration: 185890 loss: 0.0024 lr: 0.02\n",
      "iteration: 185900 loss: 0.0017 lr: 0.02\n",
      "iteration: 185910 loss: 0.0023 lr: 0.02\n",
      "iteration: 185920 loss: 0.0020 lr: 0.02\n",
      "iteration: 185930 loss: 0.0016 lr: 0.02\n",
      "iteration: 185940 loss: 0.0019 lr: 0.02\n",
      "iteration: 185950 loss: 0.0024 lr: 0.02\n",
      "iteration: 185960 loss: 0.0027 lr: 0.02\n",
      "iteration: 185970 loss: 0.0017 lr: 0.02\n",
      "iteration: 185980 loss: 0.0022 lr: 0.02\n",
      "iteration: 185990 loss: 0.0022 lr: 0.02\n",
      "iteration: 186000 loss: 0.0021 lr: 0.02\n",
      "iteration: 186010 loss: 0.0021 lr: 0.02\n",
      "iteration: 186020 loss: 0.0017 lr: 0.02\n",
      "iteration: 186030 loss: 0.0023 lr: 0.02\n",
      "iteration: 186040 loss: 0.0018 lr: 0.02\n",
      "iteration: 186050 loss: 0.0020 lr: 0.02\n",
      "iteration: 186060 loss: 0.0019 lr: 0.02\n",
      "iteration: 186070 loss: 0.0034 lr: 0.02\n",
      "iteration: 186080 loss: 0.0025 lr: 0.02\n",
      "iteration: 186090 loss: 0.0020 lr: 0.02\n",
      "iteration: 186100 loss: 0.0018 lr: 0.02\n",
      "iteration: 186110 loss: 0.0033 lr: 0.02\n",
      "iteration: 186120 loss: 0.0022 lr: 0.02\n",
      "iteration: 186130 loss: 0.0020 lr: 0.02\n",
      "iteration: 186140 loss: 0.0024 lr: 0.02\n",
      "iteration: 186150 loss: 0.0021 lr: 0.02\n",
      "iteration: 186160 loss: 0.0022 lr: 0.02\n",
      "iteration: 186170 loss: 0.0017 lr: 0.02\n",
      "iteration: 186180 loss: 0.0022 lr: 0.02\n",
      "iteration: 186190 loss: 0.0021 lr: 0.02\n",
      "iteration: 186200 loss: 0.0022 lr: 0.02\n",
      "iteration: 186210 loss: 0.0023 lr: 0.02\n",
      "iteration: 186220 loss: 0.0020 lr: 0.02\n",
      "iteration: 186230 loss: 0.0024 lr: 0.02\n",
      "iteration: 186240 loss: 0.0024 lr: 0.02\n",
      "iteration: 186250 loss: 0.0021 lr: 0.02\n",
      "iteration: 186260 loss: 0.0021 lr: 0.02\n",
      "iteration: 186270 loss: 0.0018 lr: 0.02\n",
      "iteration: 186280 loss: 0.0027 lr: 0.02\n",
      "iteration: 186290 loss: 0.0019 lr: 0.02\n",
      "iteration: 186300 loss: 0.0027 lr: 0.02\n",
      "iteration: 186310 loss: 0.0023 lr: 0.02\n",
      "iteration: 186320 loss: 0.0021 lr: 0.02\n",
      "iteration: 186330 loss: 0.0022 lr: 0.02\n",
      "iteration: 186340 loss: 0.0016 lr: 0.02\n",
      "iteration: 186350 loss: 0.0020 lr: 0.02\n",
      "iteration: 186360 loss: 0.0021 lr: 0.02\n",
      "iteration: 186370 loss: 0.0023 lr: 0.02\n",
      "iteration: 186380 loss: 0.0023 lr: 0.02\n",
      "iteration: 186390 loss: 0.0018 lr: 0.02\n",
      "iteration: 186400 loss: 0.0019 lr: 0.02\n",
      "iteration: 186410 loss: 0.0023 lr: 0.02\n",
      "iteration: 186420 loss: 0.0024 lr: 0.02\n",
      "iteration: 186430 loss: 0.0021 lr: 0.02\n",
      "iteration: 186440 loss: 0.0021 lr: 0.02\n",
      "iteration: 186450 loss: 0.0018 lr: 0.02\n",
      "iteration: 186460 loss: 0.0020 lr: 0.02\n",
      "iteration: 186470 loss: 0.0020 lr: 0.02\n",
      "iteration: 186480 loss: 0.0018 lr: 0.02\n",
      "iteration: 186490 loss: 0.0022 lr: 0.02\n",
      "iteration: 186500 loss: 0.0020 lr: 0.02\n",
      "iteration: 186510 loss: 0.0014 lr: 0.02\n",
      "iteration: 186520 loss: 0.0022 lr: 0.02\n",
      "iteration: 186530 loss: 0.0021 lr: 0.02\n",
      "iteration: 186540 loss: 0.0021 lr: 0.02\n",
      "iteration: 186550 loss: 0.0018 lr: 0.02\n",
      "iteration: 186560 loss: 0.0028 lr: 0.02\n",
      "iteration: 186570 loss: 0.0018 lr: 0.02\n",
      "iteration: 186580 loss: 0.0023 lr: 0.02\n",
      "iteration: 186590 loss: 0.0019 lr: 0.02\n",
      "iteration: 186600 loss: 0.0020 lr: 0.02\n",
      "iteration: 186610 loss: 0.0023 lr: 0.02\n",
      "iteration: 186620 loss: 0.0026 lr: 0.02\n",
      "iteration: 186630 loss: 0.0023 lr: 0.02\n",
      "iteration: 186640 loss: 0.0024 lr: 0.02\n",
      "iteration: 186650 loss: 0.0027 lr: 0.02\n",
      "iteration: 186660 loss: 0.0018 lr: 0.02\n",
      "iteration: 186670 loss: 0.0022 lr: 0.02\n",
      "iteration: 186680 loss: 0.0024 lr: 0.02\n",
      "iteration: 186690 loss: 0.0023 lr: 0.02\n",
      "iteration: 186700 loss: 0.0017 lr: 0.02\n",
      "iteration: 186710 loss: 0.0016 lr: 0.02\n",
      "iteration: 186720 loss: 0.0018 lr: 0.02\n",
      "iteration: 186730 loss: 0.0016 lr: 0.02\n",
      "iteration: 186740 loss: 0.0022 lr: 0.02\n",
      "iteration: 186750 loss: 0.0021 lr: 0.02\n",
      "iteration: 186760 loss: 0.0029 lr: 0.02\n",
      "iteration: 186770 loss: 0.0018 lr: 0.02\n",
      "iteration: 186780 loss: 0.0022 lr: 0.02\n",
      "iteration: 186790 loss: 0.0021 lr: 0.02\n",
      "iteration: 186800 loss: 0.0021 lr: 0.02\n",
      "iteration: 186810 loss: 0.0023 lr: 0.02\n",
      "iteration: 186820 loss: 0.0020 lr: 0.02\n",
      "iteration: 186830 loss: 0.0020 lr: 0.02\n",
      "iteration: 186840 loss: 0.0019 lr: 0.02\n",
      "iteration: 186850 loss: 0.0020 lr: 0.02\n",
      "iteration: 186860 loss: 0.0025 lr: 0.02\n",
      "iteration: 186870 loss: 0.0020 lr: 0.02\n",
      "iteration: 186880 loss: 0.0024 lr: 0.02\n",
      "iteration: 186890 loss: 0.0018 lr: 0.02\n",
      "iteration: 186900 loss: 0.0016 lr: 0.02\n",
      "iteration: 186910 loss: 0.0019 lr: 0.02\n",
      "iteration: 186920 loss: 0.0024 lr: 0.02\n",
      "iteration: 186930 loss: 0.0016 lr: 0.02\n",
      "iteration: 186940 loss: 0.0016 lr: 0.02\n",
      "iteration: 186950 loss: 0.0018 lr: 0.02\n",
      "iteration: 186960 loss: 0.0025 lr: 0.02\n",
      "iteration: 186970 loss: 0.0019 lr: 0.02\n",
      "iteration: 186980 loss: 0.0023 lr: 0.02\n",
      "iteration: 186990 loss: 0.0018 lr: 0.02\n",
      "iteration: 187000 loss: 0.0020 lr: 0.02\n",
      "iteration: 187010 loss: 0.0018 lr: 0.02\n",
      "iteration: 187020 loss: 0.0026 lr: 0.02\n",
      "iteration: 187030 loss: 0.0016 lr: 0.02\n",
      "iteration: 187040 loss: 0.0022 lr: 0.02\n",
      "iteration: 187050 loss: 0.0018 lr: 0.02\n",
      "iteration: 187060 loss: 0.0018 lr: 0.02\n",
      "iteration: 187070 loss: 0.0023 lr: 0.02\n",
      "iteration: 187080 loss: 0.0018 lr: 0.02\n",
      "iteration: 187090 loss: 0.0023 lr: 0.02\n",
      "iteration: 187100 loss: 0.0029 lr: 0.02\n",
      "iteration: 187110 loss: 0.0027 lr: 0.02\n",
      "iteration: 187120 loss: 0.0026 lr: 0.02\n",
      "iteration: 187130 loss: 0.0020 lr: 0.02\n",
      "iteration: 187140 loss: 0.0024 lr: 0.02\n",
      "iteration: 187150 loss: 0.0015 lr: 0.02\n",
      "iteration: 187160 loss: 0.0019 lr: 0.02\n",
      "iteration: 187170 loss: 0.0021 lr: 0.02\n",
      "iteration: 187180 loss: 0.0028 lr: 0.02\n",
      "iteration: 187190 loss: 0.0018 lr: 0.02\n",
      "iteration: 187200 loss: 0.0019 lr: 0.02\n",
      "iteration: 187210 loss: 0.0017 lr: 0.02\n",
      "iteration: 187220 loss: 0.0024 lr: 0.02\n",
      "iteration: 187230 loss: 0.0029 lr: 0.02\n",
      "iteration: 187240 loss: 0.0020 lr: 0.02\n",
      "iteration: 187250 loss: 0.0017 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 187260 loss: 0.0024 lr: 0.02\n",
      "iteration: 187270 loss: 0.0019 lr: 0.02\n",
      "iteration: 187280 loss: 0.0020 lr: 0.02\n",
      "iteration: 187290 loss: 0.0023 lr: 0.02\n",
      "iteration: 187300 loss: 0.0020 lr: 0.02\n",
      "iteration: 187310 loss: 0.0021 lr: 0.02\n",
      "iteration: 187320 loss: 0.0023 lr: 0.02\n",
      "iteration: 187330 loss: 0.0015 lr: 0.02\n",
      "iteration: 187340 loss: 0.0018 lr: 0.02\n",
      "iteration: 187350 loss: 0.0017 lr: 0.02\n",
      "iteration: 187360 loss: 0.0025 lr: 0.02\n",
      "iteration: 187370 loss: 0.0019 lr: 0.02\n",
      "iteration: 187380 loss: 0.0020 lr: 0.02\n",
      "iteration: 187390 loss: 0.0025 lr: 0.02\n",
      "iteration: 187400 loss: 0.0022 lr: 0.02\n",
      "iteration: 187410 loss: 0.0025 lr: 0.02\n",
      "iteration: 187420 loss: 0.0018 lr: 0.02\n",
      "iteration: 187430 loss: 0.0020 lr: 0.02\n",
      "iteration: 187440 loss: 0.0022 lr: 0.02\n",
      "iteration: 187450 loss: 0.0025 lr: 0.02\n",
      "iteration: 187460 loss: 0.0017 lr: 0.02\n",
      "iteration: 187470 loss: 0.0015 lr: 0.02\n",
      "iteration: 187480 loss: 0.0023 lr: 0.02\n",
      "iteration: 187490 loss: 0.0025 lr: 0.02\n",
      "iteration: 187500 loss: 0.0018 lr: 0.02\n",
      "iteration: 187510 loss: 0.0027 lr: 0.02\n",
      "iteration: 187520 loss: 0.0019 lr: 0.02\n",
      "iteration: 187530 loss: 0.0016 lr: 0.02\n",
      "iteration: 187540 loss: 0.0017 lr: 0.02\n",
      "iteration: 187550 loss: 0.0022 lr: 0.02\n",
      "iteration: 187560 loss: 0.0017 lr: 0.02\n",
      "iteration: 187570 loss: 0.0017 lr: 0.02\n",
      "iteration: 187580 loss: 0.0017 lr: 0.02\n",
      "iteration: 187590 loss: 0.0017 lr: 0.02\n",
      "iteration: 187600 loss: 0.0016 lr: 0.02\n",
      "iteration: 187610 loss: 0.0021 lr: 0.02\n",
      "iteration: 187620 loss: 0.0020 lr: 0.02\n",
      "iteration: 187630 loss: 0.0023 lr: 0.02\n",
      "iteration: 187640 loss: 0.0018 lr: 0.02\n",
      "iteration: 187650 loss: 0.0014 lr: 0.02\n",
      "iteration: 187660 loss: 0.0023 lr: 0.02\n",
      "iteration: 187670 loss: 0.0027 lr: 0.02\n",
      "iteration: 187680 loss: 0.0027 lr: 0.02\n",
      "iteration: 187690 loss: 0.0025 lr: 0.02\n",
      "iteration: 187700 loss: 0.0018 lr: 0.02\n",
      "iteration: 187710 loss: 0.0019 lr: 0.02\n",
      "iteration: 187720 loss: 0.0018 lr: 0.02\n",
      "iteration: 187730 loss: 0.0022 lr: 0.02\n",
      "iteration: 187740 loss: 0.0015 lr: 0.02\n",
      "iteration: 187750 loss: 0.0014 lr: 0.02\n",
      "iteration: 187760 loss: 0.0015 lr: 0.02\n",
      "iteration: 187770 loss: 0.0016 lr: 0.02\n",
      "iteration: 187780 loss: 0.0032 lr: 0.02\n",
      "iteration: 187790 loss: 0.0022 lr: 0.02\n",
      "iteration: 187800 loss: 0.0021 lr: 0.02\n",
      "iteration: 187810 loss: 0.0025 lr: 0.02\n",
      "iteration: 187820 loss: 0.0019 lr: 0.02\n",
      "iteration: 187830 loss: 0.0026 lr: 0.02\n",
      "iteration: 187840 loss: 0.0021 lr: 0.02\n",
      "iteration: 187850 loss: 0.0022 lr: 0.02\n",
      "iteration: 187860 loss: 0.0020 lr: 0.02\n",
      "iteration: 187870 loss: 0.0026 lr: 0.02\n",
      "iteration: 187880 loss: 0.0019 lr: 0.02\n",
      "iteration: 187890 loss: 0.0025 lr: 0.02\n",
      "iteration: 187900 loss: 0.0019 lr: 0.02\n",
      "iteration: 187910 loss: 0.0019 lr: 0.02\n",
      "iteration: 187920 loss: 0.0024 lr: 0.02\n",
      "iteration: 187930 loss: 0.0020 lr: 0.02\n",
      "iteration: 187940 loss: 0.0021 lr: 0.02\n",
      "iteration: 187950 loss: 0.0018 lr: 0.02\n",
      "iteration: 187960 loss: 0.0018 lr: 0.02\n",
      "iteration: 187970 loss: 0.0019 lr: 0.02\n",
      "iteration: 187980 loss: 0.0018 lr: 0.02\n",
      "iteration: 187990 loss: 0.0020 lr: 0.02\n",
      "iteration: 188000 loss: 0.0015 lr: 0.02\n",
      "iteration: 188010 loss: 0.0019 lr: 0.02\n",
      "iteration: 188020 loss: 0.0020 lr: 0.02\n",
      "iteration: 188030 loss: 0.0026 lr: 0.02\n",
      "iteration: 188040 loss: 0.0019 lr: 0.02\n",
      "iteration: 188050 loss: 0.0021 lr: 0.02\n",
      "iteration: 188060 loss: 0.0029 lr: 0.02\n",
      "iteration: 188070 loss: 0.0015 lr: 0.02\n",
      "iteration: 188080 loss: 0.0025 lr: 0.02\n",
      "iteration: 188090 loss: 0.0021 lr: 0.02\n",
      "iteration: 188100 loss: 0.0019 lr: 0.02\n",
      "iteration: 188110 loss: 0.0024 lr: 0.02\n",
      "iteration: 188120 loss: 0.0019 lr: 0.02\n",
      "iteration: 188130 loss: 0.0018 lr: 0.02\n",
      "iteration: 188140 loss: 0.0017 lr: 0.02\n",
      "iteration: 188150 loss: 0.0021 lr: 0.02\n",
      "iteration: 188160 loss: 0.0024 lr: 0.02\n",
      "iteration: 188170 loss: 0.0019 lr: 0.02\n",
      "iteration: 188180 loss: 0.0017 lr: 0.02\n",
      "iteration: 188190 loss: 0.0017 lr: 0.02\n",
      "iteration: 188200 loss: 0.0016 lr: 0.02\n",
      "iteration: 188210 loss: 0.0023 lr: 0.02\n",
      "iteration: 188220 loss: 0.0019 lr: 0.02\n",
      "iteration: 188230 loss: 0.0017 lr: 0.02\n",
      "iteration: 188240 loss: 0.0020 lr: 0.02\n",
      "iteration: 188250 loss: 0.0018 lr: 0.02\n",
      "iteration: 188260 loss: 0.0020 lr: 0.02\n",
      "iteration: 188270 loss: 0.0022 lr: 0.02\n",
      "iteration: 188280 loss: 0.0023 lr: 0.02\n",
      "iteration: 188290 loss: 0.0020 lr: 0.02\n",
      "iteration: 188300 loss: 0.0020 lr: 0.02\n",
      "iteration: 188310 loss: 0.0023 lr: 0.02\n",
      "iteration: 188320 loss: 0.0021 lr: 0.02\n",
      "iteration: 188330 loss: 0.0024 lr: 0.02\n",
      "iteration: 188340 loss: 0.0022 lr: 0.02\n",
      "iteration: 188350 loss: 0.0024 lr: 0.02\n",
      "iteration: 188360 loss: 0.0027 lr: 0.02\n",
      "iteration: 188370 loss: 0.0018 lr: 0.02\n",
      "iteration: 188380 loss: 0.0017 lr: 0.02\n",
      "iteration: 188390 loss: 0.0021 lr: 0.02\n",
      "iteration: 188400 loss: 0.0020 lr: 0.02\n",
      "iteration: 188410 loss: 0.0021 lr: 0.02\n",
      "iteration: 188420 loss: 0.0025 lr: 0.02\n",
      "iteration: 188430 loss: 0.0025 lr: 0.02\n",
      "iteration: 188440 loss: 0.0027 lr: 0.02\n",
      "iteration: 188450 loss: 0.0019 lr: 0.02\n",
      "iteration: 188460 loss: 0.0023 lr: 0.02\n",
      "iteration: 188470 loss: 0.0021 lr: 0.02\n",
      "iteration: 188480 loss: 0.0023 lr: 0.02\n",
      "iteration: 188490 loss: 0.0019 lr: 0.02\n",
      "iteration: 188500 loss: 0.0020 lr: 0.02\n",
      "iteration: 188510 loss: 0.0020 lr: 0.02\n",
      "iteration: 188520 loss: 0.0018 lr: 0.02\n",
      "iteration: 188530 loss: 0.0020 lr: 0.02\n",
      "iteration: 188540 loss: 0.0015 lr: 0.02\n",
      "iteration: 188550 loss: 0.0022 lr: 0.02\n",
      "iteration: 188560 loss: 0.0015 lr: 0.02\n",
      "iteration: 188570 loss: 0.0023 lr: 0.02\n",
      "iteration: 188580 loss: 0.0019 lr: 0.02\n",
      "iteration: 188590 loss: 0.0019 lr: 0.02\n",
      "iteration: 188600 loss: 0.0018 lr: 0.02\n",
      "iteration: 188610 loss: 0.0023 lr: 0.02\n",
      "iteration: 188620 loss: 0.0016 lr: 0.02\n",
      "iteration: 188630 loss: 0.0031 lr: 0.02\n",
      "iteration: 188640 loss: 0.0015 lr: 0.02\n",
      "iteration: 188650 loss: 0.0023 lr: 0.02\n",
      "iteration: 188660 loss: 0.0016 lr: 0.02\n",
      "iteration: 188670 loss: 0.0019 lr: 0.02\n",
      "iteration: 188680 loss: 0.0018 lr: 0.02\n",
      "iteration: 188690 loss: 0.0021 lr: 0.02\n",
      "iteration: 188700 loss: 0.0018 lr: 0.02\n",
      "iteration: 188710 loss: 0.0020 lr: 0.02\n",
      "iteration: 188720 loss: 0.0028 lr: 0.02\n",
      "iteration: 188730 loss: 0.0021 lr: 0.02\n",
      "iteration: 188740 loss: 0.0018 lr: 0.02\n",
      "iteration: 188750 loss: 0.0020 lr: 0.02\n",
      "iteration: 188760 loss: 0.0025 lr: 0.02\n",
      "iteration: 188770 loss: 0.0018 lr: 0.02\n",
      "iteration: 188780 loss: 0.0021 lr: 0.02\n",
      "iteration: 188790 loss: 0.0016 lr: 0.02\n",
      "iteration: 188800 loss: 0.0019 lr: 0.02\n",
      "iteration: 188810 loss: 0.0018 lr: 0.02\n",
      "iteration: 188820 loss: 0.0022 lr: 0.02\n",
      "iteration: 188830 loss: 0.0019 lr: 0.02\n",
      "iteration: 188840 loss: 0.0021 lr: 0.02\n",
      "iteration: 188850 loss: 0.0019 lr: 0.02\n",
      "iteration: 188860 loss: 0.0019 lr: 0.02\n",
      "iteration: 188870 loss: 0.0023 lr: 0.02\n",
      "iteration: 188880 loss: 0.0018 lr: 0.02\n",
      "iteration: 188890 loss: 0.0017 lr: 0.02\n",
      "iteration: 188900 loss: 0.0021 lr: 0.02\n",
      "iteration: 188910 loss: 0.0018 lr: 0.02\n",
      "iteration: 188920 loss: 0.0024 lr: 0.02\n",
      "iteration: 188930 loss: 0.0021 lr: 0.02\n",
      "iteration: 188940 loss: 0.0021 lr: 0.02\n",
      "iteration: 188950 loss: 0.0016 lr: 0.02\n",
      "iteration: 188960 loss: 0.0022 lr: 0.02\n",
      "iteration: 188970 loss: 0.0019 lr: 0.02\n",
      "iteration: 188980 loss: 0.0032 lr: 0.02\n",
      "iteration: 188990 loss: 0.0016 lr: 0.02\n",
      "iteration: 189000 loss: 0.0019 lr: 0.02\n",
      "iteration: 189010 loss: 0.0024 lr: 0.02\n",
      "iteration: 189020 loss: 0.0022 lr: 0.02\n",
      "iteration: 189030 loss: 0.0024 lr: 0.02\n",
      "iteration: 189040 loss: 0.0022 lr: 0.02\n",
      "iteration: 189050 loss: 0.0025 lr: 0.02\n",
      "iteration: 189060 loss: 0.0016 lr: 0.02\n",
      "iteration: 189070 loss: 0.0028 lr: 0.02\n",
      "iteration: 189080 loss: 0.0019 lr: 0.02\n",
      "iteration: 189090 loss: 0.0024 lr: 0.02\n",
      "iteration: 189100 loss: 0.0024 lr: 0.02\n",
      "iteration: 189110 loss: 0.0026 lr: 0.02\n",
      "iteration: 189120 loss: 0.0017 lr: 0.02\n",
      "iteration: 189130 loss: 0.0019 lr: 0.02\n",
      "iteration: 189140 loss: 0.0020 lr: 0.02\n",
      "iteration: 189150 loss: 0.0019 lr: 0.02\n",
      "iteration: 189160 loss: 0.0020 lr: 0.02\n",
      "iteration: 189170 loss: 0.0018 lr: 0.02\n",
      "iteration: 189180 loss: 0.0017 lr: 0.02\n",
      "iteration: 189190 loss: 0.0021 lr: 0.02\n",
      "iteration: 189200 loss: 0.0021 lr: 0.02\n",
      "iteration: 189210 loss: 0.0018 lr: 0.02\n",
      "iteration: 189220 loss: 0.0020 lr: 0.02\n",
      "iteration: 189230 loss: 0.0021 lr: 0.02\n",
      "iteration: 189240 loss: 0.0023 lr: 0.02\n",
      "iteration: 189250 loss: 0.0017 lr: 0.02\n",
      "iteration: 189260 loss: 0.0019 lr: 0.02\n",
      "iteration: 189270 loss: 0.0019 lr: 0.02\n",
      "iteration: 189280 loss: 0.0024 lr: 0.02\n",
      "iteration: 189290 loss: 0.0026 lr: 0.02\n",
      "iteration: 189300 loss: 0.0015 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 189310 loss: 0.0022 lr: 0.02\n",
      "iteration: 189320 loss: 0.0019 lr: 0.02\n",
      "iteration: 189330 loss: 0.0018 lr: 0.02\n",
      "iteration: 189340 loss: 0.0020 lr: 0.02\n",
      "iteration: 189350 loss: 0.0024 lr: 0.02\n",
      "iteration: 189360 loss: 0.0028 lr: 0.02\n",
      "iteration: 189370 loss: 0.0027 lr: 0.02\n",
      "iteration: 189380 loss: 0.0019 lr: 0.02\n",
      "iteration: 189390 loss: 0.0019 lr: 0.02\n",
      "iteration: 189400 loss: 0.0023 lr: 0.02\n",
      "iteration: 189410 loss: 0.0020 lr: 0.02\n",
      "iteration: 189420 loss: 0.0019 lr: 0.02\n",
      "iteration: 189430 loss: 0.0019 lr: 0.02\n",
      "iteration: 189440 loss: 0.0038 lr: 0.02\n",
      "iteration: 189450 loss: 0.0022 lr: 0.02\n",
      "iteration: 189460 loss: 0.0021 lr: 0.02\n",
      "iteration: 189470 loss: 0.0019 lr: 0.02\n",
      "iteration: 189480 loss: 0.0021 lr: 0.02\n",
      "iteration: 189490 loss: 0.0018 lr: 0.02\n",
      "iteration: 189500 loss: 0.0019 lr: 0.02\n",
      "iteration: 189510 loss: 0.0018 lr: 0.02\n",
      "iteration: 189520 loss: 0.0022 lr: 0.02\n",
      "iteration: 189530 loss: 0.0016 lr: 0.02\n",
      "iteration: 189540 loss: 0.0022 lr: 0.02\n",
      "iteration: 189550 loss: 0.0018 lr: 0.02\n",
      "iteration: 189560 loss: 0.0023 lr: 0.02\n",
      "iteration: 189570 loss: 0.0025 lr: 0.02\n",
      "iteration: 189580 loss: 0.0027 lr: 0.02\n",
      "iteration: 189590 loss: 0.0025 lr: 0.02\n",
      "iteration: 189600 loss: 0.0016 lr: 0.02\n",
      "iteration: 189610 loss: 0.0022 lr: 0.02\n",
      "iteration: 189620 loss: 0.0022 lr: 0.02\n",
      "iteration: 189630 loss: 0.0020 lr: 0.02\n",
      "iteration: 189640 loss: 0.0018 lr: 0.02\n",
      "iteration: 189650 loss: 0.0025 lr: 0.02\n",
      "iteration: 189660 loss: 0.0017 lr: 0.02\n",
      "iteration: 189670 loss: 0.0028 lr: 0.02\n",
      "iteration: 189680 loss: 0.0027 lr: 0.02\n",
      "iteration: 189690 loss: 0.0023 lr: 0.02\n",
      "iteration: 189700 loss: 0.0017 lr: 0.02\n",
      "iteration: 189710 loss: 0.0018 lr: 0.02\n",
      "iteration: 189720 loss: 0.0026 lr: 0.02\n",
      "iteration: 189730 loss: 0.0019 lr: 0.02\n",
      "iteration: 189740 loss: 0.0023 lr: 0.02\n",
      "iteration: 189750 loss: 0.0025 lr: 0.02\n",
      "iteration: 189760 loss: 0.0019 lr: 0.02\n",
      "iteration: 189770 loss: 0.0024 lr: 0.02\n",
      "iteration: 189780 loss: 0.0017 lr: 0.02\n",
      "iteration: 189790 loss: 0.0021 lr: 0.02\n",
      "iteration: 189800 loss: 0.0017 lr: 0.02\n",
      "iteration: 189810 loss: 0.0023 lr: 0.02\n",
      "iteration: 189820 loss: 0.0016 lr: 0.02\n",
      "iteration: 189830 loss: 0.0028 lr: 0.02\n",
      "iteration: 189840 loss: 0.0019 lr: 0.02\n",
      "iteration: 189850 loss: 0.0015 lr: 0.02\n",
      "iteration: 189860 loss: 0.0023 lr: 0.02\n",
      "iteration: 189870 loss: 0.0026 lr: 0.02\n",
      "iteration: 189880 loss: 0.0023 lr: 0.02\n",
      "iteration: 189890 loss: 0.0020 lr: 0.02\n",
      "iteration: 189900 loss: 0.0022 lr: 0.02\n",
      "iteration: 189910 loss: 0.0025 lr: 0.02\n",
      "iteration: 189920 loss: 0.0030 lr: 0.02\n",
      "iteration: 189930 loss: 0.0020 lr: 0.02\n",
      "iteration: 189940 loss: 0.0020 lr: 0.02\n",
      "iteration: 189950 loss: 0.0021 lr: 0.02\n",
      "iteration: 189960 loss: 0.0017 lr: 0.02\n",
      "iteration: 189970 loss: 0.0021 lr: 0.02\n",
      "iteration: 189980 loss: 0.0020 lr: 0.02\n",
      "iteration: 189990 loss: 0.0019 lr: 0.02\n",
      "iteration: 190000 loss: 0.0019 lr: 0.02\n",
      "iteration: 190010 loss: 0.0019 lr: 0.02\n",
      "iteration: 190020 loss: 0.0020 lr: 0.02\n",
      "iteration: 190030 loss: 0.0026 lr: 0.02\n",
      "iteration: 190040 loss: 0.0020 lr: 0.02\n",
      "iteration: 190050 loss: 0.0018 lr: 0.02\n",
      "iteration: 190060 loss: 0.0019 lr: 0.02\n",
      "iteration: 190070 loss: 0.0019 lr: 0.02\n",
      "iteration: 190080 loss: 0.0022 lr: 0.02\n",
      "iteration: 190090 loss: 0.0025 lr: 0.02\n",
      "iteration: 190100 loss: 0.0024 lr: 0.02\n",
      "iteration: 190110 loss: 0.0021 lr: 0.02\n",
      "iteration: 190120 loss: 0.0015 lr: 0.02\n",
      "iteration: 190130 loss: 0.0027 lr: 0.02\n",
      "iteration: 190140 loss: 0.0024 lr: 0.02\n",
      "iteration: 190150 loss: 0.0019 lr: 0.02\n",
      "iteration: 190160 loss: 0.0021 lr: 0.02\n",
      "iteration: 190170 loss: 0.0020 lr: 0.02\n",
      "iteration: 190180 loss: 0.0023 lr: 0.02\n",
      "iteration: 190190 loss: 0.0027 lr: 0.02\n",
      "iteration: 190200 loss: 0.0019 lr: 0.02\n",
      "iteration: 190210 loss: 0.0020 lr: 0.02\n",
      "iteration: 190220 loss: 0.0014 lr: 0.02\n",
      "iteration: 190230 loss: 0.0020 lr: 0.02\n",
      "iteration: 190240 loss: 0.0019 lr: 0.02\n",
      "iteration: 190250 loss: 0.0016 lr: 0.02\n",
      "iteration: 190260 loss: 0.0020 lr: 0.02\n",
      "iteration: 190270 loss: 0.0021 lr: 0.02\n",
      "iteration: 190280 loss: 0.0022 lr: 0.02\n",
      "iteration: 190290 loss: 0.0019 lr: 0.02\n",
      "iteration: 190300 loss: 0.0015 lr: 0.02\n",
      "iteration: 190310 loss: 0.0021 lr: 0.02\n",
      "iteration: 190320 loss: 0.0018 lr: 0.02\n",
      "iteration: 190330 loss: 0.0022 lr: 0.02\n",
      "iteration: 190340 loss: 0.0021 lr: 0.02\n",
      "iteration: 190350 loss: 0.0020 lr: 0.02\n",
      "iteration: 190360 loss: 0.0023 lr: 0.02\n",
      "iteration: 190370 loss: 0.0020 lr: 0.02\n",
      "iteration: 190380 loss: 0.0018 lr: 0.02\n",
      "iteration: 190390 loss: 0.0020 lr: 0.02\n",
      "iteration: 190400 loss: 0.0017 lr: 0.02\n",
      "iteration: 190410 loss: 0.0016 lr: 0.02\n",
      "iteration: 190420 loss: 0.0025 lr: 0.02\n",
      "iteration: 190430 loss: 0.0021 lr: 0.02\n",
      "iteration: 190440 loss: 0.0021 lr: 0.02\n",
      "iteration: 190450 loss: 0.0020 lr: 0.02\n",
      "iteration: 190460 loss: 0.0024 lr: 0.02\n",
      "iteration: 190470 loss: 0.0025 lr: 0.02\n",
      "iteration: 190480 loss: 0.0023 lr: 0.02\n",
      "iteration: 190490 loss: 0.0023 lr: 0.02\n",
      "iteration: 190500 loss: 0.0021 lr: 0.02\n",
      "iteration: 190510 loss: 0.0028 lr: 0.02\n",
      "iteration: 190520 loss: 0.0018 lr: 0.02\n",
      "iteration: 190530 loss: 0.0017 lr: 0.02\n",
      "iteration: 190540 loss: 0.0018 lr: 0.02\n",
      "iteration: 190550 loss: 0.0019 lr: 0.02\n",
      "iteration: 190560 loss: 0.0016 lr: 0.02\n",
      "iteration: 190570 loss: 0.0023 lr: 0.02\n",
      "iteration: 190580 loss: 0.0019 lr: 0.02\n",
      "iteration: 190590 loss: 0.0016 lr: 0.02\n",
      "iteration: 190600 loss: 0.0023 lr: 0.02\n",
      "iteration: 190610 loss: 0.0015 lr: 0.02\n",
      "iteration: 190620 loss: 0.0025 lr: 0.02\n",
      "iteration: 190630 loss: 0.0017 lr: 0.02\n",
      "iteration: 190640 loss: 0.0019 lr: 0.02\n",
      "iteration: 190650 loss: 0.0017 lr: 0.02\n",
      "iteration: 190660 loss: 0.0016 lr: 0.02\n",
      "iteration: 190670 loss: 0.0021 lr: 0.02\n",
      "iteration: 190680 loss: 0.0023 lr: 0.02\n",
      "iteration: 190690 loss: 0.0020 lr: 0.02\n",
      "iteration: 190700 loss: 0.0025 lr: 0.02\n",
      "iteration: 190710 loss: 0.0018 lr: 0.02\n",
      "iteration: 190720 loss: 0.0040 lr: 0.02\n",
      "iteration: 190730 loss: 0.0027 lr: 0.02\n",
      "iteration: 190740 loss: 0.0019 lr: 0.02\n",
      "iteration: 190750 loss: 0.0025 lr: 0.02\n",
      "iteration: 190760 loss: 0.0018 lr: 0.02\n",
      "iteration: 190770 loss: 0.0018 lr: 0.02\n",
      "iteration: 190780 loss: 0.0019 lr: 0.02\n",
      "iteration: 190790 loss: 0.0024 lr: 0.02\n",
      "iteration: 190800 loss: 0.0030 lr: 0.02\n",
      "iteration: 190810 loss: 0.0018 lr: 0.02\n",
      "iteration: 190820 loss: 0.0023 lr: 0.02\n",
      "iteration: 190830 loss: 0.0018 lr: 0.02\n",
      "iteration: 190840 loss: 0.0021 lr: 0.02\n",
      "iteration: 190850 loss: 0.0019 lr: 0.02\n",
      "iteration: 190860 loss: 0.0016 lr: 0.02\n",
      "iteration: 190870 loss: 0.0020 lr: 0.02\n",
      "iteration: 190880 loss: 0.0017 lr: 0.02\n",
      "iteration: 190890 loss: 0.0021 lr: 0.02\n",
      "iteration: 190900 loss: 0.0024 lr: 0.02\n",
      "iteration: 190910 loss: 0.0020 lr: 0.02\n",
      "iteration: 190920 loss: 0.0024 lr: 0.02\n",
      "iteration: 190930 loss: 0.0021 lr: 0.02\n",
      "iteration: 190940 loss: 0.0019 lr: 0.02\n",
      "iteration: 190950 loss: 0.0021 lr: 0.02\n",
      "iteration: 190960 loss: 0.0028 lr: 0.02\n",
      "iteration: 190970 loss: 0.0026 lr: 0.02\n",
      "iteration: 190980 loss: 0.0019 lr: 0.02\n",
      "iteration: 190990 loss: 0.0019 lr: 0.02\n",
      "iteration: 191000 loss: 0.0018 lr: 0.02\n",
      "iteration: 191010 loss: 0.0017 lr: 0.02\n",
      "iteration: 191020 loss: 0.0018 lr: 0.02\n",
      "iteration: 191030 loss: 0.0018 lr: 0.02\n",
      "iteration: 191040 loss: 0.0020 lr: 0.02\n",
      "iteration: 191050 loss: 0.0022 lr: 0.02\n",
      "iteration: 191060 loss: 0.0020 lr: 0.02\n",
      "iteration: 191070 loss: 0.0020 lr: 0.02\n",
      "iteration: 191080 loss: 0.0019 lr: 0.02\n",
      "iteration: 191090 loss: 0.0026 lr: 0.02\n",
      "iteration: 191100 loss: 0.0019 lr: 0.02\n",
      "iteration: 191110 loss: 0.0021 lr: 0.02\n",
      "iteration: 191120 loss: 0.0016 lr: 0.02\n",
      "iteration: 191130 loss: 0.0024 lr: 0.02\n",
      "iteration: 191140 loss: 0.0023 lr: 0.02\n",
      "iteration: 191150 loss: 0.0021 lr: 0.02\n",
      "iteration: 191160 loss: 0.0023 lr: 0.02\n",
      "iteration: 191170 loss: 0.0028 lr: 0.02\n",
      "iteration: 191180 loss: 0.0024 lr: 0.02\n",
      "iteration: 191190 loss: 0.0023 lr: 0.02\n",
      "iteration: 191200 loss: 0.0018 lr: 0.02\n",
      "iteration: 191210 loss: 0.0020 lr: 0.02\n",
      "iteration: 191220 loss: 0.0023 lr: 0.02\n",
      "iteration: 191230 loss: 0.0020 lr: 0.02\n",
      "iteration: 191240 loss: 0.0023 lr: 0.02\n",
      "iteration: 191250 loss: 0.0017 lr: 0.02\n",
      "iteration: 191260 loss: 0.0021 lr: 0.02\n",
      "iteration: 191270 loss: 0.0017 lr: 0.02\n",
      "iteration: 191280 loss: 0.0019 lr: 0.02\n",
      "iteration: 191290 loss: 0.0024 lr: 0.02\n",
      "iteration: 191300 loss: 0.0016 lr: 0.02\n",
      "iteration: 191310 loss: 0.0020 lr: 0.02\n",
      "iteration: 191320 loss: 0.0016 lr: 0.02\n",
      "iteration: 191330 loss: 0.0023 lr: 0.02\n",
      "iteration: 191340 loss: 0.0022 lr: 0.02\n",
      "iteration: 191350 loss: 0.0021 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 191360 loss: 0.0023 lr: 0.02\n",
      "iteration: 191370 loss: 0.0019 lr: 0.02\n",
      "iteration: 191380 loss: 0.0024 lr: 0.02\n",
      "iteration: 191390 loss: 0.0020 lr: 0.02\n",
      "iteration: 191400 loss: 0.0023 lr: 0.02\n",
      "iteration: 191410 loss: 0.0020 lr: 0.02\n",
      "iteration: 191420 loss: 0.0019 lr: 0.02\n",
      "iteration: 191430 loss: 0.0017 lr: 0.02\n",
      "iteration: 191440 loss: 0.0016 lr: 0.02\n",
      "iteration: 191450 loss: 0.0021 lr: 0.02\n",
      "iteration: 191460 loss: 0.0018 lr: 0.02\n",
      "iteration: 191470 loss: 0.0022 lr: 0.02\n",
      "iteration: 191480 loss: 0.0025 lr: 0.02\n",
      "iteration: 191490 loss: 0.0021 lr: 0.02\n",
      "iteration: 191500 loss: 0.0020 lr: 0.02\n",
      "iteration: 191510 loss: 0.0021 lr: 0.02\n",
      "iteration: 191520 loss: 0.0022 lr: 0.02\n",
      "iteration: 191530 loss: 0.0019 lr: 0.02\n",
      "iteration: 191540 loss: 0.0023 lr: 0.02\n",
      "iteration: 191550 loss: 0.0023 lr: 0.02\n",
      "iteration: 191560 loss: 0.0029 lr: 0.02\n",
      "iteration: 191570 loss: 0.0023 lr: 0.02\n",
      "iteration: 191580 loss: 0.0018 lr: 0.02\n",
      "iteration: 191590 loss: 0.0017 lr: 0.02\n",
      "iteration: 191600 loss: 0.0020 lr: 0.02\n",
      "iteration: 191610 loss: 0.0023 lr: 0.02\n",
      "iteration: 191620 loss: 0.0022 lr: 0.02\n",
      "iteration: 191630 loss: 0.0027 lr: 0.02\n",
      "iteration: 191640 loss: 0.0031 lr: 0.02\n",
      "iteration: 191650 loss: 0.0019 lr: 0.02\n",
      "iteration: 191660 loss: 0.0018 lr: 0.02\n",
      "iteration: 191670 loss: 0.0019 lr: 0.02\n",
      "iteration: 191680 loss: 0.0023 lr: 0.02\n",
      "iteration: 191690 loss: 0.0020 lr: 0.02\n",
      "iteration: 191700 loss: 0.0024 lr: 0.02\n",
      "iteration: 191710 loss: 0.0028 lr: 0.02\n",
      "iteration: 191720 loss: 0.0025 lr: 0.02\n",
      "iteration: 191730 loss: 0.0020 lr: 0.02\n",
      "iteration: 191740 loss: 0.0024 lr: 0.02\n",
      "iteration: 191750 loss: 0.0026 lr: 0.02\n",
      "iteration: 191760 loss: 0.0020 lr: 0.02\n",
      "iteration: 191770 loss: 0.0022 lr: 0.02\n",
      "iteration: 191780 loss: 0.0023 lr: 0.02\n",
      "iteration: 191790 loss: 0.0018 lr: 0.02\n",
      "iteration: 191800 loss: 0.0025 lr: 0.02\n",
      "iteration: 191810 loss: 0.0019 lr: 0.02\n",
      "iteration: 191820 loss: 0.0023 lr: 0.02\n",
      "iteration: 191830 loss: 0.0026 lr: 0.02\n",
      "iteration: 191840 loss: 0.0018 lr: 0.02\n",
      "iteration: 191850 loss: 0.0019 lr: 0.02\n",
      "iteration: 191860 loss: 0.0021 lr: 0.02\n",
      "iteration: 191870 loss: 0.0021 lr: 0.02\n",
      "iteration: 191880 loss: 0.0018 lr: 0.02\n",
      "iteration: 191890 loss: 0.0022 lr: 0.02\n",
      "iteration: 191900 loss: 0.0017 lr: 0.02\n",
      "iteration: 191910 loss: 0.0023 lr: 0.02\n",
      "iteration: 191920 loss: 0.0020 lr: 0.02\n",
      "iteration: 191930 loss: 0.0020 lr: 0.02\n",
      "iteration: 191940 loss: 0.0023 lr: 0.02\n",
      "iteration: 191950 loss: 0.0020 lr: 0.02\n",
      "iteration: 191960 loss: 0.0025 lr: 0.02\n",
      "iteration: 191970 loss: 0.0026 lr: 0.02\n",
      "iteration: 191980 loss: 0.0020 lr: 0.02\n",
      "iteration: 191990 loss: 0.0025 lr: 0.02\n",
      "iteration: 192000 loss: 0.0029 lr: 0.02\n",
      "iteration: 192010 loss: 0.0020 lr: 0.02\n",
      "iteration: 192020 loss: 0.0018 lr: 0.02\n",
      "iteration: 192030 loss: 0.0024 lr: 0.02\n",
      "iteration: 192040 loss: 0.0026 lr: 0.02\n",
      "iteration: 192050 loss: 0.0019 lr: 0.02\n",
      "iteration: 192060 loss: 0.0020 lr: 0.02\n",
      "iteration: 192070 loss: 0.0020 lr: 0.02\n",
      "iteration: 192080 loss: 0.0017 lr: 0.02\n",
      "iteration: 192090 loss: 0.0016 lr: 0.02\n",
      "iteration: 192100 loss: 0.0019 lr: 0.02\n",
      "iteration: 192110 loss: 0.0022 lr: 0.02\n",
      "iteration: 192120 loss: 0.0024 lr: 0.02\n",
      "iteration: 192130 loss: 0.0018 lr: 0.02\n",
      "iteration: 192140 loss: 0.0021 lr: 0.02\n",
      "iteration: 192150 loss: 0.0021 lr: 0.02\n",
      "iteration: 192160 loss: 0.0019 lr: 0.02\n",
      "iteration: 192170 loss: 0.0018 lr: 0.02\n",
      "iteration: 192180 loss: 0.0025 lr: 0.02\n",
      "iteration: 192190 loss: 0.0018 lr: 0.02\n",
      "iteration: 192200 loss: 0.0020 lr: 0.02\n",
      "iteration: 192210 loss: 0.0026 lr: 0.02\n",
      "iteration: 192220 loss: 0.0020 lr: 0.02\n",
      "iteration: 192230 loss: 0.0018 lr: 0.02\n",
      "iteration: 192240 loss: 0.0020 lr: 0.02\n",
      "iteration: 192250 loss: 0.0017 lr: 0.02\n",
      "iteration: 192260 loss: 0.0020 lr: 0.02\n",
      "iteration: 192270 loss: 0.0027 lr: 0.02\n",
      "iteration: 192280 loss: 0.0019 lr: 0.02\n",
      "iteration: 192290 loss: 0.0017 lr: 0.02\n",
      "iteration: 192300 loss: 0.0023 lr: 0.02\n",
      "iteration: 192310 loss: 0.0027 lr: 0.02\n",
      "iteration: 192320 loss: 0.0022 lr: 0.02\n",
      "iteration: 192330 loss: 0.0020 lr: 0.02\n",
      "iteration: 192340 loss: 0.0026 lr: 0.02\n",
      "iteration: 192350 loss: 0.0032 lr: 0.02\n",
      "iteration: 192360 loss: 0.0020 lr: 0.02\n",
      "iteration: 192370 loss: 0.0023 lr: 0.02\n",
      "iteration: 192380 loss: 0.0022 lr: 0.02\n",
      "iteration: 192390 loss: 0.0030 lr: 0.02\n",
      "iteration: 192400 loss: 0.0019 lr: 0.02\n",
      "iteration: 192410 loss: 0.0023 lr: 0.02\n",
      "iteration: 192420 loss: 0.0016 lr: 0.02\n",
      "iteration: 192430 loss: 0.0021 lr: 0.02\n",
      "iteration: 192440 loss: 0.0023 lr: 0.02\n",
      "iteration: 192450 loss: 0.0022 lr: 0.02\n",
      "iteration: 192460 loss: 0.0022 lr: 0.02\n",
      "iteration: 192470 loss: 0.0022 lr: 0.02\n",
      "iteration: 192480 loss: 0.0020 lr: 0.02\n",
      "iteration: 192490 loss: 0.0023 lr: 0.02\n",
      "iteration: 192500 loss: 0.0023 lr: 0.02\n",
      "iteration: 192510 loss: 0.0025 lr: 0.02\n",
      "iteration: 192520 loss: 0.0019 lr: 0.02\n",
      "iteration: 192530 loss: 0.0020 lr: 0.02\n",
      "iteration: 192540 loss: 0.0023 lr: 0.02\n",
      "iteration: 192550 loss: 0.0026 lr: 0.02\n",
      "iteration: 192560 loss: 0.0022 lr: 0.02\n",
      "iteration: 192570 loss: 0.0022 lr: 0.02\n",
      "iteration: 192580 loss: 0.0017 lr: 0.02\n",
      "iteration: 192590 loss: 0.0023 lr: 0.02\n",
      "iteration: 192600 loss: 0.0015 lr: 0.02\n",
      "iteration: 192610 loss: 0.0018 lr: 0.02\n",
      "iteration: 192620 loss: 0.0026 lr: 0.02\n",
      "iteration: 192630 loss: 0.0021 lr: 0.02\n",
      "iteration: 192640 loss: 0.0018 lr: 0.02\n",
      "iteration: 192650 loss: 0.0019 lr: 0.02\n",
      "iteration: 192660 loss: 0.0018 lr: 0.02\n",
      "iteration: 192670 loss: 0.0023 lr: 0.02\n",
      "iteration: 192680 loss: 0.0022 lr: 0.02\n",
      "iteration: 192690 loss: 0.0021 lr: 0.02\n",
      "iteration: 192700 loss: 0.0019 lr: 0.02\n",
      "iteration: 192710 loss: 0.0018 lr: 0.02\n",
      "iteration: 192720 loss: 0.0016 lr: 0.02\n",
      "iteration: 192730 loss: 0.0020 lr: 0.02\n",
      "iteration: 192740 loss: 0.0018 lr: 0.02\n",
      "iteration: 192750 loss: 0.0022 lr: 0.02\n",
      "iteration: 192760 loss: 0.0020 lr: 0.02\n",
      "iteration: 192770 loss: 0.0017 lr: 0.02\n",
      "iteration: 192780 loss: 0.0018 lr: 0.02\n",
      "iteration: 192790 loss: 0.0021 lr: 0.02\n",
      "iteration: 192800 loss: 0.0026 lr: 0.02\n",
      "iteration: 192810 loss: 0.0017 lr: 0.02\n",
      "iteration: 192820 loss: 0.0020 lr: 0.02\n",
      "iteration: 192830 loss: 0.0021 lr: 0.02\n",
      "iteration: 192840 loss: 0.0024 lr: 0.02\n",
      "iteration: 192850 loss: 0.0020 lr: 0.02\n",
      "iteration: 192860 loss: 0.0017 lr: 0.02\n",
      "iteration: 192870 loss: 0.0020 lr: 0.02\n",
      "iteration: 192880 loss: 0.0015 lr: 0.02\n",
      "iteration: 192890 loss: 0.0015 lr: 0.02\n",
      "iteration: 192900 loss: 0.0024 lr: 0.02\n",
      "iteration: 192910 loss: 0.0019 lr: 0.02\n",
      "iteration: 192920 loss: 0.0023 lr: 0.02\n",
      "iteration: 192930 loss: 0.0020 lr: 0.02\n",
      "iteration: 192940 loss: 0.0021 lr: 0.02\n",
      "iteration: 192950 loss: 0.0025 lr: 0.02\n",
      "iteration: 192960 loss: 0.0021 lr: 0.02\n",
      "iteration: 192970 loss: 0.0015 lr: 0.02\n",
      "iteration: 192980 loss: 0.0020 lr: 0.02\n",
      "iteration: 192990 loss: 0.0025 lr: 0.02\n",
      "iteration: 193000 loss: 0.0023 lr: 0.02\n",
      "iteration: 193010 loss: 0.0025 lr: 0.02\n",
      "iteration: 193020 loss: 0.0025 lr: 0.02\n",
      "iteration: 193030 loss: 0.0020 lr: 0.02\n",
      "iteration: 193040 loss: 0.0025 lr: 0.02\n",
      "iteration: 193050 loss: 0.0018 lr: 0.02\n",
      "iteration: 193060 loss: 0.0020 lr: 0.02\n",
      "iteration: 193070 loss: 0.0020 lr: 0.02\n",
      "iteration: 193080 loss: 0.0019 lr: 0.02\n",
      "iteration: 193090 loss: 0.0016 lr: 0.02\n",
      "iteration: 193100 loss: 0.0019 lr: 0.02\n",
      "iteration: 193110 loss: 0.0017 lr: 0.02\n",
      "iteration: 193120 loss: 0.0021 lr: 0.02\n",
      "iteration: 193130 loss: 0.0020 lr: 0.02\n",
      "iteration: 193140 loss: 0.0015 lr: 0.02\n",
      "iteration: 193150 loss: 0.0029 lr: 0.02\n",
      "iteration: 193160 loss: 0.0019 lr: 0.02\n",
      "iteration: 193170 loss: 0.0024 lr: 0.02\n",
      "iteration: 193180 loss: 0.0019 lr: 0.02\n",
      "iteration: 193190 loss: 0.0016 lr: 0.02\n",
      "iteration: 193200 loss: 0.0021 lr: 0.02\n",
      "iteration: 193210 loss: 0.0027 lr: 0.02\n",
      "iteration: 193220 loss: 0.0017 lr: 0.02\n",
      "iteration: 193230 loss: 0.0017 lr: 0.02\n",
      "iteration: 193240 loss: 0.0023 lr: 0.02\n",
      "iteration: 193250 loss: 0.0018 lr: 0.02\n",
      "iteration: 193260 loss: 0.0018 lr: 0.02\n",
      "iteration: 193270 loss: 0.0020 lr: 0.02\n",
      "iteration: 193280 loss: 0.0019 lr: 0.02\n",
      "iteration: 193290 loss: 0.0019 lr: 0.02\n",
      "iteration: 193300 loss: 0.0018 lr: 0.02\n",
      "iteration: 193310 loss: 0.0017 lr: 0.02\n",
      "iteration: 193320 loss: 0.0030 lr: 0.02\n",
      "iteration: 193330 loss: 0.0020 lr: 0.02\n",
      "iteration: 193340 loss: 0.0018 lr: 0.02\n",
      "iteration: 193350 loss: 0.0029 lr: 0.02\n",
      "iteration: 193360 loss: 0.0022 lr: 0.02\n",
      "iteration: 193370 loss: 0.0021 lr: 0.02\n",
      "iteration: 193380 loss: 0.0017 lr: 0.02\n",
      "iteration: 193390 loss: 0.0019 lr: 0.02\n",
      "iteration: 193400 loss: 0.0016 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 193410 loss: 0.0017 lr: 0.02\n",
      "iteration: 193420 loss: 0.0019 lr: 0.02\n",
      "iteration: 193430 loss: 0.0018 lr: 0.02\n",
      "iteration: 193440 loss: 0.0025 lr: 0.02\n",
      "iteration: 193450 loss: 0.0019 lr: 0.02\n",
      "iteration: 193460 loss: 0.0020 lr: 0.02\n",
      "iteration: 193470 loss: 0.0026 lr: 0.02\n",
      "iteration: 193480 loss: 0.0022 lr: 0.02\n",
      "iteration: 193490 loss: 0.0020 lr: 0.02\n",
      "iteration: 193500 loss: 0.0021 lr: 0.02\n",
      "iteration: 193510 loss: 0.0026 lr: 0.02\n",
      "iteration: 193520 loss: 0.0018 lr: 0.02\n",
      "iteration: 193530 loss: 0.0019 lr: 0.02\n",
      "iteration: 193540 loss: 0.0019 lr: 0.02\n",
      "iteration: 193550 loss: 0.0018 lr: 0.02\n",
      "iteration: 193560 loss: 0.0017 lr: 0.02\n",
      "iteration: 193570 loss: 0.0019 lr: 0.02\n",
      "iteration: 193580 loss: 0.0021 lr: 0.02\n",
      "iteration: 193590 loss: 0.0019 lr: 0.02\n",
      "iteration: 193600 loss: 0.0020 lr: 0.02\n",
      "iteration: 193610 loss: 0.0017 lr: 0.02\n",
      "iteration: 193620 loss: 0.0020 lr: 0.02\n",
      "iteration: 193630 loss: 0.0019 lr: 0.02\n",
      "iteration: 193640 loss: 0.0017 lr: 0.02\n",
      "iteration: 193650 loss: 0.0018 lr: 0.02\n",
      "iteration: 193660 loss: 0.0018 lr: 0.02\n",
      "iteration: 193670 loss: 0.0019 lr: 0.02\n",
      "iteration: 193680 loss: 0.0021 lr: 0.02\n",
      "iteration: 193690 loss: 0.0024 lr: 0.02\n",
      "iteration: 193700 loss: 0.0019 lr: 0.02\n",
      "iteration: 193710 loss: 0.0018 lr: 0.02\n",
      "iteration: 193720 loss: 0.0032 lr: 0.02\n",
      "iteration: 193730 loss: 0.0019 lr: 0.02\n",
      "iteration: 193740 loss: 0.0018 lr: 0.02\n",
      "iteration: 193750 loss: 0.0023 lr: 0.02\n",
      "iteration: 193760 loss: 0.0017 lr: 0.02\n",
      "iteration: 193770 loss: 0.0018 lr: 0.02\n",
      "iteration: 193780 loss: 0.0021 lr: 0.02\n",
      "iteration: 193790 loss: 0.0015 lr: 0.02\n",
      "iteration: 193800 loss: 0.0025 lr: 0.02\n",
      "iteration: 193810 loss: 0.0019 lr: 0.02\n",
      "iteration: 193820 loss: 0.0024 lr: 0.02\n",
      "iteration: 193830 loss: 0.0032 lr: 0.02\n",
      "iteration: 193840 loss: 0.0021 lr: 0.02\n",
      "iteration: 193850 loss: 0.0028 lr: 0.02\n",
      "iteration: 193860 loss: 0.0027 lr: 0.02\n",
      "iteration: 193870 loss: 0.0024 lr: 0.02\n",
      "iteration: 193880 loss: 0.0024 lr: 0.02\n",
      "iteration: 193890 loss: 0.0028 lr: 0.02\n",
      "iteration: 193900 loss: 0.0024 lr: 0.02\n",
      "iteration: 193910 loss: 0.0017 lr: 0.02\n",
      "iteration: 193920 loss: 0.0017 lr: 0.02\n",
      "iteration: 193930 loss: 0.0022 lr: 0.02\n",
      "iteration: 193940 loss: 0.0018 lr: 0.02\n",
      "iteration: 193950 loss: 0.0019 lr: 0.02\n",
      "iteration: 193960 loss: 0.0024 lr: 0.02\n",
      "iteration: 193970 loss: 0.0020 lr: 0.02\n",
      "iteration: 193980 loss: 0.0022 lr: 0.02\n",
      "iteration: 193990 loss: 0.0018 lr: 0.02\n",
      "iteration: 194000 loss: 0.0019 lr: 0.02\n",
      "iteration: 194010 loss: 0.0027 lr: 0.02\n",
      "iteration: 194020 loss: 0.0017 lr: 0.02\n",
      "iteration: 194030 loss: 0.0025 lr: 0.02\n",
      "iteration: 194040 loss: 0.0017 lr: 0.02\n",
      "iteration: 194050 loss: 0.0023 lr: 0.02\n",
      "iteration: 194060 loss: 0.0024 lr: 0.02\n",
      "iteration: 194070 loss: 0.0021 lr: 0.02\n",
      "iteration: 194080 loss: 0.0019 lr: 0.02\n",
      "iteration: 194090 loss: 0.0020 lr: 0.02\n",
      "iteration: 194100 loss: 0.0023 lr: 0.02\n",
      "iteration: 194110 loss: 0.0020 lr: 0.02\n",
      "iteration: 194120 loss: 0.0025 lr: 0.02\n",
      "iteration: 194130 loss: 0.0017 lr: 0.02\n",
      "iteration: 194140 loss: 0.0021 lr: 0.02\n",
      "iteration: 194150 loss: 0.0019 lr: 0.02\n",
      "iteration: 194160 loss: 0.0020 lr: 0.02\n",
      "iteration: 194170 loss: 0.0020 lr: 0.02\n",
      "iteration: 194180 loss: 0.0019 lr: 0.02\n",
      "iteration: 194190 loss: 0.0017 lr: 0.02\n",
      "iteration: 194200 loss: 0.0018 lr: 0.02\n",
      "iteration: 194210 loss: 0.0022 lr: 0.02\n",
      "iteration: 194220 loss: 0.0023 lr: 0.02\n",
      "iteration: 194230 loss: 0.0026 lr: 0.02\n",
      "iteration: 194240 loss: 0.0027 lr: 0.02\n",
      "iteration: 194250 loss: 0.0020 lr: 0.02\n",
      "iteration: 194260 loss: 0.0018 lr: 0.02\n",
      "iteration: 194270 loss: 0.0024 lr: 0.02\n",
      "iteration: 194280 loss: 0.0019 lr: 0.02\n",
      "iteration: 194290 loss: 0.0021 lr: 0.02\n",
      "iteration: 194300 loss: 0.0018 lr: 0.02\n",
      "iteration: 194310 loss: 0.0018 lr: 0.02\n",
      "iteration: 194320 loss: 0.0019 lr: 0.02\n",
      "iteration: 194330 loss: 0.0020 lr: 0.02\n",
      "iteration: 194340 loss: 0.0023 lr: 0.02\n",
      "iteration: 194350 loss: 0.0027 lr: 0.02\n",
      "iteration: 194360 loss: 0.0020 lr: 0.02\n",
      "iteration: 194370 loss: 0.0022 lr: 0.02\n",
      "iteration: 194380 loss: 0.0025 lr: 0.02\n",
      "iteration: 194390 loss: 0.0024 lr: 0.02\n",
      "iteration: 194400 loss: 0.0017 lr: 0.02\n",
      "iteration: 194410 loss: 0.0020 lr: 0.02\n",
      "iteration: 194420 loss: 0.0024 lr: 0.02\n",
      "iteration: 194430 loss: 0.0022 lr: 0.02\n",
      "iteration: 194440 loss: 0.0027 lr: 0.02\n",
      "iteration: 194450 loss: 0.0023 lr: 0.02\n",
      "iteration: 194460 loss: 0.0016 lr: 0.02\n",
      "iteration: 194470 loss: 0.0023 lr: 0.02\n",
      "iteration: 194480 loss: 0.0017 lr: 0.02\n",
      "iteration: 194490 loss: 0.0023 lr: 0.02\n",
      "iteration: 194500 loss: 0.0019 lr: 0.02\n",
      "iteration: 194510 loss: 0.0019 lr: 0.02\n",
      "iteration: 194520 loss: 0.0017 lr: 0.02\n",
      "iteration: 194530 loss: 0.0017 lr: 0.02\n",
      "iteration: 194540 loss: 0.0018 lr: 0.02\n",
      "iteration: 194550 loss: 0.0020 lr: 0.02\n",
      "iteration: 194560 loss: 0.0020 lr: 0.02\n",
      "iteration: 194570 loss: 0.0020 lr: 0.02\n",
      "iteration: 194580 loss: 0.0016 lr: 0.02\n",
      "iteration: 194590 loss: 0.0018 lr: 0.02\n",
      "iteration: 194600 loss: 0.0017 lr: 0.02\n",
      "iteration: 194610 loss: 0.0016 lr: 0.02\n",
      "iteration: 194620 loss: 0.0019 lr: 0.02\n",
      "iteration: 194630 loss: 0.0023 lr: 0.02\n",
      "iteration: 194640 loss: 0.0018 lr: 0.02\n",
      "iteration: 194650 loss: 0.0021 lr: 0.02\n",
      "iteration: 194660 loss: 0.0015 lr: 0.02\n",
      "iteration: 194670 loss: 0.0016 lr: 0.02\n",
      "iteration: 194680 loss: 0.0019 lr: 0.02\n",
      "iteration: 194690 loss: 0.0024 lr: 0.02\n",
      "iteration: 194700 loss: 0.0023 lr: 0.02\n",
      "iteration: 194710 loss: 0.0020 lr: 0.02\n",
      "iteration: 194720 loss: 0.0021 lr: 0.02\n",
      "iteration: 194730 loss: 0.0017 lr: 0.02\n",
      "iteration: 194740 loss: 0.0024 lr: 0.02\n",
      "iteration: 194750 loss: 0.0022 lr: 0.02\n",
      "iteration: 194760 loss: 0.0022 lr: 0.02\n",
      "iteration: 194770 loss: 0.0017 lr: 0.02\n",
      "iteration: 194780 loss: 0.0018 lr: 0.02\n",
      "iteration: 194790 loss: 0.0025 lr: 0.02\n",
      "iteration: 194800 loss: 0.0027 lr: 0.02\n",
      "iteration: 194810 loss: 0.0019 lr: 0.02\n",
      "iteration: 194820 loss: 0.0022 lr: 0.02\n",
      "iteration: 194830 loss: 0.0020 lr: 0.02\n",
      "iteration: 194840 loss: 0.0023 lr: 0.02\n",
      "iteration: 194850 loss: 0.0021 lr: 0.02\n",
      "iteration: 194860 loss: 0.0015 lr: 0.02\n",
      "iteration: 194870 loss: 0.0019 lr: 0.02\n",
      "iteration: 194880 loss: 0.0031 lr: 0.02\n",
      "iteration: 194890 loss: 0.0025 lr: 0.02\n",
      "iteration: 194900 loss: 0.0020 lr: 0.02\n",
      "iteration: 194910 loss: 0.0029 lr: 0.02\n",
      "iteration: 194920 loss: 0.0023 lr: 0.02\n",
      "iteration: 194930 loss: 0.0023 lr: 0.02\n",
      "iteration: 194940 loss: 0.0026 lr: 0.02\n",
      "iteration: 194950 loss: 0.0026 lr: 0.02\n",
      "iteration: 194960 loss: 0.0019 lr: 0.02\n",
      "iteration: 194970 loss: 0.0029 lr: 0.02\n",
      "iteration: 194980 loss: 0.0018 lr: 0.02\n",
      "iteration: 194990 loss: 0.0015 lr: 0.02\n",
      "iteration: 195000 loss: 0.0021 lr: 0.02\n",
      "iteration: 195010 loss: 0.0021 lr: 0.02\n",
      "iteration: 195020 loss: 0.0016 lr: 0.02\n",
      "iteration: 195030 loss: 0.0016 lr: 0.02\n",
      "iteration: 195040 loss: 0.0018 lr: 0.02\n",
      "iteration: 195050 loss: 0.0017 lr: 0.02\n",
      "iteration: 195060 loss: 0.0020 lr: 0.02\n",
      "iteration: 195070 loss: 0.0020 lr: 0.02\n",
      "iteration: 195080 loss: 0.0025 lr: 0.02\n",
      "iteration: 195090 loss: 0.0024 lr: 0.02\n",
      "iteration: 195100 loss: 0.0018 lr: 0.02\n",
      "iteration: 195110 loss: 0.0021 lr: 0.02\n",
      "iteration: 195120 loss: 0.0023 lr: 0.02\n",
      "iteration: 195130 loss: 0.0022 lr: 0.02\n",
      "iteration: 195140 loss: 0.0016 lr: 0.02\n",
      "iteration: 195150 loss: 0.0017 lr: 0.02\n",
      "iteration: 195160 loss: 0.0017 lr: 0.02\n",
      "iteration: 195170 loss: 0.0025 lr: 0.02\n",
      "iteration: 195180 loss: 0.0022 lr: 0.02\n",
      "iteration: 195190 loss: 0.0023 lr: 0.02\n",
      "iteration: 195200 loss: 0.0023 lr: 0.02\n",
      "iteration: 195210 loss: 0.0021 lr: 0.02\n",
      "iteration: 195220 loss: 0.0020 lr: 0.02\n",
      "iteration: 195230 loss: 0.0023 lr: 0.02\n",
      "iteration: 195240 loss: 0.0019 lr: 0.02\n",
      "iteration: 195250 loss: 0.0022 lr: 0.02\n",
      "iteration: 195260 loss: 0.0022 lr: 0.02\n",
      "iteration: 195270 loss: 0.0015 lr: 0.02\n",
      "iteration: 195280 loss: 0.0017 lr: 0.02\n",
      "iteration: 195290 loss: 0.0018 lr: 0.02\n",
      "iteration: 195300 loss: 0.0022 lr: 0.02\n",
      "iteration: 195310 loss: 0.0024 lr: 0.02\n",
      "iteration: 195320 loss: 0.0022 lr: 0.02\n",
      "iteration: 195330 loss: 0.0024 lr: 0.02\n",
      "iteration: 195340 loss: 0.0018 lr: 0.02\n",
      "iteration: 195350 loss: 0.0017 lr: 0.02\n",
      "iteration: 195360 loss: 0.0018 lr: 0.02\n",
      "iteration: 195370 loss: 0.0018 lr: 0.02\n",
      "iteration: 195380 loss: 0.0023 lr: 0.02\n",
      "iteration: 195390 loss: 0.0028 lr: 0.02\n",
      "iteration: 195400 loss: 0.0018 lr: 0.02\n",
      "iteration: 195410 loss: 0.0020 lr: 0.02\n",
      "iteration: 195420 loss: 0.0022 lr: 0.02\n",
      "iteration: 195430 loss: 0.0022 lr: 0.02\n",
      "iteration: 195440 loss: 0.0019 lr: 0.02\n",
      "iteration: 195450 loss: 0.0023 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 195460 loss: 0.0018 lr: 0.02\n",
      "iteration: 195470 loss: 0.0022 lr: 0.02\n",
      "iteration: 195480 loss: 0.0019 lr: 0.02\n",
      "iteration: 195490 loss: 0.0022 lr: 0.02\n",
      "iteration: 195500 loss: 0.0021 lr: 0.02\n",
      "iteration: 195510 loss: 0.0019 lr: 0.02\n",
      "iteration: 195520 loss: 0.0016 lr: 0.02\n",
      "iteration: 195530 loss: 0.0020 lr: 0.02\n",
      "iteration: 195540 loss: 0.0018 lr: 0.02\n",
      "iteration: 195550 loss: 0.0016 lr: 0.02\n",
      "iteration: 195560 loss: 0.0029 lr: 0.02\n",
      "iteration: 195570 loss: 0.0021 lr: 0.02\n",
      "iteration: 195580 loss: 0.0022 lr: 0.02\n",
      "iteration: 195590 loss: 0.0023 lr: 0.02\n",
      "iteration: 195600 loss: 0.0018 lr: 0.02\n",
      "iteration: 195610 loss: 0.0018 lr: 0.02\n",
      "iteration: 195620 loss: 0.0016 lr: 0.02\n",
      "iteration: 195630 loss: 0.0017 lr: 0.02\n",
      "iteration: 195640 loss: 0.0019 lr: 0.02\n",
      "iteration: 195650 loss: 0.0020 lr: 0.02\n",
      "iteration: 195660 loss: 0.0022 lr: 0.02\n",
      "iteration: 195670 loss: 0.0016 lr: 0.02\n",
      "iteration: 195680 loss: 0.0020 lr: 0.02\n",
      "iteration: 195690 loss: 0.0018 lr: 0.02\n",
      "iteration: 195700 loss: 0.0028 lr: 0.02\n",
      "iteration: 195710 loss: 0.0020 lr: 0.02\n",
      "iteration: 195720 loss: 0.0028 lr: 0.02\n",
      "iteration: 195730 loss: 0.0020 lr: 0.02\n",
      "iteration: 195740 loss: 0.0023 lr: 0.02\n",
      "iteration: 195750 loss: 0.0022 lr: 0.02\n",
      "iteration: 195760 loss: 0.0019 lr: 0.02\n",
      "iteration: 195770 loss: 0.0019 lr: 0.02\n",
      "iteration: 195780 loss: 0.0019 lr: 0.02\n",
      "iteration: 195790 loss: 0.0018 lr: 0.02\n",
      "iteration: 195800 loss: 0.0018 lr: 0.02\n",
      "iteration: 195810 loss: 0.0024 lr: 0.02\n",
      "iteration: 195820 loss: 0.0023 lr: 0.02\n",
      "iteration: 195830 loss: 0.0017 lr: 0.02\n",
      "iteration: 195840 loss: 0.0021 lr: 0.02\n",
      "iteration: 195850 loss: 0.0019 lr: 0.02\n",
      "iteration: 195860 loss: 0.0018 lr: 0.02\n",
      "iteration: 195870 loss: 0.0021 lr: 0.02\n",
      "iteration: 195880 loss: 0.0021 lr: 0.02\n",
      "iteration: 195890 loss: 0.0024 lr: 0.02\n",
      "iteration: 195900 loss: 0.0019 lr: 0.02\n",
      "iteration: 195910 loss: 0.0021 lr: 0.02\n",
      "iteration: 195920 loss: 0.0024 lr: 0.02\n",
      "iteration: 195930 loss: 0.0016 lr: 0.02\n",
      "iteration: 195940 loss: 0.0026 lr: 0.02\n",
      "iteration: 195950 loss: 0.0019 lr: 0.02\n",
      "iteration: 195960 loss: 0.0016 lr: 0.02\n",
      "iteration: 195970 loss: 0.0016 lr: 0.02\n",
      "iteration: 195980 loss: 0.0023 lr: 0.02\n",
      "iteration: 195990 loss: 0.0018 lr: 0.02\n",
      "iteration: 196000 loss: 0.0017 lr: 0.02\n",
      "iteration: 196010 loss: 0.0019 lr: 0.02\n",
      "iteration: 196020 loss: 0.0017 lr: 0.02\n",
      "iteration: 196030 loss: 0.0017 lr: 0.02\n",
      "iteration: 196040 loss: 0.0018 lr: 0.02\n",
      "iteration: 196050 loss: 0.0019 lr: 0.02\n",
      "iteration: 196060 loss: 0.0020 lr: 0.02\n",
      "iteration: 196070 loss: 0.0022 lr: 0.02\n",
      "iteration: 196080 loss: 0.0022 lr: 0.02\n",
      "iteration: 196090 loss: 0.0018 lr: 0.02\n",
      "iteration: 196100 loss: 0.0020 lr: 0.02\n",
      "iteration: 196110 loss: 0.0018 lr: 0.02\n",
      "iteration: 196120 loss: 0.0025 lr: 0.02\n",
      "iteration: 196130 loss: 0.0018 lr: 0.02\n",
      "iteration: 196140 loss: 0.0020 lr: 0.02\n",
      "iteration: 196150 loss: 0.0017 lr: 0.02\n",
      "iteration: 196160 loss: 0.0017 lr: 0.02\n",
      "iteration: 196170 loss: 0.0022 lr: 0.02\n",
      "iteration: 196180 loss: 0.0036 lr: 0.02\n",
      "iteration: 196190 loss: 0.0021 lr: 0.02\n",
      "iteration: 196200 loss: 0.0027 lr: 0.02\n",
      "iteration: 196210 loss: 0.0021 lr: 0.02\n",
      "iteration: 196220 loss: 0.0023 lr: 0.02\n",
      "iteration: 196230 loss: 0.0018 lr: 0.02\n",
      "iteration: 196240 loss: 0.0022 lr: 0.02\n",
      "iteration: 196250 loss: 0.0022 lr: 0.02\n",
      "iteration: 196260 loss: 0.0016 lr: 0.02\n",
      "iteration: 196270 loss: 0.0023 lr: 0.02\n",
      "iteration: 196280 loss: 0.0024 lr: 0.02\n",
      "iteration: 196290 loss: 0.0018 lr: 0.02\n",
      "iteration: 196300 loss: 0.0023 lr: 0.02\n",
      "iteration: 196310 loss: 0.0020 lr: 0.02\n",
      "iteration: 196320 loss: 0.0018 lr: 0.02\n",
      "iteration: 196330 loss: 0.0020 lr: 0.02\n",
      "iteration: 196340 loss: 0.0018 lr: 0.02\n",
      "iteration: 196350 loss: 0.0021 lr: 0.02\n",
      "iteration: 196360 loss: 0.0017 lr: 0.02\n",
      "iteration: 196370 loss: 0.0022 lr: 0.02\n",
      "iteration: 196380 loss: 0.0017 lr: 0.02\n",
      "iteration: 196390 loss: 0.0025 lr: 0.02\n",
      "iteration: 196400 loss: 0.0021 lr: 0.02\n",
      "iteration: 196410 loss: 0.0013 lr: 0.02\n",
      "iteration: 196420 loss: 0.0021 lr: 0.02\n",
      "iteration: 196430 loss: 0.0021 lr: 0.02\n",
      "iteration: 196440 loss: 0.0023 lr: 0.02\n",
      "iteration: 196450 loss: 0.0022 lr: 0.02\n",
      "iteration: 196460 loss: 0.0018 lr: 0.02\n",
      "iteration: 196470 loss: 0.0022 lr: 0.02\n",
      "iteration: 196480 loss: 0.0022 lr: 0.02\n",
      "iteration: 196490 loss: 0.0015 lr: 0.02\n",
      "iteration: 196500 loss: 0.0020 lr: 0.02\n",
      "iteration: 196510 loss: 0.0019 lr: 0.02\n",
      "iteration: 196520 loss: 0.0024 lr: 0.02\n",
      "iteration: 196530 loss: 0.0024 lr: 0.02\n",
      "iteration: 196540 loss: 0.0022 lr: 0.02\n",
      "iteration: 196550 loss: 0.0019 lr: 0.02\n",
      "iteration: 196560 loss: 0.0016 lr: 0.02\n",
      "iteration: 196570 loss: 0.0021 lr: 0.02\n",
      "iteration: 196580 loss: 0.0020 lr: 0.02\n",
      "iteration: 196590 loss: 0.0021 lr: 0.02\n",
      "iteration: 196600 loss: 0.0018 lr: 0.02\n",
      "iteration: 196610 loss: 0.0025 lr: 0.02\n",
      "iteration: 196620 loss: 0.0026 lr: 0.02\n",
      "iteration: 196630 loss: 0.0023 lr: 0.02\n",
      "iteration: 196640 loss: 0.0025 lr: 0.02\n",
      "iteration: 196650 loss: 0.0028 lr: 0.02\n",
      "iteration: 196660 loss: 0.0019 lr: 0.02\n",
      "iteration: 196670 loss: 0.0022 lr: 0.02\n",
      "iteration: 196680 loss: 0.0018 lr: 0.02\n",
      "iteration: 196690 loss: 0.0023 lr: 0.02\n",
      "iteration: 196700 loss: 0.0015 lr: 0.02\n",
      "iteration: 196710 loss: 0.0019 lr: 0.02\n",
      "iteration: 196720 loss: 0.0013 lr: 0.02\n",
      "iteration: 196730 loss: 0.0027 lr: 0.02\n",
      "iteration: 196740 loss: 0.0018 lr: 0.02\n",
      "iteration: 196750 loss: 0.0019 lr: 0.02\n",
      "iteration: 196760 loss: 0.0022 lr: 0.02\n",
      "iteration: 196770 loss: 0.0022 lr: 0.02\n",
      "iteration: 196780 loss: 0.0023 lr: 0.02\n",
      "iteration: 196790 loss: 0.0017 lr: 0.02\n",
      "iteration: 196800 loss: 0.0019 lr: 0.02\n",
      "iteration: 196810 loss: 0.0017 lr: 0.02\n",
      "iteration: 196820 loss: 0.0021 lr: 0.02\n",
      "iteration: 196830 loss: 0.0017 lr: 0.02\n",
      "iteration: 196840 loss: 0.0017 lr: 0.02\n",
      "iteration: 196850 loss: 0.0019 lr: 0.02\n",
      "iteration: 196860 loss: 0.0015 lr: 0.02\n",
      "iteration: 196870 loss: 0.0017 lr: 0.02\n",
      "iteration: 196880 loss: 0.0017 lr: 0.02\n",
      "iteration: 196890 loss: 0.0023 lr: 0.02\n",
      "iteration: 196900 loss: 0.0017 lr: 0.02\n",
      "iteration: 196910 loss: 0.0021 lr: 0.02\n",
      "iteration: 196920 loss: 0.0015 lr: 0.02\n",
      "iteration: 196930 loss: 0.0019 lr: 0.02\n",
      "iteration: 196940 loss: 0.0023 lr: 0.02\n",
      "iteration: 196950 loss: 0.0023 lr: 0.02\n",
      "iteration: 196960 loss: 0.0025 lr: 0.02\n",
      "iteration: 196970 loss: 0.0023 lr: 0.02\n",
      "iteration: 196980 loss: 0.0021 lr: 0.02\n",
      "iteration: 196990 loss: 0.0022 lr: 0.02\n",
      "iteration: 197000 loss: 0.0020 lr: 0.02\n",
      "iteration: 197010 loss: 0.0021 lr: 0.02\n",
      "iteration: 197020 loss: 0.0021 lr: 0.02\n",
      "iteration: 197030 loss: 0.0019 lr: 0.02\n",
      "iteration: 197040 loss: 0.0021 lr: 0.02\n",
      "iteration: 197050 loss: 0.0018 lr: 0.02\n",
      "iteration: 197060 loss: 0.0016 lr: 0.02\n",
      "iteration: 197070 loss: 0.0018 lr: 0.02\n",
      "iteration: 197080 loss: 0.0014 lr: 0.02\n",
      "iteration: 197090 loss: 0.0016 lr: 0.02\n",
      "iteration: 197100 loss: 0.0022 lr: 0.02\n",
      "iteration: 197110 loss: 0.0025 lr: 0.02\n",
      "iteration: 197120 loss: 0.0023 lr: 0.02\n",
      "iteration: 197130 loss: 0.0018 lr: 0.02\n",
      "iteration: 197140 loss: 0.0016 lr: 0.02\n",
      "iteration: 197150 loss: 0.0016 lr: 0.02\n",
      "iteration: 197160 loss: 0.0016 lr: 0.02\n",
      "iteration: 197170 loss: 0.0016 lr: 0.02\n",
      "iteration: 197180 loss: 0.0023 lr: 0.02\n",
      "iteration: 197190 loss: 0.0020 lr: 0.02\n",
      "iteration: 197200 loss: 0.0019 lr: 0.02\n",
      "iteration: 197210 loss: 0.0018 lr: 0.02\n",
      "iteration: 197220 loss: 0.0019 lr: 0.02\n",
      "iteration: 197230 loss: 0.0020 lr: 0.02\n",
      "iteration: 197240 loss: 0.0015 lr: 0.02\n",
      "iteration: 197250 loss: 0.0022 lr: 0.02\n",
      "iteration: 197260 loss: 0.0021 lr: 0.02\n",
      "iteration: 197270 loss: 0.0021 lr: 0.02\n",
      "iteration: 197280 loss: 0.0020 lr: 0.02\n",
      "iteration: 197290 loss: 0.0020 lr: 0.02\n",
      "iteration: 197300 loss: 0.0025 lr: 0.02\n",
      "iteration: 197310 loss: 0.0022 lr: 0.02\n",
      "iteration: 197320 loss: 0.0018 lr: 0.02\n",
      "iteration: 197330 loss: 0.0019 lr: 0.02\n",
      "iteration: 197340 loss: 0.0020 lr: 0.02\n",
      "iteration: 197350 loss: 0.0018 lr: 0.02\n",
      "iteration: 197360 loss: 0.0016 lr: 0.02\n",
      "iteration: 197370 loss: 0.0017 lr: 0.02\n",
      "iteration: 197380 loss: 0.0020 lr: 0.02\n",
      "iteration: 197390 loss: 0.0017 lr: 0.02\n",
      "iteration: 197400 loss: 0.0023 lr: 0.02\n",
      "iteration: 197410 loss: 0.0029 lr: 0.02\n",
      "iteration: 197420 loss: 0.0017 lr: 0.02\n",
      "iteration: 197430 loss: 0.0019 lr: 0.02\n",
      "iteration: 197440 loss: 0.0020 lr: 0.02\n",
      "iteration: 197450 loss: 0.0024 lr: 0.02\n",
      "iteration: 197460 loss: 0.0017 lr: 0.02\n",
      "iteration: 197470 loss: 0.0020 lr: 0.02\n",
      "iteration: 197480 loss: 0.0020 lr: 0.02\n",
      "iteration: 197490 loss: 0.0018 lr: 0.02\n",
      "iteration: 197500 loss: 0.0019 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 197510 loss: 0.0021 lr: 0.02\n",
      "iteration: 197520 loss: 0.0021 lr: 0.02\n",
      "iteration: 197530 loss: 0.0019 lr: 0.02\n",
      "iteration: 197540 loss: 0.0020 lr: 0.02\n",
      "iteration: 197550 loss: 0.0021 lr: 0.02\n",
      "iteration: 197560 loss: 0.0021 lr: 0.02\n",
      "iteration: 197570 loss: 0.0023 lr: 0.02\n",
      "iteration: 197580 loss: 0.0017 lr: 0.02\n",
      "iteration: 197590 loss: 0.0023 lr: 0.02\n",
      "iteration: 197600 loss: 0.0015 lr: 0.02\n",
      "iteration: 197610 loss: 0.0019 lr: 0.02\n",
      "iteration: 197620 loss: 0.0020 lr: 0.02\n",
      "iteration: 197630 loss: 0.0010 lr: 0.02\n",
      "iteration: 197640 loss: 0.0019 lr: 0.02\n",
      "iteration: 197650 loss: 0.0023 lr: 0.02\n",
      "iteration: 197660 loss: 0.0019 lr: 0.02\n",
      "iteration: 197670 loss: 0.0019 lr: 0.02\n",
      "iteration: 197680 loss: 0.0018 lr: 0.02\n",
      "iteration: 197690 loss: 0.0020 lr: 0.02\n",
      "iteration: 197700 loss: 0.0018 lr: 0.02\n",
      "iteration: 197710 loss: 0.0019 lr: 0.02\n",
      "iteration: 197720 loss: 0.0022 lr: 0.02\n",
      "iteration: 197730 loss: 0.0018 lr: 0.02\n",
      "iteration: 197740 loss: 0.0021 lr: 0.02\n",
      "iteration: 197750 loss: 0.0024 lr: 0.02\n",
      "iteration: 197760 loss: 0.0018 lr: 0.02\n",
      "iteration: 197770 loss: 0.0020 lr: 0.02\n",
      "iteration: 197780 loss: 0.0018 lr: 0.02\n",
      "iteration: 197790 loss: 0.0024 lr: 0.02\n",
      "iteration: 197800 loss: 0.0022 lr: 0.02\n",
      "iteration: 197810 loss: 0.0017 lr: 0.02\n",
      "iteration: 197820 loss: 0.0015 lr: 0.02\n",
      "iteration: 197830 loss: 0.0018 lr: 0.02\n",
      "iteration: 197840 loss: 0.0022 lr: 0.02\n",
      "iteration: 197850 loss: 0.0025 lr: 0.02\n",
      "iteration: 197860 loss: 0.0021 lr: 0.02\n",
      "iteration: 197870 loss: 0.0016 lr: 0.02\n",
      "iteration: 197880 loss: 0.0028 lr: 0.02\n",
      "iteration: 197890 loss: 0.0020 lr: 0.02\n",
      "iteration: 197900 loss: 0.0016 lr: 0.02\n",
      "iteration: 197910 loss: 0.0016 lr: 0.02\n",
      "iteration: 197920 loss: 0.0017 lr: 0.02\n",
      "iteration: 197930 loss: 0.0020 lr: 0.02\n",
      "iteration: 197940 loss: 0.0018 lr: 0.02\n",
      "iteration: 197950 loss: 0.0021 lr: 0.02\n",
      "iteration: 197960 loss: 0.0021 lr: 0.02\n",
      "iteration: 197970 loss: 0.0015 lr: 0.02\n",
      "iteration: 197980 loss: 0.0017 lr: 0.02\n",
      "iteration: 197990 loss: 0.0018 lr: 0.02\n",
      "iteration: 198000 loss: 0.0019 lr: 0.02\n",
      "iteration: 198010 loss: 0.0018 lr: 0.02\n",
      "iteration: 198020 loss: 0.0019 lr: 0.02\n",
      "iteration: 198030 loss: 0.0018 lr: 0.02\n",
      "iteration: 198040 loss: 0.0015 lr: 0.02\n",
      "iteration: 198050 loss: 0.0014 lr: 0.02\n",
      "iteration: 198060 loss: 0.0016 lr: 0.02\n",
      "iteration: 198070 loss: 0.0022 lr: 0.02\n",
      "iteration: 198080 loss: 0.0020 lr: 0.02\n",
      "iteration: 198090 loss: 0.0017 lr: 0.02\n",
      "iteration: 198100 loss: 0.0018 lr: 0.02\n",
      "iteration: 198110 loss: 0.0016 lr: 0.02\n",
      "iteration: 198120 loss: 0.0019 lr: 0.02\n",
      "iteration: 198130 loss: 0.0019 lr: 0.02\n",
      "iteration: 198140 loss: 0.0017 lr: 0.02\n",
      "iteration: 198150 loss: 0.0018 lr: 0.02\n",
      "iteration: 198160 loss: 0.0021 lr: 0.02\n",
      "iteration: 198170 loss: 0.0017 lr: 0.02\n",
      "iteration: 198180 loss: 0.0019 lr: 0.02\n",
      "iteration: 198190 loss: 0.0028 lr: 0.02\n",
      "iteration: 198200 loss: 0.0033 lr: 0.02\n",
      "iteration: 198210 loss: 0.0016 lr: 0.02\n",
      "iteration: 198220 loss: 0.0017 lr: 0.02\n",
      "iteration: 198230 loss: 0.0020 lr: 0.02\n",
      "iteration: 198240 loss: 0.0022 lr: 0.02\n",
      "iteration: 198250 loss: 0.0018 lr: 0.02\n",
      "iteration: 198260 loss: 0.0018 lr: 0.02\n",
      "iteration: 198270 loss: 0.0019 lr: 0.02\n",
      "iteration: 198280 loss: 0.0017 lr: 0.02\n",
      "iteration: 198290 loss: 0.0026 lr: 0.02\n",
      "iteration: 198300 loss: 0.0024 lr: 0.02\n",
      "iteration: 198310 loss: 0.0021 lr: 0.02\n",
      "iteration: 198320 loss: 0.0017 lr: 0.02\n",
      "iteration: 198330 loss: 0.0018 lr: 0.02\n",
      "iteration: 198340 loss: 0.0018 lr: 0.02\n",
      "iteration: 198350 loss: 0.0019 lr: 0.02\n",
      "iteration: 198360 loss: 0.0027 lr: 0.02\n",
      "iteration: 198370 loss: 0.0020 lr: 0.02\n",
      "iteration: 198380 loss: 0.0024 lr: 0.02\n",
      "iteration: 198390 loss: 0.0021 lr: 0.02\n",
      "iteration: 198400 loss: 0.0018 lr: 0.02\n",
      "iteration: 198410 loss: 0.0019 lr: 0.02\n",
      "iteration: 198420 loss: 0.0019 lr: 0.02\n",
      "iteration: 198430 loss: 0.0022 lr: 0.02\n",
      "iteration: 198440 loss: 0.0025 lr: 0.02\n",
      "iteration: 198450 loss: 0.0026 lr: 0.02\n",
      "iteration: 198460 loss: 0.0021 lr: 0.02\n",
      "iteration: 198470 loss: 0.0016 lr: 0.02\n",
      "iteration: 198480 loss: 0.0020 lr: 0.02\n",
      "iteration: 198490 loss: 0.0017 lr: 0.02\n",
      "iteration: 198500 loss: 0.0019 lr: 0.02\n",
      "iteration: 198510 loss: 0.0018 lr: 0.02\n",
      "iteration: 198520 loss: 0.0022 lr: 0.02\n",
      "iteration: 198530 loss: 0.0030 lr: 0.02\n",
      "iteration: 198540 loss: 0.0018 lr: 0.02\n",
      "iteration: 198550 loss: 0.0023 lr: 0.02\n",
      "iteration: 198560 loss: 0.0025 lr: 0.02\n",
      "iteration: 198570 loss: 0.0019 lr: 0.02\n",
      "iteration: 198580 loss: 0.0020 lr: 0.02\n",
      "iteration: 198590 loss: 0.0018 lr: 0.02\n",
      "iteration: 198600 loss: 0.0014 lr: 0.02\n",
      "iteration: 198610 loss: 0.0017 lr: 0.02\n",
      "iteration: 198620 loss: 0.0022 lr: 0.02\n",
      "iteration: 198630 loss: 0.0020 lr: 0.02\n",
      "iteration: 198640 loss: 0.0018 lr: 0.02\n",
      "iteration: 198650 loss: 0.0018 lr: 0.02\n",
      "iteration: 198660 loss: 0.0019 lr: 0.02\n",
      "iteration: 198670 loss: 0.0016 lr: 0.02\n",
      "iteration: 198680 loss: 0.0019 lr: 0.02\n",
      "iteration: 198690 loss: 0.0021 lr: 0.02\n",
      "iteration: 198700 loss: 0.0022 lr: 0.02\n",
      "iteration: 198710 loss: 0.0018 lr: 0.02\n",
      "iteration: 198720 loss: 0.0020 lr: 0.02\n",
      "iteration: 198730 loss: 0.0017 lr: 0.02\n",
      "iteration: 198740 loss: 0.0017 lr: 0.02\n",
      "iteration: 198750 loss: 0.0023 lr: 0.02\n",
      "iteration: 198760 loss: 0.0019 lr: 0.02\n",
      "iteration: 198770 loss: 0.0018 lr: 0.02\n",
      "iteration: 198780 loss: 0.0025 lr: 0.02\n",
      "iteration: 198790 loss: 0.0018 lr: 0.02\n",
      "iteration: 198800 loss: 0.0022 lr: 0.02\n",
      "iteration: 198810 loss: 0.0021 lr: 0.02\n",
      "iteration: 198820 loss: 0.0021 lr: 0.02\n",
      "iteration: 198830 loss: 0.0017 lr: 0.02\n",
      "iteration: 198840 loss: 0.0018 lr: 0.02\n",
      "iteration: 198850 loss: 0.0020 lr: 0.02\n",
      "iteration: 198860 loss: 0.0021 lr: 0.02\n",
      "iteration: 198870 loss: 0.0021 lr: 0.02\n",
      "iteration: 198880 loss: 0.0016 lr: 0.02\n",
      "iteration: 198890 loss: 0.0017 lr: 0.02\n",
      "iteration: 198900 loss: 0.0021 lr: 0.02\n",
      "iteration: 198910 loss: 0.0019 lr: 0.02\n",
      "iteration: 198920 loss: 0.0018 lr: 0.02\n",
      "iteration: 198930 loss: 0.0020 lr: 0.02\n",
      "iteration: 198940 loss: 0.0022 lr: 0.02\n",
      "iteration: 198950 loss: 0.0035 lr: 0.02\n",
      "iteration: 198960 loss: 0.0022 lr: 0.02\n",
      "iteration: 198970 loss: 0.0020 lr: 0.02\n",
      "iteration: 198980 loss: 0.0028 lr: 0.02\n",
      "iteration: 198990 loss: 0.0014 lr: 0.02\n",
      "iteration: 199000 loss: 0.0022 lr: 0.02\n",
      "iteration: 199010 loss: 0.0016 lr: 0.02\n",
      "iteration: 199020 loss: 0.0018 lr: 0.02\n",
      "iteration: 199030 loss: 0.0019 lr: 0.02\n",
      "iteration: 199040 loss: 0.0026 lr: 0.02\n",
      "iteration: 199050 loss: 0.0019 lr: 0.02\n",
      "iteration: 199060 loss: 0.0022 lr: 0.02\n",
      "iteration: 199070 loss: 0.0027 lr: 0.02\n",
      "iteration: 199080 loss: 0.0019 lr: 0.02\n",
      "iteration: 199090 loss: 0.0025 lr: 0.02\n",
      "iteration: 199100 loss: 0.0017 lr: 0.02\n",
      "iteration: 199110 loss: 0.0022 lr: 0.02\n",
      "iteration: 199120 loss: 0.0027 lr: 0.02\n",
      "iteration: 199130 loss: 0.0020 lr: 0.02\n",
      "iteration: 199140 loss: 0.0019 lr: 0.02\n",
      "iteration: 199150 loss: 0.0022 lr: 0.02\n",
      "iteration: 199160 loss: 0.0020 lr: 0.02\n",
      "iteration: 199170 loss: 0.0015 lr: 0.02\n",
      "iteration: 199180 loss: 0.0022 lr: 0.02\n",
      "iteration: 199190 loss: 0.0019 lr: 0.02\n",
      "iteration: 199200 loss: 0.0021 lr: 0.02\n",
      "iteration: 199210 loss: 0.0015 lr: 0.02\n",
      "iteration: 199220 loss: 0.0019 lr: 0.02\n",
      "iteration: 199230 loss: 0.0020 lr: 0.02\n",
      "iteration: 199240 loss: 0.0022 lr: 0.02\n",
      "iteration: 199250 loss: 0.0017 lr: 0.02\n",
      "iteration: 199260 loss: 0.0018 lr: 0.02\n",
      "iteration: 199270 loss: 0.0015 lr: 0.02\n",
      "iteration: 199280 loss: 0.0016 lr: 0.02\n",
      "iteration: 199290 loss: 0.0022 lr: 0.02\n",
      "iteration: 199300 loss: 0.0018 lr: 0.02\n",
      "iteration: 199310 loss: 0.0016 lr: 0.02\n",
      "iteration: 199320 loss: 0.0017 lr: 0.02\n",
      "iteration: 199330 loss: 0.0019 lr: 0.02\n",
      "iteration: 199340 loss: 0.0022 lr: 0.02\n",
      "iteration: 199350 loss: 0.0022 lr: 0.02\n",
      "iteration: 199360 loss: 0.0020 lr: 0.02\n",
      "iteration: 199370 loss: 0.0021 lr: 0.02\n",
      "iteration: 199380 loss: 0.0017 lr: 0.02\n",
      "iteration: 199390 loss: 0.0018 lr: 0.02\n",
      "iteration: 199400 loss: 0.0014 lr: 0.02\n",
      "iteration: 199410 loss: 0.0017 lr: 0.02\n",
      "iteration: 199420 loss: 0.0020 lr: 0.02\n",
      "iteration: 199430 loss: 0.0019 lr: 0.02\n",
      "iteration: 199440 loss: 0.0020 lr: 0.02\n",
      "iteration: 199450 loss: 0.0016 lr: 0.02\n",
      "iteration: 199460 loss: 0.0021 lr: 0.02\n",
      "iteration: 199470 loss: 0.0022 lr: 0.02\n",
      "iteration: 199480 loss: 0.0023 lr: 0.02\n",
      "iteration: 199490 loss: 0.0029 lr: 0.02\n",
      "iteration: 199500 loss: 0.0019 lr: 0.02\n",
      "iteration: 199510 loss: 0.0017 lr: 0.02\n",
      "iteration: 199520 loss: 0.0019 lr: 0.02\n",
      "iteration: 199530 loss: 0.0017 lr: 0.02\n",
      "iteration: 199540 loss: 0.0030 lr: 0.02\n",
      "iteration: 199550 loss: 0.0023 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 199560 loss: 0.0017 lr: 0.02\n",
      "iteration: 199570 loss: 0.0021 lr: 0.02\n",
      "iteration: 199580 loss: 0.0018 lr: 0.02\n",
      "iteration: 199590 loss: 0.0018 lr: 0.02\n",
      "iteration: 199600 loss: 0.0019 lr: 0.02\n",
      "iteration: 199610 loss: 0.0021 lr: 0.02\n",
      "iteration: 199620 loss: 0.0018 lr: 0.02\n",
      "iteration: 199630 loss: 0.0019 lr: 0.02\n",
      "iteration: 199640 loss: 0.0020 lr: 0.02\n",
      "iteration: 199650 loss: 0.0016 lr: 0.02\n",
      "iteration: 199660 loss: 0.0025 lr: 0.02\n",
      "iteration: 199670 loss: 0.0019 lr: 0.02\n",
      "iteration: 199680 loss: 0.0016 lr: 0.02\n",
      "iteration: 199690 loss: 0.0020 lr: 0.02\n",
      "iteration: 199700 loss: 0.0024 lr: 0.02\n",
      "iteration: 199710 loss: 0.0014 lr: 0.02\n",
      "iteration: 199720 loss: 0.0019 lr: 0.02\n",
      "iteration: 199730 loss: 0.0018 lr: 0.02\n",
      "iteration: 199740 loss: 0.0015 lr: 0.02\n",
      "iteration: 199750 loss: 0.0021 lr: 0.02\n",
      "iteration: 199760 loss: 0.0014 lr: 0.02\n",
      "iteration: 199770 loss: 0.0018 lr: 0.02\n",
      "iteration: 199780 loss: 0.0019 lr: 0.02\n",
      "iteration: 199790 loss: 0.0019 lr: 0.02\n",
      "iteration: 199800 loss: 0.0021 lr: 0.02\n",
      "iteration: 199810 loss: 0.0017 lr: 0.02\n",
      "iteration: 199820 loss: 0.0020 lr: 0.02\n",
      "iteration: 199830 loss: 0.0018 lr: 0.02\n",
      "iteration: 199840 loss: 0.0014 lr: 0.02\n",
      "iteration: 199850 loss: 0.0019 lr: 0.02\n",
      "iteration: 199860 loss: 0.0019 lr: 0.02\n",
      "iteration: 199870 loss: 0.0030 lr: 0.02\n",
      "iteration: 199880 loss: 0.0017 lr: 0.02\n",
      "iteration: 199890 loss: 0.0021 lr: 0.02\n",
      "iteration: 199900 loss: 0.0026 lr: 0.02\n",
      "iteration: 199910 loss: 0.0014 lr: 0.02\n",
      "iteration: 199920 loss: 0.0017 lr: 0.02\n",
      "iteration: 199930 loss: 0.0024 lr: 0.02\n",
      "iteration: 199940 loss: 0.0018 lr: 0.02\n",
      "iteration: 199950 loss: 0.0023 lr: 0.02\n",
      "iteration: 199960 loss: 0.0020 lr: 0.02\n",
      "iteration: 199970 loss: 0.0021 lr: 0.02\n",
      "iteration: 199980 loss: 0.0014 lr: 0.02\n",
      "iteration: 199990 loss: 0.0016 lr: 0.02\n",
      "iteration: 200000 loss: 0.0017 lr: 0.02\n",
      "iteration: 200010 loss: 0.0024 lr: 0.02\n",
      "iteration: 200020 loss: 0.0025 lr: 0.02\n",
      "iteration: 200030 loss: 0.0029 lr: 0.02\n",
      "iteration: 200040 loss: 0.0018 lr: 0.02\n",
      "iteration: 200050 loss: 0.0020 lr: 0.02\n",
      "iteration: 200060 loss: 0.0017 lr: 0.02\n",
      "iteration: 200070 loss: 0.0020 lr: 0.02\n",
      "iteration: 200080 loss: 0.0022 lr: 0.02\n",
      "iteration: 200090 loss: 0.0017 lr: 0.02\n",
      "iteration: 200100 loss: 0.0019 lr: 0.02\n",
      "iteration: 200110 loss: 0.0016 lr: 0.02\n",
      "iteration: 200120 loss: 0.0019 lr: 0.02\n",
      "iteration: 200130 loss: 0.0021 lr: 0.02\n",
      "iteration: 200140 loss: 0.0016 lr: 0.02\n",
      "iteration: 200150 loss: 0.0022 lr: 0.02\n",
      "iteration: 200160 loss: 0.0018 lr: 0.02\n",
      "iteration: 200170 loss: 0.0020 lr: 0.02\n",
      "iteration: 200180 loss: 0.0016 lr: 0.02\n",
      "iteration: 200190 loss: 0.0033 lr: 0.02\n",
      "iteration: 200200 loss: 0.0024 lr: 0.02\n",
      "iteration: 200210 loss: 0.0021 lr: 0.02\n",
      "iteration: 200220 loss: 0.0020 lr: 0.02\n",
      "iteration: 200230 loss: 0.0018 lr: 0.02\n",
      "iteration: 200240 loss: 0.0022 lr: 0.02\n",
      "iteration: 200250 loss: 0.0017 lr: 0.02\n",
      "iteration: 200260 loss: 0.0018 lr: 0.02\n",
      "iteration: 200270 loss: 0.0016 lr: 0.02\n",
      "iteration: 200280 loss: 0.0021 lr: 0.02\n",
      "iteration: 200290 loss: 0.0028 lr: 0.02\n",
      "iteration: 200300 loss: 0.0017 lr: 0.02\n",
      "iteration: 200310 loss: 0.0024 lr: 0.02\n",
      "iteration: 200320 loss: 0.0018 lr: 0.02\n",
      "iteration: 200330 loss: 0.0015 lr: 0.02\n",
      "iteration: 200340 loss: 0.0026 lr: 0.02\n",
      "iteration: 200350 loss: 0.0017 lr: 0.02\n",
      "iteration: 200360 loss: 0.0024 lr: 0.02\n",
      "iteration: 200370 loss: 0.0020 lr: 0.02\n",
      "iteration: 200380 loss: 0.0023 lr: 0.02\n",
      "iteration: 200390 loss: 0.0018 lr: 0.02\n",
      "iteration: 200400 loss: 0.0019 lr: 0.02\n",
      "iteration: 200410 loss: 0.0019 lr: 0.02\n",
      "iteration: 200420 loss: 0.0026 lr: 0.02\n",
      "iteration: 200430 loss: 0.0027 lr: 0.02\n",
      "iteration: 200440 loss: 0.0021 lr: 0.02\n",
      "iteration: 200450 loss: 0.0024 lr: 0.02\n",
      "iteration: 200460 loss: 0.0018 lr: 0.02\n",
      "iteration: 200470 loss: 0.0017 lr: 0.02\n",
      "iteration: 200480 loss: 0.0025 lr: 0.02\n",
      "iteration: 200490 loss: 0.0017 lr: 0.02\n",
      "iteration: 200500 loss: 0.0016 lr: 0.02\n",
      "iteration: 200510 loss: 0.0024 lr: 0.02\n",
      "iteration: 200520 loss: 0.0026 lr: 0.02\n",
      "iteration: 200530 loss: 0.0023 lr: 0.02\n",
      "iteration: 200540 loss: 0.0023 lr: 0.02\n",
      "iteration: 200550 loss: 0.0021 lr: 0.02\n",
      "iteration: 200560 loss: 0.0017 lr: 0.02\n",
      "iteration: 200570 loss: 0.0023 lr: 0.02\n",
      "iteration: 200580 loss: 0.0020 lr: 0.02\n",
      "iteration: 200590 loss: 0.0021 lr: 0.02\n",
      "iteration: 200600 loss: 0.0016 lr: 0.02\n",
      "iteration: 200610 loss: 0.0021 lr: 0.02\n",
      "iteration: 200620 loss: 0.0019 lr: 0.02\n",
      "iteration: 200630 loss: 0.0017 lr: 0.02\n",
      "iteration: 200640 loss: 0.0017 lr: 0.02\n",
      "iteration: 200650 loss: 0.0028 lr: 0.02\n",
      "iteration: 200660 loss: 0.0023 lr: 0.02\n",
      "iteration: 200670 loss: 0.0016 lr: 0.02\n",
      "iteration: 200680 loss: 0.0020 lr: 0.02\n",
      "iteration: 200690 loss: 0.0018 lr: 0.02\n",
      "iteration: 200700 loss: 0.0023 lr: 0.02\n",
      "iteration: 200710 loss: 0.0020 lr: 0.02\n",
      "iteration: 200720 loss: 0.0014 lr: 0.02\n",
      "iteration: 200730 loss: 0.0016 lr: 0.02\n",
      "iteration: 200740 loss: 0.0024 lr: 0.02\n",
      "iteration: 200750 loss: 0.0017 lr: 0.02\n",
      "iteration: 200760 loss: 0.0017 lr: 0.02\n",
      "iteration: 200770 loss: 0.0016 lr: 0.02\n",
      "iteration: 200780 loss: 0.0018 lr: 0.02\n",
      "iteration: 200790 loss: 0.0014 lr: 0.02\n",
      "iteration: 200800 loss: 0.0016 lr: 0.02\n",
      "iteration: 200810 loss: 0.0021 lr: 0.02\n",
      "iteration: 200820 loss: 0.0025 lr: 0.02\n",
      "iteration: 200830 loss: 0.0018 lr: 0.02\n",
      "iteration: 200840 loss: 0.0022 lr: 0.02\n",
      "iteration: 200850 loss: 0.0020 lr: 0.02\n",
      "iteration: 200860 loss: 0.0024 lr: 0.02\n",
      "iteration: 200870 loss: 0.0022 lr: 0.02\n",
      "iteration: 200880 loss: 0.0020 lr: 0.02\n",
      "iteration: 200890 loss: 0.0016 lr: 0.02\n",
      "iteration: 200900 loss: 0.0020 lr: 0.02\n",
      "iteration: 200910 loss: 0.0018 lr: 0.02\n",
      "iteration: 200920 loss: 0.0013 lr: 0.02\n",
      "iteration: 200930 loss: 0.0021 lr: 0.02\n",
      "iteration: 200940 loss: 0.0018 lr: 0.02\n",
      "iteration: 200950 loss: 0.0019 lr: 0.02\n",
      "iteration: 200960 loss: 0.0015 lr: 0.02\n",
      "iteration: 200970 loss: 0.0031 lr: 0.02\n",
      "iteration: 200980 loss: 0.0013 lr: 0.02\n",
      "iteration: 200990 loss: 0.0020 lr: 0.02\n",
      "iteration: 201000 loss: 0.0017 lr: 0.02\n",
      "iteration: 201010 loss: 0.0023 lr: 0.02\n",
      "iteration: 201020 loss: 0.0016 lr: 0.02\n",
      "iteration: 201030 loss: 0.0019 lr: 0.02\n",
      "iteration: 201040 loss: 0.0020 lr: 0.02\n",
      "iteration: 201050 loss: 0.0016 lr: 0.02\n",
      "iteration: 201060 loss: 0.0024 lr: 0.02\n",
      "iteration: 201070 loss: 0.0019 lr: 0.02\n",
      "iteration: 201080 loss: 0.0019 lr: 0.02\n",
      "iteration: 201090 loss: 0.0015 lr: 0.02\n",
      "iteration: 201100 loss: 0.0020 lr: 0.02\n",
      "iteration: 201110 loss: 0.0022 lr: 0.02\n",
      "iteration: 201120 loss: 0.0025 lr: 0.02\n",
      "iteration: 201130 loss: 0.0019 lr: 0.02\n",
      "iteration: 201140 loss: 0.0016 lr: 0.02\n",
      "iteration: 201150 loss: 0.0020 lr: 0.02\n",
      "iteration: 201160 loss: 0.0019 lr: 0.02\n",
      "iteration: 201170 loss: 0.0018 lr: 0.02\n",
      "iteration: 201180 loss: 0.0023 lr: 0.02\n",
      "iteration: 201190 loss: 0.0016 lr: 0.02\n",
      "iteration: 201200 loss: 0.0019 lr: 0.02\n",
      "iteration: 201210 loss: 0.0019 lr: 0.02\n",
      "iteration: 201220 loss: 0.0021 lr: 0.02\n",
      "iteration: 201230 loss: 0.0016 lr: 0.02\n",
      "iteration: 201240 loss: 0.0019 lr: 0.02\n",
      "iteration: 201250 loss: 0.0019 lr: 0.02\n",
      "iteration: 201260 loss: 0.0017 lr: 0.02\n",
      "iteration: 201270 loss: 0.0017 lr: 0.02\n",
      "iteration: 201280 loss: 0.0019 lr: 0.02\n",
      "iteration: 201290 loss: 0.0021 lr: 0.02\n",
      "iteration: 201300 loss: 0.0025 lr: 0.02\n",
      "iteration: 201310 loss: 0.0022 lr: 0.02\n",
      "iteration: 201320 loss: 0.0018 lr: 0.02\n",
      "iteration: 201330 loss: 0.0018 lr: 0.02\n",
      "iteration: 201340 loss: 0.0018 lr: 0.02\n",
      "iteration: 201350 loss: 0.0020 lr: 0.02\n",
      "iteration: 201360 loss: 0.0020 lr: 0.02\n",
      "iteration: 201370 loss: 0.0019 lr: 0.02\n",
      "iteration: 201380 loss: 0.0020 lr: 0.02\n",
      "iteration: 201390 loss: 0.0016 lr: 0.02\n",
      "iteration: 201400 loss: 0.0024 lr: 0.02\n",
      "iteration: 201410 loss: 0.0023 lr: 0.02\n",
      "iteration: 201420 loss: 0.0017 lr: 0.02\n",
      "iteration: 201430 loss: 0.0020 lr: 0.02\n",
      "iteration: 201440 loss: 0.0018 lr: 0.02\n",
      "iteration: 201450 loss: 0.0031 lr: 0.02\n",
      "iteration: 201460 loss: 0.0024 lr: 0.02\n",
      "iteration: 201470 loss: 0.0028 lr: 0.02\n",
      "iteration: 201480 loss: 0.0015 lr: 0.02\n",
      "iteration: 201490 loss: 0.0021 lr: 0.02\n",
      "iteration: 201500 loss: 0.0020 lr: 0.02\n",
      "iteration: 201510 loss: 0.0021 lr: 0.02\n",
      "iteration: 201520 loss: 0.0022 lr: 0.02\n",
      "iteration: 201530 loss: 0.0023 lr: 0.02\n",
      "iteration: 201540 loss: 0.0020 lr: 0.02\n",
      "iteration: 201550 loss: 0.0021 lr: 0.02\n",
      "iteration: 201560 loss: 0.0014 lr: 0.02\n",
      "iteration: 201570 loss: 0.0022 lr: 0.02\n",
      "iteration: 201580 loss: 0.0017 lr: 0.02\n",
      "iteration: 201590 loss: 0.0024 lr: 0.02\n",
      "iteration: 201600 loss: 0.0016 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 201610 loss: 0.0020 lr: 0.02\n",
      "iteration: 201620 loss: 0.0025 lr: 0.02\n",
      "iteration: 201630 loss: 0.0013 lr: 0.02\n",
      "iteration: 201640 loss: 0.0024 lr: 0.02\n",
      "iteration: 201650 loss: 0.0016 lr: 0.02\n",
      "iteration: 201660 loss: 0.0020 lr: 0.02\n",
      "iteration: 201670 loss: 0.0018 lr: 0.02\n",
      "iteration: 201680 loss: 0.0016 lr: 0.02\n",
      "iteration: 201690 loss: 0.0020 lr: 0.02\n",
      "iteration: 201700 loss: 0.0018 lr: 0.02\n",
      "iteration: 201710 loss: 0.0017 lr: 0.02\n",
      "iteration: 201720 loss: 0.0017 lr: 0.02\n",
      "iteration: 201730 loss: 0.0021 lr: 0.02\n",
      "iteration: 201740 loss: 0.0020 lr: 0.02\n",
      "iteration: 201750 loss: 0.0015 lr: 0.02\n",
      "iteration: 201760 loss: 0.0025 lr: 0.02\n",
      "iteration: 201770 loss: 0.0017 lr: 0.02\n",
      "iteration: 201780 loss: 0.0024 lr: 0.02\n",
      "iteration: 201790 loss: 0.0018 lr: 0.02\n",
      "iteration: 201800 loss: 0.0025 lr: 0.02\n",
      "iteration: 201810 loss: 0.0021 lr: 0.02\n",
      "iteration: 201820 loss: 0.0022 lr: 0.02\n",
      "iteration: 201830 loss: 0.0017 lr: 0.02\n",
      "iteration: 201840 loss: 0.0020 lr: 0.02\n",
      "iteration: 201850 loss: 0.0025 lr: 0.02\n",
      "iteration: 201860 loss: 0.0019 lr: 0.02\n",
      "iteration: 201870 loss: 0.0016 lr: 0.02\n",
      "iteration: 201880 loss: 0.0013 lr: 0.02\n",
      "iteration: 201890 loss: 0.0024 lr: 0.02\n",
      "iteration: 201900 loss: 0.0020 lr: 0.02\n",
      "iteration: 201910 loss: 0.0028 lr: 0.02\n",
      "iteration: 201920 loss: 0.0019 lr: 0.02\n",
      "iteration: 201930 loss: 0.0021 lr: 0.02\n",
      "iteration: 201940 loss: 0.0022 lr: 0.02\n",
      "iteration: 201950 loss: 0.0028 lr: 0.02\n",
      "iteration: 201960 loss: 0.0027 lr: 0.02\n",
      "iteration: 201970 loss: 0.0015 lr: 0.02\n",
      "iteration: 201980 loss: 0.0017 lr: 0.02\n",
      "iteration: 201990 loss: 0.0019 lr: 0.02\n",
      "iteration: 202000 loss: 0.0021 lr: 0.02\n",
      "iteration: 202010 loss: 0.0016 lr: 0.02\n",
      "iteration: 202020 loss: 0.0020 lr: 0.02\n",
      "iteration: 202030 loss: 0.0026 lr: 0.02\n",
      "iteration: 202040 loss: 0.0021 lr: 0.02\n",
      "iteration: 202050 loss: 0.0023 lr: 0.02\n",
      "iteration: 202060 loss: 0.0015 lr: 0.02\n",
      "iteration: 202070 loss: 0.0021 lr: 0.02\n",
      "iteration: 202080 loss: 0.0016 lr: 0.02\n",
      "iteration: 202090 loss: 0.0020 lr: 0.02\n",
      "iteration: 202100 loss: 0.0019 lr: 0.02\n",
      "iteration: 202110 loss: 0.0021 lr: 0.02\n",
      "iteration: 202120 loss: 0.0018 lr: 0.02\n",
      "iteration: 202130 loss: 0.0021 lr: 0.02\n",
      "iteration: 202140 loss: 0.0024 lr: 0.02\n",
      "iteration: 202150 loss: 0.0022 lr: 0.02\n",
      "iteration: 202160 loss: 0.0022 lr: 0.02\n",
      "iteration: 202170 loss: 0.0026 lr: 0.02\n",
      "iteration: 202180 loss: 0.0021 lr: 0.02\n",
      "iteration: 202190 loss: 0.0017 lr: 0.02\n",
      "iteration: 202200 loss: 0.0020 lr: 0.02\n",
      "iteration: 202210 loss: 0.0013 lr: 0.02\n",
      "iteration: 202220 loss: 0.0031 lr: 0.02\n",
      "iteration: 202230 loss: 0.0022 lr: 0.02\n",
      "iteration: 202240 loss: 0.0020 lr: 0.02\n",
      "iteration: 202250 loss: 0.0018 lr: 0.02\n",
      "iteration: 202260 loss: 0.0019 lr: 0.02\n",
      "iteration: 202270 loss: 0.0014 lr: 0.02\n",
      "iteration: 202280 loss: 0.0019 lr: 0.02\n",
      "iteration: 202290 loss: 0.0018 lr: 0.02\n",
      "iteration: 202300 loss: 0.0019 lr: 0.02\n",
      "iteration: 202310 loss: 0.0024 lr: 0.02\n",
      "iteration: 202320 loss: 0.0016 lr: 0.02\n",
      "iteration: 202330 loss: 0.0017 lr: 0.02\n",
      "iteration: 202340 loss: 0.0017 lr: 0.02\n",
      "iteration: 202350 loss: 0.0020 lr: 0.02\n",
      "iteration: 202360 loss: 0.0018 lr: 0.02\n",
      "iteration: 202370 loss: 0.0020 lr: 0.02\n",
      "iteration: 202380 loss: 0.0020 lr: 0.02\n",
      "iteration: 202390 loss: 0.0018 lr: 0.02\n",
      "iteration: 202400 loss: 0.0023 lr: 0.02\n",
      "iteration: 202410 loss: 0.0025 lr: 0.02\n",
      "iteration: 202420 loss: 0.0026 lr: 0.02\n",
      "iteration: 202430 loss: 0.0028 lr: 0.02\n",
      "iteration: 202440 loss: 0.0017 lr: 0.02\n",
      "iteration: 202450 loss: 0.0018 lr: 0.02\n",
      "iteration: 202460 loss: 0.0022 lr: 0.02\n",
      "iteration: 202470 loss: 0.0016 lr: 0.02\n",
      "iteration: 202480 loss: 0.0018 lr: 0.02\n",
      "iteration: 202490 loss: 0.0019 lr: 0.02\n",
      "iteration: 202500 loss: 0.0021 lr: 0.02\n",
      "iteration: 202510 loss: 0.0019 lr: 0.02\n",
      "iteration: 202520 loss: 0.0018 lr: 0.02\n",
      "iteration: 202530 loss: 0.0021 lr: 0.02\n",
      "iteration: 202540 loss: 0.0027 lr: 0.02\n",
      "iteration: 202550 loss: 0.0020 lr: 0.02\n",
      "iteration: 202560 loss: 0.0018 lr: 0.02\n",
      "iteration: 202570 loss: 0.0024 lr: 0.02\n",
      "iteration: 202580 loss: 0.0020 lr: 0.02\n",
      "iteration: 202590 loss: 0.0018 lr: 0.02\n",
      "iteration: 202600 loss: 0.0025 lr: 0.02\n",
      "iteration: 202610 loss: 0.0019 lr: 0.02\n",
      "iteration: 202620 loss: 0.0017 lr: 0.02\n",
      "iteration: 202630 loss: 0.0015 lr: 0.02\n",
      "iteration: 202640 loss: 0.0019 lr: 0.02\n",
      "iteration: 202650 loss: 0.0019 lr: 0.02\n",
      "iteration: 202660 loss: 0.0025 lr: 0.02\n",
      "iteration: 202670 loss: 0.0015 lr: 0.02\n",
      "iteration: 202680 loss: 0.0015 lr: 0.02\n",
      "iteration: 202690 loss: 0.0016 lr: 0.02\n",
      "iteration: 202700 loss: 0.0023 lr: 0.02\n",
      "iteration: 202710 loss: 0.0018 lr: 0.02\n",
      "iteration: 202720 loss: 0.0027 lr: 0.02\n",
      "iteration: 202730 loss: 0.0016 lr: 0.02\n",
      "iteration: 202740 loss: 0.0020 lr: 0.02\n",
      "iteration: 202750 loss: 0.0016 lr: 0.02\n",
      "iteration: 202760 loss: 0.0023 lr: 0.02\n",
      "iteration: 202770 loss: 0.0018 lr: 0.02\n",
      "iteration: 202780 loss: 0.0020 lr: 0.02\n",
      "iteration: 202790 loss: 0.0025 lr: 0.02\n",
      "iteration: 202800 loss: 0.0021 lr: 0.02\n",
      "iteration: 202810 loss: 0.0024 lr: 0.02\n",
      "iteration: 202820 loss: 0.0017 lr: 0.02\n",
      "iteration: 202830 loss: 0.0017 lr: 0.02\n",
      "iteration: 202840 loss: 0.0024 lr: 0.02\n",
      "iteration: 202850 loss: 0.0019 lr: 0.02\n",
      "iteration: 202860 loss: 0.0017 lr: 0.02\n",
      "iteration: 202870 loss: 0.0021 lr: 0.02\n",
      "iteration: 202880 loss: 0.0019 lr: 0.02\n",
      "iteration: 202890 loss: 0.0024 lr: 0.02\n",
      "iteration: 202900 loss: 0.0016 lr: 0.02\n",
      "iteration: 202910 loss: 0.0015 lr: 0.02\n",
      "iteration: 202920 loss: 0.0015 lr: 0.02\n",
      "iteration: 202930 loss: 0.0019 lr: 0.02\n",
      "iteration: 202940 loss: 0.0022 lr: 0.02\n",
      "iteration: 202950 loss: 0.0017 lr: 0.02\n",
      "iteration: 202960 loss: 0.0020 lr: 0.02\n",
      "iteration: 202970 loss: 0.0019 lr: 0.02\n",
      "iteration: 202980 loss: 0.0018 lr: 0.02\n",
      "iteration: 202990 loss: 0.0020 lr: 0.02\n",
      "iteration: 203000 loss: 0.0017 lr: 0.02\n",
      "iteration: 203010 loss: 0.0017 lr: 0.02\n",
      "iteration: 203020 loss: 0.0018 lr: 0.02\n",
      "iteration: 203030 loss: 0.0015 lr: 0.02\n",
      "iteration: 203040 loss: 0.0020 lr: 0.02\n",
      "iteration: 203050 loss: 0.0025 lr: 0.02\n",
      "iteration: 203060 loss: 0.0020 lr: 0.02\n",
      "iteration: 203070 loss: 0.0023 lr: 0.02\n",
      "iteration: 203080 loss: 0.0017 lr: 0.02\n",
      "iteration: 203090 loss: 0.0015 lr: 0.02\n",
      "iteration: 203100 loss: 0.0023 lr: 0.02\n",
      "iteration: 203110 loss: 0.0024 lr: 0.02\n",
      "iteration: 203120 loss: 0.0019 lr: 0.02\n",
      "iteration: 203130 loss: 0.0020 lr: 0.02\n",
      "iteration: 203140 loss: 0.0015 lr: 0.02\n",
      "iteration: 203150 loss: 0.0026 lr: 0.02\n",
      "iteration: 203160 loss: 0.0019 lr: 0.02\n",
      "iteration: 203170 loss: 0.0018 lr: 0.02\n",
      "iteration: 203180 loss: 0.0023 lr: 0.02\n",
      "iteration: 203190 loss: 0.0020 lr: 0.02\n",
      "iteration: 203200 loss: 0.0019 lr: 0.02\n",
      "iteration: 203210 loss: 0.0020 lr: 0.02\n",
      "iteration: 203220 loss: 0.0019 lr: 0.02\n",
      "iteration: 203230 loss: 0.0026 lr: 0.02\n",
      "iteration: 203240 loss: 0.0017 lr: 0.02\n",
      "iteration: 203250 loss: 0.0027 lr: 0.02\n",
      "iteration: 203260 loss: 0.0018 lr: 0.02\n",
      "iteration: 203270 loss: 0.0019 lr: 0.02\n",
      "iteration: 203280 loss: 0.0026 lr: 0.02\n",
      "iteration: 203290 loss: 0.0019 lr: 0.02\n",
      "iteration: 203300 loss: 0.0019 lr: 0.02\n",
      "iteration: 203310 loss: 0.0016 lr: 0.02\n",
      "iteration: 203320 loss: 0.0018 lr: 0.02\n",
      "iteration: 203330 loss: 0.0016 lr: 0.02\n",
      "iteration: 203340 loss: 0.0016 lr: 0.02\n",
      "iteration: 203350 loss: 0.0020 lr: 0.02\n",
      "iteration: 203360 loss: 0.0027 lr: 0.02\n",
      "iteration: 203370 loss: 0.0017 lr: 0.02\n",
      "iteration: 203380 loss: 0.0020 lr: 0.02\n",
      "iteration: 203390 loss: 0.0019 lr: 0.02\n",
      "iteration: 203400 loss: 0.0021 lr: 0.02\n",
      "iteration: 203410 loss: 0.0029 lr: 0.02\n",
      "iteration: 203420 loss: 0.0014 lr: 0.02\n",
      "iteration: 203430 loss: 0.0025 lr: 0.02\n",
      "iteration: 203440 loss: 0.0018 lr: 0.02\n",
      "iteration: 203450 loss: 0.0019 lr: 0.02\n",
      "iteration: 203460 loss: 0.0021 lr: 0.02\n",
      "iteration: 203470 loss: 0.0022 lr: 0.02\n",
      "iteration: 203480 loss: 0.0021 lr: 0.02\n",
      "iteration: 203490 loss: 0.0019 lr: 0.02\n",
      "iteration: 203500 loss: 0.0016 lr: 0.02\n",
      "iteration: 203510 loss: 0.0022 lr: 0.02\n",
      "iteration: 203520 loss: 0.0017 lr: 0.02\n",
      "iteration: 203530 loss: 0.0021 lr: 0.02\n",
      "iteration: 203540 loss: 0.0025 lr: 0.02\n",
      "iteration: 203550 loss: 0.0018 lr: 0.02\n",
      "iteration: 203560 loss: 0.0017 lr: 0.02\n",
      "iteration: 203570 loss: 0.0025 lr: 0.02\n",
      "iteration: 203580 loss: 0.0023 lr: 0.02\n",
      "iteration: 203590 loss: 0.0021 lr: 0.02\n",
      "iteration: 203600 loss: 0.0021 lr: 0.02\n",
      "iteration: 203610 loss: 0.0018 lr: 0.02\n",
      "iteration: 203620 loss: 0.0015 lr: 0.02\n",
      "iteration: 203630 loss: 0.0017 lr: 0.02\n",
      "iteration: 203640 loss: 0.0019 lr: 0.02\n",
      "iteration: 203650 loss: 0.0019 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 203660 loss: 0.0017 lr: 0.02\n",
      "iteration: 203670 loss: 0.0015 lr: 0.02\n",
      "iteration: 203680 loss: 0.0020 lr: 0.02\n",
      "iteration: 203690 loss: 0.0018 lr: 0.02\n",
      "iteration: 203700 loss: 0.0018 lr: 0.02\n",
      "iteration: 203710 loss: 0.0017 lr: 0.02\n",
      "iteration: 203720 loss: 0.0022 lr: 0.02\n",
      "iteration: 203730 loss: 0.0021 lr: 0.02\n",
      "iteration: 203740 loss: 0.0016 lr: 0.02\n",
      "iteration: 203750 loss: 0.0018 lr: 0.02\n",
      "iteration: 203760 loss: 0.0021 lr: 0.02\n",
      "iteration: 203770 loss: 0.0019 lr: 0.02\n",
      "iteration: 203780 loss: 0.0016 lr: 0.02\n",
      "iteration: 203790 loss: 0.0026 lr: 0.02\n",
      "iteration: 203800 loss: 0.0018 lr: 0.02\n",
      "iteration: 203810 loss: 0.0016 lr: 0.02\n",
      "iteration: 203820 loss: 0.0022 lr: 0.02\n",
      "iteration: 203830 loss: 0.0019 lr: 0.02\n",
      "iteration: 203840 loss: 0.0025 lr: 0.02\n",
      "iteration: 203850 loss: 0.0016 lr: 0.02\n",
      "iteration: 203860 loss: 0.0022 lr: 0.02\n",
      "iteration: 203870 loss: 0.0022 lr: 0.02\n",
      "iteration: 203880 loss: 0.0018 lr: 0.02\n",
      "iteration: 203890 loss: 0.0024 lr: 0.02\n",
      "iteration: 203900 loss: 0.0018 lr: 0.02\n",
      "iteration: 203910 loss: 0.0014 lr: 0.02\n",
      "iteration: 203920 loss: 0.0020 lr: 0.02\n",
      "iteration: 203930 loss: 0.0019 lr: 0.02\n",
      "iteration: 203940 loss: 0.0020 lr: 0.02\n",
      "iteration: 203950 loss: 0.0016 lr: 0.02\n",
      "iteration: 203960 loss: 0.0023 lr: 0.02\n",
      "iteration: 203970 loss: 0.0028 lr: 0.02\n",
      "iteration: 203980 loss: 0.0017 lr: 0.02\n",
      "iteration: 203990 loss: 0.0017 lr: 0.02\n",
      "iteration: 204000 loss: 0.0020 lr: 0.02\n",
      "iteration: 204010 loss: 0.0015 lr: 0.02\n",
      "iteration: 204020 loss: 0.0022 lr: 0.02\n",
      "iteration: 204030 loss: 0.0017 lr: 0.02\n",
      "iteration: 204040 loss: 0.0019 lr: 0.02\n",
      "iteration: 204050 loss: 0.0024 lr: 0.02\n",
      "iteration: 204060 loss: 0.0021 lr: 0.02\n",
      "iteration: 204070 loss: 0.0021 lr: 0.02\n",
      "iteration: 204080 loss: 0.0017 lr: 0.02\n",
      "iteration: 204090 loss: 0.0023 lr: 0.02\n",
      "iteration: 204100 loss: 0.0020 lr: 0.02\n",
      "iteration: 204110 loss: 0.0017 lr: 0.02\n",
      "iteration: 204120 loss: 0.0021 lr: 0.02\n",
      "iteration: 204130 loss: 0.0021 lr: 0.02\n",
      "iteration: 204140 loss: 0.0015 lr: 0.02\n",
      "iteration: 204150 loss: 0.0027 lr: 0.02\n",
      "iteration: 204160 loss: 0.0029 lr: 0.02\n",
      "iteration: 204170 loss: 0.0020 lr: 0.02\n",
      "iteration: 204180 loss: 0.0018 lr: 0.02\n",
      "iteration: 204190 loss: 0.0019 lr: 0.02\n",
      "iteration: 204200 loss: 0.0021 lr: 0.02\n",
      "iteration: 204210 loss: 0.0022 lr: 0.02\n",
      "iteration: 204220 loss: 0.0022 lr: 0.02\n",
      "iteration: 204230 loss: 0.0021 lr: 0.02\n",
      "iteration: 204240 loss: 0.0019 lr: 0.02\n",
      "iteration: 204250 loss: 0.0029 lr: 0.02\n",
      "iteration: 204260 loss: 0.0018 lr: 0.02\n",
      "iteration: 204270 loss: 0.0015 lr: 0.02\n",
      "iteration: 204280 loss: 0.0022 lr: 0.02\n",
      "iteration: 204290 loss: 0.0016 lr: 0.02\n",
      "iteration: 204300 loss: 0.0020 lr: 0.02\n",
      "iteration: 204310 loss: 0.0016 lr: 0.02\n",
      "iteration: 204320 loss: 0.0021 lr: 0.02\n",
      "iteration: 204330 loss: 0.0020 lr: 0.02\n",
      "iteration: 204340 loss: 0.0015 lr: 0.02\n",
      "iteration: 204350 loss: 0.0017 lr: 0.02\n",
      "iteration: 204360 loss: 0.0021 lr: 0.02\n",
      "iteration: 204370 loss: 0.0020 lr: 0.02\n",
      "iteration: 204380 loss: 0.0019 lr: 0.02\n",
      "iteration: 204390 loss: 0.0018 lr: 0.02\n",
      "iteration: 204400 loss: 0.0019 lr: 0.02\n",
      "iteration: 204410 loss: 0.0020 lr: 0.02\n",
      "iteration: 204420 loss: 0.0023 lr: 0.02\n",
      "iteration: 204430 loss: 0.0022 lr: 0.02\n",
      "iteration: 204440 loss: 0.0017 lr: 0.02\n",
      "iteration: 204450 loss: 0.0020 lr: 0.02\n",
      "iteration: 204460 loss: 0.0026 lr: 0.02\n",
      "iteration: 204470 loss: 0.0016 lr: 0.02\n",
      "iteration: 204480 loss: 0.0023 lr: 0.02\n",
      "iteration: 204490 loss: 0.0025 lr: 0.02\n",
      "iteration: 204500 loss: 0.0015 lr: 0.02\n",
      "iteration: 204510 loss: 0.0026 lr: 0.02\n",
      "iteration: 204520 loss: 0.0017 lr: 0.02\n",
      "iteration: 204530 loss: 0.0024 lr: 0.02\n",
      "iteration: 204540 loss: 0.0021 lr: 0.02\n",
      "iteration: 204550 loss: 0.0023 lr: 0.02\n",
      "iteration: 204560 loss: 0.0017 lr: 0.02\n",
      "iteration: 204570 loss: 0.0021 lr: 0.02\n",
      "iteration: 204580 loss: 0.0022 lr: 0.02\n",
      "iteration: 204590 loss: 0.0017 lr: 0.02\n",
      "iteration: 204600 loss: 0.0016 lr: 0.02\n",
      "iteration: 204610 loss: 0.0023 lr: 0.02\n",
      "iteration: 204620 loss: 0.0019 lr: 0.02\n",
      "iteration: 204630 loss: 0.0017 lr: 0.02\n",
      "iteration: 204640 loss: 0.0021 lr: 0.02\n",
      "iteration: 204650 loss: 0.0020 lr: 0.02\n",
      "iteration: 204660 loss: 0.0021 lr: 0.02\n",
      "iteration: 204670 loss: 0.0023 lr: 0.02\n",
      "iteration: 204680 loss: 0.0021 lr: 0.02\n",
      "iteration: 204690 loss: 0.0021 lr: 0.02\n",
      "iteration: 204700 loss: 0.0017 lr: 0.02\n",
      "iteration: 204710 loss: 0.0020 lr: 0.02\n",
      "iteration: 204720 loss: 0.0021 lr: 0.02\n",
      "iteration: 204730 loss: 0.0026 lr: 0.02\n",
      "iteration: 204740 loss: 0.0019 lr: 0.02\n",
      "iteration: 204750 loss: 0.0018 lr: 0.02\n",
      "iteration: 204760 loss: 0.0019 lr: 0.02\n",
      "iteration: 204770 loss: 0.0015 lr: 0.02\n",
      "iteration: 204780 loss: 0.0017 lr: 0.02\n",
      "iteration: 204790 loss: 0.0022 lr: 0.02\n",
      "iteration: 204800 loss: 0.0021 lr: 0.02\n",
      "iteration: 204810 loss: 0.0021 lr: 0.02\n",
      "iteration: 204820 loss: 0.0024 lr: 0.02\n",
      "iteration: 204830 loss: 0.0019 lr: 0.02\n",
      "iteration: 204840 loss: 0.0018 lr: 0.02\n",
      "iteration: 204850 loss: 0.0017 lr: 0.02\n",
      "iteration: 204860 loss: 0.0018 lr: 0.02\n",
      "iteration: 204870 loss: 0.0019 lr: 0.02\n",
      "iteration: 204880 loss: 0.0020 lr: 0.02\n",
      "iteration: 204890 loss: 0.0018 lr: 0.02\n",
      "iteration: 204900 loss: 0.0023 lr: 0.02\n",
      "iteration: 204910 loss: 0.0017 lr: 0.02\n",
      "iteration: 204920 loss: 0.0017 lr: 0.02\n",
      "iteration: 204930 loss: 0.0023 lr: 0.02\n",
      "iteration: 204940 loss: 0.0023 lr: 0.02\n",
      "iteration: 204950 loss: 0.0020 lr: 0.02\n",
      "iteration: 204960 loss: 0.0026 lr: 0.02\n",
      "iteration: 204970 loss: 0.0023 lr: 0.02\n",
      "iteration: 204980 loss: 0.0015 lr: 0.02\n",
      "iteration: 204990 loss: 0.0018 lr: 0.02\n",
      "iteration: 205000 loss: 0.0023 lr: 0.02\n",
      "iteration: 205010 loss: 0.0021 lr: 0.02\n",
      "iteration: 205020 loss: 0.0021 lr: 0.02\n",
      "iteration: 205030 loss: 0.0020 lr: 0.02\n",
      "iteration: 205040 loss: 0.0025 lr: 0.02\n",
      "iteration: 205050 loss: 0.0021 lr: 0.02\n",
      "iteration: 205060 loss: 0.0020 lr: 0.02\n",
      "iteration: 205070 loss: 0.0019 lr: 0.02\n",
      "iteration: 205080 loss: 0.0030 lr: 0.02\n",
      "iteration: 205090 loss: 0.0018 lr: 0.02\n",
      "iteration: 205100 loss: 0.0017 lr: 0.02\n",
      "iteration: 205110 loss: 0.0016 lr: 0.02\n",
      "iteration: 205120 loss: 0.0023 lr: 0.02\n",
      "iteration: 205130 loss: 0.0025 lr: 0.02\n",
      "iteration: 205140 loss: 0.0019 lr: 0.02\n",
      "iteration: 205150 loss: 0.0017 lr: 0.02\n",
      "iteration: 205160 loss: 0.0018 lr: 0.02\n",
      "iteration: 205170 loss: 0.0023 lr: 0.02\n",
      "iteration: 205180 loss: 0.0023 lr: 0.02\n",
      "iteration: 205190 loss: 0.0018 lr: 0.02\n",
      "iteration: 205200 loss: 0.0027 lr: 0.02\n",
      "iteration: 205210 loss: 0.0018 lr: 0.02\n",
      "iteration: 205220 loss: 0.0022 lr: 0.02\n",
      "iteration: 205230 loss: 0.0018 lr: 0.02\n",
      "iteration: 205240 loss: 0.0025 lr: 0.02\n",
      "iteration: 205250 loss: 0.0021 lr: 0.02\n",
      "iteration: 205260 loss: 0.0017 lr: 0.02\n",
      "iteration: 205270 loss: 0.0019 lr: 0.02\n",
      "iteration: 205280 loss: 0.0021 lr: 0.02\n",
      "iteration: 205290 loss: 0.0023 lr: 0.02\n",
      "iteration: 205300 loss: 0.0019 lr: 0.02\n",
      "iteration: 205310 loss: 0.0022 lr: 0.02\n",
      "iteration: 205320 loss: 0.0017 lr: 0.02\n",
      "iteration: 205330 loss: 0.0021 lr: 0.02\n",
      "iteration: 205340 loss: 0.0020 lr: 0.02\n",
      "iteration: 205350 loss: 0.0026 lr: 0.02\n",
      "iteration: 205360 loss: 0.0018 lr: 0.02\n",
      "iteration: 205370 loss: 0.0023 lr: 0.02\n",
      "iteration: 205380 loss: 0.0018 lr: 0.02\n",
      "iteration: 205390 loss: 0.0019 lr: 0.02\n",
      "iteration: 205400 loss: 0.0021 lr: 0.02\n",
      "iteration: 205410 loss: 0.0034 lr: 0.02\n",
      "iteration: 205420 loss: 0.0019 lr: 0.02\n",
      "iteration: 205430 loss: 0.0015 lr: 0.02\n",
      "iteration: 205440 loss: 0.0021 lr: 0.02\n",
      "iteration: 205450 loss: 0.0016 lr: 0.02\n",
      "iteration: 205460 loss: 0.0017 lr: 0.02\n",
      "iteration: 205470 loss: 0.0015 lr: 0.02\n",
      "iteration: 205480 loss: 0.0022 lr: 0.02\n",
      "iteration: 205490 loss: 0.0023 lr: 0.02\n",
      "iteration: 205500 loss: 0.0021 lr: 0.02\n",
      "iteration: 205510 loss: 0.0018 lr: 0.02\n",
      "iteration: 205520 loss: 0.0023 lr: 0.02\n",
      "iteration: 205530 loss: 0.0021 lr: 0.02\n",
      "iteration: 205540 loss: 0.0022 lr: 0.02\n",
      "iteration: 205550 loss: 0.0022 lr: 0.02\n",
      "iteration: 205560 loss: 0.0016 lr: 0.02\n",
      "iteration: 205570 loss: 0.0018 lr: 0.02\n",
      "iteration: 205580 loss: 0.0020 lr: 0.02\n",
      "iteration: 205590 loss: 0.0020 lr: 0.02\n",
      "iteration: 205600 loss: 0.0023 lr: 0.02\n",
      "iteration: 205610 loss: 0.0015 lr: 0.02\n",
      "iteration: 205620 loss: 0.0023 lr: 0.02\n",
      "iteration: 205630 loss: 0.0022 lr: 0.02\n",
      "iteration: 205640 loss: 0.0021 lr: 0.02\n",
      "iteration: 205650 loss: 0.0019 lr: 0.02\n",
      "iteration: 205660 loss: 0.0021 lr: 0.02\n",
      "iteration: 205670 loss: 0.0022 lr: 0.02\n",
      "iteration: 205680 loss: 0.0020 lr: 0.02\n",
      "iteration: 205690 loss: 0.0027 lr: 0.02\n",
      "iteration: 205700 loss: 0.0021 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 205710 loss: 0.0019 lr: 0.02\n",
      "iteration: 205720 loss: 0.0023 lr: 0.02\n",
      "iteration: 205730 loss: 0.0023 lr: 0.02\n",
      "iteration: 205740 loss: 0.0017 lr: 0.02\n",
      "iteration: 205750 loss: 0.0020 lr: 0.02\n",
      "iteration: 205760 loss: 0.0018 lr: 0.02\n",
      "iteration: 205770 loss: 0.0019 lr: 0.02\n",
      "iteration: 205780 loss: 0.0020 lr: 0.02\n",
      "iteration: 205790 loss: 0.0020 lr: 0.02\n",
      "iteration: 205800 loss: 0.0022 lr: 0.02\n",
      "iteration: 205810 loss: 0.0022 lr: 0.02\n",
      "iteration: 205820 loss: 0.0013 lr: 0.02\n",
      "iteration: 205830 loss: 0.0019 lr: 0.02\n",
      "iteration: 205840 loss: 0.0023 lr: 0.02\n",
      "iteration: 205850 loss: 0.0019 lr: 0.02\n",
      "iteration: 205860 loss: 0.0023 lr: 0.02\n",
      "iteration: 205870 loss: 0.0019 lr: 0.02\n",
      "iteration: 205880 loss: 0.0018 lr: 0.02\n",
      "iteration: 205890 loss: 0.0018 lr: 0.02\n",
      "iteration: 205900 loss: 0.0023 lr: 0.02\n",
      "iteration: 205910 loss: 0.0018 lr: 0.02\n",
      "iteration: 205920 loss: 0.0022 lr: 0.02\n",
      "iteration: 205930 loss: 0.0017 lr: 0.02\n",
      "iteration: 205940 loss: 0.0023 lr: 0.02\n",
      "iteration: 205950 loss: 0.0017 lr: 0.02\n",
      "iteration: 205960 loss: 0.0023 lr: 0.02\n",
      "iteration: 205970 loss: 0.0017 lr: 0.02\n",
      "iteration: 205980 loss: 0.0021 lr: 0.02\n",
      "iteration: 205990 loss: 0.0022 lr: 0.02\n",
      "iteration: 206000 loss: 0.0025 lr: 0.02\n",
      "iteration: 206010 loss: 0.0022 lr: 0.02\n",
      "iteration: 206020 loss: 0.0022 lr: 0.02\n",
      "iteration: 206030 loss: 0.0019 lr: 0.02\n",
      "iteration: 206040 loss: 0.0022 lr: 0.02\n",
      "iteration: 206050 loss: 0.0027 lr: 0.02\n",
      "iteration: 206060 loss: 0.0014 lr: 0.02\n",
      "iteration: 206070 loss: 0.0021 lr: 0.02\n",
      "iteration: 206080 loss: 0.0036 lr: 0.02\n",
      "iteration: 206090 loss: 0.0018 lr: 0.02\n",
      "iteration: 206100 loss: 0.0024 lr: 0.02\n",
      "iteration: 206110 loss: 0.0026 lr: 0.02\n",
      "iteration: 206120 loss: 0.0020 lr: 0.02\n",
      "iteration: 206130 loss: 0.0022 lr: 0.02\n",
      "iteration: 206140 loss: 0.0020 lr: 0.02\n",
      "iteration: 206150 loss: 0.0017 lr: 0.02\n",
      "iteration: 206160 loss: 0.0024 lr: 0.02\n",
      "iteration: 206170 loss: 0.0019 lr: 0.02\n",
      "iteration: 206180 loss: 0.0019 lr: 0.02\n",
      "iteration: 206190 loss: 0.0020 lr: 0.02\n",
      "iteration: 206200 loss: 0.0021 lr: 0.02\n",
      "iteration: 206210 loss: 0.0024 lr: 0.02\n",
      "iteration: 206220 loss: 0.0019 lr: 0.02\n",
      "iteration: 206230 loss: 0.0016 lr: 0.02\n",
      "iteration: 206240 loss: 0.0019 lr: 0.02\n",
      "iteration: 206250 loss: 0.0018 lr: 0.02\n",
      "iteration: 206260 loss: 0.0019 lr: 0.02\n",
      "iteration: 206270 loss: 0.0022 lr: 0.02\n",
      "iteration: 206280 loss: 0.0023 lr: 0.02\n",
      "iteration: 206290 loss: 0.0020 lr: 0.02\n",
      "iteration: 206300 loss: 0.0016 lr: 0.02\n",
      "iteration: 206310 loss: 0.0021 lr: 0.02\n",
      "iteration: 206320 loss: 0.0021 lr: 0.02\n",
      "iteration: 206330 loss: 0.0016 lr: 0.02\n",
      "iteration: 206340 loss: 0.0017 lr: 0.02\n",
      "iteration: 206350 loss: 0.0015 lr: 0.02\n",
      "iteration: 206360 loss: 0.0014 lr: 0.02\n",
      "iteration: 206370 loss: 0.0022 lr: 0.02\n",
      "iteration: 206380 loss: 0.0018 lr: 0.02\n",
      "iteration: 206390 loss: 0.0018 lr: 0.02\n",
      "iteration: 206400 loss: 0.0019 lr: 0.02\n",
      "iteration: 206410 loss: 0.0021 lr: 0.02\n",
      "iteration: 206420 loss: 0.0017 lr: 0.02\n",
      "iteration: 206430 loss: 0.0023 lr: 0.02\n",
      "iteration: 206440 loss: 0.0018 lr: 0.02\n",
      "iteration: 206450 loss: 0.0020 lr: 0.02\n",
      "iteration: 206460 loss: 0.0027 lr: 0.02\n",
      "iteration: 206470 loss: 0.0029 lr: 0.02\n",
      "iteration: 206480 loss: 0.0024 lr: 0.02\n",
      "iteration: 206490 loss: 0.0020 lr: 0.02\n",
      "iteration: 206500 loss: 0.0020 lr: 0.02\n",
      "iteration: 206510 loss: 0.0018 lr: 0.02\n",
      "iteration: 206520 loss: 0.0018 lr: 0.02\n",
      "iteration: 206530 loss: 0.0019 lr: 0.02\n",
      "iteration: 206540 loss: 0.0017 lr: 0.02\n",
      "iteration: 206550 loss: 0.0020 lr: 0.02\n",
      "iteration: 206560 loss: 0.0018 lr: 0.02\n",
      "iteration: 206570 loss: 0.0018 lr: 0.02\n",
      "iteration: 206580 loss: 0.0025 lr: 0.02\n",
      "iteration: 206590 loss: 0.0019 lr: 0.02\n",
      "iteration: 206600 loss: 0.0022 lr: 0.02\n",
      "iteration: 206610 loss: 0.0022 lr: 0.02\n",
      "iteration: 206620 loss: 0.0019 lr: 0.02\n",
      "iteration: 206630 loss: 0.0020 lr: 0.02\n",
      "iteration: 206640 loss: 0.0019 lr: 0.02\n",
      "iteration: 206650 loss: 0.0026 lr: 0.02\n",
      "iteration: 206660 loss: 0.0018 lr: 0.02\n",
      "iteration: 206670 loss: 0.0017 lr: 0.02\n",
      "iteration: 206680 loss: 0.0021 lr: 0.02\n",
      "iteration: 206690 loss: 0.0022 lr: 0.02\n",
      "iteration: 206700 loss: 0.0018 lr: 0.02\n",
      "iteration: 206710 loss: 0.0019 lr: 0.02\n",
      "iteration: 206720 loss: 0.0020 lr: 0.02\n",
      "iteration: 206730 loss: 0.0013 lr: 0.02\n",
      "iteration: 206740 loss: 0.0028 lr: 0.02\n",
      "iteration: 206750 loss: 0.0023 lr: 0.02\n",
      "iteration: 206760 loss: 0.0015 lr: 0.02\n",
      "iteration: 206770 loss: 0.0030 lr: 0.02\n",
      "iteration: 206780 loss: 0.0020 lr: 0.02\n",
      "iteration: 206790 loss: 0.0013 lr: 0.02\n",
      "iteration: 206800 loss: 0.0019 lr: 0.02\n",
      "iteration: 206810 loss: 0.0020 lr: 0.02\n",
      "iteration: 206820 loss: 0.0016 lr: 0.02\n",
      "iteration: 206830 loss: 0.0018 lr: 0.02\n",
      "iteration: 206840 loss: 0.0014 lr: 0.02\n",
      "iteration: 206850 loss: 0.0032 lr: 0.02\n",
      "iteration: 206860 loss: 0.0018 lr: 0.02\n",
      "iteration: 206870 loss: 0.0022 lr: 0.02\n",
      "iteration: 206880 loss: 0.0023 lr: 0.02\n",
      "iteration: 206890 loss: 0.0019 lr: 0.02\n",
      "iteration: 206900 loss: 0.0016 lr: 0.02\n",
      "iteration: 206910 loss: 0.0022 lr: 0.02\n",
      "iteration: 206920 loss: 0.0018 lr: 0.02\n",
      "iteration: 206930 loss: 0.0025 lr: 0.02\n",
      "iteration: 206940 loss: 0.0020 lr: 0.02\n",
      "iteration: 206950 loss: 0.0021 lr: 0.02\n",
      "iteration: 206960 loss: 0.0017 lr: 0.02\n",
      "iteration: 206970 loss: 0.0017 lr: 0.02\n",
      "iteration: 206980 loss: 0.0019 lr: 0.02\n",
      "iteration: 206990 loss: 0.0015 lr: 0.02\n",
      "iteration: 207000 loss: 0.0024 lr: 0.02\n",
      "iteration: 207010 loss: 0.0021 lr: 0.02\n",
      "iteration: 207020 loss: 0.0017 lr: 0.02\n",
      "iteration: 207030 loss: 0.0015 lr: 0.02\n",
      "iteration: 207040 loss: 0.0024 lr: 0.02\n",
      "iteration: 207050 loss: 0.0021 lr: 0.02\n",
      "iteration: 207060 loss: 0.0022 lr: 0.02\n",
      "iteration: 207070 loss: 0.0021 lr: 0.02\n",
      "iteration: 207080 loss: 0.0019 lr: 0.02\n",
      "iteration: 207090 loss: 0.0015 lr: 0.02\n",
      "iteration: 207100 loss: 0.0018 lr: 0.02\n",
      "iteration: 207110 loss: 0.0020 lr: 0.02\n",
      "iteration: 207120 loss: 0.0018 lr: 0.02\n",
      "iteration: 207130 loss: 0.0022 lr: 0.02\n",
      "iteration: 207140 loss: 0.0018 lr: 0.02\n",
      "iteration: 207150 loss: 0.0019 lr: 0.02\n",
      "iteration: 207160 loss: 0.0015 lr: 0.02\n",
      "iteration: 207170 loss: 0.0018 lr: 0.02\n",
      "iteration: 207180 loss: 0.0016 lr: 0.02\n",
      "iteration: 207190 loss: 0.0028 lr: 0.02\n",
      "iteration: 207200 loss: 0.0024 lr: 0.02\n",
      "iteration: 207210 loss: 0.0017 lr: 0.02\n",
      "iteration: 207220 loss: 0.0021 lr: 0.02\n",
      "iteration: 207230 loss: 0.0019 lr: 0.02\n",
      "iteration: 207240 loss: 0.0018 lr: 0.02\n",
      "iteration: 207250 loss: 0.0023 lr: 0.02\n",
      "iteration: 207260 loss: 0.0018 lr: 0.02\n",
      "iteration: 207270 loss: 0.0023 lr: 0.02\n",
      "iteration: 207280 loss: 0.0022 lr: 0.02\n",
      "iteration: 207290 loss: 0.0020 lr: 0.02\n",
      "iteration: 207300 loss: 0.0020 lr: 0.02\n",
      "iteration: 207310 loss: 0.0018 lr: 0.02\n",
      "iteration: 207320 loss: 0.0023 lr: 0.02\n",
      "iteration: 207330 loss: 0.0019 lr: 0.02\n",
      "iteration: 207340 loss: 0.0021 lr: 0.02\n",
      "iteration: 207350 loss: 0.0022 lr: 0.02\n",
      "iteration: 207360 loss: 0.0016 lr: 0.02\n",
      "iteration: 207370 loss: 0.0027 lr: 0.02\n",
      "iteration: 207380 loss: 0.0018 lr: 0.02\n",
      "iteration: 207390 loss: 0.0017 lr: 0.02\n",
      "iteration: 207400 loss: 0.0023 lr: 0.02\n",
      "iteration: 207410 loss: 0.0023 lr: 0.02\n",
      "iteration: 207420 loss: 0.0021 lr: 0.02\n",
      "iteration: 207430 loss: 0.0019 lr: 0.02\n",
      "iteration: 207440 loss: 0.0020 lr: 0.02\n",
      "iteration: 207450 loss: 0.0021 lr: 0.02\n",
      "iteration: 207460 loss: 0.0019 lr: 0.02\n",
      "iteration: 207470 loss: 0.0024 lr: 0.02\n",
      "iteration: 207480 loss: 0.0020 lr: 0.02\n",
      "iteration: 207490 loss: 0.0017 lr: 0.02\n",
      "iteration: 207500 loss: 0.0020 lr: 0.02\n",
      "iteration: 207510 loss: 0.0020 lr: 0.02\n",
      "iteration: 207520 loss: 0.0018 lr: 0.02\n",
      "iteration: 207530 loss: 0.0024 lr: 0.02\n",
      "iteration: 207540 loss: 0.0017 lr: 0.02\n",
      "iteration: 207550 loss: 0.0021 lr: 0.02\n",
      "iteration: 207560 loss: 0.0020 lr: 0.02\n",
      "iteration: 207570 loss: 0.0019 lr: 0.02\n",
      "iteration: 207580 loss: 0.0024 lr: 0.02\n",
      "iteration: 207590 loss: 0.0022 lr: 0.02\n",
      "iteration: 207600 loss: 0.0023 lr: 0.02\n",
      "iteration: 207610 loss: 0.0023 lr: 0.02\n",
      "iteration: 207620 loss: 0.0017 lr: 0.02\n",
      "iteration: 207630 loss: 0.0016 lr: 0.02\n",
      "iteration: 207640 loss: 0.0021 lr: 0.02\n",
      "iteration: 207650 loss: 0.0029 lr: 0.02\n",
      "iteration: 207660 loss: 0.0018 lr: 0.02\n",
      "iteration: 207670 loss: 0.0016 lr: 0.02\n",
      "iteration: 207680 loss: 0.0021 lr: 0.02\n",
      "iteration: 207690 loss: 0.0017 lr: 0.02\n",
      "iteration: 207700 loss: 0.0016 lr: 0.02\n",
      "iteration: 207710 loss: 0.0017 lr: 0.02\n",
      "iteration: 207720 loss: 0.0024 lr: 0.02\n",
      "iteration: 207730 loss: 0.0023 lr: 0.02\n",
      "iteration: 207740 loss: 0.0027 lr: 0.02\n",
      "iteration: 207750 loss: 0.0018 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 207760 loss: 0.0022 lr: 0.02\n",
      "iteration: 207770 loss: 0.0016 lr: 0.02\n",
      "iteration: 207780 loss: 0.0024 lr: 0.02\n",
      "iteration: 207790 loss: 0.0015 lr: 0.02\n",
      "iteration: 207800 loss: 0.0021 lr: 0.02\n",
      "iteration: 207810 loss: 0.0018 lr: 0.02\n",
      "iteration: 207820 loss: 0.0021 lr: 0.02\n",
      "iteration: 207830 loss: 0.0021 lr: 0.02\n",
      "iteration: 207840 loss: 0.0021 lr: 0.02\n",
      "iteration: 207850 loss: 0.0018 lr: 0.02\n",
      "iteration: 207860 loss: 0.0021 lr: 0.02\n",
      "iteration: 207870 loss: 0.0018 lr: 0.02\n",
      "iteration: 207880 loss: 0.0021 lr: 0.02\n",
      "iteration: 207890 loss: 0.0015 lr: 0.02\n",
      "iteration: 207900 loss: 0.0013 lr: 0.02\n",
      "iteration: 207910 loss: 0.0017 lr: 0.02\n",
      "iteration: 207920 loss: 0.0020 lr: 0.02\n",
      "iteration: 207930 loss: 0.0019 lr: 0.02\n",
      "iteration: 207940 loss: 0.0014 lr: 0.02\n",
      "iteration: 207950 loss: 0.0016 lr: 0.02\n",
      "iteration: 207960 loss: 0.0018 lr: 0.02\n",
      "iteration: 207970 loss: 0.0021 lr: 0.02\n",
      "iteration: 207980 loss: 0.0019 lr: 0.02\n",
      "iteration: 207990 loss: 0.0025 lr: 0.02\n",
      "iteration: 208000 loss: 0.0025 lr: 0.02\n",
      "iteration: 208010 loss: 0.0026 lr: 0.02\n",
      "iteration: 208020 loss: 0.0017 lr: 0.02\n",
      "iteration: 208030 loss: 0.0019 lr: 0.02\n",
      "iteration: 208040 loss: 0.0021 lr: 0.02\n",
      "iteration: 208050 loss: 0.0022 lr: 0.02\n",
      "iteration: 208060 loss: 0.0025 lr: 0.02\n",
      "iteration: 208070 loss: 0.0019 lr: 0.02\n",
      "iteration: 208080 loss: 0.0023 lr: 0.02\n",
      "iteration: 208090 loss: 0.0020 lr: 0.02\n",
      "iteration: 208100 loss: 0.0019 lr: 0.02\n",
      "iteration: 208110 loss: 0.0019 lr: 0.02\n",
      "iteration: 208120 loss: 0.0025 lr: 0.02\n",
      "iteration: 208130 loss: 0.0016 lr: 0.02\n",
      "iteration: 208140 loss: 0.0018 lr: 0.02\n",
      "iteration: 208150 loss: 0.0016 lr: 0.02\n",
      "iteration: 208160 loss: 0.0022 lr: 0.02\n",
      "iteration: 208170 loss: 0.0015 lr: 0.02\n",
      "iteration: 208180 loss: 0.0019 lr: 0.02\n",
      "iteration: 208190 loss: 0.0019 lr: 0.02\n",
      "iteration: 208200 loss: 0.0016 lr: 0.02\n",
      "iteration: 208210 loss: 0.0019 lr: 0.02\n",
      "iteration: 208220 loss: 0.0025 lr: 0.02\n",
      "iteration: 208230 loss: 0.0022 lr: 0.02\n",
      "iteration: 208240 loss: 0.0018 lr: 0.02\n",
      "iteration: 208250 loss: 0.0017 lr: 0.02\n",
      "iteration: 208260 loss: 0.0022 lr: 0.02\n",
      "iteration: 208270 loss: 0.0022 lr: 0.02\n",
      "iteration: 208280 loss: 0.0017 lr: 0.02\n",
      "iteration: 208290 loss: 0.0022 lr: 0.02\n",
      "iteration: 208300 loss: 0.0018 lr: 0.02\n",
      "iteration: 208310 loss: 0.0024 lr: 0.02\n",
      "iteration: 208320 loss: 0.0018 lr: 0.02\n",
      "iteration: 208330 loss: 0.0016 lr: 0.02\n",
      "iteration: 208340 loss: 0.0021 lr: 0.02\n",
      "iteration: 208350 loss: 0.0017 lr: 0.02\n",
      "iteration: 208360 loss: 0.0016 lr: 0.02\n",
      "iteration: 208370 loss: 0.0016 lr: 0.02\n",
      "iteration: 208380 loss: 0.0024 lr: 0.02\n",
      "iteration: 208390 loss: 0.0015 lr: 0.02\n",
      "iteration: 208400 loss: 0.0021 lr: 0.02\n",
      "iteration: 208410 loss: 0.0017 lr: 0.02\n",
      "iteration: 208420 loss: 0.0020 lr: 0.02\n",
      "iteration: 208430 loss: 0.0014 lr: 0.02\n",
      "iteration: 208440 loss: 0.0020 lr: 0.02\n",
      "iteration: 208450 loss: 0.0017 lr: 0.02\n",
      "iteration: 208460 loss: 0.0022 lr: 0.02\n",
      "iteration: 208470 loss: 0.0020 lr: 0.02\n",
      "iteration: 208480 loss: 0.0013 lr: 0.02\n",
      "iteration: 208490 loss: 0.0022 lr: 0.02\n",
      "iteration: 208500 loss: 0.0023 lr: 0.02\n",
      "iteration: 208510 loss: 0.0019 lr: 0.02\n",
      "iteration: 208520 loss: 0.0016 lr: 0.02\n",
      "iteration: 208530 loss: 0.0013 lr: 0.02\n",
      "iteration: 208540 loss: 0.0017 lr: 0.02\n",
      "iteration: 208550 loss: 0.0018 lr: 0.02\n",
      "iteration: 208560 loss: 0.0017 lr: 0.02\n",
      "iteration: 208570 loss: 0.0017 lr: 0.02\n",
      "iteration: 208580 loss: 0.0015 lr: 0.02\n",
      "iteration: 208590 loss: 0.0018 lr: 0.02\n",
      "iteration: 208600 loss: 0.0020 lr: 0.02\n",
      "iteration: 208610 loss: 0.0022 lr: 0.02\n",
      "iteration: 208620 loss: 0.0016 lr: 0.02\n",
      "iteration: 208630 loss: 0.0024 lr: 0.02\n",
      "iteration: 208640 loss: 0.0016 lr: 0.02\n",
      "iteration: 208650 loss: 0.0025 lr: 0.02\n",
      "iteration: 208660 loss: 0.0017 lr: 0.02\n",
      "iteration: 208670 loss: 0.0026 lr: 0.02\n",
      "iteration: 208680 loss: 0.0024 lr: 0.02\n",
      "iteration: 208690 loss: 0.0027 lr: 0.02\n",
      "iteration: 208700 loss: 0.0018 lr: 0.02\n",
      "iteration: 208710 loss: 0.0023 lr: 0.02\n",
      "iteration: 208720 loss: 0.0031 lr: 0.02\n",
      "iteration: 208730 loss: 0.0022 lr: 0.02\n",
      "iteration: 208740 loss: 0.0021 lr: 0.02\n",
      "iteration: 208750 loss: 0.0022 lr: 0.02\n",
      "iteration: 208760 loss: 0.0018 lr: 0.02\n",
      "iteration: 208770 loss: 0.0017 lr: 0.02\n",
      "iteration: 208780 loss: 0.0017 lr: 0.02\n",
      "iteration: 208790 loss: 0.0022 lr: 0.02\n",
      "iteration: 208800 loss: 0.0021 lr: 0.02\n",
      "iteration: 208810 loss: 0.0015 lr: 0.02\n",
      "iteration: 208820 loss: 0.0023 lr: 0.02\n",
      "iteration: 208830 loss: 0.0024 lr: 0.02\n",
      "iteration: 208840 loss: 0.0019 lr: 0.02\n",
      "iteration: 208850 loss: 0.0015 lr: 0.02\n",
      "iteration: 208860 loss: 0.0021 lr: 0.02\n",
      "iteration: 208870 loss: 0.0021 lr: 0.02\n",
      "iteration: 208880 loss: 0.0031 lr: 0.02\n",
      "iteration: 208890 loss: 0.0017 lr: 0.02\n",
      "iteration: 208900 loss: 0.0017 lr: 0.02\n",
      "iteration: 208910 loss: 0.0024 lr: 0.02\n",
      "iteration: 208920 loss: 0.0017 lr: 0.02\n",
      "iteration: 208930 loss: 0.0024 lr: 0.02\n",
      "iteration: 208940 loss: 0.0015 lr: 0.02\n",
      "iteration: 208950 loss: 0.0014 lr: 0.02\n",
      "iteration: 208960 loss: 0.0020 lr: 0.02\n",
      "iteration: 208970 loss: 0.0021 lr: 0.02\n",
      "iteration: 208980 loss: 0.0016 lr: 0.02\n",
      "iteration: 208990 loss: 0.0025 lr: 0.02\n",
      "iteration: 209000 loss: 0.0018 lr: 0.02\n",
      "iteration: 209010 loss: 0.0022 lr: 0.02\n",
      "iteration: 209020 loss: 0.0022 lr: 0.02\n",
      "iteration: 209030 loss: 0.0017 lr: 0.02\n",
      "iteration: 209040 loss: 0.0020 lr: 0.02\n",
      "iteration: 209050 loss: 0.0018 lr: 0.02\n",
      "iteration: 209060 loss: 0.0022 lr: 0.02\n",
      "iteration: 209070 loss: 0.0023 lr: 0.02\n",
      "iteration: 209080 loss: 0.0016 lr: 0.02\n",
      "iteration: 209090 loss: 0.0018 lr: 0.02\n",
      "iteration: 209100 loss: 0.0019 lr: 0.02\n",
      "iteration: 209110 loss: 0.0021 lr: 0.02\n",
      "iteration: 209120 loss: 0.0022 lr: 0.02\n",
      "iteration: 209130 loss: 0.0024 lr: 0.02\n",
      "iteration: 209140 loss: 0.0025 lr: 0.02\n",
      "iteration: 209150 loss: 0.0024 lr: 0.02\n",
      "iteration: 209160 loss: 0.0016 lr: 0.02\n",
      "iteration: 209170 loss: 0.0021 lr: 0.02\n",
      "iteration: 209180 loss: 0.0021 lr: 0.02\n",
      "iteration: 209190 loss: 0.0018 lr: 0.02\n",
      "iteration: 209200 loss: 0.0020 lr: 0.02\n",
      "iteration: 209210 loss: 0.0016 lr: 0.02\n",
      "iteration: 209220 loss: 0.0018 lr: 0.02\n",
      "iteration: 209230 loss: 0.0021 lr: 0.02\n",
      "iteration: 209240 loss: 0.0020 lr: 0.02\n",
      "iteration: 209250 loss: 0.0022 lr: 0.02\n",
      "iteration: 209260 loss: 0.0019 lr: 0.02\n",
      "iteration: 209270 loss: 0.0026 lr: 0.02\n",
      "iteration: 209280 loss: 0.0027 lr: 0.02\n",
      "iteration: 209290 loss: 0.0016 lr: 0.02\n",
      "iteration: 209300 loss: 0.0026 lr: 0.02\n",
      "iteration: 209310 loss: 0.0017 lr: 0.02\n",
      "iteration: 209320 loss: 0.0026 lr: 0.02\n",
      "iteration: 209330 loss: 0.0022 lr: 0.02\n",
      "iteration: 209340 loss: 0.0020 lr: 0.02\n",
      "iteration: 209350 loss: 0.0023 lr: 0.02\n",
      "iteration: 209360 loss: 0.0019 lr: 0.02\n",
      "iteration: 209370 loss: 0.0015 lr: 0.02\n",
      "iteration: 209380 loss: 0.0022 lr: 0.02\n",
      "iteration: 209390 loss: 0.0019 lr: 0.02\n",
      "iteration: 209400 loss: 0.0018 lr: 0.02\n",
      "iteration: 209410 loss: 0.0022 lr: 0.02\n",
      "iteration: 209420 loss: 0.0020 lr: 0.02\n",
      "iteration: 209430 loss: 0.0018 lr: 0.02\n",
      "iteration: 209440 loss: 0.0022 lr: 0.02\n",
      "iteration: 209450 loss: 0.0017 lr: 0.02\n",
      "iteration: 209460 loss: 0.0017 lr: 0.02\n",
      "iteration: 209470 loss: 0.0018 lr: 0.02\n",
      "iteration: 209480 loss: 0.0018 lr: 0.02\n",
      "iteration: 209490 loss: 0.0020 lr: 0.02\n",
      "iteration: 209500 loss: 0.0019 lr: 0.02\n",
      "iteration: 209510 loss: 0.0018 lr: 0.02\n",
      "iteration: 209520 loss: 0.0021 lr: 0.02\n",
      "iteration: 209530 loss: 0.0018 lr: 0.02\n",
      "iteration: 209540 loss: 0.0020 lr: 0.02\n",
      "iteration: 209550 loss: 0.0020 lr: 0.02\n",
      "iteration: 209560 loss: 0.0012 lr: 0.02\n",
      "iteration: 209570 loss: 0.0022 lr: 0.02\n",
      "iteration: 209580 loss: 0.0026 lr: 0.02\n",
      "iteration: 209590 loss: 0.0019 lr: 0.02\n",
      "iteration: 209600 loss: 0.0019 lr: 0.02\n",
      "iteration: 209610 loss: 0.0019 lr: 0.02\n",
      "iteration: 209620 loss: 0.0020 lr: 0.02\n",
      "iteration: 209630 loss: 0.0020 lr: 0.02\n",
      "iteration: 209640 loss: 0.0025 lr: 0.02\n",
      "iteration: 209650 loss: 0.0020 lr: 0.02\n",
      "iteration: 209660 loss: 0.0017 lr: 0.02\n",
      "iteration: 209670 loss: 0.0020 lr: 0.02\n",
      "iteration: 209680 loss: 0.0020 lr: 0.02\n",
      "iteration: 209690 loss: 0.0019 lr: 0.02\n",
      "iteration: 209700 loss: 0.0020 lr: 0.02\n",
      "iteration: 209710 loss: 0.0018 lr: 0.02\n",
      "iteration: 209720 loss: 0.0018 lr: 0.02\n",
      "iteration: 209730 loss: 0.0020 lr: 0.02\n",
      "iteration: 209740 loss: 0.0016 lr: 0.02\n",
      "iteration: 209750 loss: 0.0022 lr: 0.02\n",
      "iteration: 209760 loss: 0.0016 lr: 0.02\n",
      "iteration: 209770 loss: 0.0016 lr: 0.02\n",
      "iteration: 209780 loss: 0.0017 lr: 0.02\n",
      "iteration: 209790 loss: 0.0019 lr: 0.02\n",
      "iteration: 209800 loss: 0.0022 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 209810 loss: 0.0023 lr: 0.02\n",
      "iteration: 209820 loss: 0.0020 lr: 0.02\n",
      "iteration: 209830 loss: 0.0022 lr: 0.02\n",
      "iteration: 209840 loss: 0.0018 lr: 0.02\n",
      "iteration: 209850 loss: 0.0017 lr: 0.02\n",
      "iteration: 209860 loss: 0.0019 lr: 0.02\n",
      "iteration: 209870 loss: 0.0025 lr: 0.02\n",
      "iteration: 209880 loss: 0.0023 lr: 0.02\n",
      "iteration: 209890 loss: 0.0017 lr: 0.02\n",
      "iteration: 209900 loss: 0.0020 lr: 0.02\n",
      "iteration: 209910 loss: 0.0018 lr: 0.02\n",
      "iteration: 209920 loss: 0.0019 lr: 0.02\n",
      "iteration: 209930 loss: 0.0020 lr: 0.02\n",
      "iteration: 209940 loss: 0.0017 lr: 0.02\n",
      "iteration: 209950 loss: 0.0014 lr: 0.02\n",
      "iteration: 209960 loss: 0.0023 lr: 0.02\n",
      "iteration: 209970 loss: 0.0027 lr: 0.02\n",
      "iteration: 209980 loss: 0.0024 lr: 0.02\n",
      "iteration: 209990 loss: 0.0014 lr: 0.02\n",
      "iteration: 210000 loss: 0.0016 lr: 0.02\n",
      "iteration: 210010 loss: 0.0016 lr: 0.02\n",
      "iteration: 210020 loss: 0.0025 lr: 0.02\n",
      "iteration: 210030 loss: 0.0021 lr: 0.02\n",
      "iteration: 210040 loss: 0.0018 lr: 0.02\n",
      "iteration: 210050 loss: 0.0016 lr: 0.02\n",
      "iteration: 210060 loss: 0.0018 lr: 0.02\n",
      "iteration: 210070 loss: 0.0021 lr: 0.02\n",
      "iteration: 210080 loss: 0.0022 lr: 0.02\n",
      "iteration: 210090 loss: 0.0018 lr: 0.02\n",
      "iteration: 210100 loss: 0.0021 lr: 0.02\n",
      "iteration: 210110 loss: 0.0018 lr: 0.02\n",
      "iteration: 210120 loss: 0.0013 lr: 0.02\n",
      "iteration: 210130 loss: 0.0022 lr: 0.02\n",
      "iteration: 210140 loss: 0.0018 lr: 0.02\n",
      "iteration: 210150 loss: 0.0017 lr: 0.02\n",
      "iteration: 210160 loss: 0.0028 lr: 0.02\n",
      "iteration: 210170 loss: 0.0015 lr: 0.02\n",
      "iteration: 210180 loss: 0.0023 lr: 0.02\n",
      "iteration: 210190 loss: 0.0021 lr: 0.02\n",
      "iteration: 210200 loss: 0.0017 lr: 0.02\n",
      "iteration: 210210 loss: 0.0017 lr: 0.02\n",
      "iteration: 210220 loss: 0.0023 lr: 0.02\n",
      "iteration: 210230 loss: 0.0021 lr: 0.02\n",
      "iteration: 210240 loss: 0.0019 lr: 0.02\n",
      "iteration: 210250 loss: 0.0030 lr: 0.02\n",
      "iteration: 210260 loss: 0.0019 lr: 0.02\n",
      "iteration: 210270 loss: 0.0027 lr: 0.02\n",
      "iteration: 210280 loss: 0.0015 lr: 0.02\n",
      "iteration: 210290 loss: 0.0019 lr: 0.02\n",
      "iteration: 210300 loss: 0.0018 lr: 0.02\n",
      "iteration: 210310 loss: 0.0018 lr: 0.02\n",
      "iteration: 210320 loss: 0.0024 lr: 0.02\n",
      "iteration: 210330 loss: 0.0023 lr: 0.02\n",
      "iteration: 210340 loss: 0.0020 lr: 0.02\n",
      "iteration: 210350 loss: 0.0018 lr: 0.02\n",
      "iteration: 210360 loss: 0.0018 lr: 0.02\n",
      "iteration: 210370 loss: 0.0016 lr: 0.02\n",
      "iteration: 210380 loss: 0.0018 lr: 0.02\n",
      "iteration: 210390 loss: 0.0017 lr: 0.02\n",
      "iteration: 210400 loss: 0.0020 lr: 0.02\n",
      "iteration: 210410 loss: 0.0020 lr: 0.02\n",
      "iteration: 210420 loss: 0.0022 lr: 0.02\n",
      "iteration: 210430 loss: 0.0022 lr: 0.02\n",
      "iteration: 210440 loss: 0.0023 lr: 0.02\n",
      "iteration: 210450 loss: 0.0023 lr: 0.02\n",
      "iteration: 210460 loss: 0.0020 lr: 0.02\n",
      "iteration: 210470 loss: 0.0017 lr: 0.02\n",
      "iteration: 210480 loss: 0.0023 lr: 0.02\n",
      "iteration: 210490 loss: 0.0016 lr: 0.02\n",
      "iteration: 210500 loss: 0.0016 lr: 0.02\n",
      "iteration: 210510 loss: 0.0017 lr: 0.02\n",
      "iteration: 210520 loss: 0.0021 lr: 0.02\n",
      "iteration: 210530 loss: 0.0019 lr: 0.02\n",
      "iteration: 210540 loss: 0.0021 lr: 0.02\n",
      "iteration: 210550 loss: 0.0018 lr: 0.02\n",
      "iteration: 210560 loss: 0.0019 lr: 0.02\n",
      "iteration: 210570 loss: 0.0019 lr: 0.02\n",
      "iteration: 210580 loss: 0.0016 lr: 0.02\n",
      "iteration: 210590 loss: 0.0019 lr: 0.02\n",
      "iteration: 210600 loss: 0.0017 lr: 0.02\n",
      "iteration: 210610 loss: 0.0020 lr: 0.02\n",
      "iteration: 210620 loss: 0.0020 lr: 0.02\n",
      "iteration: 210630 loss: 0.0018 lr: 0.02\n",
      "iteration: 210640 loss: 0.0015 lr: 0.02\n",
      "iteration: 210650 loss: 0.0019 lr: 0.02\n",
      "iteration: 210660 loss: 0.0017 lr: 0.02\n",
      "iteration: 210670 loss: 0.0016 lr: 0.02\n",
      "iteration: 210680 loss: 0.0021 lr: 0.02\n",
      "iteration: 210690 loss: 0.0020 lr: 0.02\n",
      "iteration: 210700 loss: 0.0017 lr: 0.02\n",
      "iteration: 210710 loss: 0.0021 lr: 0.02\n",
      "iteration: 210720 loss: 0.0014 lr: 0.02\n",
      "iteration: 210730 loss: 0.0017 lr: 0.02\n",
      "iteration: 210740 loss: 0.0016 lr: 0.02\n",
      "iteration: 210750 loss: 0.0018 lr: 0.02\n",
      "iteration: 210760 loss: 0.0019 lr: 0.02\n",
      "iteration: 210770 loss: 0.0021 lr: 0.02\n",
      "iteration: 210780 loss: 0.0016 lr: 0.02\n",
      "iteration: 210790 loss: 0.0019 lr: 0.02\n",
      "iteration: 210800 loss: 0.0017 lr: 0.02\n",
      "iteration: 210810 loss: 0.0029 lr: 0.02\n",
      "iteration: 210820 loss: 0.0022 lr: 0.02\n",
      "iteration: 210830 loss: 0.0016 lr: 0.02\n",
      "iteration: 210840 loss: 0.0021 lr: 0.02\n",
      "iteration: 210850 loss: 0.0025 lr: 0.02\n",
      "iteration: 210860 loss: 0.0016 lr: 0.02\n",
      "iteration: 210870 loss: 0.0019 lr: 0.02\n",
      "iteration: 210880 loss: 0.0018 lr: 0.02\n",
      "iteration: 210890 loss: 0.0022 lr: 0.02\n",
      "iteration: 210900 loss: 0.0017 lr: 0.02\n",
      "iteration: 210910 loss: 0.0019 lr: 0.02\n",
      "iteration: 210920 loss: 0.0017 lr: 0.02\n",
      "iteration: 210930 loss: 0.0019 lr: 0.02\n",
      "iteration: 210940 loss: 0.0026 lr: 0.02\n",
      "iteration: 210950 loss: 0.0021 lr: 0.02\n",
      "iteration: 210960 loss: 0.0015 lr: 0.02\n",
      "iteration: 210970 loss: 0.0023 lr: 0.02\n",
      "iteration: 210980 loss: 0.0021 lr: 0.02\n",
      "iteration: 210990 loss: 0.0019 lr: 0.02\n",
      "iteration: 211000 loss: 0.0015 lr: 0.02\n",
      "iteration: 211010 loss: 0.0025 lr: 0.02\n",
      "iteration: 211020 loss: 0.0022 lr: 0.02\n",
      "iteration: 211030 loss: 0.0017 lr: 0.02\n",
      "iteration: 211040 loss: 0.0021 lr: 0.02\n",
      "iteration: 211050 loss: 0.0017 lr: 0.02\n",
      "iteration: 211060 loss: 0.0020 lr: 0.02\n",
      "iteration: 211070 loss: 0.0017 lr: 0.02\n",
      "iteration: 211080 loss: 0.0014 lr: 0.02\n",
      "iteration: 211090 loss: 0.0022 lr: 0.02\n",
      "iteration: 211100 loss: 0.0022 lr: 0.02\n",
      "iteration: 211110 loss: 0.0019 lr: 0.02\n",
      "iteration: 211120 loss: 0.0016 lr: 0.02\n",
      "iteration: 211130 loss: 0.0015 lr: 0.02\n",
      "iteration: 211140 loss: 0.0019 lr: 0.02\n",
      "iteration: 211150 loss: 0.0016 lr: 0.02\n",
      "iteration: 211160 loss: 0.0020 lr: 0.02\n",
      "iteration: 211170 loss: 0.0017 lr: 0.02\n",
      "iteration: 211180 loss: 0.0019 lr: 0.02\n",
      "iteration: 211190 loss: 0.0016 lr: 0.02\n",
      "iteration: 211200 loss: 0.0022 lr: 0.02\n",
      "iteration: 211210 loss: 0.0024 lr: 0.02\n",
      "iteration: 211220 loss: 0.0022 lr: 0.02\n",
      "iteration: 211230 loss: 0.0021 lr: 0.02\n",
      "iteration: 211240 loss: 0.0020 lr: 0.02\n",
      "iteration: 211250 loss: 0.0020 lr: 0.02\n",
      "iteration: 211260 loss: 0.0016 lr: 0.02\n",
      "iteration: 211270 loss: 0.0017 lr: 0.02\n",
      "iteration: 211280 loss: 0.0021 lr: 0.02\n",
      "iteration: 211290 loss: 0.0021 lr: 0.02\n",
      "iteration: 211300 loss: 0.0021 lr: 0.02\n",
      "iteration: 211310 loss: 0.0020 lr: 0.02\n",
      "iteration: 211320 loss: 0.0015 lr: 0.02\n",
      "iteration: 211330 loss: 0.0022 lr: 0.02\n",
      "iteration: 211340 loss: 0.0023 lr: 0.02\n",
      "iteration: 211350 loss: 0.0018 lr: 0.02\n",
      "iteration: 211360 loss: 0.0019 lr: 0.02\n",
      "iteration: 211370 loss: 0.0020 lr: 0.02\n",
      "iteration: 211380 loss: 0.0020 lr: 0.02\n",
      "iteration: 211390 loss: 0.0019 lr: 0.02\n",
      "iteration: 211400 loss: 0.0018 lr: 0.02\n",
      "iteration: 211410 loss: 0.0018 lr: 0.02\n",
      "iteration: 211420 loss: 0.0021 lr: 0.02\n",
      "iteration: 211430 loss: 0.0022 lr: 0.02\n",
      "iteration: 211440 loss: 0.0023 lr: 0.02\n",
      "iteration: 211450 loss: 0.0023 lr: 0.02\n",
      "iteration: 211460 loss: 0.0023 lr: 0.02\n",
      "iteration: 211470 loss: 0.0022 lr: 0.02\n",
      "iteration: 211480 loss: 0.0020 lr: 0.02\n",
      "iteration: 211490 loss: 0.0023 lr: 0.02\n",
      "iteration: 211500 loss: 0.0016 lr: 0.02\n",
      "iteration: 211510 loss: 0.0019 lr: 0.02\n",
      "iteration: 211520 loss: 0.0020 lr: 0.02\n",
      "iteration: 211530 loss: 0.0019 lr: 0.02\n",
      "iteration: 211540 loss: 0.0025 lr: 0.02\n",
      "iteration: 211550 loss: 0.0020 lr: 0.02\n",
      "iteration: 211560 loss: 0.0020 lr: 0.02\n",
      "iteration: 211570 loss: 0.0018 lr: 0.02\n",
      "iteration: 211580 loss: 0.0020 lr: 0.02\n",
      "iteration: 211590 loss: 0.0020 lr: 0.02\n",
      "iteration: 211600 loss: 0.0023 lr: 0.02\n",
      "iteration: 211610 loss: 0.0023 lr: 0.02\n",
      "iteration: 211620 loss: 0.0020 lr: 0.02\n",
      "iteration: 211630 loss: 0.0019 lr: 0.02\n",
      "iteration: 211640 loss: 0.0021 lr: 0.02\n",
      "iteration: 211650 loss: 0.0015 lr: 0.02\n",
      "iteration: 211660 loss: 0.0029 lr: 0.02\n",
      "iteration: 211670 loss: 0.0024 lr: 0.02\n",
      "iteration: 211680 loss: 0.0020 lr: 0.02\n",
      "iteration: 211690 loss: 0.0018 lr: 0.02\n",
      "iteration: 211700 loss: 0.0018 lr: 0.02\n",
      "iteration: 211710 loss: 0.0023 lr: 0.02\n",
      "iteration: 211720 loss: 0.0017 lr: 0.02\n",
      "iteration: 211730 loss: 0.0013 lr: 0.02\n",
      "iteration: 211740 loss: 0.0024 lr: 0.02\n",
      "iteration: 211750 loss: 0.0016 lr: 0.02\n",
      "iteration: 211760 loss: 0.0020 lr: 0.02\n",
      "iteration: 211770 loss: 0.0026 lr: 0.02\n",
      "iteration: 211780 loss: 0.0026 lr: 0.02\n",
      "iteration: 211790 loss: 0.0021 lr: 0.02\n",
      "iteration: 211800 loss: 0.0014 lr: 0.02\n",
      "iteration: 211810 loss: 0.0018 lr: 0.02\n",
      "iteration: 211820 loss: 0.0019 lr: 0.02\n",
      "iteration: 211830 loss: 0.0016 lr: 0.02\n",
      "iteration: 211840 loss: 0.0021 lr: 0.02\n",
      "iteration: 211850 loss: 0.0018 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 211860 loss: 0.0018 lr: 0.02\n",
      "iteration: 211870 loss: 0.0026 lr: 0.02\n",
      "iteration: 211880 loss: 0.0018 lr: 0.02\n",
      "iteration: 211890 loss: 0.0019 lr: 0.02\n",
      "iteration: 211900 loss: 0.0016 lr: 0.02\n",
      "iteration: 211910 loss: 0.0015 lr: 0.02\n",
      "iteration: 211920 loss: 0.0015 lr: 0.02\n",
      "iteration: 211930 loss: 0.0021 lr: 0.02\n",
      "iteration: 211940 loss: 0.0018 lr: 0.02\n",
      "iteration: 211950 loss: 0.0026 lr: 0.02\n",
      "iteration: 211960 loss: 0.0017 lr: 0.02\n",
      "iteration: 211970 loss: 0.0015 lr: 0.02\n",
      "iteration: 211980 loss: 0.0021 lr: 0.02\n",
      "iteration: 211990 loss: 0.0016 lr: 0.02\n",
      "iteration: 212000 loss: 0.0015 lr: 0.02\n",
      "iteration: 212010 loss: 0.0017 lr: 0.02\n",
      "iteration: 212020 loss: 0.0021 lr: 0.02\n",
      "iteration: 212030 loss: 0.0011 lr: 0.02\n",
      "iteration: 212040 loss: 0.0020 lr: 0.02\n",
      "iteration: 212050 loss: 0.0016 lr: 0.02\n",
      "iteration: 212060 loss: 0.0016 lr: 0.02\n",
      "iteration: 212070 loss: 0.0021 lr: 0.02\n",
      "iteration: 212080 loss: 0.0022 lr: 0.02\n",
      "iteration: 212090 loss: 0.0018 lr: 0.02\n",
      "iteration: 212100 loss: 0.0023 lr: 0.02\n",
      "iteration: 212110 loss: 0.0019 lr: 0.02\n",
      "iteration: 212120 loss: 0.0015 lr: 0.02\n",
      "iteration: 212130 loss: 0.0018 lr: 0.02\n",
      "iteration: 212140 loss: 0.0019 lr: 0.02\n",
      "iteration: 212150 loss: 0.0020 lr: 0.02\n",
      "iteration: 212160 loss: 0.0017 lr: 0.02\n",
      "iteration: 212170 loss: 0.0017 lr: 0.02\n",
      "iteration: 212180 loss: 0.0015 lr: 0.02\n",
      "iteration: 212190 loss: 0.0017 lr: 0.02\n",
      "iteration: 212200 loss: 0.0016 lr: 0.02\n",
      "iteration: 212210 loss: 0.0022 lr: 0.02\n",
      "iteration: 212220 loss: 0.0023 lr: 0.02\n",
      "iteration: 212230 loss: 0.0019 lr: 0.02\n",
      "iteration: 212240 loss: 0.0015 lr: 0.02\n",
      "iteration: 212250 loss: 0.0023 lr: 0.02\n",
      "iteration: 212260 loss: 0.0015 lr: 0.02\n",
      "iteration: 212270 loss: 0.0019 lr: 0.02\n",
      "iteration: 212280 loss: 0.0018 lr: 0.02\n",
      "iteration: 212290 loss: 0.0018 lr: 0.02\n",
      "iteration: 212300 loss: 0.0021 lr: 0.02\n",
      "iteration: 212310 loss: 0.0020 lr: 0.02\n",
      "iteration: 212320 loss: 0.0026 lr: 0.02\n",
      "iteration: 212330 loss: 0.0021 lr: 0.02\n",
      "iteration: 212340 loss: 0.0019 lr: 0.02\n",
      "iteration: 212350 loss: 0.0013 lr: 0.02\n",
      "iteration: 212360 loss: 0.0021 lr: 0.02\n",
      "iteration: 212370 loss: 0.0017 lr: 0.02\n",
      "iteration: 212380 loss: 0.0014 lr: 0.02\n",
      "iteration: 212390 loss: 0.0015 lr: 0.02\n",
      "iteration: 212400 loss: 0.0018 lr: 0.02\n",
      "iteration: 212410 loss: 0.0025 lr: 0.02\n",
      "iteration: 212420 loss: 0.0014 lr: 0.02\n",
      "iteration: 212430 loss: 0.0020 lr: 0.02\n",
      "iteration: 212440 loss: 0.0018 lr: 0.02\n",
      "iteration: 212450 loss: 0.0018 lr: 0.02\n",
      "iteration: 212460 loss: 0.0013 lr: 0.02\n",
      "iteration: 212470 loss: 0.0021 lr: 0.02\n",
      "iteration: 212480 loss: 0.0018 lr: 0.02\n",
      "iteration: 212490 loss: 0.0013 lr: 0.02\n",
      "iteration: 212500 loss: 0.0028 lr: 0.02\n",
      "iteration: 212510 loss: 0.0019 lr: 0.02\n",
      "iteration: 212520 loss: 0.0021 lr: 0.02\n",
      "iteration: 212530 loss: 0.0019 lr: 0.02\n",
      "iteration: 212540 loss: 0.0020 lr: 0.02\n",
      "iteration: 212550 loss: 0.0020 lr: 0.02\n",
      "iteration: 212560 loss: 0.0018 lr: 0.02\n",
      "iteration: 212570 loss: 0.0020 lr: 0.02\n",
      "iteration: 212580 loss: 0.0014 lr: 0.02\n",
      "iteration: 212590 loss: 0.0019 lr: 0.02\n",
      "iteration: 212600 loss: 0.0018 lr: 0.02\n",
      "iteration: 212610 loss: 0.0016 lr: 0.02\n",
      "iteration: 212620 loss: 0.0019 lr: 0.02\n",
      "iteration: 212630 loss: 0.0017 lr: 0.02\n",
      "iteration: 212640 loss: 0.0016 lr: 0.02\n",
      "iteration: 212650 loss: 0.0021 lr: 0.02\n",
      "iteration: 212660 loss: 0.0014 lr: 0.02\n",
      "iteration: 212670 loss: 0.0017 lr: 0.02\n",
      "iteration: 212680 loss: 0.0017 lr: 0.02\n",
      "iteration: 212690 loss: 0.0019 lr: 0.02\n",
      "iteration: 212700 loss: 0.0022 lr: 0.02\n",
      "iteration: 212710 loss: 0.0019 lr: 0.02\n",
      "iteration: 212720 loss: 0.0017 lr: 0.02\n",
      "iteration: 212730 loss: 0.0016 lr: 0.02\n",
      "iteration: 212740 loss: 0.0020 lr: 0.02\n",
      "iteration: 212750 loss: 0.0024 lr: 0.02\n",
      "iteration: 212760 loss: 0.0018 lr: 0.02\n",
      "iteration: 212770 loss: 0.0020 lr: 0.02\n",
      "iteration: 212780 loss: 0.0019 lr: 0.02\n",
      "iteration: 212790 loss: 0.0020 lr: 0.02\n",
      "iteration: 212800 loss: 0.0016 lr: 0.02\n",
      "iteration: 212810 loss: 0.0018 lr: 0.02\n",
      "iteration: 212820 loss: 0.0019 lr: 0.02\n",
      "iteration: 212830 loss: 0.0025 lr: 0.02\n",
      "iteration: 212840 loss: 0.0028 lr: 0.02\n",
      "iteration: 212850 loss: 0.0021 lr: 0.02\n",
      "iteration: 212860 loss: 0.0018 lr: 0.02\n",
      "iteration: 212870 loss: 0.0020 lr: 0.02\n",
      "iteration: 212880 loss: 0.0016 lr: 0.02\n",
      "iteration: 212890 loss: 0.0018 lr: 0.02\n",
      "iteration: 212900 loss: 0.0017 lr: 0.02\n",
      "iteration: 212910 loss: 0.0030 lr: 0.02\n",
      "iteration: 212920 loss: 0.0022 lr: 0.02\n",
      "iteration: 212930 loss: 0.0020 lr: 0.02\n",
      "iteration: 212940 loss: 0.0022 lr: 0.02\n",
      "iteration: 212950 loss: 0.0017 lr: 0.02\n",
      "iteration: 212960 loss: 0.0018 lr: 0.02\n",
      "iteration: 212970 loss: 0.0017 lr: 0.02\n",
      "iteration: 212980 loss: 0.0023 lr: 0.02\n",
      "iteration: 212990 loss: 0.0021 lr: 0.02\n",
      "iteration: 213000 loss: 0.0016 lr: 0.02\n",
      "iteration: 213010 loss: 0.0015 lr: 0.02\n",
      "iteration: 213020 loss: 0.0020 lr: 0.02\n",
      "iteration: 213030 loss: 0.0017 lr: 0.02\n",
      "iteration: 213040 loss: 0.0023 lr: 0.02\n",
      "iteration: 213050 loss: 0.0016 lr: 0.02\n",
      "iteration: 213060 loss: 0.0019 lr: 0.02\n",
      "iteration: 213070 loss: 0.0018 lr: 0.02\n",
      "iteration: 213080 loss: 0.0019 lr: 0.02\n",
      "iteration: 213090 loss: 0.0023 lr: 0.02\n",
      "iteration: 213100 loss: 0.0016 lr: 0.02\n",
      "iteration: 213110 loss: 0.0015 lr: 0.02\n",
      "iteration: 213120 loss: 0.0018 lr: 0.02\n",
      "iteration: 213130 loss: 0.0021 lr: 0.02\n",
      "iteration: 213140 loss: 0.0016 lr: 0.02\n",
      "iteration: 213150 loss: 0.0025 lr: 0.02\n",
      "iteration: 213160 loss: 0.0023 lr: 0.02\n",
      "iteration: 213170 loss: 0.0017 lr: 0.02\n",
      "iteration: 213180 loss: 0.0017 lr: 0.02\n",
      "iteration: 213190 loss: 0.0017 lr: 0.02\n",
      "iteration: 213200 loss: 0.0021 lr: 0.02\n",
      "iteration: 213210 loss: 0.0019 lr: 0.02\n",
      "iteration: 213220 loss: 0.0018 lr: 0.02\n",
      "iteration: 213230 loss: 0.0018 lr: 0.02\n",
      "iteration: 213240 loss: 0.0019 lr: 0.02\n",
      "iteration: 213250 loss: 0.0022 lr: 0.02\n",
      "iteration: 213260 loss: 0.0020 lr: 0.02\n",
      "iteration: 213270 loss: 0.0022 lr: 0.02\n",
      "iteration: 213280 loss: 0.0017 lr: 0.02\n",
      "iteration: 213290 loss: 0.0022 lr: 0.02\n",
      "iteration: 213300 loss: 0.0022 lr: 0.02\n",
      "iteration: 213310 loss: 0.0021 lr: 0.02\n",
      "iteration: 213320 loss: 0.0020 lr: 0.02\n",
      "iteration: 213330 loss: 0.0021 lr: 0.02\n",
      "iteration: 213340 loss: 0.0020 lr: 0.02\n",
      "iteration: 213350 loss: 0.0023 lr: 0.02\n",
      "iteration: 213360 loss: 0.0019 lr: 0.02\n",
      "iteration: 213370 loss: 0.0021 lr: 0.02\n",
      "iteration: 213380 loss: 0.0020 lr: 0.02\n",
      "iteration: 213390 loss: 0.0017 lr: 0.02\n",
      "iteration: 213400 loss: 0.0021 lr: 0.02\n",
      "iteration: 213410 loss: 0.0020 lr: 0.02\n",
      "iteration: 213420 loss: 0.0025 lr: 0.02\n",
      "iteration: 213430 loss: 0.0019 lr: 0.02\n",
      "iteration: 213440 loss: 0.0019 lr: 0.02\n",
      "iteration: 213450 loss: 0.0018 lr: 0.02\n",
      "iteration: 213460 loss: 0.0019 lr: 0.02\n",
      "iteration: 213470 loss: 0.0023 lr: 0.02\n",
      "iteration: 213480 loss: 0.0023 lr: 0.02\n",
      "iteration: 213490 loss: 0.0019 lr: 0.02\n",
      "iteration: 213500 loss: 0.0022 lr: 0.02\n",
      "iteration: 213510 loss: 0.0017 lr: 0.02\n",
      "iteration: 213520 loss: 0.0020 lr: 0.02\n",
      "iteration: 213530 loss: 0.0021 lr: 0.02\n",
      "iteration: 213540 loss: 0.0023 lr: 0.02\n",
      "iteration: 213550 loss: 0.0015 lr: 0.02\n",
      "iteration: 213560 loss: 0.0018 lr: 0.02\n",
      "iteration: 213570 loss: 0.0022 lr: 0.02\n",
      "iteration: 213580 loss: 0.0018 lr: 0.02\n",
      "iteration: 213590 loss: 0.0019 lr: 0.02\n",
      "iteration: 213600 loss: 0.0015 lr: 0.02\n",
      "iteration: 213610 loss: 0.0018 lr: 0.02\n",
      "iteration: 213620 loss: 0.0017 lr: 0.02\n",
      "iteration: 213630 loss: 0.0021 lr: 0.02\n",
      "iteration: 213640 loss: 0.0017 lr: 0.02\n",
      "iteration: 213650 loss: 0.0020 lr: 0.02\n",
      "iteration: 213660 loss: 0.0023 lr: 0.02\n",
      "iteration: 213670 loss: 0.0014 lr: 0.02\n",
      "iteration: 213680 loss: 0.0022 lr: 0.02\n",
      "iteration: 213690 loss: 0.0024 lr: 0.02\n",
      "iteration: 213700 loss: 0.0021 lr: 0.02\n",
      "iteration: 213710 loss: 0.0018 lr: 0.02\n",
      "iteration: 213720 loss: 0.0020 lr: 0.02\n",
      "iteration: 213730 loss: 0.0013 lr: 0.02\n",
      "iteration: 213740 loss: 0.0019 lr: 0.02\n",
      "iteration: 213750 loss: 0.0019 lr: 0.02\n",
      "iteration: 213760 loss: 0.0021 lr: 0.02\n",
      "iteration: 213770 loss: 0.0020 lr: 0.02\n",
      "iteration: 213780 loss: 0.0019 lr: 0.02\n",
      "iteration: 213790 loss: 0.0025 lr: 0.02\n",
      "iteration: 213800 loss: 0.0017 lr: 0.02\n",
      "iteration: 213810 loss: 0.0018 lr: 0.02\n",
      "iteration: 213820 loss: 0.0015 lr: 0.02\n",
      "iteration: 213830 loss: 0.0025 lr: 0.02\n",
      "iteration: 213840 loss: 0.0018 lr: 0.02\n",
      "iteration: 213850 loss: 0.0022 lr: 0.02\n",
      "iteration: 213860 loss: 0.0022 lr: 0.02\n",
      "iteration: 213870 loss: 0.0024 lr: 0.02\n",
      "iteration: 213880 loss: 0.0021 lr: 0.02\n",
      "iteration: 213890 loss: 0.0016 lr: 0.02\n",
      "iteration: 213900 loss: 0.0018 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 213910 loss: 0.0015 lr: 0.02\n",
      "iteration: 213920 loss: 0.0021 lr: 0.02\n",
      "iteration: 213930 loss: 0.0018 lr: 0.02\n",
      "iteration: 213940 loss: 0.0018 lr: 0.02\n",
      "iteration: 213950 loss: 0.0018 lr: 0.02\n",
      "iteration: 213960 loss: 0.0023 lr: 0.02\n",
      "iteration: 213970 loss: 0.0020 lr: 0.02\n",
      "iteration: 213980 loss: 0.0017 lr: 0.02\n",
      "iteration: 213990 loss: 0.0016 lr: 0.02\n",
      "iteration: 214000 loss: 0.0025 lr: 0.02\n",
      "iteration: 214010 loss: 0.0015 lr: 0.02\n",
      "iteration: 214020 loss: 0.0020 lr: 0.02\n",
      "iteration: 214030 loss: 0.0019 lr: 0.02\n",
      "iteration: 214040 loss: 0.0017 lr: 0.02\n",
      "iteration: 214050 loss: 0.0024 lr: 0.02\n",
      "iteration: 214060 loss: 0.0022 lr: 0.02\n",
      "iteration: 214070 loss: 0.0028 lr: 0.02\n",
      "iteration: 214080 loss: 0.0021 lr: 0.02\n",
      "iteration: 214090 loss: 0.0019 lr: 0.02\n",
      "iteration: 214100 loss: 0.0021 lr: 0.02\n",
      "iteration: 214110 loss: 0.0019 lr: 0.02\n",
      "iteration: 214120 loss: 0.0020 lr: 0.02\n",
      "iteration: 214130 loss: 0.0023 lr: 0.02\n",
      "iteration: 214140 loss: 0.0017 lr: 0.02\n",
      "iteration: 214150 loss: 0.0014 lr: 0.02\n",
      "iteration: 214160 loss: 0.0018 lr: 0.02\n",
      "iteration: 214170 loss: 0.0034 lr: 0.02\n",
      "iteration: 214180 loss: 0.0024 lr: 0.02\n",
      "iteration: 214190 loss: 0.0018 lr: 0.02\n",
      "iteration: 214200 loss: 0.0021 lr: 0.02\n",
      "iteration: 214210 loss: 0.0021 lr: 0.02\n",
      "iteration: 214220 loss: 0.0016 lr: 0.02\n",
      "iteration: 214230 loss: 0.0021 lr: 0.02\n",
      "iteration: 214240 loss: 0.0020 lr: 0.02\n",
      "iteration: 214250 loss: 0.0021 lr: 0.02\n",
      "iteration: 214260 loss: 0.0021 lr: 0.02\n",
      "iteration: 214270 loss: 0.0023 lr: 0.02\n",
      "iteration: 214280 loss: 0.0019 lr: 0.02\n",
      "iteration: 214290 loss: 0.0019 lr: 0.02\n",
      "iteration: 214300 loss: 0.0020 lr: 0.02\n",
      "iteration: 214310 loss: 0.0021 lr: 0.02\n",
      "iteration: 214320 loss: 0.0019 lr: 0.02\n",
      "iteration: 214330 loss: 0.0022 lr: 0.02\n",
      "iteration: 214340 loss: 0.0019 lr: 0.02\n",
      "iteration: 214350 loss: 0.0029 lr: 0.02\n",
      "iteration: 214360 loss: 0.0021 lr: 0.02\n",
      "iteration: 214370 loss: 0.0020 lr: 0.02\n",
      "iteration: 214380 loss: 0.0024 lr: 0.02\n",
      "iteration: 214390 loss: 0.0015 lr: 0.02\n",
      "iteration: 214400 loss: 0.0018 lr: 0.02\n",
      "iteration: 214410 loss: 0.0022 lr: 0.02\n",
      "iteration: 214420 loss: 0.0019 lr: 0.02\n",
      "iteration: 214430 loss: 0.0022 lr: 0.02\n",
      "iteration: 214440 loss: 0.0021 lr: 0.02\n",
      "iteration: 214450 loss: 0.0017 lr: 0.02\n",
      "iteration: 214460 loss: 0.0018 lr: 0.02\n",
      "iteration: 214470 loss: 0.0023 lr: 0.02\n",
      "iteration: 214480 loss: 0.0026 lr: 0.02\n",
      "iteration: 214490 loss: 0.0024 lr: 0.02\n",
      "iteration: 214500 loss: 0.0021 lr: 0.02\n",
      "iteration: 214510 loss: 0.0024 lr: 0.02\n",
      "iteration: 214520 loss: 0.0020 lr: 0.02\n",
      "iteration: 214530 loss: 0.0015 lr: 0.02\n",
      "iteration: 214540 loss: 0.0020 lr: 0.02\n",
      "iteration: 214550 loss: 0.0021 lr: 0.02\n",
      "iteration: 214560 loss: 0.0015 lr: 0.02\n",
      "iteration: 214570 loss: 0.0022 lr: 0.02\n",
      "iteration: 214580 loss: 0.0018 lr: 0.02\n",
      "iteration: 214590 loss: 0.0019 lr: 0.02\n",
      "iteration: 214600 loss: 0.0014 lr: 0.02\n",
      "iteration: 214610 loss: 0.0017 lr: 0.02\n",
      "iteration: 214620 loss: 0.0021 lr: 0.02\n",
      "iteration: 214630 loss: 0.0020 lr: 0.02\n",
      "iteration: 214640 loss: 0.0017 lr: 0.02\n",
      "iteration: 214650 loss: 0.0019 lr: 0.02\n",
      "iteration: 214660 loss: 0.0017 lr: 0.02\n",
      "iteration: 214670 loss: 0.0018 lr: 0.02\n",
      "iteration: 214680 loss: 0.0018 lr: 0.02\n",
      "iteration: 214690 loss: 0.0021 lr: 0.02\n",
      "iteration: 214700 loss: 0.0020 lr: 0.02\n",
      "iteration: 214710 loss: 0.0019 lr: 0.02\n",
      "iteration: 214720 loss: 0.0021 lr: 0.02\n",
      "iteration: 214730 loss: 0.0017 lr: 0.02\n",
      "iteration: 214740 loss: 0.0018 lr: 0.02\n",
      "iteration: 214750 loss: 0.0026 lr: 0.02\n",
      "iteration: 214760 loss: 0.0017 lr: 0.02\n",
      "iteration: 214770 loss: 0.0018 lr: 0.02\n",
      "iteration: 214780 loss: 0.0018 lr: 0.02\n",
      "iteration: 214790 loss: 0.0017 lr: 0.02\n",
      "iteration: 214800 loss: 0.0019 lr: 0.02\n",
      "iteration: 214810 loss: 0.0014 lr: 0.02\n",
      "iteration: 214820 loss: 0.0028 lr: 0.02\n",
      "iteration: 214830 loss: 0.0026 lr: 0.02\n",
      "iteration: 214840 loss: 0.0019 lr: 0.02\n",
      "iteration: 214850 loss: 0.0017 lr: 0.02\n",
      "iteration: 214860 loss: 0.0025 lr: 0.02\n",
      "iteration: 214870 loss: 0.0019 lr: 0.02\n",
      "iteration: 214880 loss: 0.0019 lr: 0.02\n",
      "iteration: 214890 loss: 0.0017 lr: 0.02\n",
      "iteration: 214900 loss: 0.0024 lr: 0.02\n",
      "iteration: 214910 loss: 0.0015 lr: 0.02\n",
      "iteration: 214920 loss: 0.0029 lr: 0.02\n",
      "iteration: 214930 loss: 0.0025 lr: 0.02\n",
      "iteration: 214940 loss: 0.0026 lr: 0.02\n",
      "iteration: 214950 loss: 0.0027 lr: 0.02\n",
      "iteration: 214960 loss: 0.0021 lr: 0.02\n",
      "iteration: 214970 loss: 0.0017 lr: 0.02\n",
      "iteration: 214980 loss: 0.0016 lr: 0.02\n",
      "iteration: 214990 loss: 0.0015 lr: 0.02\n",
      "iteration: 215000 loss: 0.0016 lr: 0.02\n",
      "iteration: 215010 loss: 0.0020 lr: 0.02\n",
      "iteration: 215020 loss: 0.0024 lr: 0.02\n",
      "iteration: 215030 loss: 0.0024 lr: 0.02\n",
      "iteration: 215040 loss: 0.0021 lr: 0.02\n",
      "iteration: 215050 loss: 0.0018 lr: 0.02\n",
      "iteration: 215060 loss: 0.0020 lr: 0.02\n",
      "iteration: 215070 loss: 0.0022 lr: 0.02\n",
      "iteration: 215080 loss: 0.0021 lr: 0.02\n",
      "iteration: 215090 loss: 0.0019 lr: 0.02\n",
      "iteration: 215100 loss: 0.0017 lr: 0.02\n",
      "iteration: 215110 loss: 0.0020 lr: 0.02\n",
      "iteration: 215120 loss: 0.0019 lr: 0.02\n",
      "iteration: 215130 loss: 0.0019 lr: 0.02\n",
      "iteration: 215140 loss: 0.0022 lr: 0.02\n",
      "iteration: 215150 loss: 0.0020 lr: 0.02\n",
      "iteration: 215160 loss: 0.0017 lr: 0.02\n",
      "iteration: 215170 loss: 0.0015 lr: 0.02\n",
      "iteration: 215180 loss: 0.0017 lr: 0.02\n",
      "iteration: 215190 loss: 0.0015 lr: 0.02\n",
      "iteration: 215200 loss: 0.0018 lr: 0.02\n",
      "iteration: 215210 loss: 0.0023 lr: 0.02\n",
      "iteration: 215220 loss: 0.0017 lr: 0.02\n",
      "iteration: 215230 loss: 0.0018 lr: 0.02\n",
      "iteration: 215240 loss: 0.0020 lr: 0.02\n",
      "iteration: 215250 loss: 0.0017 lr: 0.02\n",
      "iteration: 215260 loss: 0.0016 lr: 0.02\n",
      "iteration: 215270 loss: 0.0017 lr: 0.02\n",
      "iteration: 215280 loss: 0.0015 lr: 0.02\n",
      "iteration: 215290 loss: 0.0019 lr: 0.02\n",
      "iteration: 215300 loss: 0.0020 lr: 0.02\n",
      "iteration: 215310 loss: 0.0020 lr: 0.02\n",
      "iteration: 215320 loss: 0.0014 lr: 0.02\n",
      "iteration: 215330 loss: 0.0019 lr: 0.02\n",
      "iteration: 215340 loss: 0.0029 lr: 0.02\n",
      "iteration: 215350 loss: 0.0018 lr: 0.02\n",
      "iteration: 215360 loss: 0.0021 lr: 0.02\n",
      "iteration: 215370 loss: 0.0018 lr: 0.02\n",
      "iteration: 215380 loss: 0.0021 lr: 0.02\n",
      "iteration: 215390 loss: 0.0015 lr: 0.02\n",
      "iteration: 215400 loss: 0.0015 lr: 0.02\n",
      "iteration: 215410 loss: 0.0014 lr: 0.02\n",
      "iteration: 215420 loss: 0.0023 lr: 0.02\n",
      "iteration: 215430 loss: 0.0017 lr: 0.02\n",
      "iteration: 215440 loss: 0.0019 lr: 0.02\n",
      "iteration: 215450 loss: 0.0025 lr: 0.02\n",
      "iteration: 215460 loss: 0.0021 lr: 0.02\n",
      "iteration: 215470 loss: 0.0023 lr: 0.02\n",
      "iteration: 215480 loss: 0.0018 lr: 0.02\n",
      "iteration: 215490 loss: 0.0021 lr: 0.02\n",
      "iteration: 215500 loss: 0.0017 lr: 0.02\n",
      "iteration: 215510 loss: 0.0016 lr: 0.02\n",
      "iteration: 215520 loss: 0.0023 lr: 0.02\n",
      "iteration: 215530 loss: 0.0018 lr: 0.02\n",
      "iteration: 215540 loss: 0.0022 lr: 0.02\n",
      "iteration: 215550 loss: 0.0027 lr: 0.02\n",
      "iteration: 215560 loss: 0.0017 lr: 0.02\n",
      "iteration: 215570 loss: 0.0019 lr: 0.02\n",
      "iteration: 215580 loss: 0.0015 lr: 0.02\n",
      "iteration: 215590 loss: 0.0028 lr: 0.02\n",
      "iteration: 215600 loss: 0.0018 lr: 0.02\n",
      "iteration: 215610 loss: 0.0015 lr: 0.02\n",
      "iteration: 215620 loss: 0.0018 lr: 0.02\n",
      "iteration: 215630 loss: 0.0014 lr: 0.02\n",
      "iteration: 215640 loss: 0.0017 lr: 0.02\n",
      "iteration: 215650 loss: 0.0021 lr: 0.02\n",
      "iteration: 215660 loss: 0.0017 lr: 0.02\n",
      "iteration: 215670 loss: 0.0026 lr: 0.02\n",
      "iteration: 215680 loss: 0.0014 lr: 0.02\n",
      "iteration: 215690 loss: 0.0018 lr: 0.02\n",
      "iteration: 215700 loss: 0.0020 lr: 0.02\n",
      "iteration: 215710 loss: 0.0017 lr: 0.02\n",
      "iteration: 215720 loss: 0.0015 lr: 0.02\n",
      "iteration: 215730 loss: 0.0018 lr: 0.02\n",
      "iteration: 215740 loss: 0.0021 lr: 0.02\n",
      "iteration: 215750 loss: 0.0021 lr: 0.02\n",
      "iteration: 215760 loss: 0.0025 lr: 0.02\n",
      "iteration: 215770 loss: 0.0021 lr: 0.02\n",
      "iteration: 215780 loss: 0.0021 lr: 0.02\n",
      "iteration: 215790 loss: 0.0018 lr: 0.02\n",
      "iteration: 215800 loss: 0.0020 lr: 0.02\n",
      "iteration: 215810 loss: 0.0018 lr: 0.02\n",
      "iteration: 215820 loss: 0.0012 lr: 0.02\n",
      "iteration: 215830 loss: 0.0017 lr: 0.02\n",
      "iteration: 215840 loss: 0.0017 lr: 0.02\n",
      "iteration: 215850 loss: 0.0014 lr: 0.02\n",
      "iteration: 215860 loss: 0.0021 lr: 0.02\n",
      "iteration: 215870 loss: 0.0017 lr: 0.02\n",
      "iteration: 215880 loss: 0.0019 lr: 0.02\n",
      "iteration: 215890 loss: 0.0021 lr: 0.02\n",
      "iteration: 215900 loss: 0.0023 lr: 0.02\n",
      "iteration: 215910 loss: 0.0018 lr: 0.02\n",
      "iteration: 215920 loss: 0.0017 lr: 0.02\n",
      "iteration: 215930 loss: 0.0022 lr: 0.02\n",
      "iteration: 215940 loss: 0.0018 lr: 0.02\n",
      "iteration: 215950 loss: 0.0016 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 215960 loss: 0.0018 lr: 0.02\n",
      "iteration: 215970 loss: 0.0015 lr: 0.02\n",
      "iteration: 215980 loss: 0.0026 lr: 0.02\n",
      "iteration: 215990 loss: 0.0019 lr: 0.02\n",
      "iteration: 216000 loss: 0.0018 lr: 0.02\n",
      "iteration: 216010 loss: 0.0020 lr: 0.02\n",
      "iteration: 216020 loss: 0.0019 lr: 0.02\n",
      "iteration: 216030 loss: 0.0023 lr: 0.02\n",
      "iteration: 216040 loss: 0.0018 lr: 0.02\n",
      "iteration: 216050 loss: 0.0016 lr: 0.02\n",
      "iteration: 216060 loss: 0.0014 lr: 0.02\n",
      "iteration: 216070 loss: 0.0021 lr: 0.02\n",
      "iteration: 216080 loss: 0.0020 lr: 0.02\n",
      "iteration: 216090 loss: 0.0019 lr: 0.02\n",
      "iteration: 216100 loss: 0.0021 lr: 0.02\n",
      "iteration: 216110 loss: 0.0021 lr: 0.02\n",
      "iteration: 216120 loss: 0.0023 lr: 0.02\n",
      "iteration: 216130 loss: 0.0026 lr: 0.02\n",
      "iteration: 216140 loss: 0.0017 lr: 0.02\n",
      "iteration: 216150 loss: 0.0025 lr: 0.02\n",
      "iteration: 216160 loss: 0.0020 lr: 0.02\n",
      "iteration: 216170 loss: 0.0019 lr: 0.02\n",
      "iteration: 216180 loss: 0.0013 lr: 0.02\n",
      "iteration: 216190 loss: 0.0017 lr: 0.02\n",
      "iteration: 216200 loss: 0.0020 lr: 0.02\n",
      "iteration: 216210 loss: 0.0018 lr: 0.02\n",
      "iteration: 216220 loss: 0.0017 lr: 0.02\n",
      "iteration: 216230 loss: 0.0019 lr: 0.02\n",
      "iteration: 216240 loss: 0.0018 lr: 0.02\n",
      "iteration: 216250 loss: 0.0023 lr: 0.02\n",
      "iteration: 216260 loss: 0.0026 lr: 0.02\n",
      "iteration: 216270 loss: 0.0022 lr: 0.02\n",
      "iteration: 216280 loss: 0.0017 lr: 0.02\n",
      "iteration: 216290 loss: 0.0018 lr: 0.02\n",
      "iteration: 216300 loss: 0.0018 lr: 0.02\n",
      "iteration: 216310 loss: 0.0024 lr: 0.02\n",
      "iteration: 216320 loss: 0.0021 lr: 0.02\n",
      "iteration: 216330 loss: 0.0020 lr: 0.02\n",
      "iteration: 216340 loss: 0.0019 lr: 0.02\n",
      "iteration: 216350 loss: 0.0024 lr: 0.02\n",
      "iteration: 216360 loss: 0.0025 lr: 0.02\n",
      "iteration: 216370 loss: 0.0022 lr: 0.02\n",
      "iteration: 216380 loss: 0.0015 lr: 0.02\n",
      "iteration: 216390 loss: 0.0021 lr: 0.02\n",
      "iteration: 216400 loss: 0.0017 lr: 0.02\n",
      "iteration: 216410 loss: 0.0016 lr: 0.02\n",
      "iteration: 216420 loss: 0.0018 lr: 0.02\n",
      "iteration: 216430 loss: 0.0020 lr: 0.02\n",
      "iteration: 216440 loss: 0.0018 lr: 0.02\n",
      "iteration: 216450 loss: 0.0020 lr: 0.02\n",
      "iteration: 216460 loss: 0.0024 lr: 0.02\n",
      "iteration: 216470 loss: 0.0018 lr: 0.02\n",
      "iteration: 216480 loss: 0.0023 lr: 0.02\n",
      "iteration: 216490 loss: 0.0015 lr: 0.02\n",
      "iteration: 216500 loss: 0.0023 lr: 0.02\n",
      "iteration: 216510 loss: 0.0022 lr: 0.02\n",
      "iteration: 216520 loss: 0.0020 lr: 0.02\n",
      "iteration: 216530 loss: 0.0018 lr: 0.02\n",
      "iteration: 216540 loss: 0.0014 lr: 0.02\n",
      "iteration: 216550 loss: 0.0019 lr: 0.02\n",
      "iteration: 216560 loss: 0.0022 lr: 0.02\n",
      "iteration: 216570 loss: 0.0019 lr: 0.02\n",
      "iteration: 216580 loss: 0.0018 lr: 0.02\n",
      "iteration: 216590 loss: 0.0021 lr: 0.02\n",
      "iteration: 216600 loss: 0.0021 lr: 0.02\n",
      "iteration: 216610 loss: 0.0030 lr: 0.02\n",
      "iteration: 216620 loss: 0.0021 lr: 0.02\n",
      "iteration: 216630 loss: 0.0019 lr: 0.02\n",
      "iteration: 216640 loss: 0.0014 lr: 0.02\n",
      "iteration: 216650 loss: 0.0024 lr: 0.02\n",
      "iteration: 216660 loss: 0.0019 lr: 0.02\n",
      "iteration: 216670 loss: 0.0020 lr: 0.02\n",
      "iteration: 216680 loss: 0.0018 lr: 0.02\n",
      "iteration: 216690 loss: 0.0022 lr: 0.02\n",
      "iteration: 216700 loss: 0.0028 lr: 0.02\n",
      "iteration: 216710 loss: 0.0019 lr: 0.02\n",
      "iteration: 216720 loss: 0.0021 lr: 0.02\n",
      "iteration: 216730 loss: 0.0025 lr: 0.02\n",
      "iteration: 216740 loss: 0.0018 lr: 0.02\n",
      "iteration: 216750 loss: 0.0020 lr: 0.02\n",
      "iteration: 216760 loss: 0.0018 lr: 0.02\n",
      "iteration: 216770 loss: 0.0017 lr: 0.02\n",
      "iteration: 216780 loss: 0.0024 lr: 0.02\n",
      "iteration: 216790 loss: 0.0019 lr: 0.02\n",
      "iteration: 216800 loss: 0.0020 lr: 0.02\n",
      "iteration: 216810 loss: 0.0021 lr: 0.02\n",
      "iteration: 216820 loss: 0.0017 lr: 0.02\n",
      "iteration: 216830 loss: 0.0019 lr: 0.02\n",
      "iteration: 216840 loss: 0.0017 lr: 0.02\n",
      "iteration: 216850 loss: 0.0024 lr: 0.02\n",
      "iteration: 216860 loss: 0.0019 lr: 0.02\n",
      "iteration: 216870 loss: 0.0019 lr: 0.02\n",
      "iteration: 216880 loss: 0.0018 lr: 0.02\n",
      "iteration: 216890 loss: 0.0017 lr: 0.02\n",
      "iteration: 216900 loss: 0.0018 lr: 0.02\n",
      "iteration: 216910 loss: 0.0018 lr: 0.02\n",
      "iteration: 216920 loss: 0.0019 lr: 0.02\n",
      "iteration: 216930 loss: 0.0016 lr: 0.02\n",
      "iteration: 216940 loss: 0.0018 lr: 0.02\n",
      "iteration: 216950 loss: 0.0017 lr: 0.02\n",
      "iteration: 216960 loss: 0.0020 lr: 0.02\n",
      "iteration: 216970 loss: 0.0015 lr: 0.02\n",
      "iteration: 216980 loss: 0.0019 lr: 0.02\n",
      "iteration: 216990 loss: 0.0017 lr: 0.02\n",
      "iteration: 217000 loss: 0.0023 lr: 0.02\n",
      "iteration: 217010 loss: 0.0023 lr: 0.02\n",
      "iteration: 217020 loss: 0.0013 lr: 0.02\n",
      "iteration: 217030 loss: 0.0024 lr: 0.02\n",
      "iteration: 217040 loss: 0.0020 lr: 0.02\n",
      "iteration: 217050 loss: 0.0020 lr: 0.02\n",
      "iteration: 217060 loss: 0.0015 lr: 0.02\n",
      "iteration: 217070 loss: 0.0020 lr: 0.02\n",
      "iteration: 217080 loss: 0.0016 lr: 0.02\n",
      "iteration: 217090 loss: 0.0016 lr: 0.02\n",
      "iteration: 217100 loss: 0.0020 lr: 0.02\n",
      "iteration: 217110 loss: 0.0024 lr: 0.02\n",
      "iteration: 217120 loss: 0.0022 lr: 0.02\n",
      "iteration: 217130 loss: 0.0019 lr: 0.02\n",
      "iteration: 217140 loss: 0.0016 lr: 0.02\n",
      "iteration: 217150 loss: 0.0018 lr: 0.02\n",
      "iteration: 217160 loss: 0.0017 lr: 0.02\n",
      "iteration: 217170 loss: 0.0022 lr: 0.02\n",
      "iteration: 217180 loss: 0.0021 lr: 0.02\n",
      "iteration: 217190 loss: 0.0021 lr: 0.02\n",
      "iteration: 217200 loss: 0.0017 lr: 0.02\n",
      "iteration: 217210 loss: 0.0017 lr: 0.02\n",
      "iteration: 217220 loss: 0.0020 lr: 0.02\n",
      "iteration: 217230 loss: 0.0022 lr: 0.02\n",
      "iteration: 217240 loss: 0.0016 lr: 0.02\n",
      "iteration: 217250 loss: 0.0020 lr: 0.02\n",
      "iteration: 217260 loss: 0.0020 lr: 0.02\n",
      "iteration: 217270 loss: 0.0027 lr: 0.02\n",
      "iteration: 217280 loss: 0.0020 lr: 0.02\n",
      "iteration: 217290 loss: 0.0024 lr: 0.02\n",
      "iteration: 217300 loss: 0.0019 lr: 0.02\n",
      "iteration: 217310 loss: 0.0018 lr: 0.02\n",
      "iteration: 217320 loss: 0.0018 lr: 0.02\n",
      "iteration: 217330 loss: 0.0028 lr: 0.02\n",
      "iteration: 217340 loss: 0.0016 lr: 0.02\n",
      "iteration: 217350 loss: 0.0015 lr: 0.02\n",
      "iteration: 217360 loss: 0.0029 lr: 0.02\n",
      "iteration: 217370 loss: 0.0023 lr: 0.02\n",
      "iteration: 217380 loss: 0.0022 lr: 0.02\n",
      "iteration: 217390 loss: 0.0019 lr: 0.02\n",
      "iteration: 217400 loss: 0.0015 lr: 0.02\n",
      "iteration: 217410 loss: 0.0018 lr: 0.02\n",
      "iteration: 217420 loss: 0.0026 lr: 0.02\n",
      "iteration: 217430 loss: 0.0024 lr: 0.02\n",
      "iteration: 217440 loss: 0.0019 lr: 0.02\n",
      "iteration: 217450 loss: 0.0025 lr: 0.02\n",
      "iteration: 217460 loss: 0.0017 lr: 0.02\n",
      "iteration: 217470 loss: 0.0023 lr: 0.02\n",
      "iteration: 217480 loss: 0.0017 lr: 0.02\n",
      "iteration: 217490 loss: 0.0017 lr: 0.02\n",
      "iteration: 217500 loss: 0.0020 lr: 0.02\n",
      "iteration: 217510 loss: 0.0019 lr: 0.02\n",
      "iteration: 217520 loss: 0.0020 lr: 0.02\n",
      "iteration: 217530 loss: 0.0017 lr: 0.02\n",
      "iteration: 217540 loss: 0.0025 lr: 0.02\n",
      "iteration: 217550 loss: 0.0019 lr: 0.02\n",
      "iteration: 217560 loss: 0.0015 lr: 0.02\n",
      "iteration: 217570 loss: 0.0018 lr: 0.02\n",
      "iteration: 217580 loss: 0.0019 lr: 0.02\n",
      "iteration: 217590 loss: 0.0024 lr: 0.02\n",
      "iteration: 217600 loss: 0.0022 lr: 0.02\n",
      "iteration: 217610 loss: 0.0023 lr: 0.02\n",
      "iteration: 217620 loss: 0.0017 lr: 0.02\n",
      "iteration: 217630 loss: 0.0018 lr: 0.02\n",
      "iteration: 217640 loss: 0.0020 lr: 0.02\n",
      "iteration: 217650 loss: 0.0016 lr: 0.02\n",
      "iteration: 217660 loss: 0.0017 lr: 0.02\n",
      "iteration: 217670 loss: 0.0023 lr: 0.02\n",
      "iteration: 217680 loss: 0.0016 lr: 0.02\n",
      "iteration: 217690 loss: 0.0019 lr: 0.02\n",
      "iteration: 217700 loss: 0.0019 lr: 0.02\n",
      "iteration: 217710 loss: 0.0019 lr: 0.02\n",
      "iteration: 217720 loss: 0.0019 lr: 0.02\n",
      "iteration: 217730 loss: 0.0024 lr: 0.02\n",
      "iteration: 217740 loss: 0.0019 lr: 0.02\n",
      "iteration: 217750 loss: 0.0017 lr: 0.02\n",
      "iteration: 217760 loss: 0.0021 lr: 0.02\n",
      "iteration: 217770 loss: 0.0023 lr: 0.02\n",
      "iteration: 217780 loss: 0.0018 lr: 0.02\n",
      "iteration: 217790 loss: 0.0028 lr: 0.02\n",
      "iteration: 217800 loss: 0.0018 lr: 0.02\n",
      "iteration: 217810 loss: 0.0022 lr: 0.02\n",
      "iteration: 217820 loss: 0.0021 lr: 0.02\n",
      "iteration: 217830 loss: 0.0030 lr: 0.02\n",
      "iteration: 217840 loss: 0.0017 lr: 0.02\n",
      "iteration: 217850 loss: 0.0027 lr: 0.02\n",
      "iteration: 217860 loss: 0.0019 lr: 0.02\n",
      "iteration: 217870 loss: 0.0022 lr: 0.02\n",
      "iteration: 217880 loss: 0.0016 lr: 0.02\n",
      "iteration: 217890 loss: 0.0031 lr: 0.02\n",
      "iteration: 217900 loss: 0.0022 lr: 0.02\n",
      "iteration: 217910 loss: 0.0022 lr: 0.02\n",
      "iteration: 217920 loss: 0.0019 lr: 0.02\n",
      "iteration: 217930 loss: 0.0016 lr: 0.02\n",
      "iteration: 217940 loss: 0.0020 lr: 0.02\n",
      "iteration: 217950 loss: 0.0020 lr: 0.02\n",
      "iteration: 217960 loss: 0.0019 lr: 0.02\n",
      "iteration: 217970 loss: 0.0019 lr: 0.02\n",
      "iteration: 217980 loss: 0.0017 lr: 0.02\n",
      "iteration: 217990 loss: 0.0018 lr: 0.02\n",
      "iteration: 218000 loss: 0.0016 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 218010 loss: 0.0020 lr: 0.02\n",
      "iteration: 218020 loss: 0.0017 lr: 0.02\n",
      "iteration: 218030 loss: 0.0017 lr: 0.02\n",
      "iteration: 218040 loss: 0.0024 lr: 0.02\n",
      "iteration: 218050 loss: 0.0014 lr: 0.02\n",
      "iteration: 218060 loss: 0.0017 lr: 0.02\n",
      "iteration: 218070 loss: 0.0023 lr: 0.02\n",
      "iteration: 218080 loss: 0.0018 lr: 0.02\n",
      "iteration: 218090 loss: 0.0016 lr: 0.02\n",
      "iteration: 218100 loss: 0.0020 lr: 0.02\n",
      "iteration: 218110 loss: 0.0015 lr: 0.02\n",
      "iteration: 218120 loss: 0.0023 lr: 0.02\n",
      "iteration: 218130 loss: 0.0022 lr: 0.02\n",
      "iteration: 218140 loss: 0.0018 lr: 0.02\n",
      "iteration: 218150 loss: 0.0019 lr: 0.02\n",
      "iteration: 218160 loss: 0.0019 lr: 0.02\n",
      "iteration: 218170 loss: 0.0015 lr: 0.02\n",
      "iteration: 218180 loss: 0.0038 lr: 0.02\n",
      "iteration: 218190 loss: 0.0018 lr: 0.02\n",
      "iteration: 218200 loss: 0.0033 lr: 0.02\n",
      "iteration: 218210 loss: 0.0015 lr: 0.02\n",
      "iteration: 218220 loss: 0.0016 lr: 0.02\n",
      "iteration: 218230 loss: 0.0022 lr: 0.02\n",
      "iteration: 218240 loss: 0.0022 lr: 0.02\n",
      "iteration: 218250 loss: 0.0014 lr: 0.02\n",
      "iteration: 218260 loss: 0.0017 lr: 0.02\n",
      "iteration: 218270 loss: 0.0019 lr: 0.02\n",
      "iteration: 218280 loss: 0.0022 lr: 0.02\n",
      "iteration: 218290 loss: 0.0018 lr: 0.02\n",
      "iteration: 218300 loss: 0.0020 lr: 0.02\n",
      "iteration: 218310 loss: 0.0018 lr: 0.02\n",
      "iteration: 218320 loss: 0.0020 lr: 0.02\n",
      "iteration: 218330 loss: 0.0022 lr: 0.02\n",
      "iteration: 218340 loss: 0.0019 lr: 0.02\n",
      "iteration: 218350 loss: 0.0016 lr: 0.02\n",
      "iteration: 218360 loss: 0.0021 lr: 0.02\n",
      "iteration: 218370 loss: 0.0020 lr: 0.02\n",
      "iteration: 218380 loss: 0.0021 lr: 0.02\n",
      "iteration: 218390 loss: 0.0021 lr: 0.02\n",
      "iteration: 218400 loss: 0.0026 lr: 0.02\n",
      "iteration: 218410 loss: 0.0020 lr: 0.02\n",
      "iteration: 218420 loss: 0.0018 lr: 0.02\n",
      "iteration: 218430 loss: 0.0019 lr: 0.02\n",
      "iteration: 218440 loss: 0.0019 lr: 0.02\n",
      "iteration: 218450 loss: 0.0015 lr: 0.02\n",
      "iteration: 218460 loss: 0.0018 lr: 0.02\n",
      "iteration: 218470 loss: 0.0027 lr: 0.02\n",
      "iteration: 218480 loss: 0.0019 lr: 0.02\n",
      "iteration: 218490 loss: 0.0015 lr: 0.02\n",
      "iteration: 218500 loss: 0.0017 lr: 0.02\n",
      "iteration: 218510 loss: 0.0020 lr: 0.02\n",
      "iteration: 218520 loss: 0.0020 lr: 0.02\n",
      "iteration: 218530 loss: 0.0019 lr: 0.02\n",
      "iteration: 218540 loss: 0.0017 lr: 0.02\n",
      "iteration: 218550 loss: 0.0022 lr: 0.02\n",
      "iteration: 218560 loss: 0.0023 lr: 0.02\n",
      "iteration: 218570 loss: 0.0015 lr: 0.02\n",
      "iteration: 218580 loss: 0.0021 lr: 0.02\n",
      "iteration: 218590 loss: 0.0016 lr: 0.02\n",
      "iteration: 218600 loss: 0.0018 lr: 0.02\n",
      "iteration: 218610 loss: 0.0015 lr: 0.02\n",
      "iteration: 218620 loss: 0.0018 lr: 0.02\n",
      "iteration: 218630 loss: 0.0016 lr: 0.02\n",
      "iteration: 218640 loss: 0.0024 lr: 0.02\n",
      "iteration: 218650 loss: 0.0020 lr: 0.02\n",
      "iteration: 218660 loss: 0.0022 lr: 0.02\n",
      "iteration: 218670 loss: 0.0020 lr: 0.02\n",
      "iteration: 218680 loss: 0.0021 lr: 0.02\n",
      "iteration: 218690 loss: 0.0016 lr: 0.02\n",
      "iteration: 218700 loss: 0.0017 lr: 0.02\n",
      "iteration: 218710 loss: 0.0017 lr: 0.02\n",
      "iteration: 218720 loss: 0.0020 lr: 0.02\n",
      "iteration: 218730 loss: 0.0022 lr: 0.02\n",
      "iteration: 218740 loss: 0.0016 lr: 0.02\n",
      "iteration: 218750 loss: 0.0019 lr: 0.02\n",
      "iteration: 218760 loss: 0.0016 lr: 0.02\n",
      "iteration: 218770 loss: 0.0019 lr: 0.02\n",
      "iteration: 218780 loss: 0.0014 lr: 0.02\n",
      "iteration: 218790 loss: 0.0022 lr: 0.02\n",
      "iteration: 218800 loss: 0.0015 lr: 0.02\n",
      "iteration: 218810 loss: 0.0022 lr: 0.02\n",
      "iteration: 218820 loss: 0.0020 lr: 0.02\n",
      "iteration: 218830 loss: 0.0021 lr: 0.02\n",
      "iteration: 218840 loss: 0.0020 lr: 0.02\n",
      "iteration: 218850 loss: 0.0020 lr: 0.02\n",
      "iteration: 218860 loss: 0.0019 lr: 0.02\n",
      "iteration: 218870 loss: 0.0018 lr: 0.02\n",
      "iteration: 218880 loss: 0.0021 lr: 0.02\n",
      "iteration: 218890 loss: 0.0014 lr: 0.02\n",
      "iteration: 218900 loss: 0.0016 lr: 0.02\n",
      "iteration: 218910 loss: 0.0020 lr: 0.02\n",
      "iteration: 218920 loss: 0.0018 lr: 0.02\n",
      "iteration: 218930 loss: 0.0015 lr: 0.02\n",
      "iteration: 218940 loss: 0.0021 lr: 0.02\n",
      "iteration: 218950 loss: 0.0020 lr: 0.02\n",
      "iteration: 218960 loss: 0.0020 lr: 0.02\n",
      "iteration: 218970 loss: 0.0019 lr: 0.02\n",
      "iteration: 218980 loss: 0.0021 lr: 0.02\n",
      "iteration: 218990 loss: 0.0019 lr: 0.02\n",
      "iteration: 219000 loss: 0.0021 lr: 0.02\n",
      "iteration: 219010 loss: 0.0025 lr: 0.02\n",
      "iteration: 219020 loss: 0.0019 lr: 0.02\n",
      "iteration: 219030 loss: 0.0022 lr: 0.02\n",
      "iteration: 219040 loss: 0.0018 lr: 0.02\n",
      "iteration: 219050 loss: 0.0019 lr: 0.02\n",
      "iteration: 219060 loss: 0.0018 lr: 0.02\n",
      "iteration: 219070 loss: 0.0017 lr: 0.02\n",
      "iteration: 219080 loss: 0.0022 lr: 0.02\n",
      "iteration: 219090 loss: 0.0016 lr: 0.02\n",
      "iteration: 219100 loss: 0.0020 lr: 0.02\n",
      "iteration: 219110 loss: 0.0018 lr: 0.02\n",
      "iteration: 219120 loss: 0.0019 lr: 0.02\n",
      "iteration: 219130 loss: 0.0018 lr: 0.02\n",
      "iteration: 219140 loss: 0.0028 lr: 0.02\n",
      "iteration: 219150 loss: 0.0022 lr: 0.02\n",
      "iteration: 219160 loss: 0.0013 lr: 0.02\n",
      "iteration: 219170 loss: 0.0016 lr: 0.02\n",
      "iteration: 219180 loss: 0.0018 lr: 0.02\n",
      "iteration: 219190 loss: 0.0016 lr: 0.02\n",
      "iteration: 219200 loss: 0.0017 lr: 0.02\n",
      "iteration: 219210 loss: 0.0022 lr: 0.02\n",
      "iteration: 219220 loss: 0.0014 lr: 0.02\n",
      "iteration: 219230 loss: 0.0014 lr: 0.02\n",
      "iteration: 219240 loss: 0.0015 lr: 0.02\n",
      "iteration: 219250 loss: 0.0020 lr: 0.02\n",
      "iteration: 219260 loss: 0.0018 lr: 0.02\n",
      "iteration: 219270 loss: 0.0015 lr: 0.02\n",
      "iteration: 219280 loss: 0.0020 lr: 0.02\n",
      "iteration: 219290 loss: 0.0018 lr: 0.02\n",
      "iteration: 219300 loss: 0.0015 lr: 0.02\n",
      "iteration: 219310 loss: 0.0016 lr: 0.02\n",
      "iteration: 219320 loss: 0.0016 lr: 0.02\n",
      "iteration: 219330 loss: 0.0027 lr: 0.02\n",
      "iteration: 219340 loss: 0.0018 lr: 0.02\n",
      "iteration: 219350 loss: 0.0015 lr: 0.02\n",
      "iteration: 219360 loss: 0.0018 lr: 0.02\n",
      "iteration: 219370 loss: 0.0015 lr: 0.02\n",
      "iteration: 219380 loss: 0.0018 lr: 0.02\n",
      "iteration: 219390 loss: 0.0023 lr: 0.02\n",
      "iteration: 219400 loss: 0.0027 lr: 0.02\n",
      "iteration: 219410 loss: 0.0017 lr: 0.02\n",
      "iteration: 219420 loss: 0.0022 lr: 0.02\n",
      "iteration: 219430 loss: 0.0019 lr: 0.02\n",
      "iteration: 219440 loss: 0.0023 lr: 0.02\n",
      "iteration: 219450 loss: 0.0018 lr: 0.02\n",
      "iteration: 219460 loss: 0.0013 lr: 0.02\n",
      "iteration: 219470 loss: 0.0021 lr: 0.02\n",
      "iteration: 219480 loss: 0.0014 lr: 0.02\n",
      "iteration: 219490 loss: 0.0018 lr: 0.02\n",
      "iteration: 219500 loss: 0.0022 lr: 0.02\n",
      "iteration: 219510 loss: 0.0016 lr: 0.02\n",
      "iteration: 219520 loss: 0.0019 lr: 0.02\n",
      "iteration: 219530 loss: 0.0020 lr: 0.02\n",
      "iteration: 219540 loss: 0.0023 lr: 0.02\n",
      "iteration: 219550 loss: 0.0016 lr: 0.02\n",
      "iteration: 219560 loss: 0.0019 lr: 0.02\n",
      "iteration: 219570 loss: 0.0020 lr: 0.02\n",
      "iteration: 219580 loss: 0.0022 lr: 0.02\n",
      "iteration: 219590 loss: 0.0017 lr: 0.02\n",
      "iteration: 219600 loss: 0.0017 lr: 0.02\n",
      "iteration: 219610 loss: 0.0022 lr: 0.02\n",
      "iteration: 219620 loss: 0.0020 lr: 0.02\n",
      "iteration: 219630 loss: 0.0027 lr: 0.02\n",
      "iteration: 219640 loss: 0.0019 lr: 0.02\n",
      "iteration: 219650 loss: 0.0017 lr: 0.02\n",
      "iteration: 219660 loss: 0.0018 lr: 0.02\n",
      "iteration: 219670 loss: 0.0020 lr: 0.02\n",
      "iteration: 219680 loss: 0.0020 lr: 0.02\n",
      "iteration: 219690 loss: 0.0012 lr: 0.02\n",
      "iteration: 219700 loss: 0.0019 lr: 0.02\n",
      "iteration: 219710 loss: 0.0018 lr: 0.02\n",
      "iteration: 219720 loss: 0.0028 lr: 0.02\n",
      "iteration: 219730 loss: 0.0015 lr: 0.02\n",
      "iteration: 219740 loss: 0.0019 lr: 0.02\n",
      "iteration: 219750 loss: 0.0020 lr: 0.02\n",
      "iteration: 219760 loss: 0.0021 lr: 0.02\n",
      "iteration: 219770 loss: 0.0019 lr: 0.02\n",
      "iteration: 219780 loss: 0.0016 lr: 0.02\n",
      "iteration: 219790 loss: 0.0017 lr: 0.02\n",
      "iteration: 219800 loss: 0.0018 lr: 0.02\n",
      "iteration: 219810 loss: 0.0017 lr: 0.02\n",
      "iteration: 219820 loss: 0.0017 lr: 0.02\n",
      "iteration: 219830 loss: 0.0018 lr: 0.02\n",
      "iteration: 219840 loss: 0.0022 lr: 0.02\n",
      "iteration: 219850 loss: 0.0022 lr: 0.02\n",
      "iteration: 219860 loss: 0.0025 lr: 0.02\n",
      "iteration: 219870 loss: 0.0018 lr: 0.02\n",
      "iteration: 219880 loss: 0.0018 lr: 0.02\n",
      "iteration: 219890 loss: 0.0015 lr: 0.02\n",
      "iteration: 219900 loss: 0.0017 lr: 0.02\n",
      "iteration: 219910 loss: 0.0017 lr: 0.02\n",
      "iteration: 219920 loss: 0.0016 lr: 0.02\n",
      "iteration: 219930 loss: 0.0014 lr: 0.02\n",
      "iteration: 219940 loss: 0.0019 lr: 0.02\n",
      "iteration: 219950 loss: 0.0023 lr: 0.02\n",
      "iteration: 219960 loss: 0.0013 lr: 0.02\n",
      "iteration: 219970 loss: 0.0018 lr: 0.02\n",
      "iteration: 219980 loss: 0.0019 lr: 0.02\n",
      "iteration: 219990 loss: 0.0022 lr: 0.02\n",
      "iteration: 220000 loss: 0.0013 lr: 0.02\n",
      "iteration: 220010 loss: 0.0018 lr: 0.02\n",
      "iteration: 220020 loss: 0.0019 lr: 0.02\n",
      "iteration: 220030 loss: 0.0019 lr: 0.02\n",
      "iteration: 220040 loss: 0.0018 lr: 0.02\n",
      "iteration: 220050 loss: 0.0013 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 220060 loss: 0.0024 lr: 0.02\n",
      "iteration: 220070 loss: 0.0019 lr: 0.02\n",
      "iteration: 220080 loss: 0.0021 lr: 0.02\n",
      "iteration: 220090 loss: 0.0017 lr: 0.02\n",
      "iteration: 220100 loss: 0.0027 lr: 0.02\n",
      "iteration: 220110 loss: 0.0026 lr: 0.02\n",
      "iteration: 220120 loss: 0.0024 lr: 0.02\n",
      "iteration: 220130 loss: 0.0020 lr: 0.02\n",
      "iteration: 220140 loss: 0.0018 lr: 0.02\n",
      "iteration: 220150 loss: 0.0020 lr: 0.02\n",
      "iteration: 220160 loss: 0.0017 lr: 0.02\n",
      "iteration: 220170 loss: 0.0018 lr: 0.02\n",
      "iteration: 220180 loss: 0.0021 lr: 0.02\n",
      "iteration: 220190 loss: 0.0022 lr: 0.02\n",
      "iteration: 220200 loss: 0.0021 lr: 0.02\n",
      "iteration: 220210 loss: 0.0016 lr: 0.02\n",
      "iteration: 220220 loss: 0.0017 lr: 0.02\n",
      "iteration: 220230 loss: 0.0018 lr: 0.02\n",
      "iteration: 220240 loss: 0.0016 lr: 0.02\n",
      "iteration: 220250 loss: 0.0017 lr: 0.02\n",
      "iteration: 220260 loss: 0.0016 lr: 0.02\n",
      "iteration: 220270 loss: 0.0017 lr: 0.02\n",
      "iteration: 220280 loss: 0.0025 lr: 0.02\n",
      "iteration: 220290 loss: 0.0019 lr: 0.02\n",
      "iteration: 220300 loss: 0.0020 lr: 0.02\n",
      "iteration: 220310 loss: 0.0020 lr: 0.02\n",
      "iteration: 220320 loss: 0.0018 lr: 0.02\n",
      "iteration: 220330 loss: 0.0021 lr: 0.02\n",
      "iteration: 220340 loss: 0.0017 lr: 0.02\n",
      "iteration: 220350 loss: 0.0020 lr: 0.02\n",
      "iteration: 220360 loss: 0.0020 lr: 0.02\n",
      "iteration: 220370 loss: 0.0026 lr: 0.02\n",
      "iteration: 220380 loss: 0.0019 lr: 0.02\n",
      "iteration: 220390 loss: 0.0023 lr: 0.02\n",
      "iteration: 220400 loss: 0.0023 lr: 0.02\n",
      "iteration: 220410 loss: 0.0016 lr: 0.02\n",
      "iteration: 220420 loss: 0.0017 lr: 0.02\n",
      "iteration: 220430 loss: 0.0020 lr: 0.02\n",
      "iteration: 220440 loss: 0.0015 lr: 0.02\n",
      "iteration: 220450 loss: 0.0013 lr: 0.02\n",
      "iteration: 220460 loss: 0.0018 lr: 0.02\n",
      "iteration: 220470 loss: 0.0022 lr: 0.02\n",
      "iteration: 220480 loss: 0.0017 lr: 0.02\n",
      "iteration: 220490 loss: 0.0019 lr: 0.02\n",
      "iteration: 220500 loss: 0.0023 lr: 0.02\n",
      "iteration: 220510 loss: 0.0015 lr: 0.02\n",
      "iteration: 220520 loss: 0.0013 lr: 0.02\n",
      "iteration: 220530 loss: 0.0019 lr: 0.02\n",
      "iteration: 220540 loss: 0.0017 lr: 0.02\n",
      "iteration: 220550 loss: 0.0036 lr: 0.02\n",
      "iteration: 220560 loss: 0.0019 lr: 0.02\n",
      "iteration: 220570 loss: 0.0025 lr: 0.02\n",
      "iteration: 220580 loss: 0.0020 lr: 0.02\n",
      "iteration: 220590 loss: 0.0016 lr: 0.02\n",
      "iteration: 220600 loss: 0.0025 lr: 0.02\n",
      "iteration: 220610 loss: 0.0019 lr: 0.02\n",
      "iteration: 220620 loss: 0.0016 lr: 0.02\n",
      "iteration: 220630 loss: 0.0016 lr: 0.02\n",
      "iteration: 220640 loss: 0.0018 lr: 0.02\n",
      "iteration: 220650 loss: 0.0018 lr: 0.02\n",
      "iteration: 220660 loss: 0.0019 lr: 0.02\n",
      "iteration: 220670 loss: 0.0017 lr: 0.02\n",
      "iteration: 220680 loss: 0.0019 lr: 0.02\n",
      "iteration: 220690 loss: 0.0021 lr: 0.02\n",
      "iteration: 220700 loss: 0.0018 lr: 0.02\n",
      "iteration: 220710 loss: 0.0020 lr: 0.02\n",
      "iteration: 220720 loss: 0.0024 lr: 0.02\n",
      "iteration: 220730 loss: 0.0019 lr: 0.02\n",
      "iteration: 220740 loss: 0.0018 lr: 0.02\n",
      "iteration: 220750 loss: 0.0019 lr: 0.02\n",
      "iteration: 220760 loss: 0.0014 lr: 0.02\n",
      "iteration: 220770 loss: 0.0021 lr: 0.02\n",
      "iteration: 220780 loss: 0.0019 lr: 0.02\n",
      "iteration: 220790 loss: 0.0024 lr: 0.02\n",
      "iteration: 220800 loss: 0.0019 lr: 0.02\n",
      "iteration: 220810 loss: 0.0021 lr: 0.02\n",
      "iteration: 220820 loss: 0.0018 lr: 0.02\n",
      "iteration: 220830 loss: 0.0023 lr: 0.02\n",
      "iteration: 220840 loss: 0.0018 lr: 0.02\n",
      "iteration: 220850 loss: 0.0020 lr: 0.02\n",
      "iteration: 220860 loss: 0.0016 lr: 0.02\n",
      "iteration: 220870 loss: 0.0015 lr: 0.02\n",
      "iteration: 220880 loss: 0.0015 lr: 0.02\n",
      "iteration: 220890 loss: 0.0019 lr: 0.02\n",
      "iteration: 220900 loss: 0.0017 lr: 0.02\n",
      "iteration: 220910 loss: 0.0025 lr: 0.02\n",
      "iteration: 220920 loss: 0.0014 lr: 0.02\n",
      "iteration: 220930 loss: 0.0021 lr: 0.02\n",
      "iteration: 220940 loss: 0.0019 lr: 0.02\n",
      "iteration: 220950 loss: 0.0015 lr: 0.02\n",
      "iteration: 220960 loss: 0.0017 lr: 0.02\n",
      "iteration: 220970 loss: 0.0015 lr: 0.02\n",
      "iteration: 220980 loss: 0.0018 lr: 0.02\n",
      "iteration: 220990 loss: 0.0015 lr: 0.02\n",
      "iteration: 221000 loss: 0.0023 lr: 0.02\n",
      "iteration: 221010 loss: 0.0019 lr: 0.02\n",
      "iteration: 221020 loss: 0.0024 lr: 0.02\n",
      "iteration: 221030 loss: 0.0015 lr: 0.02\n",
      "iteration: 221040 loss: 0.0015 lr: 0.02\n",
      "iteration: 221050 loss: 0.0019 lr: 0.02\n",
      "iteration: 221060 loss: 0.0015 lr: 0.02\n",
      "iteration: 221070 loss: 0.0019 lr: 0.02\n",
      "iteration: 221080 loss: 0.0016 lr: 0.02\n",
      "iteration: 221090 loss: 0.0015 lr: 0.02\n",
      "iteration: 221100 loss: 0.0014 lr: 0.02\n",
      "iteration: 221110 loss: 0.0026 lr: 0.02\n",
      "iteration: 221120 loss: 0.0021 lr: 0.02\n",
      "iteration: 221130 loss: 0.0014 lr: 0.02\n",
      "iteration: 221140 loss: 0.0015 lr: 0.02\n",
      "iteration: 221150 loss: 0.0020 lr: 0.02\n",
      "iteration: 221160 loss: 0.0014 lr: 0.02\n",
      "iteration: 221170 loss: 0.0021 lr: 0.02\n",
      "iteration: 221180 loss: 0.0014 lr: 0.02\n",
      "iteration: 221190 loss: 0.0017 lr: 0.02\n",
      "iteration: 221200 loss: 0.0021 lr: 0.02\n",
      "iteration: 221210 loss: 0.0019 lr: 0.02\n",
      "iteration: 221220 loss: 0.0020 lr: 0.02\n",
      "iteration: 221230 loss: 0.0017 lr: 0.02\n",
      "iteration: 221240 loss: 0.0019 lr: 0.02\n",
      "iteration: 221250 loss: 0.0015 lr: 0.02\n",
      "iteration: 221260 loss: 0.0024 lr: 0.02\n",
      "iteration: 221270 loss: 0.0017 lr: 0.02\n",
      "iteration: 221280 loss: 0.0016 lr: 0.02\n",
      "iteration: 221290 loss: 0.0020 lr: 0.02\n",
      "iteration: 221300 loss: 0.0019 lr: 0.02\n",
      "iteration: 221310 loss: 0.0020 lr: 0.02\n",
      "iteration: 221320 loss: 0.0024 lr: 0.02\n",
      "iteration: 221330 loss: 0.0017 lr: 0.02\n",
      "iteration: 221340 loss: 0.0020 lr: 0.02\n",
      "iteration: 221350 loss: 0.0017 lr: 0.02\n",
      "iteration: 221360 loss: 0.0021 lr: 0.02\n",
      "iteration: 221370 loss: 0.0019 lr: 0.02\n",
      "iteration: 221380 loss: 0.0021 lr: 0.02\n",
      "iteration: 221390 loss: 0.0020 lr: 0.02\n",
      "iteration: 221400 loss: 0.0027 lr: 0.02\n",
      "iteration: 221410 loss: 0.0022 lr: 0.02\n",
      "iteration: 221420 loss: 0.0020 lr: 0.02\n",
      "iteration: 221430 loss: 0.0019 lr: 0.02\n",
      "iteration: 221440 loss: 0.0015 lr: 0.02\n",
      "iteration: 221450 loss: 0.0018 lr: 0.02\n",
      "iteration: 221460 loss: 0.0025 lr: 0.02\n",
      "iteration: 221470 loss: 0.0018 lr: 0.02\n",
      "iteration: 221480 loss: 0.0022 lr: 0.02\n",
      "iteration: 221490 loss: 0.0014 lr: 0.02\n",
      "iteration: 221500 loss: 0.0018 lr: 0.02\n",
      "iteration: 221510 loss: 0.0021 lr: 0.02\n",
      "iteration: 221520 loss: 0.0019 lr: 0.02\n",
      "iteration: 221530 loss: 0.0018 lr: 0.02\n",
      "iteration: 221540 loss: 0.0023 lr: 0.02\n",
      "iteration: 221550 loss: 0.0023 lr: 0.02\n",
      "iteration: 221560 loss: 0.0018 lr: 0.02\n",
      "iteration: 221570 loss: 0.0021 lr: 0.02\n",
      "iteration: 221580 loss: 0.0016 lr: 0.02\n",
      "iteration: 221590 loss: 0.0013 lr: 0.02\n",
      "iteration: 221600 loss: 0.0014 lr: 0.02\n",
      "iteration: 221610 loss: 0.0020 lr: 0.02\n",
      "iteration: 221620 loss: 0.0017 lr: 0.02\n",
      "iteration: 221630 loss: 0.0016 lr: 0.02\n",
      "iteration: 221640 loss: 0.0021 lr: 0.02\n",
      "iteration: 221650 loss: 0.0016 lr: 0.02\n",
      "iteration: 221660 loss: 0.0021 lr: 0.02\n",
      "iteration: 221670 loss: 0.0020 lr: 0.02\n",
      "iteration: 221680 loss: 0.0017 lr: 0.02\n",
      "iteration: 221690 loss: 0.0017 lr: 0.02\n",
      "iteration: 221700 loss: 0.0018 lr: 0.02\n",
      "iteration: 221710 loss: 0.0021 lr: 0.02\n",
      "iteration: 221720 loss: 0.0014 lr: 0.02\n",
      "iteration: 221730 loss: 0.0019 lr: 0.02\n",
      "iteration: 221740 loss: 0.0021 lr: 0.02\n",
      "iteration: 221750 loss: 0.0020 lr: 0.02\n",
      "iteration: 221760 loss: 0.0022 lr: 0.02\n",
      "iteration: 221770 loss: 0.0020 lr: 0.02\n",
      "iteration: 221780 loss: 0.0019 lr: 0.02\n",
      "iteration: 221790 loss: 0.0024 lr: 0.02\n",
      "iteration: 221800 loss: 0.0018 lr: 0.02\n",
      "iteration: 221810 loss: 0.0028 lr: 0.02\n",
      "iteration: 221820 loss: 0.0020 lr: 0.02\n",
      "iteration: 221830 loss: 0.0024 lr: 0.02\n",
      "iteration: 221840 loss: 0.0020 lr: 0.02\n",
      "iteration: 221850 loss: 0.0020 lr: 0.02\n",
      "iteration: 221860 loss: 0.0020 lr: 0.02\n",
      "iteration: 221870 loss: 0.0019 lr: 0.02\n",
      "iteration: 221880 loss: 0.0020 lr: 0.02\n",
      "iteration: 221890 loss: 0.0018 lr: 0.02\n",
      "iteration: 221900 loss: 0.0018 lr: 0.02\n",
      "iteration: 221910 loss: 0.0018 lr: 0.02\n",
      "iteration: 221920 loss: 0.0023 lr: 0.02\n",
      "iteration: 221930 loss: 0.0016 lr: 0.02\n",
      "iteration: 221940 loss: 0.0014 lr: 0.02\n",
      "iteration: 221950 loss: 0.0020 lr: 0.02\n",
      "iteration: 221960 loss: 0.0017 lr: 0.02\n",
      "iteration: 221970 loss: 0.0019 lr: 0.02\n",
      "iteration: 221980 loss: 0.0017 lr: 0.02\n",
      "iteration: 221990 loss: 0.0018 lr: 0.02\n",
      "iteration: 222000 loss: 0.0020 lr: 0.02\n",
      "iteration: 222010 loss: 0.0015 lr: 0.02\n",
      "iteration: 222020 loss: 0.0017 lr: 0.02\n",
      "iteration: 222030 loss: 0.0020 lr: 0.02\n",
      "iteration: 222040 loss: 0.0017 lr: 0.02\n",
      "iteration: 222050 loss: 0.0019 lr: 0.02\n",
      "iteration: 222060 loss: 0.0017 lr: 0.02\n",
      "iteration: 222070 loss: 0.0022 lr: 0.02\n",
      "iteration: 222080 loss: 0.0016 lr: 0.02\n",
      "iteration: 222090 loss: 0.0020 lr: 0.02\n",
      "iteration: 222100 loss: 0.0018 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 222110 loss: 0.0022 lr: 0.02\n",
      "iteration: 222120 loss: 0.0014 lr: 0.02\n",
      "iteration: 222130 loss: 0.0015 lr: 0.02\n",
      "iteration: 222140 loss: 0.0025 lr: 0.02\n",
      "iteration: 222150 loss: 0.0017 lr: 0.02\n",
      "iteration: 222160 loss: 0.0021 lr: 0.02\n",
      "iteration: 222170 loss: 0.0021 lr: 0.02\n",
      "iteration: 222180 loss: 0.0016 lr: 0.02\n",
      "iteration: 222190 loss: 0.0016 lr: 0.02\n",
      "iteration: 222200 loss: 0.0015 lr: 0.02\n",
      "iteration: 222210 loss: 0.0020 lr: 0.02\n",
      "iteration: 222220 loss: 0.0019 lr: 0.02\n",
      "iteration: 222230 loss: 0.0018 lr: 0.02\n",
      "iteration: 222240 loss: 0.0028 lr: 0.02\n",
      "iteration: 222250 loss: 0.0017 lr: 0.02\n",
      "iteration: 222260 loss: 0.0022 lr: 0.02\n",
      "iteration: 222270 loss: 0.0022 lr: 0.02\n",
      "iteration: 222280 loss: 0.0018 lr: 0.02\n",
      "iteration: 222290 loss: 0.0015 lr: 0.02\n",
      "iteration: 222300 loss: 0.0021 lr: 0.02\n",
      "iteration: 222310 loss: 0.0016 lr: 0.02\n",
      "iteration: 222320 loss: 0.0019 lr: 0.02\n",
      "iteration: 222330 loss: 0.0019 lr: 0.02\n",
      "iteration: 222340 loss: 0.0024 lr: 0.02\n",
      "iteration: 222350 loss: 0.0019 lr: 0.02\n",
      "iteration: 222360 loss: 0.0027 lr: 0.02\n",
      "iteration: 222370 loss: 0.0029 lr: 0.02\n",
      "iteration: 222380 loss: 0.0021 lr: 0.02\n",
      "iteration: 222390 loss: 0.0016 lr: 0.02\n",
      "iteration: 222400 loss: 0.0024 lr: 0.02\n",
      "iteration: 222410 loss: 0.0018 lr: 0.02\n",
      "iteration: 222420 loss: 0.0021 lr: 0.02\n",
      "iteration: 222430 loss: 0.0022 lr: 0.02\n",
      "iteration: 222440 loss: 0.0017 lr: 0.02\n",
      "iteration: 222450 loss: 0.0017 lr: 0.02\n",
      "iteration: 222460 loss: 0.0018 lr: 0.02\n",
      "iteration: 222470 loss: 0.0023 lr: 0.02\n",
      "iteration: 222480 loss: 0.0016 lr: 0.02\n",
      "iteration: 222490 loss: 0.0017 lr: 0.02\n",
      "iteration: 222500 loss: 0.0020 lr: 0.02\n",
      "iteration: 222510 loss: 0.0018 lr: 0.02\n",
      "iteration: 222520 loss: 0.0017 lr: 0.02\n",
      "iteration: 222530 loss: 0.0016 lr: 0.02\n",
      "iteration: 222540 loss: 0.0022 lr: 0.02\n",
      "iteration: 222550 loss: 0.0021 lr: 0.02\n",
      "iteration: 222560 loss: 0.0014 lr: 0.02\n",
      "iteration: 222570 loss: 0.0018 lr: 0.02\n",
      "iteration: 222580 loss: 0.0022 lr: 0.02\n",
      "iteration: 222590 loss: 0.0020 lr: 0.02\n",
      "iteration: 222600 loss: 0.0018 lr: 0.02\n",
      "iteration: 222610 loss: 0.0018 lr: 0.02\n",
      "iteration: 222620 loss: 0.0018 lr: 0.02\n",
      "iteration: 222630 loss: 0.0018 lr: 0.02\n",
      "iteration: 222640 loss: 0.0025 lr: 0.02\n",
      "iteration: 222650 loss: 0.0019 lr: 0.02\n",
      "iteration: 222660 loss: 0.0015 lr: 0.02\n",
      "iteration: 222670 loss: 0.0017 lr: 0.02\n",
      "iteration: 222680 loss: 0.0013 lr: 0.02\n",
      "iteration: 222690 loss: 0.0016 lr: 0.02\n",
      "iteration: 222700 loss: 0.0021 lr: 0.02\n",
      "iteration: 222710 loss: 0.0018 lr: 0.02\n",
      "iteration: 222720 loss: 0.0016 lr: 0.02\n",
      "iteration: 222730 loss: 0.0018 lr: 0.02\n",
      "iteration: 222740 loss: 0.0017 lr: 0.02\n",
      "iteration: 222750 loss: 0.0022 lr: 0.02\n",
      "iteration: 222760 loss: 0.0017 lr: 0.02\n",
      "iteration: 222770 loss: 0.0019 lr: 0.02\n",
      "iteration: 222780 loss: 0.0018 lr: 0.02\n",
      "iteration: 222790 loss: 0.0016 lr: 0.02\n",
      "iteration: 222800 loss: 0.0021 lr: 0.02\n",
      "iteration: 222810 loss: 0.0014 lr: 0.02\n",
      "iteration: 222820 loss: 0.0018 lr: 0.02\n",
      "iteration: 222830 loss: 0.0026 lr: 0.02\n",
      "iteration: 222840 loss: 0.0019 lr: 0.02\n",
      "iteration: 222850 loss: 0.0019 lr: 0.02\n",
      "iteration: 222860 loss: 0.0017 lr: 0.02\n",
      "iteration: 222870 loss: 0.0024 lr: 0.02\n",
      "iteration: 222880 loss: 0.0032 lr: 0.02\n",
      "iteration: 222890 loss: 0.0034 lr: 0.02\n",
      "iteration: 222900 loss: 0.0018 lr: 0.02\n",
      "iteration: 222910 loss: 0.0017 lr: 0.02\n",
      "iteration: 222920 loss: 0.0021 lr: 0.02\n",
      "iteration: 222930 loss: 0.0021 lr: 0.02\n",
      "iteration: 222940 loss: 0.0020 lr: 0.02\n",
      "iteration: 222950 loss: 0.0019 lr: 0.02\n",
      "iteration: 222960 loss: 0.0023 lr: 0.02\n",
      "iteration: 222970 loss: 0.0021 lr: 0.02\n",
      "iteration: 222980 loss: 0.0024 lr: 0.02\n",
      "iteration: 222990 loss: 0.0025 lr: 0.02\n",
      "iteration: 223000 loss: 0.0022 lr: 0.02\n",
      "iteration: 223010 loss: 0.0026 lr: 0.02\n",
      "iteration: 223020 loss: 0.0018 lr: 0.02\n",
      "iteration: 223030 loss: 0.0017 lr: 0.02\n",
      "iteration: 223040 loss: 0.0019 lr: 0.02\n",
      "iteration: 223050 loss: 0.0015 lr: 0.02\n",
      "iteration: 223060 loss: 0.0019 lr: 0.02\n",
      "iteration: 223070 loss: 0.0027 lr: 0.02\n",
      "iteration: 223080 loss: 0.0022 lr: 0.02\n",
      "iteration: 223090 loss: 0.0019 lr: 0.02\n",
      "iteration: 223100 loss: 0.0020 lr: 0.02\n",
      "iteration: 223110 loss: 0.0022 lr: 0.02\n",
      "iteration: 223120 loss: 0.0014 lr: 0.02\n",
      "iteration: 223130 loss: 0.0020 lr: 0.02\n",
      "iteration: 223140 loss: 0.0019 lr: 0.02\n",
      "iteration: 223150 loss: 0.0017 lr: 0.02\n",
      "iteration: 223160 loss: 0.0019 lr: 0.02\n",
      "iteration: 223170 loss: 0.0016 lr: 0.02\n",
      "iteration: 223180 loss: 0.0017 lr: 0.02\n",
      "iteration: 223190 loss: 0.0015 lr: 0.02\n",
      "iteration: 223200 loss: 0.0020 lr: 0.02\n",
      "iteration: 223210 loss: 0.0019 lr: 0.02\n",
      "iteration: 223220 loss: 0.0020 lr: 0.02\n",
      "iteration: 223230 loss: 0.0020 lr: 0.02\n",
      "iteration: 223240 loss: 0.0020 lr: 0.02\n",
      "iteration: 223250 loss: 0.0018 lr: 0.02\n",
      "iteration: 223260 loss: 0.0018 lr: 0.02\n",
      "iteration: 223270 loss: 0.0020 lr: 0.02\n",
      "iteration: 223280 loss: 0.0018 lr: 0.02\n",
      "iteration: 223290 loss: 0.0023 lr: 0.02\n",
      "iteration: 223300 loss: 0.0023 lr: 0.02\n",
      "iteration: 223310 loss: 0.0018 lr: 0.02\n",
      "iteration: 223320 loss: 0.0018 lr: 0.02\n",
      "iteration: 223330 loss: 0.0018 lr: 0.02\n",
      "iteration: 223340 loss: 0.0019 lr: 0.02\n",
      "iteration: 223350 loss: 0.0021 lr: 0.02\n",
      "iteration: 223360 loss: 0.0029 lr: 0.02\n",
      "iteration: 223370 loss: 0.0020 lr: 0.02\n",
      "iteration: 223380 loss: 0.0020 lr: 0.02\n",
      "iteration: 223390 loss: 0.0023 lr: 0.02\n",
      "iteration: 223400 loss: 0.0018 lr: 0.02\n",
      "iteration: 223410 loss: 0.0019 lr: 0.02\n",
      "iteration: 223420 loss: 0.0018 lr: 0.02\n",
      "iteration: 223430 loss: 0.0018 lr: 0.02\n",
      "iteration: 223440 loss: 0.0021 lr: 0.02\n",
      "iteration: 223450 loss: 0.0019 lr: 0.02\n",
      "iteration: 223460 loss: 0.0023 lr: 0.02\n",
      "iteration: 223470 loss: 0.0016 lr: 0.02\n",
      "iteration: 223480 loss: 0.0031 lr: 0.02\n",
      "iteration: 223490 loss: 0.0018 lr: 0.02\n",
      "iteration: 223500 loss: 0.0017 lr: 0.02\n",
      "iteration: 223510 loss: 0.0019 lr: 0.02\n",
      "iteration: 223520 loss: 0.0025 lr: 0.02\n",
      "iteration: 223530 loss: 0.0023 lr: 0.02\n",
      "iteration: 223540 loss: 0.0019 lr: 0.02\n",
      "iteration: 223550 loss: 0.0018 lr: 0.02\n",
      "iteration: 223560 loss: 0.0021 lr: 0.02\n",
      "iteration: 223570 loss: 0.0021 lr: 0.02\n",
      "iteration: 223580 loss: 0.0017 lr: 0.02\n",
      "iteration: 223590 loss: 0.0017 lr: 0.02\n",
      "iteration: 223600 loss: 0.0024 lr: 0.02\n",
      "iteration: 223610 loss: 0.0020 lr: 0.02\n",
      "iteration: 223620 loss: 0.0016 lr: 0.02\n",
      "iteration: 223630 loss: 0.0016 lr: 0.02\n",
      "iteration: 223640 loss: 0.0024 lr: 0.02\n",
      "iteration: 223650 loss: 0.0015 lr: 0.02\n",
      "iteration: 223660 loss: 0.0024 lr: 0.02\n",
      "iteration: 223670 loss: 0.0018 lr: 0.02\n",
      "iteration: 223680 loss: 0.0021 lr: 0.02\n",
      "iteration: 223690 loss: 0.0025 lr: 0.02\n",
      "iteration: 223700 loss: 0.0024 lr: 0.02\n",
      "iteration: 223710 loss: 0.0019 lr: 0.02\n",
      "iteration: 223720 loss: 0.0022 lr: 0.02\n",
      "iteration: 223730 loss: 0.0016 lr: 0.02\n",
      "iteration: 223740 loss: 0.0018 lr: 0.02\n",
      "iteration: 223750 loss: 0.0024 lr: 0.02\n",
      "iteration: 223760 loss: 0.0019 lr: 0.02\n",
      "iteration: 223770 loss: 0.0016 lr: 0.02\n",
      "iteration: 223780 loss: 0.0019 lr: 0.02\n",
      "iteration: 223790 loss: 0.0023 lr: 0.02\n",
      "iteration: 223800 loss: 0.0019 lr: 0.02\n",
      "iteration: 223810 loss: 0.0024 lr: 0.02\n",
      "iteration: 223820 loss: 0.0023 lr: 0.02\n",
      "iteration: 223830 loss: 0.0015 lr: 0.02\n",
      "iteration: 223840 loss: 0.0015 lr: 0.02\n",
      "iteration: 223850 loss: 0.0020 lr: 0.02\n",
      "iteration: 223860 loss: 0.0020 lr: 0.02\n",
      "iteration: 223870 loss: 0.0017 lr: 0.02\n",
      "iteration: 223880 loss: 0.0023 lr: 0.02\n",
      "iteration: 223890 loss: 0.0020 lr: 0.02\n",
      "iteration: 223900 loss: 0.0019 lr: 0.02\n",
      "iteration: 223910 loss: 0.0016 lr: 0.02\n",
      "iteration: 223920 loss: 0.0019 lr: 0.02\n",
      "iteration: 223930 loss: 0.0020 lr: 0.02\n",
      "iteration: 223940 loss: 0.0016 lr: 0.02\n",
      "iteration: 223950 loss: 0.0018 lr: 0.02\n",
      "iteration: 223960 loss: 0.0017 lr: 0.02\n",
      "iteration: 223970 loss: 0.0022 lr: 0.02\n",
      "iteration: 223980 loss: 0.0018 lr: 0.02\n",
      "iteration: 223990 loss: 0.0017 lr: 0.02\n",
      "iteration: 224000 loss: 0.0017 lr: 0.02\n",
      "iteration: 224010 loss: 0.0025 lr: 0.02\n",
      "iteration: 224020 loss: 0.0021 lr: 0.02\n",
      "iteration: 224030 loss: 0.0017 lr: 0.02\n",
      "iteration: 224040 loss: 0.0020 lr: 0.02\n",
      "iteration: 224050 loss: 0.0022 lr: 0.02\n",
      "iteration: 224060 loss: 0.0021 lr: 0.02\n",
      "iteration: 224070 loss: 0.0019 lr: 0.02\n",
      "iteration: 224080 loss: 0.0018 lr: 0.02\n",
      "iteration: 224090 loss: 0.0021 lr: 0.02\n",
      "iteration: 224100 loss: 0.0021 lr: 0.02\n",
      "iteration: 224110 loss: 0.0016 lr: 0.02\n",
      "iteration: 224120 loss: 0.0021 lr: 0.02\n",
      "iteration: 224130 loss: 0.0017 lr: 0.02\n",
      "iteration: 224140 loss: 0.0022 lr: 0.02\n",
      "iteration: 224150 loss: 0.0016 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 224160 loss: 0.0022 lr: 0.02\n",
      "iteration: 224170 loss: 0.0022 lr: 0.02\n",
      "iteration: 224180 loss: 0.0021 lr: 0.02\n",
      "iteration: 224190 loss: 0.0020 lr: 0.02\n",
      "iteration: 224200 loss: 0.0020 lr: 0.02\n",
      "iteration: 224210 loss: 0.0018 lr: 0.02\n",
      "iteration: 224220 loss: 0.0020 lr: 0.02\n",
      "iteration: 224230 loss: 0.0015 lr: 0.02\n",
      "iteration: 224240 loss: 0.0022 lr: 0.02\n",
      "iteration: 224250 loss: 0.0022 lr: 0.02\n",
      "iteration: 224260 loss: 0.0026 lr: 0.02\n",
      "iteration: 224270 loss: 0.0017 lr: 0.02\n",
      "iteration: 224280 loss: 0.0018 lr: 0.02\n",
      "iteration: 224290 loss: 0.0020 lr: 0.02\n",
      "iteration: 224300 loss: 0.0017 lr: 0.02\n",
      "iteration: 224310 loss: 0.0018 lr: 0.02\n",
      "iteration: 224320 loss: 0.0024 lr: 0.02\n",
      "iteration: 224330 loss: 0.0015 lr: 0.02\n",
      "iteration: 224340 loss: 0.0019 lr: 0.02\n",
      "iteration: 224350 loss: 0.0018 lr: 0.02\n",
      "iteration: 224360 loss: 0.0016 lr: 0.02\n",
      "iteration: 224370 loss: 0.0017 lr: 0.02\n",
      "iteration: 224380 loss: 0.0017 lr: 0.02\n",
      "iteration: 224390 loss: 0.0020 lr: 0.02\n",
      "iteration: 224400 loss: 0.0020 lr: 0.02\n",
      "iteration: 224410 loss: 0.0018 lr: 0.02\n",
      "iteration: 224420 loss: 0.0020 lr: 0.02\n",
      "iteration: 224430 loss: 0.0020 lr: 0.02\n",
      "iteration: 224440 loss: 0.0016 lr: 0.02\n",
      "iteration: 224450 loss: 0.0015 lr: 0.02\n",
      "iteration: 224460 loss: 0.0017 lr: 0.02\n",
      "iteration: 224470 loss: 0.0016 lr: 0.02\n",
      "iteration: 224480 loss: 0.0025 lr: 0.02\n",
      "iteration: 224490 loss: 0.0017 lr: 0.02\n",
      "iteration: 224500 loss: 0.0021 lr: 0.02\n",
      "iteration: 224510 loss: 0.0018 lr: 0.02\n",
      "iteration: 224520 loss: 0.0020 lr: 0.02\n",
      "iteration: 224530 loss: 0.0024 lr: 0.02\n",
      "iteration: 224540 loss: 0.0020 lr: 0.02\n",
      "iteration: 224550 loss: 0.0018 lr: 0.02\n",
      "iteration: 224560 loss: 0.0022 lr: 0.02\n",
      "iteration: 224570 loss: 0.0019 lr: 0.02\n",
      "iteration: 224580 loss: 0.0016 lr: 0.02\n",
      "iteration: 224590 loss: 0.0018 lr: 0.02\n",
      "iteration: 224600 loss: 0.0014 lr: 0.02\n",
      "iteration: 224610 loss: 0.0025 lr: 0.02\n",
      "iteration: 224620 loss: 0.0020 lr: 0.02\n",
      "iteration: 224630 loss: 0.0020 lr: 0.02\n",
      "iteration: 224640 loss: 0.0017 lr: 0.02\n",
      "iteration: 224650 loss: 0.0017 lr: 0.02\n",
      "iteration: 224660 loss: 0.0019 lr: 0.02\n",
      "iteration: 224670 loss: 0.0018 lr: 0.02\n",
      "iteration: 224680 loss: 0.0021 lr: 0.02\n",
      "iteration: 224690 loss: 0.0018 lr: 0.02\n",
      "iteration: 224700 loss: 0.0015 lr: 0.02\n",
      "iteration: 224710 loss: 0.0021 lr: 0.02\n",
      "iteration: 224720 loss: 0.0020 lr: 0.02\n",
      "iteration: 224730 loss: 0.0018 lr: 0.02\n",
      "iteration: 224740 loss: 0.0024 lr: 0.02\n",
      "iteration: 224750 loss: 0.0020 lr: 0.02\n",
      "iteration: 224760 loss: 0.0020 lr: 0.02\n",
      "iteration: 224770 loss: 0.0020 lr: 0.02\n",
      "iteration: 224780 loss: 0.0014 lr: 0.02\n",
      "iteration: 224790 loss: 0.0016 lr: 0.02\n",
      "iteration: 224800 loss: 0.0019 lr: 0.02\n",
      "iteration: 224810 loss: 0.0013 lr: 0.02\n",
      "iteration: 224820 loss: 0.0016 lr: 0.02\n",
      "iteration: 224830 loss: 0.0018 lr: 0.02\n",
      "iteration: 224840 loss: 0.0021 lr: 0.02\n",
      "iteration: 224850 loss: 0.0018 lr: 0.02\n",
      "iteration: 224860 loss: 0.0015 lr: 0.02\n",
      "iteration: 224870 loss: 0.0023 lr: 0.02\n",
      "iteration: 224880 loss: 0.0023 lr: 0.02\n",
      "iteration: 224890 loss: 0.0027 lr: 0.02\n",
      "iteration: 224900 loss: 0.0022 lr: 0.02\n",
      "iteration: 224910 loss: 0.0019 lr: 0.02\n",
      "iteration: 224920 loss: 0.0016 lr: 0.02\n",
      "iteration: 224930 loss: 0.0020 lr: 0.02\n",
      "iteration: 224940 loss: 0.0017 lr: 0.02\n",
      "iteration: 224950 loss: 0.0016 lr: 0.02\n",
      "iteration: 224960 loss: 0.0020 lr: 0.02\n",
      "iteration: 224970 loss: 0.0018 lr: 0.02\n",
      "iteration: 224980 loss: 0.0019 lr: 0.02\n",
      "iteration: 224990 loss: 0.0029 lr: 0.02\n",
      "iteration: 225000 loss: 0.0025 lr: 0.02\n",
      "iteration: 225010 loss: 0.0027 lr: 0.02\n",
      "iteration: 225020 loss: 0.0025 lr: 0.02\n",
      "iteration: 225030 loss: 0.0020 lr: 0.02\n",
      "iteration: 225040 loss: 0.0017 lr: 0.02\n",
      "iteration: 225050 loss: 0.0017 lr: 0.02\n",
      "iteration: 225060 loss: 0.0017 lr: 0.02\n",
      "iteration: 225070 loss: 0.0018 lr: 0.02\n",
      "iteration: 225080 loss: 0.0015 lr: 0.02\n",
      "iteration: 225090 loss: 0.0021 lr: 0.02\n",
      "iteration: 225100 loss: 0.0022 lr: 0.02\n",
      "iteration: 225110 loss: 0.0013 lr: 0.02\n",
      "iteration: 225120 loss: 0.0025 lr: 0.02\n",
      "iteration: 225130 loss: 0.0017 lr: 0.02\n",
      "iteration: 225140 loss: 0.0020 lr: 0.02\n",
      "iteration: 225150 loss: 0.0018 lr: 0.02\n",
      "iteration: 225160 loss: 0.0032 lr: 0.02\n",
      "iteration: 225170 loss: 0.0018 lr: 0.02\n",
      "iteration: 225180 loss: 0.0018 lr: 0.02\n",
      "iteration: 225190 loss: 0.0021 lr: 0.02\n",
      "iteration: 225200 loss: 0.0019 lr: 0.02\n",
      "iteration: 225210 loss: 0.0030 lr: 0.02\n",
      "iteration: 225220 loss: 0.0022 lr: 0.02\n",
      "iteration: 225230 loss: 0.0016 lr: 0.02\n",
      "iteration: 225240 loss: 0.0021 lr: 0.02\n",
      "iteration: 225250 loss: 0.0020 lr: 0.02\n",
      "iteration: 225260 loss: 0.0020 lr: 0.02\n",
      "iteration: 225270 loss: 0.0018 lr: 0.02\n",
      "iteration: 225280 loss: 0.0018 lr: 0.02\n",
      "iteration: 225290 loss: 0.0018 lr: 0.02\n",
      "iteration: 225300 loss: 0.0016 lr: 0.02\n",
      "iteration: 225310 loss: 0.0016 lr: 0.02\n",
      "iteration: 225320 loss: 0.0025 lr: 0.02\n",
      "iteration: 225330 loss: 0.0014 lr: 0.02\n",
      "iteration: 225340 loss: 0.0016 lr: 0.02\n",
      "iteration: 225350 loss: 0.0017 lr: 0.02\n",
      "iteration: 225360 loss: 0.0017 lr: 0.02\n",
      "iteration: 225370 loss: 0.0023 lr: 0.02\n",
      "iteration: 225380 loss: 0.0026 lr: 0.02\n",
      "iteration: 225390 loss: 0.0023 lr: 0.02\n",
      "iteration: 225400 loss: 0.0017 lr: 0.02\n",
      "iteration: 225410 loss: 0.0018 lr: 0.02\n",
      "iteration: 225420 loss: 0.0022 lr: 0.02\n",
      "iteration: 225430 loss: 0.0016 lr: 0.02\n",
      "iteration: 225440 loss: 0.0027 lr: 0.02\n",
      "iteration: 225450 loss: 0.0015 lr: 0.02\n",
      "iteration: 225460 loss: 0.0018 lr: 0.02\n",
      "iteration: 225470 loss: 0.0017 lr: 0.02\n",
      "iteration: 225480 loss: 0.0017 lr: 0.02\n",
      "iteration: 225490 loss: 0.0020 lr: 0.02\n",
      "iteration: 225500 loss: 0.0015 lr: 0.02\n",
      "iteration: 225510 loss: 0.0020 lr: 0.02\n",
      "iteration: 225520 loss: 0.0017 lr: 0.02\n",
      "iteration: 225530 loss: 0.0017 lr: 0.02\n",
      "iteration: 225540 loss: 0.0021 lr: 0.02\n",
      "iteration: 225550 loss: 0.0021 lr: 0.02\n",
      "iteration: 225560 loss: 0.0022 lr: 0.02\n",
      "iteration: 225570 loss: 0.0019 lr: 0.02\n",
      "iteration: 225580 loss: 0.0018 lr: 0.02\n",
      "iteration: 225590 loss: 0.0016 lr: 0.02\n",
      "iteration: 225600 loss: 0.0015 lr: 0.02\n",
      "iteration: 225610 loss: 0.0016 lr: 0.02\n",
      "iteration: 225620 loss: 0.0017 lr: 0.02\n",
      "iteration: 225630 loss: 0.0023 lr: 0.02\n",
      "iteration: 225640 loss: 0.0019 lr: 0.02\n",
      "iteration: 225650 loss: 0.0020 lr: 0.02\n",
      "iteration: 225660 loss: 0.0021 lr: 0.02\n",
      "iteration: 225670 loss: 0.0019 lr: 0.02\n",
      "iteration: 225680 loss: 0.0020 lr: 0.02\n",
      "iteration: 225690 loss: 0.0034 lr: 0.02\n",
      "iteration: 225700 loss: 0.0022 lr: 0.02\n",
      "iteration: 225710 loss: 0.0022 lr: 0.02\n",
      "iteration: 225720 loss: 0.0019 lr: 0.02\n",
      "iteration: 225730 loss: 0.0020 lr: 0.02\n",
      "iteration: 225740 loss: 0.0021 lr: 0.02\n",
      "iteration: 225750 loss: 0.0020 lr: 0.02\n",
      "iteration: 225760 loss: 0.0021 lr: 0.02\n",
      "iteration: 225770 loss: 0.0017 lr: 0.02\n",
      "iteration: 225780 loss: 0.0022 lr: 0.02\n",
      "iteration: 225790 loss: 0.0024 lr: 0.02\n",
      "iteration: 225800 loss: 0.0021 lr: 0.02\n",
      "iteration: 225810 loss: 0.0017 lr: 0.02\n",
      "iteration: 225820 loss: 0.0021 lr: 0.02\n",
      "iteration: 225830 loss: 0.0018 lr: 0.02\n",
      "iteration: 225840 loss: 0.0019 lr: 0.02\n",
      "iteration: 225850 loss: 0.0022 lr: 0.02\n",
      "iteration: 225860 loss: 0.0023 lr: 0.02\n",
      "iteration: 225870 loss: 0.0026 lr: 0.02\n",
      "iteration: 225880 loss: 0.0015 lr: 0.02\n",
      "iteration: 225890 loss: 0.0020 lr: 0.02\n",
      "iteration: 225900 loss: 0.0020 lr: 0.02\n",
      "iteration: 225910 loss: 0.0022 lr: 0.02\n",
      "iteration: 225920 loss: 0.0016 lr: 0.02\n",
      "iteration: 225930 loss: 0.0013 lr: 0.02\n",
      "iteration: 225940 loss: 0.0018 lr: 0.02\n",
      "iteration: 225950 loss: 0.0019 lr: 0.02\n",
      "iteration: 225960 loss: 0.0022 lr: 0.02\n",
      "iteration: 225970 loss: 0.0015 lr: 0.02\n",
      "iteration: 225980 loss: 0.0020 lr: 0.02\n",
      "iteration: 225990 loss: 0.0018 lr: 0.02\n",
      "iteration: 226000 loss: 0.0023 lr: 0.02\n",
      "iteration: 226010 loss: 0.0022 lr: 0.02\n",
      "iteration: 226020 loss: 0.0017 lr: 0.02\n",
      "iteration: 226030 loss: 0.0028 lr: 0.02\n",
      "iteration: 226040 loss: 0.0023 lr: 0.02\n",
      "iteration: 226050 loss: 0.0014 lr: 0.02\n",
      "iteration: 226060 loss: 0.0017 lr: 0.02\n",
      "iteration: 226070 loss: 0.0027 lr: 0.02\n",
      "iteration: 226080 loss: 0.0015 lr: 0.02\n",
      "iteration: 226090 loss: 0.0015 lr: 0.02\n",
      "iteration: 226100 loss: 0.0018 lr: 0.02\n",
      "iteration: 226110 loss: 0.0029 lr: 0.02\n",
      "iteration: 226120 loss: 0.0028 lr: 0.02\n",
      "iteration: 226130 loss: 0.0023 lr: 0.02\n",
      "iteration: 226140 loss: 0.0019 lr: 0.02\n",
      "iteration: 226150 loss: 0.0025 lr: 0.02\n",
      "iteration: 226160 loss: 0.0024 lr: 0.02\n",
      "iteration: 226170 loss: 0.0018 lr: 0.02\n",
      "iteration: 226180 loss: 0.0026 lr: 0.02\n",
      "iteration: 226190 loss: 0.0014 lr: 0.02\n",
      "iteration: 226200 loss: 0.0018 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 226210 loss: 0.0024 lr: 0.02\n",
      "iteration: 226220 loss: 0.0020 lr: 0.02\n",
      "iteration: 226230 loss: 0.0022 lr: 0.02\n",
      "iteration: 226240 loss: 0.0019 lr: 0.02\n",
      "iteration: 226250 loss: 0.0029 lr: 0.02\n",
      "iteration: 226260 loss: 0.0018 lr: 0.02\n",
      "iteration: 226270 loss: 0.0022 lr: 0.02\n",
      "iteration: 226280 loss: 0.0020 lr: 0.02\n",
      "iteration: 226290 loss: 0.0019 lr: 0.02\n",
      "iteration: 226300 loss: 0.0018 lr: 0.02\n",
      "iteration: 226310 loss: 0.0019 lr: 0.02\n",
      "iteration: 226320 loss: 0.0016 lr: 0.02\n",
      "iteration: 226330 loss: 0.0018 lr: 0.02\n",
      "iteration: 226340 loss: 0.0018 lr: 0.02\n",
      "iteration: 226350 loss: 0.0014 lr: 0.02\n",
      "iteration: 226360 loss: 0.0017 lr: 0.02\n",
      "iteration: 226370 loss: 0.0023 lr: 0.02\n",
      "iteration: 226380 loss: 0.0017 lr: 0.02\n",
      "iteration: 226390 loss: 0.0017 lr: 0.02\n",
      "iteration: 226400 loss: 0.0019 lr: 0.02\n",
      "iteration: 226410 loss: 0.0019 lr: 0.02\n",
      "iteration: 226420 loss: 0.0017 lr: 0.02\n",
      "iteration: 226430 loss: 0.0019 lr: 0.02\n",
      "iteration: 226440 loss: 0.0016 lr: 0.02\n",
      "iteration: 226450 loss: 0.0018 lr: 0.02\n",
      "iteration: 226460 loss: 0.0017 lr: 0.02\n",
      "iteration: 226470 loss: 0.0016 lr: 0.02\n",
      "iteration: 226480 loss: 0.0017 lr: 0.02\n",
      "iteration: 226490 loss: 0.0015 lr: 0.02\n",
      "iteration: 226500 loss: 0.0016 lr: 0.02\n",
      "iteration: 226510 loss: 0.0016 lr: 0.02\n",
      "iteration: 226520 loss: 0.0017 lr: 0.02\n",
      "iteration: 226530 loss: 0.0019 lr: 0.02\n",
      "iteration: 226540 loss: 0.0021 lr: 0.02\n",
      "iteration: 226550 loss: 0.0021 lr: 0.02\n",
      "iteration: 226560 loss: 0.0018 lr: 0.02\n",
      "iteration: 226570 loss: 0.0017 lr: 0.02\n",
      "iteration: 226580 loss: 0.0021 lr: 0.02\n",
      "iteration: 226590 loss: 0.0018 lr: 0.02\n",
      "iteration: 226600 loss: 0.0020 lr: 0.02\n",
      "iteration: 226610 loss: 0.0017 lr: 0.02\n",
      "iteration: 226620 loss: 0.0018 lr: 0.02\n",
      "iteration: 226630 loss: 0.0020 lr: 0.02\n",
      "iteration: 226640 loss: 0.0014 lr: 0.02\n",
      "iteration: 226650 loss: 0.0018 lr: 0.02\n",
      "iteration: 226660 loss: 0.0016 lr: 0.02\n",
      "iteration: 226670 loss: 0.0021 lr: 0.02\n",
      "iteration: 226680 loss: 0.0020 lr: 0.02\n",
      "iteration: 226690 loss: 0.0017 lr: 0.02\n",
      "iteration: 226700 loss: 0.0023 lr: 0.02\n",
      "iteration: 226710 loss: 0.0016 lr: 0.02\n",
      "iteration: 226720 loss: 0.0018 lr: 0.02\n",
      "iteration: 226730 loss: 0.0015 lr: 0.02\n",
      "iteration: 226740 loss: 0.0018 lr: 0.02\n",
      "iteration: 226750 loss: 0.0016 lr: 0.02\n",
      "iteration: 226760 loss: 0.0021 lr: 0.02\n",
      "iteration: 226770 loss: 0.0020 lr: 0.02\n",
      "iteration: 226780 loss: 0.0015 lr: 0.02\n",
      "iteration: 226790 loss: 0.0015 lr: 0.02\n",
      "iteration: 226800 loss: 0.0019 lr: 0.02\n",
      "iteration: 226810 loss: 0.0020 lr: 0.02\n",
      "iteration: 226820 loss: 0.0020 lr: 0.02\n",
      "iteration: 226830 loss: 0.0014 lr: 0.02\n",
      "iteration: 226840 loss: 0.0018 lr: 0.02\n",
      "iteration: 226850 loss: 0.0018 lr: 0.02\n",
      "iteration: 226860 loss: 0.0016 lr: 0.02\n",
      "iteration: 226870 loss: 0.0016 lr: 0.02\n",
      "iteration: 226880 loss: 0.0039 lr: 0.02\n",
      "iteration: 226890 loss: 0.0025 lr: 0.02\n",
      "iteration: 226900 loss: 0.0020 lr: 0.02\n",
      "iteration: 226910 loss: 0.0020 lr: 0.02\n",
      "iteration: 226920 loss: 0.0020 lr: 0.02\n",
      "iteration: 226930 loss: 0.0022 lr: 0.02\n",
      "iteration: 226940 loss: 0.0016 lr: 0.02\n",
      "iteration: 226950 loss: 0.0019 lr: 0.02\n",
      "iteration: 226960 loss: 0.0015 lr: 0.02\n",
      "iteration: 226970 loss: 0.0017 lr: 0.02\n",
      "iteration: 226980 loss: 0.0017 lr: 0.02\n",
      "iteration: 226990 loss: 0.0021 lr: 0.02\n",
      "iteration: 227000 loss: 0.0019 lr: 0.02\n",
      "iteration: 227010 loss: 0.0024 lr: 0.02\n",
      "iteration: 227020 loss: 0.0019 lr: 0.02\n",
      "iteration: 227030 loss: 0.0022 lr: 0.02\n",
      "iteration: 227040 loss: 0.0022 lr: 0.02\n",
      "iteration: 227050 loss: 0.0018 lr: 0.02\n",
      "iteration: 227060 loss: 0.0022 lr: 0.02\n",
      "iteration: 227070 loss: 0.0021 lr: 0.02\n",
      "iteration: 227080 loss: 0.0023 lr: 0.02\n",
      "iteration: 227090 loss: 0.0019 lr: 0.02\n",
      "iteration: 227100 loss: 0.0016 lr: 0.02\n",
      "iteration: 227110 loss: 0.0020 lr: 0.02\n",
      "iteration: 227120 loss: 0.0021 lr: 0.02\n",
      "iteration: 227130 loss: 0.0023 lr: 0.02\n",
      "iteration: 227140 loss: 0.0017 lr: 0.02\n",
      "iteration: 227150 loss: 0.0019 lr: 0.02\n",
      "iteration: 227160 loss: 0.0018 lr: 0.02\n",
      "iteration: 227170 loss: 0.0019 lr: 0.02\n",
      "iteration: 227180 loss: 0.0025 lr: 0.02\n",
      "iteration: 227190 loss: 0.0020 lr: 0.02\n",
      "iteration: 227200 loss: 0.0016 lr: 0.02\n",
      "iteration: 227210 loss: 0.0018 lr: 0.02\n",
      "iteration: 227220 loss: 0.0016 lr: 0.02\n",
      "iteration: 227230 loss: 0.0020 lr: 0.02\n",
      "iteration: 227240 loss: 0.0018 lr: 0.02\n",
      "iteration: 227250 loss: 0.0019 lr: 0.02\n",
      "iteration: 227260 loss: 0.0016 lr: 0.02\n",
      "iteration: 227270 loss: 0.0018 lr: 0.02\n",
      "iteration: 227280 loss: 0.0015 lr: 0.02\n",
      "iteration: 227290 loss: 0.0015 lr: 0.02\n",
      "iteration: 227300 loss: 0.0018 lr: 0.02\n",
      "iteration: 227310 loss: 0.0024 lr: 0.02\n",
      "iteration: 227320 loss: 0.0022 lr: 0.02\n",
      "iteration: 227330 loss: 0.0015 lr: 0.02\n",
      "iteration: 227340 loss: 0.0017 lr: 0.02\n",
      "iteration: 227350 loss: 0.0014 lr: 0.02\n",
      "iteration: 227360 loss: 0.0018 lr: 0.02\n",
      "iteration: 227370 loss: 0.0016 lr: 0.02\n",
      "iteration: 227380 loss: 0.0019 lr: 0.02\n",
      "iteration: 227390 loss: 0.0023 lr: 0.02\n",
      "iteration: 227400 loss: 0.0018 lr: 0.02\n",
      "iteration: 227410 loss: 0.0027 lr: 0.02\n",
      "iteration: 227420 loss: 0.0021 lr: 0.02\n",
      "iteration: 227430 loss: 0.0021 lr: 0.02\n",
      "iteration: 227440 loss: 0.0020 lr: 0.02\n",
      "iteration: 227450 loss: 0.0016 lr: 0.02\n",
      "iteration: 227460 loss: 0.0026 lr: 0.02\n",
      "iteration: 227470 loss: 0.0016 lr: 0.02\n",
      "iteration: 227480 loss: 0.0030 lr: 0.02\n",
      "iteration: 227490 loss: 0.0016 lr: 0.02\n",
      "iteration: 227500 loss: 0.0020 lr: 0.02\n",
      "iteration: 227510 loss: 0.0027 lr: 0.02\n",
      "iteration: 227520 loss: 0.0021 lr: 0.02\n",
      "iteration: 227530 loss: 0.0021 lr: 0.02\n",
      "iteration: 227540 loss: 0.0022 lr: 0.02\n",
      "iteration: 227550 loss: 0.0018 lr: 0.02\n",
      "iteration: 227560 loss: 0.0014 lr: 0.02\n",
      "iteration: 227570 loss: 0.0018 lr: 0.02\n",
      "iteration: 227580 loss: 0.0022 lr: 0.02\n",
      "iteration: 227590 loss: 0.0017 lr: 0.02\n",
      "iteration: 227600 loss: 0.0021 lr: 0.02\n",
      "iteration: 227610 loss: 0.0021 lr: 0.02\n",
      "iteration: 227620 loss: 0.0018 lr: 0.02\n",
      "iteration: 227630 loss: 0.0020 lr: 0.02\n",
      "iteration: 227640 loss: 0.0019 lr: 0.02\n",
      "iteration: 227650 loss: 0.0017 lr: 0.02\n",
      "iteration: 227660 loss: 0.0018 lr: 0.02\n",
      "iteration: 227670 loss: 0.0017 lr: 0.02\n",
      "iteration: 227680 loss: 0.0015 lr: 0.02\n",
      "iteration: 227690 loss: 0.0018 lr: 0.02\n",
      "iteration: 227700 loss: 0.0027 lr: 0.02\n",
      "iteration: 227710 loss: 0.0020 lr: 0.02\n",
      "iteration: 227720 loss: 0.0022 lr: 0.02\n",
      "iteration: 227730 loss: 0.0019 lr: 0.02\n",
      "iteration: 227740 loss: 0.0017 lr: 0.02\n",
      "iteration: 227750 loss: 0.0014 lr: 0.02\n",
      "iteration: 227760 loss: 0.0016 lr: 0.02\n",
      "iteration: 227770 loss: 0.0019 lr: 0.02\n",
      "iteration: 227780 loss: 0.0014 lr: 0.02\n",
      "iteration: 227790 loss: 0.0019 lr: 0.02\n",
      "iteration: 227800 loss: 0.0016 lr: 0.02\n",
      "iteration: 227810 loss: 0.0015 lr: 0.02\n",
      "iteration: 227820 loss: 0.0014 lr: 0.02\n",
      "iteration: 227830 loss: 0.0020 lr: 0.02\n",
      "iteration: 227840 loss: 0.0017 lr: 0.02\n",
      "iteration: 227850 loss: 0.0037 lr: 0.02\n",
      "iteration: 227860 loss: 0.0021 lr: 0.02\n",
      "iteration: 227870 loss: 0.0016 lr: 0.02\n",
      "iteration: 227880 loss: 0.0019 lr: 0.02\n",
      "iteration: 227890 loss: 0.0018 lr: 0.02\n",
      "iteration: 227900 loss: 0.0023 lr: 0.02\n",
      "iteration: 227910 loss: 0.0015 lr: 0.02\n",
      "iteration: 227920 loss: 0.0019 lr: 0.02\n",
      "iteration: 227930 loss: 0.0019 lr: 0.02\n",
      "iteration: 227940 loss: 0.0022 lr: 0.02\n",
      "iteration: 227950 loss: 0.0022 lr: 0.02\n",
      "iteration: 227960 loss: 0.0014 lr: 0.02\n",
      "iteration: 227970 loss: 0.0025 lr: 0.02\n",
      "iteration: 227980 loss: 0.0017 lr: 0.02\n",
      "iteration: 227990 loss: 0.0023 lr: 0.02\n",
      "iteration: 228000 loss: 0.0021 lr: 0.02\n",
      "iteration: 228010 loss: 0.0015 lr: 0.02\n",
      "iteration: 228020 loss: 0.0018 lr: 0.02\n",
      "iteration: 228030 loss: 0.0026 lr: 0.02\n",
      "iteration: 228040 loss: 0.0021 lr: 0.02\n",
      "iteration: 228050 loss: 0.0017 lr: 0.02\n",
      "iteration: 228060 loss: 0.0020 lr: 0.02\n",
      "iteration: 228070 loss: 0.0020 lr: 0.02\n",
      "iteration: 228080 loss: 0.0029 lr: 0.02\n",
      "iteration: 228090 loss: 0.0024 lr: 0.02\n",
      "iteration: 228100 loss: 0.0026 lr: 0.02\n",
      "iteration: 228110 loss: 0.0015 lr: 0.02\n",
      "iteration: 228120 loss: 0.0018 lr: 0.02\n",
      "iteration: 228130 loss: 0.0019 lr: 0.02\n",
      "iteration: 228140 loss: 0.0019 lr: 0.02\n",
      "iteration: 228150 loss: 0.0017 lr: 0.02\n",
      "iteration: 228160 loss: 0.0016 lr: 0.02\n",
      "iteration: 228170 loss: 0.0017 lr: 0.02\n",
      "iteration: 228180 loss: 0.0023 lr: 0.02\n",
      "iteration: 228190 loss: 0.0026 lr: 0.02\n",
      "iteration: 228200 loss: 0.0014 lr: 0.02\n",
      "iteration: 228210 loss: 0.0016 lr: 0.02\n",
      "iteration: 228220 loss: 0.0019 lr: 0.02\n",
      "iteration: 228230 loss: 0.0018 lr: 0.02\n",
      "iteration: 228240 loss: 0.0023 lr: 0.02\n",
      "iteration: 228250 loss: 0.0025 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 228260 loss: 0.0024 lr: 0.02\n",
      "iteration: 228270 loss: 0.0024 lr: 0.02\n",
      "iteration: 228280 loss: 0.0019 lr: 0.02\n",
      "iteration: 228290 loss: 0.0015 lr: 0.02\n",
      "iteration: 228300 loss: 0.0017 lr: 0.02\n",
      "iteration: 228310 loss: 0.0024 lr: 0.02\n",
      "iteration: 228320 loss: 0.0028 lr: 0.02\n",
      "iteration: 228330 loss: 0.0021 lr: 0.02\n",
      "iteration: 228340 loss: 0.0020 lr: 0.02\n",
      "iteration: 228350 loss: 0.0021 lr: 0.02\n",
      "iteration: 228360 loss: 0.0019 lr: 0.02\n",
      "iteration: 228370 loss: 0.0019 lr: 0.02\n",
      "iteration: 228380 loss: 0.0018 lr: 0.02\n",
      "iteration: 228390 loss: 0.0025 lr: 0.02\n",
      "iteration: 228400 loss: 0.0018 lr: 0.02\n",
      "iteration: 228410 loss: 0.0022 lr: 0.02\n",
      "iteration: 228420 loss: 0.0018 lr: 0.02\n",
      "iteration: 228430 loss: 0.0021 lr: 0.02\n",
      "iteration: 228440 loss: 0.0017 lr: 0.02\n",
      "iteration: 228450 loss: 0.0022 lr: 0.02\n",
      "iteration: 228460 loss: 0.0016 lr: 0.02\n",
      "iteration: 228470 loss: 0.0025 lr: 0.02\n",
      "iteration: 228480 loss: 0.0017 lr: 0.02\n",
      "iteration: 228490 loss: 0.0017 lr: 0.02\n",
      "iteration: 228500 loss: 0.0023 lr: 0.02\n",
      "iteration: 228510 loss: 0.0022 lr: 0.02\n",
      "iteration: 228520 loss: 0.0014 lr: 0.02\n",
      "iteration: 228530 loss: 0.0016 lr: 0.02\n",
      "iteration: 228540 loss: 0.0015 lr: 0.02\n",
      "iteration: 228550 loss: 0.0016 lr: 0.02\n",
      "iteration: 228560 loss: 0.0019 lr: 0.02\n",
      "iteration: 228570 loss: 0.0014 lr: 0.02\n",
      "iteration: 228580 loss: 0.0021 lr: 0.02\n",
      "iteration: 228590 loss: 0.0022 lr: 0.02\n",
      "iteration: 228600 loss: 0.0019 lr: 0.02\n",
      "iteration: 228610 loss: 0.0023 lr: 0.02\n",
      "iteration: 228620 loss: 0.0019 lr: 0.02\n",
      "iteration: 228630 loss: 0.0020 lr: 0.02\n",
      "iteration: 228640 loss: 0.0018 lr: 0.02\n",
      "iteration: 228650 loss: 0.0012 lr: 0.02\n",
      "iteration: 228660 loss: 0.0019 lr: 0.02\n",
      "iteration: 228670 loss: 0.0019 lr: 0.02\n",
      "iteration: 228680 loss: 0.0019 lr: 0.02\n",
      "iteration: 228690 loss: 0.0021 lr: 0.02\n",
      "iteration: 228700 loss: 0.0016 lr: 0.02\n",
      "iteration: 228710 loss: 0.0019 lr: 0.02\n",
      "iteration: 228720 loss: 0.0028 lr: 0.02\n",
      "iteration: 228730 loss: 0.0015 lr: 0.02\n",
      "iteration: 228740 loss: 0.0025 lr: 0.02\n",
      "iteration: 228750 loss: 0.0016 lr: 0.02\n",
      "iteration: 228760 loss: 0.0019 lr: 0.02\n",
      "iteration: 228770 loss: 0.0018 lr: 0.02\n",
      "iteration: 228780 loss: 0.0018 lr: 0.02\n",
      "iteration: 228790 loss: 0.0017 lr: 0.02\n",
      "iteration: 228800 loss: 0.0020 lr: 0.02\n",
      "iteration: 228810 loss: 0.0018 lr: 0.02\n",
      "iteration: 228820 loss: 0.0014 lr: 0.02\n",
      "iteration: 228830 loss: 0.0018 lr: 0.02\n",
      "iteration: 228840 loss: 0.0024 lr: 0.02\n",
      "iteration: 228850 loss: 0.0022 lr: 0.02\n",
      "iteration: 228860 loss: 0.0029 lr: 0.02\n",
      "iteration: 228870 loss: 0.0022 lr: 0.02\n",
      "iteration: 228880 loss: 0.0014 lr: 0.02\n",
      "iteration: 228890 loss: 0.0018 lr: 0.02\n",
      "iteration: 228900 loss: 0.0018 lr: 0.02\n",
      "iteration: 228910 loss: 0.0022 lr: 0.02\n",
      "iteration: 228920 loss: 0.0018 lr: 0.02\n",
      "iteration: 228930 loss: 0.0021 lr: 0.02\n",
      "iteration: 228940 loss: 0.0018 lr: 0.02\n",
      "iteration: 228950 loss: 0.0017 lr: 0.02\n",
      "iteration: 228960 loss: 0.0021 lr: 0.02\n",
      "iteration: 228970 loss: 0.0017 lr: 0.02\n",
      "iteration: 228980 loss: 0.0017 lr: 0.02\n",
      "iteration: 228990 loss: 0.0019 lr: 0.02\n",
      "iteration: 229000 loss: 0.0016 lr: 0.02\n",
      "iteration: 229010 loss: 0.0017 lr: 0.02\n",
      "iteration: 229020 loss: 0.0016 lr: 0.02\n",
      "iteration: 229030 loss: 0.0020 lr: 0.02\n",
      "iteration: 229040 loss: 0.0020 lr: 0.02\n",
      "iteration: 229050 loss: 0.0017 lr: 0.02\n",
      "iteration: 229060 loss: 0.0022 lr: 0.02\n",
      "iteration: 229070 loss: 0.0017 lr: 0.02\n",
      "iteration: 229080 loss: 0.0021 lr: 0.02\n",
      "iteration: 229090 loss: 0.0020 lr: 0.02\n",
      "iteration: 229100 loss: 0.0024 lr: 0.02\n",
      "iteration: 229110 loss: 0.0023 lr: 0.02\n",
      "iteration: 229120 loss: 0.0025 lr: 0.02\n",
      "iteration: 229130 loss: 0.0025 lr: 0.02\n",
      "iteration: 229140 loss: 0.0025 lr: 0.02\n",
      "iteration: 229150 loss: 0.0017 lr: 0.02\n",
      "iteration: 229160 loss: 0.0016 lr: 0.02\n",
      "iteration: 229170 loss: 0.0017 lr: 0.02\n",
      "iteration: 229180 loss: 0.0023 lr: 0.02\n",
      "iteration: 229190 loss: 0.0018 lr: 0.02\n",
      "iteration: 229200 loss: 0.0021 lr: 0.02\n",
      "iteration: 229210 loss: 0.0029 lr: 0.02\n",
      "iteration: 229220 loss: 0.0022 lr: 0.02\n",
      "iteration: 229230 loss: 0.0020 lr: 0.02\n",
      "iteration: 229240 loss: 0.0018 lr: 0.02\n",
      "iteration: 229250 loss: 0.0016 lr: 0.02\n",
      "iteration: 229260 loss: 0.0024 lr: 0.02\n",
      "iteration: 229270 loss: 0.0017 lr: 0.02\n",
      "iteration: 229280 loss: 0.0014 lr: 0.02\n",
      "iteration: 229290 loss: 0.0022 lr: 0.02\n",
      "iteration: 229300 loss: 0.0019 lr: 0.02\n",
      "iteration: 229310 loss: 0.0014 lr: 0.02\n",
      "iteration: 229320 loss: 0.0018 lr: 0.02\n",
      "iteration: 229330 loss: 0.0018 lr: 0.02\n",
      "iteration: 229340 loss: 0.0016 lr: 0.02\n",
      "iteration: 229350 loss: 0.0017 lr: 0.02\n",
      "iteration: 229360 loss: 0.0020 lr: 0.02\n",
      "iteration: 229370 loss: 0.0018 lr: 0.02\n",
      "iteration: 229380 loss: 0.0020 lr: 0.02\n",
      "iteration: 229390 loss: 0.0018 lr: 0.02\n",
      "iteration: 229400 loss: 0.0018 lr: 0.02\n",
      "iteration: 229410 loss: 0.0016 lr: 0.02\n",
      "iteration: 229420 loss: 0.0020 lr: 0.02\n",
      "iteration: 229430 loss: 0.0020 lr: 0.02\n",
      "iteration: 229440 loss: 0.0023 lr: 0.02\n",
      "iteration: 229450 loss: 0.0024 lr: 0.02\n",
      "iteration: 229460 loss: 0.0024 lr: 0.02\n",
      "iteration: 229470 loss: 0.0022 lr: 0.02\n",
      "iteration: 229480 loss: 0.0022 lr: 0.02\n",
      "iteration: 229490 loss: 0.0018 lr: 0.02\n",
      "iteration: 229500 loss: 0.0020 lr: 0.02\n",
      "iteration: 229510 loss: 0.0025 lr: 0.02\n",
      "iteration: 229520 loss: 0.0017 lr: 0.02\n",
      "iteration: 229530 loss: 0.0021 lr: 0.02\n",
      "iteration: 229540 loss: 0.0018 lr: 0.02\n",
      "iteration: 229550 loss: 0.0019 lr: 0.02\n",
      "iteration: 229560 loss: 0.0020 lr: 0.02\n",
      "iteration: 229570 loss: 0.0020 lr: 0.02\n",
      "iteration: 229580 loss: 0.0019 lr: 0.02\n",
      "iteration: 229590 loss: 0.0014 lr: 0.02\n",
      "iteration: 229600 loss: 0.0019 lr: 0.02\n",
      "iteration: 229610 loss: 0.0020 lr: 0.02\n",
      "iteration: 229620 loss: 0.0026 lr: 0.02\n",
      "iteration: 229630 loss: 0.0024 lr: 0.02\n",
      "iteration: 229640 loss: 0.0021 lr: 0.02\n",
      "iteration: 229650 loss: 0.0018 lr: 0.02\n",
      "iteration: 229660 loss: 0.0018 lr: 0.02\n",
      "iteration: 229670 loss: 0.0016 lr: 0.02\n",
      "iteration: 229680 loss: 0.0022 lr: 0.02\n",
      "iteration: 229690 loss: 0.0028 lr: 0.02\n",
      "iteration: 229700 loss: 0.0017 lr: 0.02\n",
      "iteration: 229710 loss: 0.0024 lr: 0.02\n",
      "iteration: 229720 loss: 0.0017 lr: 0.02\n",
      "iteration: 229730 loss: 0.0018 lr: 0.02\n",
      "iteration: 229740 loss: 0.0021 lr: 0.02\n",
      "iteration: 229750 loss: 0.0019 lr: 0.02\n",
      "iteration: 229760 loss: 0.0016 lr: 0.02\n",
      "iteration: 229770 loss: 0.0022 lr: 0.02\n",
      "iteration: 229780 loss: 0.0022 lr: 0.02\n",
      "iteration: 229790 loss: 0.0016 lr: 0.02\n",
      "iteration: 229800 loss: 0.0017 lr: 0.02\n",
      "iteration: 229810 loss: 0.0020 lr: 0.02\n",
      "iteration: 229820 loss: 0.0024 lr: 0.02\n",
      "iteration: 229830 loss: 0.0016 lr: 0.02\n",
      "iteration: 229840 loss: 0.0019 lr: 0.02\n",
      "iteration: 229850 loss: 0.0032 lr: 0.02\n",
      "iteration: 229860 loss: 0.0017 lr: 0.02\n",
      "iteration: 229870 loss: 0.0020 lr: 0.02\n",
      "iteration: 229880 loss: 0.0019 lr: 0.02\n",
      "iteration: 229890 loss: 0.0018 lr: 0.02\n",
      "iteration: 229900 loss: 0.0023 lr: 0.02\n",
      "iteration: 229910 loss: 0.0020 lr: 0.02\n",
      "iteration: 229920 loss: 0.0016 lr: 0.02\n",
      "iteration: 229930 loss: 0.0019 lr: 0.02\n",
      "iteration: 229940 loss: 0.0023 lr: 0.02\n",
      "iteration: 229950 loss: 0.0018 lr: 0.02\n",
      "iteration: 229960 loss: 0.0018 lr: 0.02\n",
      "iteration: 229970 loss: 0.0023 lr: 0.02\n",
      "iteration: 229980 loss: 0.0018 lr: 0.02\n",
      "iteration: 229990 loss: 0.0021 lr: 0.02\n",
      "iteration: 230000 loss: 0.0020 lr: 0.02\n",
      "iteration: 230010 loss: 0.0024 lr: 0.02\n",
      "iteration: 230020 loss: 0.0021 lr: 0.02\n",
      "iteration: 230030 loss: 0.0015 lr: 0.02\n",
      "iteration: 230040 loss: 0.0016 lr: 0.02\n",
      "iteration: 230050 loss: 0.0021 lr: 0.02\n",
      "iteration: 230060 loss: 0.0024 lr: 0.02\n",
      "iteration: 230070 loss: 0.0016 lr: 0.02\n",
      "iteration: 230080 loss: 0.0017 lr: 0.02\n",
      "iteration: 230090 loss: 0.0019 lr: 0.02\n",
      "iteration: 230100 loss: 0.0018 lr: 0.02\n",
      "iteration: 230110 loss: 0.0022 lr: 0.02\n",
      "iteration: 230120 loss: 0.0013 lr: 0.02\n",
      "iteration: 230130 loss: 0.0022 lr: 0.02\n",
      "iteration: 230140 loss: 0.0018 lr: 0.02\n",
      "iteration: 230150 loss: 0.0017 lr: 0.02\n",
      "iteration: 230160 loss: 0.0020 lr: 0.02\n",
      "iteration: 230170 loss: 0.0024 lr: 0.02\n",
      "iteration: 230180 loss: 0.0021 lr: 0.02\n",
      "iteration: 230190 loss: 0.0018 lr: 0.02\n",
      "iteration: 230200 loss: 0.0022 lr: 0.02\n",
      "iteration: 230210 loss: 0.0016 lr: 0.02\n",
      "iteration: 230220 loss: 0.0018 lr: 0.02\n",
      "iteration: 230230 loss: 0.0019 lr: 0.02\n",
      "iteration: 230240 loss: 0.0021 lr: 0.02\n",
      "iteration: 230250 loss: 0.0019 lr: 0.02\n",
      "iteration: 230260 loss: 0.0029 lr: 0.02\n",
      "iteration: 230270 loss: 0.0017 lr: 0.02\n",
      "iteration: 230280 loss: 0.0014 lr: 0.02\n",
      "iteration: 230290 loss: 0.0024 lr: 0.02\n",
      "iteration: 230300 loss: 0.0015 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 230310 loss: 0.0025 lr: 0.02\n",
      "iteration: 230320 loss: 0.0020 lr: 0.02\n",
      "iteration: 230330 loss: 0.0023 lr: 0.02\n",
      "iteration: 230340 loss: 0.0017 lr: 0.02\n",
      "iteration: 230350 loss: 0.0024 lr: 0.02\n",
      "iteration: 230360 loss: 0.0019 lr: 0.02\n",
      "iteration: 230370 loss: 0.0022 lr: 0.02\n",
      "iteration: 230380 loss: 0.0020 lr: 0.02\n",
      "iteration: 230390 loss: 0.0023 lr: 0.02\n",
      "iteration: 230400 loss: 0.0022 lr: 0.02\n",
      "iteration: 230410 loss: 0.0018 lr: 0.02\n",
      "iteration: 230420 loss: 0.0017 lr: 0.02\n",
      "iteration: 230430 loss: 0.0018 lr: 0.02\n",
      "iteration: 230440 loss: 0.0019 lr: 0.02\n",
      "iteration: 230450 loss: 0.0023 lr: 0.02\n",
      "iteration: 230460 loss: 0.0020 lr: 0.02\n",
      "iteration: 230470 loss: 0.0017 lr: 0.02\n",
      "iteration: 230480 loss: 0.0019 lr: 0.02\n",
      "iteration: 230490 loss: 0.0016 lr: 0.02\n",
      "iteration: 230500 loss: 0.0023 lr: 0.02\n",
      "iteration: 230510 loss: 0.0021 lr: 0.02\n",
      "iteration: 230520 loss: 0.0021 lr: 0.02\n",
      "iteration: 230530 loss: 0.0019 lr: 0.02\n",
      "iteration: 230540 loss: 0.0015 lr: 0.02\n",
      "iteration: 230550 loss: 0.0024 lr: 0.02\n",
      "iteration: 230560 loss: 0.0017 lr: 0.02\n",
      "iteration: 230570 loss: 0.0018 lr: 0.02\n",
      "iteration: 230580 loss: 0.0015 lr: 0.02\n",
      "iteration: 230590 loss: 0.0014 lr: 0.02\n",
      "iteration: 230600 loss: 0.0013 lr: 0.02\n",
      "iteration: 230610 loss: 0.0019 lr: 0.02\n",
      "iteration: 230620 loss: 0.0019 lr: 0.02\n",
      "iteration: 230630 loss: 0.0023 lr: 0.02\n",
      "iteration: 230640 loss: 0.0019 lr: 0.02\n",
      "iteration: 230650 loss: 0.0020 lr: 0.02\n",
      "iteration: 230660 loss: 0.0015 lr: 0.02\n",
      "iteration: 230670 loss: 0.0014 lr: 0.02\n",
      "iteration: 230680 loss: 0.0016 lr: 0.02\n",
      "iteration: 230690 loss: 0.0019 lr: 0.02\n",
      "iteration: 230700 loss: 0.0020 lr: 0.02\n",
      "iteration: 230710 loss: 0.0015 lr: 0.02\n",
      "iteration: 230720 loss: 0.0018 lr: 0.02\n",
      "iteration: 230730 loss: 0.0017 lr: 0.02\n",
      "iteration: 230740 loss: 0.0015 lr: 0.02\n",
      "iteration: 230750 loss: 0.0018 lr: 0.02\n",
      "iteration: 230760 loss: 0.0024 lr: 0.02\n",
      "iteration: 230770 loss: 0.0020 lr: 0.02\n",
      "iteration: 230780 loss: 0.0019 lr: 0.02\n",
      "iteration: 230790 loss: 0.0019 lr: 0.02\n",
      "iteration: 230800 loss: 0.0023 lr: 0.02\n",
      "iteration: 230810 loss: 0.0024 lr: 0.02\n",
      "iteration: 230820 loss: 0.0018 lr: 0.02\n",
      "iteration: 230830 loss: 0.0018 lr: 0.02\n",
      "iteration: 230840 loss: 0.0020 lr: 0.02\n",
      "iteration: 230850 loss: 0.0018 lr: 0.02\n",
      "iteration: 230860 loss: 0.0024 lr: 0.02\n",
      "iteration: 230870 loss: 0.0021 lr: 0.02\n",
      "iteration: 230880 loss: 0.0023 lr: 0.02\n",
      "iteration: 230890 loss: 0.0018 lr: 0.02\n",
      "iteration: 230900 loss: 0.0018 lr: 0.02\n",
      "iteration: 230910 loss: 0.0017 lr: 0.02\n",
      "iteration: 230920 loss: 0.0016 lr: 0.02\n",
      "iteration: 230930 loss: 0.0018 lr: 0.02\n",
      "iteration: 230940 loss: 0.0021 lr: 0.02\n",
      "iteration: 230950 loss: 0.0021 lr: 0.02\n",
      "iteration: 230960 loss: 0.0018 lr: 0.02\n",
      "iteration: 230970 loss: 0.0020 lr: 0.02\n",
      "iteration: 230980 loss: 0.0021 lr: 0.02\n",
      "iteration: 230990 loss: 0.0019 lr: 0.02\n",
      "iteration: 231000 loss: 0.0021 lr: 0.02\n",
      "iteration: 231010 loss: 0.0018 lr: 0.02\n",
      "iteration: 231020 loss: 0.0019 lr: 0.02\n",
      "iteration: 231030 loss: 0.0021 lr: 0.02\n",
      "iteration: 231040 loss: 0.0019 lr: 0.02\n",
      "iteration: 231050 loss: 0.0016 lr: 0.02\n",
      "iteration: 231060 loss: 0.0025 lr: 0.02\n",
      "iteration: 231070 loss: 0.0017 lr: 0.02\n",
      "iteration: 231080 loss: 0.0021 lr: 0.02\n",
      "iteration: 231090 loss: 0.0016 lr: 0.02\n",
      "iteration: 231100 loss: 0.0016 lr: 0.02\n",
      "iteration: 231110 loss: 0.0023 lr: 0.02\n",
      "iteration: 231120 loss: 0.0021 lr: 0.02\n",
      "iteration: 231130 loss: 0.0019 lr: 0.02\n",
      "iteration: 231140 loss: 0.0014 lr: 0.02\n",
      "iteration: 231150 loss: 0.0017 lr: 0.02\n",
      "iteration: 231160 loss: 0.0022 lr: 0.02\n",
      "iteration: 231170 loss: 0.0016 lr: 0.02\n",
      "iteration: 231180 loss: 0.0021 lr: 0.02\n",
      "iteration: 231190 loss: 0.0019 lr: 0.02\n",
      "iteration: 231200 loss: 0.0016 lr: 0.02\n",
      "iteration: 231210 loss: 0.0018 lr: 0.02\n",
      "iteration: 231220 loss: 0.0017 lr: 0.02\n",
      "iteration: 231230 loss: 0.0019 lr: 0.02\n",
      "iteration: 231240 loss: 0.0022 lr: 0.02\n",
      "iteration: 231250 loss: 0.0020 lr: 0.02\n",
      "iteration: 231260 loss: 0.0019 lr: 0.02\n",
      "iteration: 231270 loss: 0.0013 lr: 0.02\n",
      "iteration: 231280 loss: 0.0017 lr: 0.02\n",
      "iteration: 231290 loss: 0.0019 lr: 0.02\n",
      "iteration: 231300 loss: 0.0016 lr: 0.02\n",
      "iteration: 231310 loss: 0.0019 lr: 0.02\n",
      "iteration: 231320 loss: 0.0016 lr: 0.02\n",
      "iteration: 231330 loss: 0.0018 lr: 0.02\n",
      "iteration: 231340 loss: 0.0017 lr: 0.02\n",
      "iteration: 231350 loss: 0.0022 lr: 0.02\n",
      "iteration: 231360 loss: 0.0018 lr: 0.02\n",
      "iteration: 231370 loss: 0.0017 lr: 0.02\n",
      "iteration: 231380 loss: 0.0017 lr: 0.02\n",
      "iteration: 231390 loss: 0.0017 lr: 0.02\n",
      "iteration: 231400 loss: 0.0015 lr: 0.02\n",
      "iteration: 231410 loss: 0.0020 lr: 0.02\n",
      "iteration: 231420 loss: 0.0017 lr: 0.02\n",
      "iteration: 231430 loss: 0.0019 lr: 0.02\n",
      "iteration: 231440 loss: 0.0020 lr: 0.02\n",
      "iteration: 231450 loss: 0.0015 lr: 0.02\n",
      "iteration: 231460 loss: 0.0017 lr: 0.02\n",
      "iteration: 231470 loss: 0.0024 lr: 0.02\n",
      "iteration: 231480 loss: 0.0018 lr: 0.02\n",
      "iteration: 231490 loss: 0.0017 lr: 0.02\n",
      "iteration: 231500 loss: 0.0020 lr: 0.02\n",
      "iteration: 231510 loss: 0.0026 lr: 0.02\n",
      "iteration: 231520 loss: 0.0016 lr: 0.02\n",
      "iteration: 231530 loss: 0.0016 lr: 0.02\n",
      "iteration: 231540 loss: 0.0014 lr: 0.02\n",
      "iteration: 231550 loss: 0.0020 lr: 0.02\n",
      "iteration: 231560 loss: 0.0026 lr: 0.02\n",
      "iteration: 231570 loss: 0.0020 lr: 0.02\n",
      "iteration: 231580 loss: 0.0021 lr: 0.02\n",
      "iteration: 231590 loss: 0.0016 lr: 0.02\n",
      "iteration: 231600 loss: 0.0021 lr: 0.02\n",
      "iteration: 231610 loss: 0.0018 lr: 0.02\n",
      "iteration: 231620 loss: 0.0019 lr: 0.02\n",
      "iteration: 231630 loss: 0.0018 lr: 0.02\n",
      "iteration: 231640 loss: 0.0018 lr: 0.02\n",
      "iteration: 231650 loss: 0.0016 lr: 0.02\n",
      "iteration: 231660 loss: 0.0017 lr: 0.02\n",
      "iteration: 231670 loss: 0.0016 lr: 0.02\n",
      "iteration: 231680 loss: 0.0016 lr: 0.02\n",
      "iteration: 231690 loss: 0.0023 lr: 0.02\n",
      "iteration: 231700 loss: 0.0018 lr: 0.02\n",
      "iteration: 231710 loss: 0.0020 lr: 0.02\n",
      "iteration: 231720 loss: 0.0021 lr: 0.02\n",
      "iteration: 231730 loss: 0.0021 lr: 0.02\n",
      "iteration: 231740 loss: 0.0014 lr: 0.02\n",
      "iteration: 231750 loss: 0.0016 lr: 0.02\n",
      "iteration: 231760 loss: 0.0020 lr: 0.02\n",
      "iteration: 231770 loss: 0.0023 lr: 0.02\n",
      "iteration: 231780 loss: 0.0016 lr: 0.02\n",
      "iteration: 231790 loss: 0.0016 lr: 0.02\n",
      "iteration: 231800 loss: 0.0018 lr: 0.02\n",
      "iteration: 231810 loss: 0.0020 lr: 0.02\n",
      "iteration: 231820 loss: 0.0033 lr: 0.02\n",
      "iteration: 231830 loss: 0.0017 lr: 0.02\n",
      "iteration: 231840 loss: 0.0022 lr: 0.02\n",
      "iteration: 231850 loss: 0.0017 lr: 0.02\n",
      "iteration: 231860 loss: 0.0025 lr: 0.02\n",
      "iteration: 231870 loss: 0.0017 lr: 0.02\n",
      "iteration: 231880 loss: 0.0019 lr: 0.02\n",
      "iteration: 231890 loss: 0.0019 lr: 0.02\n",
      "iteration: 231900 loss: 0.0021 lr: 0.02\n",
      "iteration: 231910 loss: 0.0015 lr: 0.02\n",
      "iteration: 231920 loss: 0.0015 lr: 0.02\n",
      "iteration: 231930 loss: 0.0022 lr: 0.02\n",
      "iteration: 231940 loss: 0.0021 lr: 0.02\n",
      "iteration: 231950 loss: 0.0022 lr: 0.02\n",
      "iteration: 231960 loss: 0.0016 lr: 0.02\n",
      "iteration: 231970 loss: 0.0020 lr: 0.02\n",
      "iteration: 231980 loss: 0.0019 lr: 0.02\n",
      "iteration: 231990 loss: 0.0022 lr: 0.02\n",
      "iteration: 232000 loss: 0.0018 lr: 0.02\n",
      "iteration: 232010 loss: 0.0023 lr: 0.02\n",
      "iteration: 232020 loss: 0.0014 lr: 0.02\n",
      "iteration: 232030 loss: 0.0018 lr: 0.02\n",
      "iteration: 232040 loss: 0.0013 lr: 0.02\n",
      "iteration: 232050 loss: 0.0021 lr: 0.02\n",
      "iteration: 232060 loss: 0.0021 lr: 0.02\n",
      "iteration: 232070 loss: 0.0025 lr: 0.02\n",
      "iteration: 232080 loss: 0.0020 lr: 0.02\n",
      "iteration: 232090 loss: 0.0021 lr: 0.02\n",
      "iteration: 232100 loss: 0.0015 lr: 0.02\n",
      "iteration: 232110 loss: 0.0019 lr: 0.02\n",
      "iteration: 232120 loss: 0.0017 lr: 0.02\n",
      "iteration: 232130 loss: 0.0024 lr: 0.02\n",
      "iteration: 232140 loss: 0.0018 lr: 0.02\n",
      "iteration: 232150 loss: 0.0024 lr: 0.02\n",
      "iteration: 232160 loss: 0.0021 lr: 0.02\n",
      "iteration: 232170 loss: 0.0018 lr: 0.02\n",
      "iteration: 232180 loss: 0.0023 lr: 0.02\n",
      "iteration: 232190 loss: 0.0016 lr: 0.02\n",
      "iteration: 232200 loss: 0.0017 lr: 0.02\n",
      "iteration: 232210 loss: 0.0015 lr: 0.02\n",
      "iteration: 232220 loss: 0.0016 lr: 0.02\n",
      "iteration: 232230 loss: 0.0017 lr: 0.02\n",
      "iteration: 232240 loss: 0.0021 lr: 0.02\n",
      "iteration: 232250 loss: 0.0021 lr: 0.02\n",
      "iteration: 232260 loss: 0.0020 lr: 0.02\n",
      "iteration: 232270 loss: 0.0015 lr: 0.02\n",
      "iteration: 232280 loss: 0.0016 lr: 0.02\n",
      "iteration: 232290 loss: 0.0019 lr: 0.02\n",
      "iteration: 232300 loss: 0.0015 lr: 0.02\n",
      "iteration: 232310 loss: 0.0016 lr: 0.02\n",
      "iteration: 232320 loss: 0.0018 lr: 0.02\n",
      "iteration: 232330 loss: 0.0020 lr: 0.02\n",
      "iteration: 232340 loss: 0.0019 lr: 0.02\n",
      "iteration: 232350 loss: 0.0020 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 232360 loss: 0.0018 lr: 0.02\n",
      "iteration: 232370 loss: 0.0019 lr: 0.02\n",
      "iteration: 232380 loss: 0.0019 lr: 0.02\n",
      "iteration: 232390 loss: 0.0022 lr: 0.02\n",
      "iteration: 232400 loss: 0.0017 lr: 0.02\n",
      "iteration: 232410 loss: 0.0016 lr: 0.02\n",
      "iteration: 232420 loss: 0.0018 lr: 0.02\n",
      "iteration: 232430 loss: 0.0022 lr: 0.02\n",
      "iteration: 232440 loss: 0.0017 lr: 0.02\n",
      "iteration: 232450 loss: 0.0017 lr: 0.02\n",
      "iteration: 232460 loss: 0.0019 lr: 0.02\n",
      "iteration: 232470 loss: 0.0016 lr: 0.02\n",
      "iteration: 232480 loss: 0.0019 lr: 0.02\n",
      "iteration: 232490 loss: 0.0021 lr: 0.02\n",
      "iteration: 232500 loss: 0.0017 lr: 0.02\n",
      "iteration: 232510 loss: 0.0015 lr: 0.02\n",
      "iteration: 232520 loss: 0.0025 lr: 0.02\n",
      "iteration: 232530 loss: 0.0020 lr: 0.02\n",
      "iteration: 232540 loss: 0.0019 lr: 0.02\n",
      "iteration: 232550 loss: 0.0018 lr: 0.02\n",
      "iteration: 232560 loss: 0.0017 lr: 0.02\n",
      "iteration: 232570 loss: 0.0025 lr: 0.02\n",
      "iteration: 232580 loss: 0.0015 lr: 0.02\n",
      "iteration: 232590 loss: 0.0023 lr: 0.02\n",
      "iteration: 232600 loss: 0.0021 lr: 0.02\n",
      "iteration: 232610 loss: 0.0016 lr: 0.02\n",
      "iteration: 232620 loss: 0.0018 lr: 0.02\n",
      "iteration: 232630 loss: 0.0017 lr: 0.02\n",
      "iteration: 232640 loss: 0.0022 lr: 0.02\n",
      "iteration: 232650 loss: 0.0016 lr: 0.02\n",
      "iteration: 232660 loss: 0.0021 lr: 0.02\n",
      "iteration: 232670 loss: 0.0025 lr: 0.02\n",
      "iteration: 232680 loss: 0.0020 lr: 0.02\n",
      "iteration: 232690 loss: 0.0018 lr: 0.02\n",
      "iteration: 232700 loss: 0.0017 lr: 0.02\n",
      "iteration: 232710 loss: 0.0016 lr: 0.02\n",
      "iteration: 232720 loss: 0.0016 lr: 0.02\n",
      "iteration: 232730 loss: 0.0013 lr: 0.02\n",
      "iteration: 232740 loss: 0.0018 lr: 0.02\n",
      "iteration: 232750 loss: 0.0020 lr: 0.02\n",
      "iteration: 232760 loss: 0.0021 lr: 0.02\n",
      "iteration: 232770 loss: 0.0017 lr: 0.02\n",
      "iteration: 232780 loss: 0.0015 lr: 0.02\n",
      "iteration: 232790 loss: 0.0017 lr: 0.02\n",
      "iteration: 232800 loss: 0.0017 lr: 0.02\n",
      "iteration: 232810 loss: 0.0014 lr: 0.02\n",
      "iteration: 232820 loss: 0.0020 lr: 0.02\n",
      "iteration: 232830 loss: 0.0030 lr: 0.02\n",
      "iteration: 232840 loss: 0.0026 lr: 0.02\n",
      "iteration: 232850 loss: 0.0027 lr: 0.02\n",
      "iteration: 232860 loss: 0.0016 lr: 0.02\n",
      "iteration: 232870 loss: 0.0020 lr: 0.02\n",
      "iteration: 232880 loss: 0.0019 lr: 0.02\n",
      "iteration: 232890 loss: 0.0020 lr: 0.02\n",
      "iteration: 232900 loss: 0.0025 lr: 0.02\n",
      "iteration: 232910 loss: 0.0017 lr: 0.02\n",
      "iteration: 232920 loss: 0.0024 lr: 0.02\n",
      "iteration: 232930 loss: 0.0019 lr: 0.02\n",
      "iteration: 232940 loss: 0.0016 lr: 0.02\n",
      "iteration: 232950 loss: 0.0016 lr: 0.02\n",
      "iteration: 232960 loss: 0.0020 lr: 0.02\n",
      "iteration: 232970 loss: 0.0023 lr: 0.02\n",
      "iteration: 232980 loss: 0.0017 lr: 0.02\n",
      "iteration: 232990 loss: 0.0020 lr: 0.02\n",
      "iteration: 233000 loss: 0.0018 lr: 0.02\n",
      "iteration: 233010 loss: 0.0018 lr: 0.02\n",
      "iteration: 233020 loss: 0.0017 lr: 0.02\n",
      "iteration: 233030 loss: 0.0018 lr: 0.02\n",
      "iteration: 233040 loss: 0.0021 lr: 0.02\n",
      "iteration: 233050 loss: 0.0016 lr: 0.02\n",
      "iteration: 233060 loss: 0.0017 lr: 0.02\n",
      "iteration: 233070 loss: 0.0020 lr: 0.02\n",
      "iteration: 233080 loss: 0.0022 lr: 0.02\n",
      "iteration: 233090 loss: 0.0020 lr: 0.02\n",
      "iteration: 233100 loss: 0.0016 lr: 0.02\n",
      "iteration: 233110 loss: 0.0018 lr: 0.02\n",
      "iteration: 233120 loss: 0.0022 lr: 0.02\n",
      "iteration: 233130 loss: 0.0020 lr: 0.02\n",
      "iteration: 233140 loss: 0.0014 lr: 0.02\n",
      "iteration: 233150 loss: 0.0016 lr: 0.02\n",
      "iteration: 233160 loss: 0.0017 lr: 0.02\n",
      "iteration: 233170 loss: 0.0019 lr: 0.02\n",
      "iteration: 233180 loss: 0.0016 lr: 0.02\n",
      "iteration: 233190 loss: 0.0017 lr: 0.02\n",
      "iteration: 233200 loss: 0.0019 lr: 0.02\n",
      "iteration: 233210 loss: 0.0019 lr: 0.02\n",
      "iteration: 233220 loss: 0.0017 lr: 0.02\n",
      "iteration: 233230 loss: 0.0019 lr: 0.02\n",
      "iteration: 233240 loss: 0.0013 lr: 0.02\n",
      "iteration: 233250 loss: 0.0025 lr: 0.02\n",
      "iteration: 233260 loss: 0.0019 lr: 0.02\n",
      "iteration: 233270 loss: 0.0017 lr: 0.02\n",
      "iteration: 233280 loss: 0.0019 lr: 0.02\n",
      "iteration: 233290 loss: 0.0018 lr: 0.02\n",
      "iteration: 233300 loss: 0.0016 lr: 0.02\n",
      "iteration: 233310 loss: 0.0018 lr: 0.02\n",
      "iteration: 233320 loss: 0.0017 lr: 0.02\n",
      "iteration: 233330 loss: 0.0018 lr: 0.02\n",
      "iteration: 233340 loss: 0.0020 lr: 0.02\n",
      "iteration: 233350 loss: 0.0020 lr: 0.02\n",
      "iteration: 233360 loss: 0.0016 lr: 0.02\n",
      "iteration: 233370 loss: 0.0018 lr: 0.02\n",
      "iteration: 233380 loss: 0.0017 lr: 0.02\n",
      "iteration: 233390 loss: 0.0016 lr: 0.02\n",
      "iteration: 233400 loss: 0.0024 lr: 0.02\n",
      "iteration: 233410 loss: 0.0020 lr: 0.02\n",
      "iteration: 233420 loss: 0.0020 lr: 0.02\n",
      "iteration: 233430 loss: 0.0021 lr: 0.02\n",
      "iteration: 233440 loss: 0.0020 lr: 0.02\n",
      "iteration: 233450 loss: 0.0017 lr: 0.02\n",
      "iteration: 233460 loss: 0.0020 lr: 0.02\n",
      "iteration: 233470 loss: 0.0022 lr: 0.02\n",
      "iteration: 233480 loss: 0.0021 lr: 0.02\n",
      "iteration: 233490 loss: 0.0019 lr: 0.02\n",
      "iteration: 233500 loss: 0.0021 lr: 0.02\n",
      "iteration: 233510 loss: 0.0021 lr: 0.02\n",
      "iteration: 233520 loss: 0.0020 lr: 0.02\n",
      "iteration: 233530 loss: 0.0014 lr: 0.02\n",
      "iteration: 233540 loss: 0.0020 lr: 0.02\n",
      "iteration: 233550 loss: 0.0014 lr: 0.02\n",
      "iteration: 233560 loss: 0.0020 lr: 0.02\n",
      "iteration: 233570 loss: 0.0016 lr: 0.02\n",
      "iteration: 233580 loss: 0.0021 lr: 0.02\n",
      "iteration: 233590 loss: 0.0020 lr: 0.02\n",
      "iteration: 233600 loss: 0.0018 lr: 0.02\n",
      "iteration: 233610 loss: 0.0021 lr: 0.02\n",
      "iteration: 233620 loss: 0.0019 lr: 0.02\n",
      "iteration: 233630 loss: 0.0017 lr: 0.02\n",
      "iteration: 233640 loss: 0.0027 lr: 0.02\n",
      "iteration: 233650 loss: 0.0023 lr: 0.02\n",
      "iteration: 233660 loss: 0.0014 lr: 0.02\n",
      "iteration: 233670 loss: 0.0017 lr: 0.02\n",
      "iteration: 233680 loss: 0.0021 lr: 0.02\n",
      "iteration: 233690 loss: 0.0023 lr: 0.02\n",
      "iteration: 233700 loss: 0.0021 lr: 0.02\n",
      "iteration: 233710 loss: 0.0017 lr: 0.02\n",
      "iteration: 233720 loss: 0.0016 lr: 0.02\n",
      "iteration: 233730 loss: 0.0015 lr: 0.02\n",
      "iteration: 233740 loss: 0.0019 lr: 0.02\n",
      "iteration: 233750 loss: 0.0018 lr: 0.02\n",
      "iteration: 233760 loss: 0.0015 lr: 0.02\n",
      "iteration: 233770 loss: 0.0017 lr: 0.02\n",
      "iteration: 233780 loss: 0.0017 lr: 0.02\n",
      "iteration: 233790 loss: 0.0017 lr: 0.02\n",
      "iteration: 233800 loss: 0.0017 lr: 0.02\n",
      "iteration: 233810 loss: 0.0015 lr: 0.02\n",
      "iteration: 233820 loss: 0.0016 lr: 0.02\n",
      "iteration: 233830 loss: 0.0014 lr: 0.02\n",
      "iteration: 233840 loss: 0.0017 lr: 0.02\n",
      "iteration: 233850 loss: 0.0019 lr: 0.02\n",
      "iteration: 233860 loss: 0.0021 lr: 0.02\n",
      "iteration: 233870 loss: 0.0018 lr: 0.02\n",
      "iteration: 233880 loss: 0.0019 lr: 0.02\n",
      "iteration: 233890 loss: 0.0020 lr: 0.02\n",
      "iteration: 233900 loss: 0.0019 lr: 0.02\n",
      "iteration: 233910 loss: 0.0015 lr: 0.02\n",
      "iteration: 233920 loss: 0.0016 lr: 0.02\n",
      "iteration: 233930 loss: 0.0022 lr: 0.02\n",
      "iteration: 233940 loss: 0.0016 lr: 0.02\n",
      "iteration: 233950 loss: 0.0019 lr: 0.02\n",
      "iteration: 233960 loss: 0.0014 lr: 0.02\n",
      "iteration: 233970 loss: 0.0015 lr: 0.02\n",
      "iteration: 233980 loss: 0.0014 lr: 0.02\n",
      "iteration: 233990 loss: 0.0021 lr: 0.02\n",
      "iteration: 234000 loss: 0.0017 lr: 0.02\n",
      "iteration: 234010 loss: 0.0018 lr: 0.02\n",
      "iteration: 234020 loss: 0.0017 lr: 0.02\n",
      "iteration: 234030 loss: 0.0027 lr: 0.02\n",
      "iteration: 234040 loss: 0.0020 lr: 0.02\n",
      "iteration: 234050 loss: 0.0021 lr: 0.02\n",
      "iteration: 234060 loss: 0.0017 lr: 0.02\n",
      "iteration: 234070 loss: 0.0023 lr: 0.02\n",
      "iteration: 234080 loss: 0.0018 lr: 0.02\n",
      "iteration: 234090 loss: 0.0017 lr: 0.02\n",
      "iteration: 234100 loss: 0.0018 lr: 0.02\n",
      "iteration: 234110 loss: 0.0018 lr: 0.02\n",
      "iteration: 234120 loss: 0.0023 lr: 0.02\n",
      "iteration: 234130 loss: 0.0017 lr: 0.02\n",
      "iteration: 234140 loss: 0.0020 lr: 0.02\n",
      "iteration: 234150 loss: 0.0022 lr: 0.02\n",
      "iteration: 234160 loss: 0.0017 lr: 0.02\n",
      "iteration: 234170 loss: 0.0018 lr: 0.02\n",
      "iteration: 234180 loss: 0.0026 lr: 0.02\n",
      "iteration: 234190 loss: 0.0018 lr: 0.02\n",
      "iteration: 234200 loss: 0.0016 lr: 0.02\n",
      "iteration: 234210 loss: 0.0019 lr: 0.02\n",
      "iteration: 234220 loss: 0.0021 lr: 0.02\n",
      "iteration: 234230 loss: 0.0024 lr: 0.02\n",
      "iteration: 234240 loss: 0.0022 lr: 0.02\n",
      "iteration: 234250 loss: 0.0023 lr: 0.02\n",
      "iteration: 234260 loss: 0.0018 lr: 0.02\n",
      "iteration: 234270 loss: 0.0026 lr: 0.02\n",
      "iteration: 234280 loss: 0.0018 lr: 0.02\n",
      "iteration: 234290 loss: 0.0017 lr: 0.02\n",
      "iteration: 234300 loss: 0.0020 lr: 0.02\n",
      "iteration: 234310 loss: 0.0019 lr: 0.02\n",
      "iteration: 234320 loss: 0.0024 lr: 0.02\n",
      "iteration: 234330 loss: 0.0019 lr: 0.02\n",
      "iteration: 234340 loss: 0.0014 lr: 0.02\n",
      "iteration: 234350 loss: 0.0013 lr: 0.02\n",
      "iteration: 234360 loss: 0.0015 lr: 0.02\n",
      "iteration: 234370 loss: 0.0022 lr: 0.02\n",
      "iteration: 234380 loss: 0.0013 lr: 0.02\n",
      "iteration: 234390 loss: 0.0025 lr: 0.02\n",
      "iteration: 234400 loss: 0.0025 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 234410 loss: 0.0021 lr: 0.02\n",
      "iteration: 234420 loss: 0.0021 lr: 0.02\n",
      "iteration: 234430 loss: 0.0020 lr: 0.02\n",
      "iteration: 234440 loss: 0.0020 lr: 0.02\n",
      "iteration: 234450 loss: 0.0018 lr: 0.02\n",
      "iteration: 234460 loss: 0.0025 lr: 0.02\n",
      "iteration: 234470 loss: 0.0018 lr: 0.02\n",
      "iteration: 234480 loss: 0.0022 lr: 0.02\n",
      "iteration: 234490 loss: 0.0023 lr: 0.02\n",
      "iteration: 234500 loss: 0.0018 lr: 0.02\n",
      "iteration: 234510 loss: 0.0019 lr: 0.02\n",
      "iteration: 234520 loss: 0.0019 lr: 0.02\n",
      "iteration: 234530 loss: 0.0018 lr: 0.02\n",
      "iteration: 234540 loss: 0.0018 lr: 0.02\n",
      "iteration: 234550 loss: 0.0019 lr: 0.02\n",
      "iteration: 234560 loss: 0.0018 lr: 0.02\n",
      "iteration: 234570 loss: 0.0015 lr: 0.02\n",
      "iteration: 234580 loss: 0.0019 lr: 0.02\n",
      "iteration: 234590 loss: 0.0019 lr: 0.02\n",
      "iteration: 234600 loss: 0.0017 lr: 0.02\n",
      "iteration: 234610 loss: 0.0018 lr: 0.02\n",
      "iteration: 234620 loss: 0.0022 lr: 0.02\n",
      "iteration: 234630 loss: 0.0020 lr: 0.02\n",
      "iteration: 234640 loss: 0.0018 lr: 0.02\n",
      "iteration: 234650 loss: 0.0017 lr: 0.02\n",
      "iteration: 234660 loss: 0.0019 lr: 0.02\n",
      "iteration: 234670 loss: 0.0013 lr: 0.02\n",
      "iteration: 234680 loss: 0.0020 lr: 0.02\n",
      "iteration: 234690 loss: 0.0017 lr: 0.02\n",
      "iteration: 234700 loss: 0.0028 lr: 0.02\n",
      "iteration: 234710 loss: 0.0020 lr: 0.02\n",
      "iteration: 234720 loss: 0.0021 lr: 0.02\n",
      "iteration: 234730 loss: 0.0023 lr: 0.02\n",
      "iteration: 234740 loss: 0.0020 lr: 0.02\n",
      "iteration: 234750 loss: 0.0021 lr: 0.02\n",
      "iteration: 234760 loss: 0.0021 lr: 0.02\n",
      "iteration: 234770 loss: 0.0023 lr: 0.02\n",
      "iteration: 234780 loss: 0.0020 lr: 0.02\n",
      "iteration: 234790 loss: 0.0016 lr: 0.02\n",
      "iteration: 234800 loss: 0.0014 lr: 0.02\n",
      "iteration: 234810 loss: 0.0027 lr: 0.02\n",
      "iteration: 234820 loss: 0.0023 lr: 0.02\n",
      "iteration: 234830 loss: 0.0025 lr: 0.02\n",
      "iteration: 234840 loss: 0.0015 lr: 0.02\n",
      "iteration: 234850 loss: 0.0016 lr: 0.02\n",
      "iteration: 234860 loss: 0.0021 lr: 0.02\n",
      "iteration: 234870 loss: 0.0018 lr: 0.02\n",
      "iteration: 234880 loss: 0.0018 lr: 0.02\n",
      "iteration: 234890 loss: 0.0020 lr: 0.02\n",
      "iteration: 234900 loss: 0.0020 lr: 0.02\n",
      "iteration: 234910 loss: 0.0026 lr: 0.02\n",
      "iteration: 234920 loss: 0.0019 lr: 0.02\n",
      "iteration: 234930 loss: 0.0021 lr: 0.02\n",
      "iteration: 234940 loss: 0.0016 lr: 0.02\n",
      "iteration: 234950 loss: 0.0013 lr: 0.02\n",
      "iteration: 234960 loss: 0.0025 lr: 0.02\n",
      "iteration: 234970 loss: 0.0018 lr: 0.02\n",
      "iteration: 234980 loss: 0.0017 lr: 0.02\n",
      "iteration: 234990 loss: 0.0020 lr: 0.02\n",
      "iteration: 235000 loss: 0.0019 lr: 0.02\n",
      "iteration: 235010 loss: 0.0014 lr: 0.02\n",
      "iteration: 235020 loss: 0.0024 lr: 0.02\n",
      "iteration: 235030 loss: 0.0018 lr: 0.02\n",
      "iteration: 235040 loss: 0.0017 lr: 0.02\n",
      "iteration: 235050 loss: 0.0019 lr: 0.02\n",
      "iteration: 235060 loss: 0.0021 lr: 0.02\n",
      "iteration: 235070 loss: 0.0019 lr: 0.02\n",
      "iteration: 235080 loss: 0.0018 lr: 0.02\n",
      "iteration: 235090 loss: 0.0017 lr: 0.02\n",
      "iteration: 235100 loss: 0.0016 lr: 0.02\n",
      "iteration: 235110 loss: 0.0025 lr: 0.02\n",
      "iteration: 235120 loss: 0.0022 lr: 0.02\n",
      "iteration: 235130 loss: 0.0017 lr: 0.02\n",
      "iteration: 235140 loss: 0.0015 lr: 0.02\n",
      "iteration: 235150 loss: 0.0021 lr: 0.02\n",
      "iteration: 235160 loss: 0.0020 lr: 0.02\n",
      "iteration: 235170 loss: 0.0017 lr: 0.02\n",
      "iteration: 235180 loss: 0.0016 lr: 0.02\n",
      "iteration: 235190 loss: 0.0016 lr: 0.02\n",
      "iteration: 235200 loss: 0.0023 lr: 0.02\n",
      "iteration: 235210 loss: 0.0017 lr: 0.02\n",
      "iteration: 235220 loss: 0.0022 lr: 0.02\n",
      "iteration: 235230 loss: 0.0014 lr: 0.02\n",
      "iteration: 235240 loss: 0.0019 lr: 0.02\n",
      "iteration: 235250 loss: 0.0012 lr: 0.02\n",
      "iteration: 235260 loss: 0.0016 lr: 0.02\n",
      "iteration: 235270 loss: 0.0023 lr: 0.02\n",
      "iteration: 235280 loss: 0.0018 lr: 0.02\n",
      "iteration: 235290 loss: 0.0018 lr: 0.02\n",
      "iteration: 235300 loss: 0.0021 lr: 0.02\n",
      "iteration: 235310 loss: 0.0017 lr: 0.02\n",
      "iteration: 235320 loss: 0.0022 lr: 0.02\n",
      "iteration: 235330 loss: 0.0018 lr: 0.02\n",
      "iteration: 235340 loss: 0.0019 lr: 0.02\n",
      "iteration: 235350 loss: 0.0024 lr: 0.02\n",
      "iteration: 235360 loss: 0.0016 lr: 0.02\n",
      "iteration: 235370 loss: 0.0018 lr: 0.02\n",
      "iteration: 235380 loss: 0.0025 lr: 0.02\n",
      "iteration: 235390 loss: 0.0024 lr: 0.02\n",
      "iteration: 235400 loss: 0.0017 lr: 0.02\n",
      "iteration: 235410 loss: 0.0023 lr: 0.02\n",
      "iteration: 235420 loss: 0.0018 lr: 0.02\n",
      "iteration: 235430 loss: 0.0022 lr: 0.02\n",
      "iteration: 235440 loss: 0.0020 lr: 0.02\n",
      "iteration: 235450 loss: 0.0025 lr: 0.02\n",
      "iteration: 235460 loss: 0.0017 lr: 0.02\n",
      "iteration: 235470 loss: 0.0020 lr: 0.02\n",
      "iteration: 235480 loss: 0.0018 lr: 0.02\n",
      "iteration: 235490 loss: 0.0019 lr: 0.02\n",
      "iteration: 235500 loss: 0.0017 lr: 0.02\n",
      "iteration: 235510 loss: 0.0014 lr: 0.02\n",
      "iteration: 235520 loss: 0.0014 lr: 0.02\n",
      "iteration: 235530 loss: 0.0022 lr: 0.02\n",
      "iteration: 235540 loss: 0.0017 lr: 0.02\n",
      "iteration: 235550 loss: 0.0021 lr: 0.02\n",
      "iteration: 235560 loss: 0.0015 lr: 0.02\n",
      "iteration: 235570 loss: 0.0025 lr: 0.02\n",
      "iteration: 235580 loss: 0.0014 lr: 0.02\n",
      "iteration: 235590 loss: 0.0022 lr: 0.02\n",
      "iteration: 235600 loss: 0.0018 lr: 0.02\n",
      "iteration: 235610 loss: 0.0018 lr: 0.02\n",
      "iteration: 235620 loss: 0.0018 lr: 0.02\n",
      "iteration: 235630 loss: 0.0017 lr: 0.02\n",
      "iteration: 235640 loss: 0.0013 lr: 0.02\n",
      "iteration: 235650 loss: 0.0017 lr: 0.02\n",
      "iteration: 235660 loss: 0.0016 lr: 0.02\n",
      "iteration: 235670 loss: 0.0018 lr: 0.02\n",
      "iteration: 235680 loss: 0.0020 lr: 0.02\n",
      "iteration: 235690 loss: 0.0017 lr: 0.02\n",
      "iteration: 235700 loss: 0.0015 lr: 0.02\n",
      "iteration: 235710 loss: 0.0028 lr: 0.02\n",
      "iteration: 235720 loss: 0.0015 lr: 0.02\n",
      "iteration: 235730 loss: 0.0027 lr: 0.02\n",
      "iteration: 235740 loss: 0.0020 lr: 0.02\n",
      "iteration: 235750 loss: 0.0018 lr: 0.02\n",
      "iteration: 235760 loss: 0.0016 lr: 0.02\n",
      "iteration: 235770 loss: 0.0017 lr: 0.02\n",
      "iteration: 235780 loss: 0.0014 lr: 0.02\n",
      "iteration: 235790 loss: 0.0021 lr: 0.02\n",
      "iteration: 235800 loss: 0.0019 lr: 0.02\n",
      "iteration: 235810 loss: 0.0017 lr: 0.02\n",
      "iteration: 235820 loss: 0.0017 lr: 0.02\n",
      "iteration: 235830 loss: 0.0013 lr: 0.02\n",
      "iteration: 235840 loss: 0.0016 lr: 0.02\n",
      "iteration: 235850 loss: 0.0023 lr: 0.02\n",
      "iteration: 235860 loss: 0.0017 lr: 0.02\n",
      "iteration: 235870 loss: 0.0023 lr: 0.02\n",
      "iteration: 235880 loss: 0.0018 lr: 0.02\n",
      "iteration: 235890 loss: 0.0018 lr: 0.02\n",
      "iteration: 235900 loss: 0.0016 lr: 0.02\n",
      "iteration: 235910 loss: 0.0021 lr: 0.02\n",
      "iteration: 235920 loss: 0.0014 lr: 0.02\n",
      "iteration: 235930 loss: 0.0021 lr: 0.02\n",
      "iteration: 235940 loss: 0.0018 lr: 0.02\n",
      "iteration: 235950 loss: 0.0015 lr: 0.02\n",
      "iteration: 235960 loss: 0.0019 lr: 0.02\n",
      "iteration: 235970 loss: 0.0019 lr: 0.02\n",
      "iteration: 235980 loss: 0.0016 lr: 0.02\n",
      "iteration: 235990 loss: 0.0020 lr: 0.02\n",
      "iteration: 236000 loss: 0.0020 lr: 0.02\n",
      "iteration: 236010 loss: 0.0020 lr: 0.02\n",
      "iteration: 236020 loss: 0.0016 lr: 0.02\n",
      "iteration: 236030 loss: 0.0015 lr: 0.02\n",
      "iteration: 236040 loss: 0.0018 lr: 0.02\n",
      "iteration: 236050 loss: 0.0018 lr: 0.02\n",
      "iteration: 236060 loss: 0.0018 lr: 0.02\n",
      "iteration: 236070 loss: 0.0021 lr: 0.02\n",
      "iteration: 236080 loss: 0.0018 lr: 0.02\n",
      "iteration: 236090 loss: 0.0020 lr: 0.02\n",
      "iteration: 236100 loss: 0.0020 lr: 0.02\n",
      "iteration: 236110 loss: 0.0021 lr: 0.02\n",
      "iteration: 236120 loss: 0.0018 lr: 0.02\n",
      "iteration: 236130 loss: 0.0020 lr: 0.02\n",
      "iteration: 236140 loss: 0.0017 lr: 0.02\n",
      "iteration: 236150 loss: 0.0018 lr: 0.02\n",
      "iteration: 236160 loss: 0.0018 lr: 0.02\n",
      "iteration: 236170 loss: 0.0025 lr: 0.02\n",
      "iteration: 236180 loss: 0.0018 lr: 0.02\n",
      "iteration: 236190 loss: 0.0018 lr: 0.02\n",
      "iteration: 236200 loss: 0.0016 lr: 0.02\n",
      "iteration: 236210 loss: 0.0017 lr: 0.02\n",
      "iteration: 236220 loss: 0.0025 lr: 0.02\n",
      "iteration: 236230 loss: 0.0021 lr: 0.02\n",
      "iteration: 236240 loss: 0.0019 lr: 0.02\n",
      "iteration: 236250 loss: 0.0019 lr: 0.02\n",
      "iteration: 236260 loss: 0.0015 lr: 0.02\n",
      "iteration: 236270 loss: 0.0020 lr: 0.02\n",
      "iteration: 236280 loss: 0.0015 lr: 0.02\n",
      "iteration: 236290 loss: 0.0015 lr: 0.02\n",
      "iteration: 236300 loss: 0.0021 lr: 0.02\n",
      "iteration: 236310 loss: 0.0022 lr: 0.02\n",
      "iteration: 236320 loss: 0.0018 lr: 0.02\n",
      "iteration: 236330 loss: 0.0018 lr: 0.02\n",
      "iteration: 236340 loss: 0.0016 lr: 0.02\n",
      "iteration: 236350 loss: 0.0013 lr: 0.02\n",
      "iteration: 236360 loss: 0.0017 lr: 0.02\n",
      "iteration: 236370 loss: 0.0016 lr: 0.02\n",
      "iteration: 236380 loss: 0.0021 lr: 0.02\n",
      "iteration: 236390 loss: 0.0021 lr: 0.02\n",
      "iteration: 236400 loss: 0.0016 lr: 0.02\n",
      "iteration: 236410 loss: 0.0019 lr: 0.02\n",
      "iteration: 236420 loss: 0.0014 lr: 0.02\n",
      "iteration: 236430 loss: 0.0017 lr: 0.02\n",
      "iteration: 236440 loss: 0.0026 lr: 0.02\n",
      "iteration: 236450 loss: 0.0025 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 236460 loss: 0.0016 lr: 0.02\n",
      "iteration: 236470 loss: 0.0018 lr: 0.02\n",
      "iteration: 236480 loss: 0.0020 lr: 0.02\n",
      "iteration: 236490 loss: 0.0023 lr: 0.02\n",
      "iteration: 236500 loss: 0.0017 lr: 0.02\n",
      "iteration: 236510 loss: 0.0026 lr: 0.02\n",
      "iteration: 236520 loss: 0.0021 lr: 0.02\n",
      "iteration: 236530 loss: 0.0016 lr: 0.02\n",
      "iteration: 236540 loss: 0.0023 lr: 0.02\n",
      "iteration: 236550 loss: 0.0014 lr: 0.02\n",
      "iteration: 236560 loss: 0.0020 lr: 0.02\n",
      "iteration: 236570 loss: 0.0019 lr: 0.02\n",
      "iteration: 236580 loss: 0.0018 lr: 0.02\n",
      "iteration: 236590 loss: 0.0017 lr: 0.02\n",
      "iteration: 236600 loss: 0.0015 lr: 0.02\n",
      "iteration: 236610 loss: 0.0020 lr: 0.02\n",
      "iteration: 236620 loss: 0.0026 lr: 0.02\n",
      "iteration: 236630 loss: 0.0024 lr: 0.02\n",
      "iteration: 236640 loss: 0.0019 lr: 0.02\n",
      "iteration: 236650 loss: 0.0016 lr: 0.02\n",
      "iteration: 236660 loss: 0.0019 lr: 0.02\n",
      "iteration: 236670 loss: 0.0016 lr: 0.02\n",
      "iteration: 236680 loss: 0.0020 lr: 0.02\n",
      "iteration: 236690 loss: 0.0020 lr: 0.02\n",
      "iteration: 236700 loss: 0.0018 lr: 0.02\n",
      "iteration: 236710 loss: 0.0019 lr: 0.02\n",
      "iteration: 236720 loss: 0.0019 lr: 0.02\n",
      "iteration: 236730 loss: 0.0020 lr: 0.02\n",
      "iteration: 236740 loss: 0.0018 lr: 0.02\n",
      "iteration: 236750 loss: 0.0018 lr: 0.02\n",
      "iteration: 236760 loss: 0.0026 lr: 0.02\n",
      "iteration: 236770 loss: 0.0021 lr: 0.02\n",
      "iteration: 236780 loss: 0.0020 lr: 0.02\n",
      "iteration: 236790 loss: 0.0020 lr: 0.02\n",
      "iteration: 236800 loss: 0.0017 lr: 0.02\n",
      "iteration: 236810 loss: 0.0017 lr: 0.02\n",
      "iteration: 236820 loss: 0.0020 lr: 0.02\n",
      "iteration: 236830 loss: 0.0015 lr: 0.02\n",
      "iteration: 236840 loss: 0.0020 lr: 0.02\n",
      "iteration: 236850 loss: 0.0020 lr: 0.02\n",
      "iteration: 236860 loss: 0.0021 lr: 0.02\n",
      "iteration: 236870 loss: 0.0018 lr: 0.02\n",
      "iteration: 236880 loss: 0.0019 lr: 0.02\n",
      "iteration: 236890 loss: 0.0020 lr: 0.02\n",
      "iteration: 236900 loss: 0.0019 lr: 0.02\n",
      "iteration: 236910 loss: 0.0021 lr: 0.02\n",
      "iteration: 236920 loss: 0.0023 lr: 0.02\n",
      "iteration: 236930 loss: 0.0020 lr: 0.02\n",
      "iteration: 236940 loss: 0.0020 lr: 0.02\n",
      "iteration: 236950 loss: 0.0028 lr: 0.02\n",
      "iteration: 236960 loss: 0.0015 lr: 0.02\n",
      "iteration: 236970 loss: 0.0015 lr: 0.02\n",
      "iteration: 236980 loss: 0.0024 lr: 0.02\n",
      "iteration: 236990 loss: 0.0016 lr: 0.02\n",
      "iteration: 237000 loss: 0.0020 lr: 0.02\n",
      "iteration: 237010 loss: 0.0028 lr: 0.02\n",
      "iteration: 237020 loss: 0.0021 lr: 0.02\n",
      "iteration: 237030 loss: 0.0017 lr: 0.02\n",
      "iteration: 237040 loss: 0.0019 lr: 0.02\n",
      "iteration: 237050 loss: 0.0015 lr: 0.02\n",
      "iteration: 237060 loss: 0.0022 lr: 0.02\n",
      "iteration: 237070 loss: 0.0022 lr: 0.02\n",
      "iteration: 237080 loss: 0.0016 lr: 0.02\n",
      "iteration: 237090 loss: 0.0020 lr: 0.02\n",
      "iteration: 237100 loss: 0.0021 lr: 0.02\n",
      "iteration: 237110 loss: 0.0021 lr: 0.02\n",
      "iteration: 237120 loss: 0.0019 lr: 0.02\n",
      "iteration: 237130 loss: 0.0018 lr: 0.02\n",
      "iteration: 237140 loss: 0.0018 lr: 0.02\n",
      "iteration: 237150 loss: 0.0020 lr: 0.02\n",
      "iteration: 237160 loss: 0.0018 lr: 0.02\n",
      "iteration: 237170 loss: 0.0016 lr: 0.02\n",
      "iteration: 237180 loss: 0.0021 lr: 0.02\n",
      "iteration: 237190 loss: 0.0018 lr: 0.02\n",
      "iteration: 237200 loss: 0.0024 lr: 0.02\n",
      "iteration: 237210 loss: 0.0017 lr: 0.02\n",
      "iteration: 237220 loss: 0.0020 lr: 0.02\n",
      "iteration: 237230 loss: 0.0017 lr: 0.02\n",
      "iteration: 237240 loss: 0.0013 lr: 0.02\n",
      "iteration: 237250 loss: 0.0022 lr: 0.02\n",
      "iteration: 237260 loss: 0.0021 lr: 0.02\n",
      "iteration: 237270 loss: 0.0017 lr: 0.02\n",
      "iteration: 237280 loss: 0.0015 lr: 0.02\n",
      "iteration: 237290 loss: 0.0026 lr: 0.02\n",
      "iteration: 237300 loss: 0.0018 lr: 0.02\n",
      "iteration: 237310 loss: 0.0017 lr: 0.02\n",
      "iteration: 237320 loss: 0.0021 lr: 0.02\n",
      "iteration: 237330 loss: 0.0018 lr: 0.02\n",
      "iteration: 237340 loss: 0.0016 lr: 0.02\n",
      "iteration: 237350 loss: 0.0018 lr: 0.02\n",
      "iteration: 237360 loss: 0.0017 lr: 0.02\n",
      "iteration: 237370 loss: 0.0015 lr: 0.02\n",
      "iteration: 237380 loss: 0.0014 lr: 0.02\n",
      "iteration: 237390 loss: 0.0019 lr: 0.02\n",
      "iteration: 237400 loss: 0.0021 lr: 0.02\n",
      "iteration: 237410 loss: 0.0016 lr: 0.02\n",
      "iteration: 237420 loss: 0.0019 lr: 0.02\n",
      "iteration: 237430 loss: 0.0019 lr: 0.02\n",
      "iteration: 237440 loss: 0.0022 lr: 0.02\n",
      "iteration: 237450 loss: 0.0020 lr: 0.02\n",
      "iteration: 237460 loss: 0.0022 lr: 0.02\n",
      "iteration: 237470 loss: 0.0019 lr: 0.02\n",
      "iteration: 237480 loss: 0.0019 lr: 0.02\n",
      "iteration: 237490 loss: 0.0028 lr: 0.02\n",
      "iteration: 237500 loss: 0.0035 lr: 0.02\n",
      "iteration: 237510 loss: 0.0018 lr: 0.02\n",
      "iteration: 237520 loss: 0.0022 lr: 0.02\n",
      "iteration: 237530 loss: 0.0025 lr: 0.02\n",
      "iteration: 237540 loss: 0.0018 lr: 0.02\n",
      "iteration: 237550 loss: 0.0015 lr: 0.02\n",
      "iteration: 237560 loss: 0.0016 lr: 0.02\n",
      "iteration: 237570 loss: 0.0018 lr: 0.02\n",
      "iteration: 237580 loss: 0.0017 lr: 0.02\n",
      "iteration: 237590 loss: 0.0015 lr: 0.02\n",
      "iteration: 237600 loss: 0.0013 lr: 0.02\n",
      "iteration: 237610 loss: 0.0021 lr: 0.02\n",
      "iteration: 237620 loss: 0.0020 lr: 0.02\n",
      "iteration: 237630 loss: 0.0017 lr: 0.02\n",
      "iteration: 237640 loss: 0.0017 lr: 0.02\n",
      "iteration: 237650 loss: 0.0016 lr: 0.02\n",
      "iteration: 237660 loss: 0.0023 lr: 0.02\n",
      "iteration: 237670 loss: 0.0015 lr: 0.02\n",
      "iteration: 237680 loss: 0.0021 lr: 0.02\n",
      "iteration: 237690 loss: 0.0013 lr: 0.02\n",
      "iteration: 237700 loss: 0.0022 lr: 0.02\n",
      "iteration: 237710 loss: 0.0021 lr: 0.02\n",
      "iteration: 237720 loss: 0.0019 lr: 0.02\n",
      "iteration: 237730 loss: 0.0018 lr: 0.02\n",
      "iteration: 237740 loss: 0.0025 lr: 0.02\n",
      "iteration: 237750 loss: 0.0021 lr: 0.02\n",
      "iteration: 237760 loss: 0.0017 lr: 0.02\n",
      "iteration: 237770 loss: 0.0016 lr: 0.02\n",
      "iteration: 237780 loss: 0.0018 lr: 0.02\n",
      "iteration: 237790 loss: 0.0016 lr: 0.02\n",
      "iteration: 237800 loss: 0.0019 lr: 0.02\n",
      "iteration: 237810 loss: 0.0018 lr: 0.02\n",
      "iteration: 237820 loss: 0.0016 lr: 0.02\n",
      "iteration: 237830 loss: 0.0026 lr: 0.02\n",
      "iteration: 237840 loss: 0.0019 lr: 0.02\n",
      "iteration: 237850 loss: 0.0018 lr: 0.02\n",
      "iteration: 237860 loss: 0.0019 lr: 0.02\n",
      "iteration: 237870 loss: 0.0023 lr: 0.02\n",
      "iteration: 237880 loss: 0.0016 lr: 0.02\n",
      "iteration: 237890 loss: 0.0017 lr: 0.02\n",
      "iteration: 237900 loss: 0.0019 lr: 0.02\n",
      "iteration: 237910 loss: 0.0017 lr: 0.02\n",
      "iteration: 237920 loss: 0.0020 lr: 0.02\n",
      "iteration: 237930 loss: 0.0021 lr: 0.02\n",
      "iteration: 237940 loss: 0.0014 lr: 0.02\n",
      "iteration: 237950 loss: 0.0021 lr: 0.02\n",
      "iteration: 237960 loss: 0.0018 lr: 0.02\n",
      "iteration: 237970 loss: 0.0018 lr: 0.02\n",
      "iteration: 237980 loss: 0.0017 lr: 0.02\n",
      "iteration: 237990 loss: 0.0020 lr: 0.02\n",
      "iteration: 238000 loss: 0.0019 lr: 0.02\n",
      "iteration: 238010 loss: 0.0020 lr: 0.02\n",
      "iteration: 238020 loss: 0.0018 lr: 0.02\n",
      "iteration: 238030 loss: 0.0014 lr: 0.02\n",
      "iteration: 238040 loss: 0.0016 lr: 0.02\n",
      "iteration: 238050 loss: 0.0024 lr: 0.02\n",
      "iteration: 238060 loss: 0.0019 lr: 0.02\n",
      "iteration: 238070 loss: 0.0017 lr: 0.02\n",
      "iteration: 238080 loss: 0.0016 lr: 0.02\n",
      "iteration: 238090 loss: 0.0015 lr: 0.02\n",
      "iteration: 238100 loss: 0.0014 lr: 0.02\n",
      "iteration: 238110 loss: 0.0014 lr: 0.02\n",
      "iteration: 238120 loss: 0.0016 lr: 0.02\n",
      "iteration: 238130 loss: 0.0019 lr: 0.02\n",
      "iteration: 238140 loss: 0.0013 lr: 0.02\n",
      "iteration: 238150 loss: 0.0025 lr: 0.02\n",
      "iteration: 238160 loss: 0.0018 lr: 0.02\n",
      "iteration: 238170 loss: 0.0020 lr: 0.02\n",
      "iteration: 238180 loss: 0.0017 lr: 0.02\n",
      "iteration: 238190 loss: 0.0013 lr: 0.02\n",
      "iteration: 238200 loss: 0.0020 lr: 0.02\n",
      "iteration: 238210 loss: 0.0014 lr: 0.02\n",
      "iteration: 238220 loss: 0.0021 lr: 0.02\n",
      "iteration: 238230 loss: 0.0022 lr: 0.02\n",
      "iteration: 238240 loss: 0.0016 lr: 0.02\n",
      "iteration: 238250 loss: 0.0017 lr: 0.02\n",
      "iteration: 238260 loss: 0.0020 lr: 0.02\n",
      "iteration: 238270 loss: 0.0021 lr: 0.02\n",
      "iteration: 238280 loss: 0.0022 lr: 0.02\n",
      "iteration: 238290 loss: 0.0013 lr: 0.02\n",
      "iteration: 238300 loss: 0.0013 lr: 0.02\n",
      "iteration: 238310 loss: 0.0017 lr: 0.02\n",
      "iteration: 238320 loss: 0.0018 lr: 0.02\n",
      "iteration: 238330 loss: 0.0015 lr: 0.02\n",
      "iteration: 238340 loss: 0.0018 lr: 0.02\n",
      "iteration: 238350 loss: 0.0018 lr: 0.02\n",
      "iteration: 238360 loss: 0.0017 lr: 0.02\n",
      "iteration: 238370 loss: 0.0020 lr: 0.02\n",
      "iteration: 238380 loss: 0.0022 lr: 0.02\n",
      "iteration: 238390 loss: 0.0021 lr: 0.02\n",
      "iteration: 238400 loss: 0.0015 lr: 0.02\n",
      "iteration: 238410 loss: 0.0018 lr: 0.02\n",
      "iteration: 238420 loss: 0.0018 lr: 0.02\n",
      "iteration: 238430 loss: 0.0016 lr: 0.02\n",
      "iteration: 238440 loss: 0.0016 lr: 0.02\n",
      "iteration: 238450 loss: 0.0015 lr: 0.02\n",
      "iteration: 238460 loss: 0.0016 lr: 0.02\n",
      "iteration: 238470 loss: 0.0021 lr: 0.02\n",
      "iteration: 238480 loss: 0.0014 lr: 0.02\n",
      "iteration: 238490 loss: 0.0020 lr: 0.02\n",
      "iteration: 238500 loss: 0.0015 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 238510 loss: 0.0017 lr: 0.02\n",
      "iteration: 238520 loss: 0.0018 lr: 0.02\n",
      "iteration: 238530 loss: 0.0015 lr: 0.02\n",
      "iteration: 238540 loss: 0.0022 lr: 0.02\n",
      "iteration: 238550 loss: 0.0015 lr: 0.02\n",
      "iteration: 238560 loss: 0.0018 lr: 0.02\n",
      "iteration: 238570 loss: 0.0019 lr: 0.02\n",
      "iteration: 238580 loss: 0.0014 lr: 0.02\n",
      "iteration: 238590 loss: 0.0021 lr: 0.02\n",
      "iteration: 238600 loss: 0.0019 lr: 0.02\n",
      "iteration: 238610 loss: 0.0018 lr: 0.02\n",
      "iteration: 238620 loss: 0.0021 lr: 0.02\n",
      "iteration: 238630 loss: 0.0016 lr: 0.02\n",
      "iteration: 238640 loss: 0.0019 lr: 0.02\n",
      "iteration: 238650 loss: 0.0019 lr: 0.02\n",
      "iteration: 238660 loss: 0.0025 lr: 0.02\n",
      "iteration: 238670 loss: 0.0018 lr: 0.02\n",
      "iteration: 238680 loss: 0.0021 lr: 0.02\n",
      "iteration: 238690 loss: 0.0016 lr: 0.02\n",
      "iteration: 238700 loss: 0.0020 lr: 0.02\n",
      "iteration: 238710 loss: 0.0019 lr: 0.02\n",
      "iteration: 238720 loss: 0.0022 lr: 0.02\n",
      "iteration: 238730 loss: 0.0025 lr: 0.02\n",
      "iteration: 238740 loss: 0.0019 lr: 0.02\n",
      "iteration: 238750 loss: 0.0021 lr: 0.02\n",
      "iteration: 238760 loss: 0.0017 lr: 0.02\n",
      "iteration: 238770 loss: 0.0014 lr: 0.02\n",
      "iteration: 238780 loss: 0.0014 lr: 0.02\n",
      "iteration: 238790 loss: 0.0015 lr: 0.02\n",
      "iteration: 238800 loss: 0.0022 lr: 0.02\n",
      "iteration: 238810 loss: 0.0019 lr: 0.02\n",
      "iteration: 238820 loss: 0.0019 lr: 0.02\n",
      "iteration: 238830 loss: 0.0020 lr: 0.02\n",
      "iteration: 238840 loss: 0.0014 lr: 0.02\n",
      "iteration: 238850 loss: 0.0018 lr: 0.02\n",
      "iteration: 238860 loss: 0.0023 lr: 0.02\n",
      "iteration: 238870 loss: 0.0021 lr: 0.02\n",
      "iteration: 238880 loss: 0.0020 lr: 0.02\n",
      "iteration: 238890 loss: 0.0017 lr: 0.02\n",
      "iteration: 238900 loss: 0.0018 lr: 0.02\n",
      "iteration: 238910 loss: 0.0019 lr: 0.02\n",
      "iteration: 238920 loss: 0.0026 lr: 0.02\n",
      "iteration: 238930 loss: 0.0019 lr: 0.02\n",
      "iteration: 238940 loss: 0.0026 lr: 0.02\n",
      "iteration: 238950 loss: 0.0022 lr: 0.02\n",
      "iteration: 238960 loss: 0.0019 lr: 0.02\n",
      "iteration: 238970 loss: 0.0017 lr: 0.02\n",
      "iteration: 238980 loss: 0.0023 lr: 0.02\n",
      "iteration: 238990 loss: 0.0018 lr: 0.02\n",
      "iteration: 239000 loss: 0.0021 lr: 0.02\n",
      "iteration: 239010 loss: 0.0017 lr: 0.02\n",
      "iteration: 239020 loss: 0.0023 lr: 0.02\n",
      "iteration: 239030 loss: 0.0026 lr: 0.02\n",
      "iteration: 239040 loss: 0.0019 lr: 0.02\n",
      "iteration: 239050 loss: 0.0019 lr: 0.02\n",
      "iteration: 239060 loss: 0.0020 lr: 0.02\n",
      "iteration: 239070 loss: 0.0015 lr: 0.02\n",
      "iteration: 239080 loss: 0.0025 lr: 0.02\n",
      "iteration: 239090 loss: 0.0019 lr: 0.02\n",
      "iteration: 239100 loss: 0.0027 lr: 0.02\n",
      "iteration: 239110 loss: 0.0016 lr: 0.02\n",
      "iteration: 239120 loss: 0.0016 lr: 0.02\n",
      "iteration: 239130 loss: 0.0021 lr: 0.02\n",
      "iteration: 239140 loss: 0.0018 lr: 0.02\n",
      "iteration: 239150 loss: 0.0026 lr: 0.02\n",
      "iteration: 239160 loss: 0.0018 lr: 0.02\n",
      "iteration: 239170 loss: 0.0016 lr: 0.02\n",
      "iteration: 239180 loss: 0.0019 lr: 0.02\n",
      "iteration: 239190 loss: 0.0018 lr: 0.02\n",
      "iteration: 239200 loss: 0.0018 lr: 0.02\n",
      "iteration: 239210 loss: 0.0026 lr: 0.02\n",
      "iteration: 239220 loss: 0.0019 lr: 0.02\n",
      "iteration: 239230 loss: 0.0023 lr: 0.02\n",
      "iteration: 239240 loss: 0.0018 lr: 0.02\n",
      "iteration: 239250 loss: 0.0016 lr: 0.02\n",
      "iteration: 239260 loss: 0.0016 lr: 0.02\n",
      "iteration: 239270 loss: 0.0021 lr: 0.02\n",
      "iteration: 239280 loss: 0.0017 lr: 0.02\n",
      "iteration: 239290 loss: 0.0015 lr: 0.02\n",
      "iteration: 239300 loss: 0.0021 lr: 0.02\n",
      "iteration: 239310 loss: 0.0022 lr: 0.02\n",
      "iteration: 239320 loss: 0.0018 lr: 0.02\n",
      "iteration: 239330 loss: 0.0017 lr: 0.02\n",
      "iteration: 239340 loss: 0.0016 lr: 0.02\n",
      "iteration: 239350 loss: 0.0015 lr: 0.02\n",
      "iteration: 239360 loss: 0.0014 lr: 0.02\n",
      "iteration: 239370 loss: 0.0017 lr: 0.02\n",
      "iteration: 239380 loss: 0.0026 lr: 0.02\n",
      "iteration: 239390 loss: 0.0013 lr: 0.02\n",
      "iteration: 239400 loss: 0.0017 lr: 0.02\n",
      "iteration: 239410 loss: 0.0013 lr: 0.02\n",
      "iteration: 239420 loss: 0.0016 lr: 0.02\n",
      "iteration: 239430 loss: 0.0018 lr: 0.02\n",
      "iteration: 239440 loss: 0.0020 lr: 0.02\n",
      "iteration: 239450 loss: 0.0014 lr: 0.02\n",
      "iteration: 239460 loss: 0.0019 lr: 0.02\n",
      "iteration: 239470 loss: 0.0024 lr: 0.02\n",
      "iteration: 239480 loss: 0.0019 lr: 0.02\n",
      "iteration: 239490 loss: 0.0015 lr: 0.02\n",
      "iteration: 239500 loss: 0.0018 lr: 0.02\n",
      "iteration: 239510 loss: 0.0019 lr: 0.02\n",
      "iteration: 239520 loss: 0.0020 lr: 0.02\n",
      "iteration: 239530 loss: 0.0017 lr: 0.02\n",
      "iteration: 239540 loss: 0.0018 lr: 0.02\n",
      "iteration: 239550 loss: 0.0020 lr: 0.02\n",
      "iteration: 239560 loss: 0.0022 lr: 0.02\n",
      "iteration: 239570 loss: 0.0021 lr: 0.02\n",
      "iteration: 239580 loss: 0.0024 lr: 0.02\n",
      "iteration: 239590 loss: 0.0016 lr: 0.02\n",
      "iteration: 239600 loss: 0.0022 lr: 0.02\n",
      "iteration: 239610 loss: 0.0016 lr: 0.02\n",
      "iteration: 239620 loss: 0.0019 lr: 0.02\n",
      "iteration: 239630 loss: 0.0016 lr: 0.02\n",
      "iteration: 239640 loss: 0.0019 lr: 0.02\n",
      "iteration: 239650 loss: 0.0018 lr: 0.02\n",
      "iteration: 239660 loss: 0.0037 lr: 0.02\n",
      "iteration: 239670 loss: 0.0021 lr: 0.02\n",
      "iteration: 239680 loss: 0.0020 lr: 0.02\n",
      "iteration: 239690 loss: 0.0020 lr: 0.02\n",
      "iteration: 239700 loss: 0.0018 lr: 0.02\n",
      "iteration: 239710 loss: 0.0014 lr: 0.02\n",
      "iteration: 239720 loss: 0.0014 lr: 0.02\n",
      "iteration: 239730 loss: 0.0018 lr: 0.02\n",
      "iteration: 239740 loss: 0.0023 lr: 0.02\n",
      "iteration: 239750 loss: 0.0020 lr: 0.02\n",
      "iteration: 239760 loss: 0.0015 lr: 0.02\n",
      "iteration: 239770 loss: 0.0026 lr: 0.02\n",
      "iteration: 239780 loss: 0.0020 lr: 0.02\n",
      "iteration: 239790 loss: 0.0020 lr: 0.02\n",
      "iteration: 239800 loss: 0.0015 lr: 0.02\n",
      "iteration: 239810 loss: 0.0016 lr: 0.02\n",
      "iteration: 239820 loss: 0.0017 lr: 0.02\n",
      "iteration: 239830 loss: 0.0019 lr: 0.02\n",
      "iteration: 239840 loss: 0.0015 lr: 0.02\n",
      "iteration: 239850 loss: 0.0014 lr: 0.02\n",
      "iteration: 239860 loss: 0.0019 lr: 0.02\n",
      "iteration: 239870 loss: 0.0016 lr: 0.02\n",
      "iteration: 239880 loss: 0.0017 lr: 0.02\n",
      "iteration: 239890 loss: 0.0025 lr: 0.02\n",
      "iteration: 239900 loss: 0.0019 lr: 0.02\n",
      "iteration: 239910 loss: 0.0019 lr: 0.02\n",
      "iteration: 239920 loss: 0.0020 lr: 0.02\n",
      "iteration: 239930 loss: 0.0025 lr: 0.02\n",
      "iteration: 239940 loss: 0.0020 lr: 0.02\n",
      "iteration: 239950 loss: 0.0018 lr: 0.02\n",
      "iteration: 239960 loss: 0.0018 lr: 0.02\n",
      "iteration: 239970 loss: 0.0021 lr: 0.02\n",
      "iteration: 239980 loss: 0.0020 lr: 0.02\n",
      "iteration: 239990 loss: 0.0019 lr: 0.02\n",
      "iteration: 240000 loss: 0.0016 lr: 0.02\n",
      "iteration: 240010 loss: 0.0025 lr: 0.02\n",
      "iteration: 240020 loss: 0.0017 lr: 0.02\n",
      "iteration: 240030 loss: 0.0021 lr: 0.02\n",
      "iteration: 240040 loss: 0.0018 lr: 0.02\n",
      "iteration: 240050 loss: 0.0016 lr: 0.02\n",
      "iteration: 240060 loss: 0.0022 lr: 0.02\n",
      "iteration: 240070 loss: 0.0020 lr: 0.02\n",
      "iteration: 240080 loss: 0.0022 lr: 0.02\n",
      "iteration: 240090 loss: 0.0015 lr: 0.02\n",
      "iteration: 240100 loss: 0.0017 lr: 0.02\n",
      "iteration: 240110 loss: 0.0019 lr: 0.02\n",
      "iteration: 240120 loss: 0.0016 lr: 0.02\n",
      "iteration: 240130 loss: 0.0018 lr: 0.02\n",
      "iteration: 240140 loss: 0.0016 lr: 0.02\n",
      "iteration: 240150 loss: 0.0015 lr: 0.02\n",
      "iteration: 240160 loss: 0.0017 lr: 0.02\n",
      "iteration: 240170 loss: 0.0016 lr: 0.02\n",
      "iteration: 240180 loss: 0.0020 lr: 0.02\n",
      "iteration: 240190 loss: 0.0021 lr: 0.02\n",
      "iteration: 240200 loss: 0.0019 lr: 0.02\n",
      "iteration: 240210 loss: 0.0016 lr: 0.02\n",
      "iteration: 240220 loss: 0.0022 lr: 0.02\n",
      "iteration: 240230 loss: 0.0017 lr: 0.02\n",
      "iteration: 240240 loss: 0.0018 lr: 0.02\n",
      "iteration: 240250 loss: 0.0016 lr: 0.02\n",
      "iteration: 240260 loss: 0.0021 lr: 0.02\n",
      "iteration: 240270 loss: 0.0013 lr: 0.02\n",
      "iteration: 240280 loss: 0.0018 lr: 0.02\n",
      "iteration: 240290 loss: 0.0023 lr: 0.02\n",
      "iteration: 240300 loss: 0.0019 lr: 0.02\n",
      "iteration: 240310 loss: 0.0018 lr: 0.02\n",
      "iteration: 240320 loss: 0.0019 lr: 0.02\n",
      "iteration: 240330 loss: 0.0018 lr: 0.02\n",
      "iteration: 240340 loss: 0.0020 lr: 0.02\n",
      "iteration: 240350 loss: 0.0019 lr: 0.02\n",
      "iteration: 240360 loss: 0.0017 lr: 0.02\n",
      "iteration: 240370 loss: 0.0020 lr: 0.02\n",
      "iteration: 240380 loss: 0.0026 lr: 0.02\n",
      "iteration: 240390 loss: 0.0019 lr: 0.02\n",
      "iteration: 240400 loss: 0.0016 lr: 0.02\n",
      "iteration: 240410 loss: 0.0018 lr: 0.02\n",
      "iteration: 240420 loss: 0.0018 lr: 0.02\n",
      "iteration: 240430 loss: 0.0015 lr: 0.02\n",
      "iteration: 240440 loss: 0.0017 lr: 0.02\n",
      "iteration: 240450 loss: 0.0014 lr: 0.02\n",
      "iteration: 240460 loss: 0.0014 lr: 0.02\n",
      "iteration: 240470 loss: 0.0019 lr: 0.02\n",
      "iteration: 240480 loss: 0.0024 lr: 0.02\n",
      "iteration: 240490 loss: 0.0022 lr: 0.02\n",
      "iteration: 240500 loss: 0.0022 lr: 0.02\n",
      "iteration: 240510 loss: 0.0021 lr: 0.02\n",
      "iteration: 240520 loss: 0.0017 lr: 0.02\n",
      "iteration: 240530 loss: 0.0014 lr: 0.02\n",
      "iteration: 240540 loss: 0.0019 lr: 0.02\n",
      "iteration: 240550 loss: 0.0015 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 240560 loss: 0.0017 lr: 0.02\n",
      "iteration: 240570 loss: 0.0015 lr: 0.02\n",
      "iteration: 240580 loss: 0.0019 lr: 0.02\n",
      "iteration: 240590 loss: 0.0015 lr: 0.02\n",
      "iteration: 240600 loss: 0.0015 lr: 0.02\n",
      "iteration: 240610 loss: 0.0022 lr: 0.02\n",
      "iteration: 240620 loss: 0.0016 lr: 0.02\n",
      "iteration: 240630 loss: 0.0023 lr: 0.02\n",
      "iteration: 240640 loss: 0.0015 lr: 0.02\n",
      "iteration: 240650 loss: 0.0026 lr: 0.02\n",
      "iteration: 240660 loss: 0.0017 lr: 0.02\n",
      "iteration: 240670 loss: 0.0018 lr: 0.02\n",
      "iteration: 240680 loss: 0.0028 lr: 0.02\n",
      "iteration: 240690 loss: 0.0019 lr: 0.02\n",
      "iteration: 240700 loss: 0.0021 lr: 0.02\n",
      "iteration: 240710 loss: 0.0018 lr: 0.02\n",
      "iteration: 240720 loss: 0.0015 lr: 0.02\n",
      "iteration: 240730 loss: 0.0022 lr: 0.02\n",
      "iteration: 240740 loss: 0.0022 lr: 0.02\n",
      "iteration: 240750 loss: 0.0017 lr: 0.02\n",
      "iteration: 240760 loss: 0.0015 lr: 0.02\n",
      "iteration: 240770 loss: 0.0020 lr: 0.02\n",
      "iteration: 240780 loss: 0.0022 lr: 0.02\n",
      "iteration: 240790 loss: 0.0016 lr: 0.02\n",
      "iteration: 240800 loss: 0.0023 lr: 0.02\n",
      "iteration: 240810 loss: 0.0017 lr: 0.02\n",
      "iteration: 240820 loss: 0.0018 lr: 0.02\n",
      "iteration: 240830 loss: 0.0022 lr: 0.02\n",
      "iteration: 240840 loss: 0.0020 lr: 0.02\n",
      "iteration: 240850 loss: 0.0015 lr: 0.02\n",
      "iteration: 240860 loss: 0.0020 lr: 0.02\n",
      "iteration: 240870 loss: 0.0019 lr: 0.02\n",
      "iteration: 240880 loss: 0.0019 lr: 0.02\n",
      "iteration: 240890 loss: 0.0022 lr: 0.02\n",
      "iteration: 240900 loss: 0.0023 lr: 0.02\n",
      "iteration: 240910 loss: 0.0021 lr: 0.02\n",
      "iteration: 240920 loss: 0.0015 lr: 0.02\n",
      "iteration: 240930 loss: 0.0019 lr: 0.02\n",
      "iteration: 240940 loss: 0.0017 lr: 0.02\n",
      "iteration: 240950 loss: 0.0018 lr: 0.02\n",
      "iteration: 240960 loss: 0.0019 lr: 0.02\n",
      "iteration: 240970 loss: 0.0022 lr: 0.02\n",
      "iteration: 240980 loss: 0.0014 lr: 0.02\n",
      "iteration: 240990 loss: 0.0017 lr: 0.02\n",
      "iteration: 241000 loss: 0.0017 lr: 0.02\n",
      "iteration: 241010 loss: 0.0020 lr: 0.02\n",
      "iteration: 241020 loss: 0.0018 lr: 0.02\n",
      "iteration: 241030 loss: 0.0021 lr: 0.02\n",
      "iteration: 241040 loss: 0.0022 lr: 0.02\n",
      "iteration: 241050 loss: 0.0020 lr: 0.02\n",
      "iteration: 241060 loss: 0.0019 lr: 0.02\n",
      "iteration: 241070 loss: 0.0017 lr: 0.02\n",
      "iteration: 241080 loss: 0.0020 lr: 0.02\n",
      "iteration: 241090 loss: 0.0023 lr: 0.02\n",
      "iteration: 241100 loss: 0.0019 lr: 0.02\n",
      "iteration: 241110 loss: 0.0015 lr: 0.02\n",
      "iteration: 241120 loss: 0.0019 lr: 0.02\n",
      "iteration: 241130 loss: 0.0017 lr: 0.02\n",
      "iteration: 241140 loss: 0.0013 lr: 0.02\n",
      "iteration: 241150 loss: 0.0020 lr: 0.02\n",
      "iteration: 241160 loss: 0.0017 lr: 0.02\n",
      "iteration: 241170 loss: 0.0013 lr: 0.02\n",
      "iteration: 241180 loss: 0.0017 lr: 0.02\n",
      "iteration: 241190 loss: 0.0022 lr: 0.02\n",
      "iteration: 241200 loss: 0.0019 lr: 0.02\n",
      "iteration: 241210 loss: 0.0019 lr: 0.02\n",
      "iteration: 241220 loss: 0.0015 lr: 0.02\n",
      "iteration: 241230 loss: 0.0020 lr: 0.02\n",
      "iteration: 241240 loss: 0.0022 lr: 0.02\n",
      "iteration: 241250 loss: 0.0019 lr: 0.02\n",
      "iteration: 241260 loss: 0.0017 lr: 0.02\n",
      "iteration: 241270 loss: 0.0017 lr: 0.02\n",
      "iteration: 241280 loss: 0.0013 lr: 0.02\n",
      "iteration: 241290 loss: 0.0017 lr: 0.02\n",
      "iteration: 241300 loss: 0.0016 lr: 0.02\n",
      "iteration: 241310 loss: 0.0020 lr: 0.02\n",
      "iteration: 241320 loss: 0.0018 lr: 0.02\n",
      "iteration: 241330 loss: 0.0018 lr: 0.02\n",
      "iteration: 241340 loss: 0.0015 lr: 0.02\n",
      "iteration: 241350 loss: 0.0014 lr: 0.02\n",
      "iteration: 241360 loss: 0.0015 lr: 0.02\n",
      "iteration: 241370 loss: 0.0019 lr: 0.02\n",
      "iteration: 241380 loss: 0.0015 lr: 0.02\n",
      "iteration: 241390 loss: 0.0017 lr: 0.02\n",
      "iteration: 241400 loss: 0.0015 lr: 0.02\n",
      "iteration: 241410 loss: 0.0024 lr: 0.02\n",
      "iteration: 241420 loss: 0.0019 lr: 0.02\n",
      "iteration: 241430 loss: 0.0016 lr: 0.02\n",
      "iteration: 241440 loss: 0.0023 lr: 0.02\n",
      "iteration: 241450 loss: 0.0018 lr: 0.02\n",
      "iteration: 241460 loss: 0.0015 lr: 0.02\n",
      "iteration: 241470 loss: 0.0022 lr: 0.02\n",
      "iteration: 241480 loss: 0.0015 lr: 0.02\n",
      "iteration: 241490 loss: 0.0016 lr: 0.02\n",
      "iteration: 241500 loss: 0.0017 lr: 0.02\n",
      "iteration: 241510 loss: 0.0018 lr: 0.02\n",
      "iteration: 241520 loss: 0.0018 lr: 0.02\n",
      "iteration: 241530 loss: 0.0015 lr: 0.02\n",
      "iteration: 241540 loss: 0.0023 lr: 0.02\n",
      "iteration: 241550 loss: 0.0018 lr: 0.02\n",
      "iteration: 241560 loss: 0.0015 lr: 0.02\n",
      "iteration: 241570 loss: 0.0015 lr: 0.02\n",
      "iteration: 241580 loss: 0.0018 lr: 0.02\n",
      "iteration: 241590 loss: 0.0016 lr: 0.02\n",
      "iteration: 241600 loss: 0.0021 lr: 0.02\n",
      "iteration: 241610 loss: 0.0020 lr: 0.02\n",
      "iteration: 241620 loss: 0.0017 lr: 0.02\n",
      "iteration: 241630 loss: 0.0016 lr: 0.02\n",
      "iteration: 241640 loss: 0.0015 lr: 0.02\n",
      "iteration: 241650 loss: 0.0016 lr: 0.02\n",
      "iteration: 241660 loss: 0.0015 lr: 0.02\n",
      "iteration: 241670 loss: 0.0018 lr: 0.02\n",
      "iteration: 241680 loss: 0.0017 lr: 0.02\n",
      "iteration: 241690 loss: 0.0015 lr: 0.02\n",
      "iteration: 241700 loss: 0.0018 lr: 0.02\n",
      "iteration: 241710 loss: 0.0019 lr: 0.02\n",
      "iteration: 241720 loss: 0.0014 lr: 0.02\n",
      "iteration: 241730 loss: 0.0016 lr: 0.02\n",
      "iteration: 241740 loss: 0.0017 lr: 0.02\n",
      "iteration: 241750 loss: 0.0024 lr: 0.02\n",
      "iteration: 241760 loss: 0.0018 lr: 0.02\n",
      "iteration: 241770 loss: 0.0019 lr: 0.02\n",
      "iteration: 241780 loss: 0.0019 lr: 0.02\n",
      "iteration: 241790 loss: 0.0025 lr: 0.02\n",
      "iteration: 241800 loss: 0.0036 lr: 0.02\n",
      "iteration: 241810 loss: 0.0016 lr: 0.02\n",
      "iteration: 241820 loss: 0.0019 lr: 0.02\n",
      "iteration: 241830 loss: 0.0014 lr: 0.02\n",
      "iteration: 241840 loss: 0.0016 lr: 0.02\n",
      "iteration: 241850 loss: 0.0020 lr: 0.02\n",
      "iteration: 241860 loss: 0.0015 lr: 0.02\n",
      "iteration: 241870 loss: 0.0017 lr: 0.02\n",
      "iteration: 241880 loss: 0.0020 lr: 0.02\n",
      "iteration: 241890 loss: 0.0018 lr: 0.02\n",
      "iteration: 241900 loss: 0.0023 lr: 0.02\n",
      "iteration: 241910 loss: 0.0019 lr: 0.02\n",
      "iteration: 241920 loss: 0.0018 lr: 0.02\n",
      "iteration: 241930 loss: 0.0018 lr: 0.02\n",
      "iteration: 241940 loss: 0.0016 lr: 0.02\n",
      "iteration: 241950 loss: 0.0018 lr: 0.02\n",
      "iteration: 241960 loss: 0.0017 lr: 0.02\n",
      "iteration: 241970 loss: 0.0020 lr: 0.02\n",
      "iteration: 241980 loss: 0.0014 lr: 0.02\n",
      "iteration: 241990 loss: 0.0013 lr: 0.02\n",
      "iteration: 242000 loss: 0.0016 lr: 0.02\n",
      "iteration: 242010 loss: 0.0017 lr: 0.02\n",
      "iteration: 242020 loss: 0.0018 lr: 0.02\n",
      "iteration: 242030 loss: 0.0017 lr: 0.02\n",
      "iteration: 242040 loss: 0.0015 lr: 0.02\n",
      "iteration: 242050 loss: 0.0015 lr: 0.02\n",
      "iteration: 242060 loss: 0.0019 lr: 0.02\n",
      "iteration: 242070 loss: 0.0017 lr: 0.02\n",
      "iteration: 242080 loss: 0.0018 lr: 0.02\n",
      "iteration: 242090 loss: 0.0015 lr: 0.02\n",
      "iteration: 242100 loss: 0.0018 lr: 0.02\n",
      "iteration: 242110 loss: 0.0014 lr: 0.02\n",
      "iteration: 242120 loss: 0.0016 lr: 0.02\n",
      "iteration: 242130 loss: 0.0017 lr: 0.02\n",
      "iteration: 242140 loss: 0.0022 lr: 0.02\n",
      "iteration: 242150 loss: 0.0016 lr: 0.02\n",
      "iteration: 242160 loss: 0.0022 lr: 0.02\n",
      "iteration: 242170 loss: 0.0016 lr: 0.02\n",
      "iteration: 242180 loss: 0.0020 lr: 0.02\n",
      "iteration: 242190 loss: 0.0016 lr: 0.02\n",
      "iteration: 242200 loss: 0.0015 lr: 0.02\n",
      "iteration: 242210 loss: 0.0015 lr: 0.02\n",
      "iteration: 242220 loss: 0.0016 lr: 0.02\n",
      "iteration: 242230 loss: 0.0018 lr: 0.02\n",
      "iteration: 242240 loss: 0.0020 lr: 0.02\n",
      "iteration: 242250 loss: 0.0022 lr: 0.02\n",
      "iteration: 242260 loss: 0.0013 lr: 0.02\n",
      "iteration: 242270 loss: 0.0023 lr: 0.02\n",
      "iteration: 242280 loss: 0.0018 lr: 0.02\n",
      "iteration: 242290 loss: 0.0020 lr: 0.02\n",
      "iteration: 242300 loss: 0.0030 lr: 0.02\n",
      "iteration: 242310 loss: 0.0017 lr: 0.02\n",
      "iteration: 242320 loss: 0.0016 lr: 0.02\n",
      "iteration: 242330 loss: 0.0021 lr: 0.02\n",
      "iteration: 242340 loss: 0.0014 lr: 0.02\n",
      "iteration: 242350 loss: 0.0015 lr: 0.02\n",
      "iteration: 242360 loss: 0.0017 lr: 0.02\n",
      "iteration: 242370 loss: 0.0019 lr: 0.02\n",
      "iteration: 242380 loss: 0.0022 lr: 0.02\n",
      "iteration: 242390 loss: 0.0019 lr: 0.02\n",
      "iteration: 242400 loss: 0.0021 lr: 0.02\n",
      "iteration: 242410 loss: 0.0019 lr: 0.02\n",
      "iteration: 242420 loss: 0.0019 lr: 0.02\n",
      "iteration: 242430 loss: 0.0020 lr: 0.02\n",
      "iteration: 242440 loss: 0.0019 lr: 0.02\n",
      "iteration: 242450 loss: 0.0021 lr: 0.02\n",
      "iteration: 242460 loss: 0.0019 lr: 0.02\n",
      "iteration: 242470 loss: 0.0018 lr: 0.02\n",
      "iteration: 242480 loss: 0.0014 lr: 0.02\n",
      "iteration: 242490 loss: 0.0017 lr: 0.02\n",
      "iteration: 242500 loss: 0.0021 lr: 0.02\n",
      "iteration: 242510 loss: 0.0024 lr: 0.02\n",
      "iteration: 242520 loss: 0.0018 lr: 0.02\n",
      "iteration: 242530 loss: 0.0014 lr: 0.02\n",
      "iteration: 242540 loss: 0.0014 lr: 0.02\n",
      "iteration: 242550 loss: 0.0021 lr: 0.02\n",
      "iteration: 242560 loss: 0.0017 lr: 0.02\n",
      "iteration: 242570 loss: 0.0017 lr: 0.02\n",
      "iteration: 242580 loss: 0.0015 lr: 0.02\n",
      "iteration: 242590 loss: 0.0021 lr: 0.02\n",
      "iteration: 242600 loss: 0.0012 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 242610 loss: 0.0023 lr: 0.02\n",
      "iteration: 242620 loss: 0.0019 lr: 0.02\n",
      "iteration: 242630 loss: 0.0016 lr: 0.02\n",
      "iteration: 242640 loss: 0.0012 lr: 0.02\n",
      "iteration: 242650 loss: 0.0021 lr: 0.02\n",
      "iteration: 242660 loss: 0.0020 lr: 0.02\n",
      "iteration: 242670 loss: 0.0020 lr: 0.02\n",
      "iteration: 242680 loss: 0.0013 lr: 0.02\n",
      "iteration: 242690 loss: 0.0019 lr: 0.02\n",
      "iteration: 242700 loss: 0.0018 lr: 0.02\n",
      "iteration: 242710 loss: 0.0014 lr: 0.02\n",
      "iteration: 242720 loss: 0.0020 lr: 0.02\n",
      "iteration: 242730 loss: 0.0021 lr: 0.02\n",
      "iteration: 242740 loss: 0.0017 lr: 0.02\n",
      "iteration: 242750 loss: 0.0017 lr: 0.02\n",
      "iteration: 242760 loss: 0.0018 lr: 0.02\n",
      "iteration: 242770 loss: 0.0024 lr: 0.02\n",
      "iteration: 242780 loss: 0.0013 lr: 0.02\n",
      "iteration: 242790 loss: 0.0023 lr: 0.02\n",
      "iteration: 242800 loss: 0.0020 lr: 0.02\n",
      "iteration: 242810 loss: 0.0019 lr: 0.02\n",
      "iteration: 242820 loss: 0.0020 lr: 0.02\n",
      "iteration: 242830 loss: 0.0015 lr: 0.02\n",
      "iteration: 242840 loss: 0.0019 lr: 0.02\n",
      "iteration: 242850 loss: 0.0016 lr: 0.02\n",
      "iteration: 242860 loss: 0.0019 lr: 0.02\n",
      "iteration: 242870 loss: 0.0016 lr: 0.02\n",
      "iteration: 242880 loss: 0.0015 lr: 0.02\n",
      "iteration: 242890 loss: 0.0020 lr: 0.02\n",
      "iteration: 242900 loss: 0.0015 lr: 0.02\n",
      "iteration: 242910 loss: 0.0017 lr: 0.02\n",
      "iteration: 242920 loss: 0.0021 lr: 0.02\n",
      "iteration: 242930 loss: 0.0019 lr: 0.02\n",
      "iteration: 242940 loss: 0.0020 lr: 0.02\n",
      "iteration: 242950 loss: 0.0019 lr: 0.02\n",
      "iteration: 242960 loss: 0.0017 lr: 0.02\n",
      "iteration: 242970 loss: 0.0018 lr: 0.02\n",
      "iteration: 242980 loss: 0.0018 lr: 0.02\n",
      "iteration: 242990 loss: 0.0018 lr: 0.02\n",
      "iteration: 243000 loss: 0.0020 lr: 0.02\n",
      "iteration: 243010 loss: 0.0017 lr: 0.02\n",
      "iteration: 243020 loss: 0.0015 lr: 0.02\n",
      "iteration: 243030 loss: 0.0013 lr: 0.02\n",
      "iteration: 243040 loss: 0.0021 lr: 0.02\n",
      "iteration: 243050 loss: 0.0020 lr: 0.02\n",
      "iteration: 243060 loss: 0.0020 lr: 0.02\n",
      "iteration: 243070 loss: 0.0016 lr: 0.02\n",
      "iteration: 243080 loss: 0.0020 lr: 0.02\n",
      "iteration: 243090 loss: 0.0019 lr: 0.02\n",
      "iteration: 243100 loss: 0.0016 lr: 0.02\n",
      "iteration: 243110 loss: 0.0022 lr: 0.02\n",
      "iteration: 243120 loss: 0.0023 lr: 0.02\n",
      "iteration: 243130 loss: 0.0020 lr: 0.02\n",
      "iteration: 243140 loss: 0.0016 lr: 0.02\n",
      "iteration: 243150 loss: 0.0017 lr: 0.02\n",
      "iteration: 243160 loss: 0.0014 lr: 0.02\n",
      "iteration: 243170 loss: 0.0018 lr: 0.02\n",
      "iteration: 243180 loss: 0.0024 lr: 0.02\n",
      "iteration: 243190 loss: 0.0012 lr: 0.02\n",
      "iteration: 243200 loss: 0.0015 lr: 0.02\n",
      "iteration: 243210 loss: 0.0017 lr: 0.02\n",
      "iteration: 243220 loss: 0.0013 lr: 0.02\n",
      "iteration: 243230 loss: 0.0016 lr: 0.02\n",
      "iteration: 243240 loss: 0.0016 lr: 0.02\n",
      "iteration: 243250 loss: 0.0013 lr: 0.02\n",
      "iteration: 243260 loss: 0.0027 lr: 0.02\n",
      "iteration: 243270 loss: 0.0019 lr: 0.02\n",
      "iteration: 243280 loss: 0.0016 lr: 0.02\n",
      "iteration: 243290 loss: 0.0012 lr: 0.02\n",
      "iteration: 243300 loss: 0.0020 lr: 0.02\n",
      "iteration: 243310 loss: 0.0027 lr: 0.02\n",
      "iteration: 243320 loss: 0.0014 lr: 0.02\n",
      "iteration: 243330 loss: 0.0021 lr: 0.02\n",
      "iteration: 243340 loss: 0.0019 lr: 0.02\n",
      "iteration: 243350 loss: 0.0016 lr: 0.02\n",
      "iteration: 243360 loss: 0.0023 lr: 0.02\n",
      "iteration: 243370 loss: 0.0022 lr: 0.02\n",
      "iteration: 243380 loss: 0.0016 lr: 0.02\n",
      "iteration: 243390 loss: 0.0022 lr: 0.02\n",
      "iteration: 243400 loss: 0.0019 lr: 0.02\n",
      "iteration: 243410 loss: 0.0017 lr: 0.02\n",
      "iteration: 243420 loss: 0.0018 lr: 0.02\n",
      "iteration: 243430 loss: 0.0019 lr: 0.02\n",
      "iteration: 243440 loss: 0.0018 lr: 0.02\n",
      "iteration: 243450 loss: 0.0020 lr: 0.02\n",
      "iteration: 243460 loss: 0.0024 lr: 0.02\n",
      "iteration: 243470 loss: 0.0016 lr: 0.02\n",
      "iteration: 243480 loss: 0.0015 lr: 0.02\n",
      "iteration: 243490 loss: 0.0018 lr: 0.02\n",
      "iteration: 243500 loss: 0.0018 lr: 0.02\n",
      "iteration: 243510 loss: 0.0025 lr: 0.02\n",
      "iteration: 243520 loss: 0.0019 lr: 0.02\n",
      "iteration: 243530 loss: 0.0014 lr: 0.02\n",
      "iteration: 243540 loss: 0.0020 lr: 0.02\n",
      "iteration: 243550 loss: 0.0018 lr: 0.02\n",
      "iteration: 243560 loss: 0.0017 lr: 0.02\n",
      "iteration: 243570 loss: 0.0020 lr: 0.02\n",
      "iteration: 243580 loss: 0.0015 lr: 0.02\n",
      "iteration: 243590 loss: 0.0018 lr: 0.02\n",
      "iteration: 243600 loss: 0.0020 lr: 0.02\n",
      "iteration: 243610 loss: 0.0018 lr: 0.02\n",
      "iteration: 243620 loss: 0.0017 lr: 0.02\n",
      "iteration: 243630 loss: 0.0015 lr: 0.02\n",
      "iteration: 243640 loss: 0.0021 lr: 0.02\n",
      "iteration: 243650 loss: 0.0019 lr: 0.02\n",
      "iteration: 243660 loss: 0.0015 lr: 0.02\n",
      "iteration: 243670 loss: 0.0026 lr: 0.02\n",
      "iteration: 243680 loss: 0.0025 lr: 0.02\n",
      "iteration: 243690 loss: 0.0015 lr: 0.02\n",
      "iteration: 243700 loss: 0.0015 lr: 0.02\n",
      "iteration: 243710 loss: 0.0018 lr: 0.02\n",
      "iteration: 243720 loss: 0.0015 lr: 0.02\n",
      "iteration: 243730 loss: 0.0020 lr: 0.02\n",
      "iteration: 243740 loss: 0.0025 lr: 0.02\n",
      "iteration: 243750 loss: 0.0015 lr: 0.02\n",
      "iteration: 243760 loss: 0.0017 lr: 0.02\n",
      "iteration: 243770 loss: 0.0031 lr: 0.02\n",
      "iteration: 243780 loss: 0.0017 lr: 0.02\n",
      "iteration: 243790 loss: 0.0020 lr: 0.02\n",
      "iteration: 243800 loss: 0.0018 lr: 0.02\n",
      "iteration: 243810 loss: 0.0016 lr: 0.02\n",
      "iteration: 243820 loss: 0.0018 lr: 0.02\n",
      "iteration: 243830 loss: 0.0024 lr: 0.02\n",
      "iteration: 243840 loss: 0.0017 lr: 0.02\n",
      "iteration: 243850 loss: 0.0018 lr: 0.02\n",
      "iteration: 243860 loss: 0.0020 lr: 0.02\n",
      "iteration: 243870 loss: 0.0019 lr: 0.02\n",
      "iteration: 243880 loss: 0.0020 lr: 0.02\n",
      "iteration: 243890 loss: 0.0016 lr: 0.02\n",
      "iteration: 243900 loss: 0.0021 lr: 0.02\n",
      "iteration: 243910 loss: 0.0028 lr: 0.02\n",
      "iteration: 243920 loss: 0.0025 lr: 0.02\n",
      "iteration: 243930 loss: 0.0023 lr: 0.02\n",
      "iteration: 243940 loss: 0.0017 lr: 0.02\n",
      "iteration: 243950 loss: 0.0020 lr: 0.02\n",
      "iteration: 243960 loss: 0.0017 lr: 0.02\n",
      "iteration: 243970 loss: 0.0014 lr: 0.02\n",
      "iteration: 243980 loss: 0.0015 lr: 0.02\n",
      "iteration: 243990 loss: 0.0018 lr: 0.02\n",
      "iteration: 244000 loss: 0.0020 lr: 0.02\n",
      "iteration: 244010 loss: 0.0028 lr: 0.02\n",
      "iteration: 244020 loss: 0.0020 lr: 0.02\n",
      "iteration: 244030 loss: 0.0017 lr: 0.02\n",
      "iteration: 244040 loss: 0.0019 lr: 0.02\n",
      "iteration: 244050 loss: 0.0019 lr: 0.02\n",
      "iteration: 244060 loss: 0.0014 lr: 0.02\n",
      "iteration: 244070 loss: 0.0017 lr: 0.02\n",
      "iteration: 244080 loss: 0.0019 lr: 0.02\n",
      "iteration: 244090 loss: 0.0018 lr: 0.02\n",
      "iteration: 244100 loss: 0.0019 lr: 0.02\n",
      "iteration: 244110 loss: 0.0019 lr: 0.02\n",
      "iteration: 244120 loss: 0.0019 lr: 0.02\n",
      "iteration: 244130 loss: 0.0021 lr: 0.02\n",
      "iteration: 244140 loss: 0.0020 lr: 0.02\n",
      "iteration: 244150 loss: 0.0018 lr: 0.02\n",
      "iteration: 244160 loss: 0.0020 lr: 0.02\n",
      "iteration: 244170 loss: 0.0014 lr: 0.02\n",
      "iteration: 244180 loss: 0.0021 lr: 0.02\n",
      "iteration: 244190 loss: 0.0021 lr: 0.02\n",
      "iteration: 244200 loss: 0.0013 lr: 0.02\n",
      "iteration: 244210 loss: 0.0018 lr: 0.02\n",
      "iteration: 244220 loss: 0.0016 lr: 0.02\n",
      "iteration: 244230 loss: 0.0022 lr: 0.02\n",
      "iteration: 244240 loss: 0.0018 lr: 0.02\n",
      "iteration: 244250 loss: 0.0021 lr: 0.02\n",
      "iteration: 244260 loss: 0.0018 lr: 0.02\n",
      "iteration: 244270 loss: 0.0018 lr: 0.02\n",
      "iteration: 244280 loss: 0.0013 lr: 0.02\n",
      "iteration: 244290 loss: 0.0014 lr: 0.02\n",
      "iteration: 244300 loss: 0.0015 lr: 0.02\n",
      "iteration: 244310 loss: 0.0019 lr: 0.02\n",
      "iteration: 244320 loss: 0.0017 lr: 0.02\n",
      "iteration: 244330 loss: 0.0016 lr: 0.02\n",
      "iteration: 244340 loss: 0.0021 lr: 0.02\n",
      "iteration: 244350 loss: 0.0022 lr: 0.02\n",
      "iteration: 244360 loss: 0.0019 lr: 0.02\n",
      "iteration: 244370 loss: 0.0023 lr: 0.02\n",
      "iteration: 244380 loss: 0.0017 lr: 0.02\n",
      "iteration: 244390 loss: 0.0020 lr: 0.02\n",
      "iteration: 244400 loss: 0.0014 lr: 0.02\n",
      "iteration: 244410 loss: 0.0019 lr: 0.02\n",
      "iteration: 244420 loss: 0.0018 lr: 0.02\n",
      "iteration: 244430 loss: 0.0018 lr: 0.02\n",
      "iteration: 244440 loss: 0.0014 lr: 0.02\n",
      "iteration: 244450 loss: 0.0024 lr: 0.02\n",
      "iteration: 244460 loss: 0.0018 lr: 0.02\n",
      "iteration: 244470 loss: 0.0020 lr: 0.02\n",
      "iteration: 244480 loss: 0.0022 lr: 0.02\n",
      "iteration: 244490 loss: 0.0018 lr: 0.02\n",
      "iteration: 244500 loss: 0.0019 lr: 0.02\n",
      "iteration: 244510 loss: 0.0017 lr: 0.02\n",
      "iteration: 244520 loss: 0.0018 lr: 0.02\n",
      "iteration: 244530 loss: 0.0019 lr: 0.02\n",
      "iteration: 244540 loss: 0.0018 lr: 0.02\n",
      "iteration: 244550 loss: 0.0022 lr: 0.02\n",
      "iteration: 244560 loss: 0.0022 lr: 0.02\n",
      "iteration: 244570 loss: 0.0022 lr: 0.02\n",
      "iteration: 244580 loss: 0.0020 lr: 0.02\n",
      "iteration: 244590 loss: 0.0019 lr: 0.02\n",
      "iteration: 244600 loss: 0.0022 lr: 0.02\n",
      "iteration: 244610 loss: 0.0017 lr: 0.02\n",
      "iteration: 244620 loss: 0.0016 lr: 0.02\n",
      "iteration: 244630 loss: 0.0020 lr: 0.02\n",
      "iteration: 244640 loss: 0.0021 lr: 0.02\n",
      "iteration: 244650 loss: 0.0024 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 244660 loss: 0.0017 lr: 0.02\n",
      "iteration: 244670 loss: 0.0020 lr: 0.02\n",
      "iteration: 244680 loss: 0.0020 lr: 0.02\n",
      "iteration: 244690 loss: 0.0014 lr: 0.02\n",
      "iteration: 244700 loss: 0.0019 lr: 0.02\n",
      "iteration: 244710 loss: 0.0019 lr: 0.02\n",
      "iteration: 244720 loss: 0.0015 lr: 0.02\n",
      "iteration: 244730 loss: 0.0016 lr: 0.02\n",
      "iteration: 244740 loss: 0.0017 lr: 0.02\n",
      "iteration: 244750 loss: 0.0016 lr: 0.02\n",
      "iteration: 244760 loss: 0.0032 lr: 0.02\n",
      "iteration: 244770 loss: 0.0014 lr: 0.02\n",
      "iteration: 244780 loss: 0.0023 lr: 0.02\n",
      "iteration: 244790 loss: 0.0017 lr: 0.02\n",
      "iteration: 244800 loss: 0.0020 lr: 0.02\n",
      "iteration: 244810 loss: 0.0018 lr: 0.02\n",
      "iteration: 244820 loss: 0.0017 lr: 0.02\n",
      "iteration: 244830 loss: 0.0016 lr: 0.02\n",
      "iteration: 244840 loss: 0.0016 lr: 0.02\n",
      "iteration: 244850 loss: 0.0015 lr: 0.02\n",
      "iteration: 244860 loss: 0.0015 lr: 0.02\n",
      "iteration: 244870 loss: 0.0022 lr: 0.02\n",
      "iteration: 244880 loss: 0.0017 lr: 0.02\n",
      "iteration: 244890 loss: 0.0024 lr: 0.02\n",
      "iteration: 244900 loss: 0.0016 lr: 0.02\n",
      "iteration: 244910 loss: 0.0021 lr: 0.02\n",
      "iteration: 244920 loss: 0.0017 lr: 0.02\n",
      "iteration: 244930 loss: 0.0014 lr: 0.02\n",
      "iteration: 244940 loss: 0.0019 lr: 0.02\n",
      "iteration: 244950 loss: 0.0022 lr: 0.02\n",
      "iteration: 244960 loss: 0.0024 lr: 0.02\n",
      "iteration: 244970 loss: 0.0016 lr: 0.02\n",
      "iteration: 244980 loss: 0.0018 lr: 0.02\n",
      "iteration: 244990 loss: 0.0025 lr: 0.02\n",
      "iteration: 245000 loss: 0.0019 lr: 0.02\n",
      "iteration: 245010 loss: 0.0025 lr: 0.02\n",
      "iteration: 245020 loss: 0.0015 lr: 0.02\n",
      "iteration: 245030 loss: 0.0014 lr: 0.02\n",
      "iteration: 245040 loss: 0.0020 lr: 0.02\n",
      "iteration: 245050 loss: 0.0018 lr: 0.02\n",
      "iteration: 245060 loss: 0.0024 lr: 0.02\n",
      "iteration: 245070 loss: 0.0018 lr: 0.02\n",
      "iteration: 245080 loss: 0.0021 lr: 0.02\n",
      "iteration: 245090 loss: 0.0023 lr: 0.02\n",
      "iteration: 245100 loss: 0.0021 lr: 0.02\n",
      "iteration: 245110 loss: 0.0019 lr: 0.02\n",
      "iteration: 245120 loss: 0.0019 lr: 0.02\n",
      "iteration: 245130 loss: 0.0020 lr: 0.02\n",
      "iteration: 245140 loss: 0.0016 lr: 0.02\n",
      "iteration: 245150 loss: 0.0018 lr: 0.02\n",
      "iteration: 245160 loss: 0.0018 lr: 0.02\n",
      "iteration: 245170 loss: 0.0021 lr: 0.02\n",
      "iteration: 245180 loss: 0.0021 lr: 0.02\n",
      "iteration: 245190 loss: 0.0016 lr: 0.02\n",
      "iteration: 245200 loss: 0.0024 lr: 0.02\n",
      "iteration: 245210 loss: 0.0016 lr: 0.02\n",
      "iteration: 245220 loss: 0.0018 lr: 0.02\n",
      "iteration: 245230 loss: 0.0016 lr: 0.02\n",
      "iteration: 245240 loss: 0.0013 lr: 0.02\n",
      "iteration: 245250 loss: 0.0016 lr: 0.02\n",
      "iteration: 245260 loss: 0.0018 lr: 0.02\n",
      "iteration: 245270 loss: 0.0023 lr: 0.02\n",
      "iteration: 245280 loss: 0.0022 lr: 0.02\n",
      "iteration: 245290 loss: 0.0017 lr: 0.02\n",
      "iteration: 245300 loss: 0.0016 lr: 0.02\n",
      "iteration: 245310 loss: 0.0020 lr: 0.02\n",
      "iteration: 245320 loss: 0.0026 lr: 0.02\n",
      "iteration: 245330 loss: 0.0014 lr: 0.02\n",
      "iteration: 245340 loss: 0.0017 lr: 0.02\n",
      "iteration: 245350 loss: 0.0020 lr: 0.02\n",
      "iteration: 245360 loss: 0.0019 lr: 0.02\n",
      "iteration: 245370 loss: 0.0017 lr: 0.02\n",
      "iteration: 245380 loss: 0.0026 lr: 0.02\n",
      "iteration: 245390 loss: 0.0017 lr: 0.02\n",
      "iteration: 245400 loss: 0.0020 lr: 0.02\n",
      "iteration: 245410 loss: 0.0025 lr: 0.02\n",
      "iteration: 245420 loss: 0.0017 lr: 0.02\n",
      "iteration: 245430 loss: 0.0020 lr: 0.02\n",
      "iteration: 245440 loss: 0.0021 lr: 0.02\n",
      "iteration: 245450 loss: 0.0020 lr: 0.02\n",
      "iteration: 245460 loss: 0.0021 lr: 0.02\n",
      "iteration: 245470 loss: 0.0017 lr: 0.02\n",
      "iteration: 245480 loss: 0.0024 lr: 0.02\n",
      "iteration: 245490 loss: 0.0016 lr: 0.02\n",
      "iteration: 245500 loss: 0.0021 lr: 0.02\n",
      "iteration: 245510 loss: 0.0019 lr: 0.02\n",
      "iteration: 245520 loss: 0.0025 lr: 0.02\n",
      "iteration: 245530 loss: 0.0015 lr: 0.02\n",
      "iteration: 245540 loss: 0.0020 lr: 0.02\n",
      "iteration: 245550 loss: 0.0019 lr: 0.02\n",
      "iteration: 245560 loss: 0.0017 lr: 0.02\n",
      "iteration: 245570 loss: 0.0018 lr: 0.02\n",
      "iteration: 245580 loss: 0.0020 lr: 0.02\n",
      "iteration: 245590 loss: 0.0018 lr: 0.02\n",
      "iteration: 245600 loss: 0.0018 lr: 0.02\n",
      "iteration: 245610 loss: 0.0016 lr: 0.02\n",
      "iteration: 245620 loss: 0.0021 lr: 0.02\n",
      "iteration: 245630 loss: 0.0016 lr: 0.02\n",
      "iteration: 245640 loss: 0.0020 lr: 0.02\n",
      "iteration: 245650 loss: 0.0016 lr: 0.02\n",
      "iteration: 245660 loss: 0.0016 lr: 0.02\n",
      "iteration: 245670 loss: 0.0020 lr: 0.02\n",
      "iteration: 245680 loss: 0.0018 lr: 0.02\n",
      "iteration: 245690 loss: 0.0017 lr: 0.02\n",
      "iteration: 245700 loss: 0.0016 lr: 0.02\n",
      "iteration: 245710 loss: 0.0017 lr: 0.02\n",
      "iteration: 245720 loss: 0.0022 lr: 0.02\n",
      "iteration: 245730 loss: 0.0016 lr: 0.02\n",
      "iteration: 245740 loss: 0.0022 lr: 0.02\n",
      "iteration: 245750 loss: 0.0019 lr: 0.02\n",
      "iteration: 245760 loss: 0.0019 lr: 0.02\n",
      "iteration: 245770 loss: 0.0019 lr: 0.02\n",
      "iteration: 245780 loss: 0.0021 lr: 0.02\n",
      "iteration: 245790 loss: 0.0018 lr: 0.02\n",
      "iteration: 245800 loss: 0.0022 lr: 0.02\n",
      "iteration: 245810 loss: 0.0015 lr: 0.02\n",
      "iteration: 245820 loss: 0.0022 lr: 0.02\n",
      "iteration: 245830 loss: 0.0014 lr: 0.02\n",
      "iteration: 245840 loss: 0.0015 lr: 0.02\n",
      "iteration: 245850 loss: 0.0018 lr: 0.02\n",
      "iteration: 245860 loss: 0.0023 lr: 0.02\n",
      "iteration: 245870 loss: 0.0023 lr: 0.02\n",
      "iteration: 245880 loss: 0.0020 lr: 0.02\n",
      "iteration: 245890 loss: 0.0021 lr: 0.02\n",
      "iteration: 245900 loss: 0.0025 lr: 0.02\n",
      "iteration: 245910 loss: 0.0022 lr: 0.02\n",
      "iteration: 245920 loss: 0.0017 lr: 0.02\n",
      "iteration: 245930 loss: 0.0017 lr: 0.02\n",
      "iteration: 245940 loss: 0.0012 lr: 0.02\n",
      "iteration: 245950 loss: 0.0022 lr: 0.02\n",
      "iteration: 245960 loss: 0.0024 lr: 0.02\n",
      "iteration: 245970 loss: 0.0025 lr: 0.02\n",
      "iteration: 245980 loss: 0.0024 lr: 0.02\n",
      "iteration: 245990 loss: 0.0021 lr: 0.02\n",
      "iteration: 246000 loss: 0.0019 lr: 0.02\n",
      "iteration: 246010 loss: 0.0020 lr: 0.02\n",
      "iteration: 246020 loss: 0.0016 lr: 0.02\n",
      "iteration: 246030 loss: 0.0022 lr: 0.02\n",
      "iteration: 246040 loss: 0.0022 lr: 0.02\n",
      "iteration: 246050 loss: 0.0017 lr: 0.02\n",
      "iteration: 246060 loss: 0.0021 lr: 0.02\n",
      "iteration: 246070 loss: 0.0020 lr: 0.02\n",
      "iteration: 246080 loss: 0.0018 lr: 0.02\n",
      "iteration: 246090 loss: 0.0015 lr: 0.02\n",
      "iteration: 246100 loss: 0.0018 lr: 0.02\n",
      "iteration: 246110 loss: 0.0016 lr: 0.02\n",
      "iteration: 246120 loss: 0.0017 lr: 0.02\n",
      "iteration: 246130 loss: 0.0020 lr: 0.02\n",
      "iteration: 246140 loss: 0.0019 lr: 0.02\n",
      "iteration: 246150 loss: 0.0016 lr: 0.02\n",
      "iteration: 246160 loss: 0.0018 lr: 0.02\n",
      "iteration: 246170 loss: 0.0015 lr: 0.02\n",
      "iteration: 246180 loss: 0.0019 lr: 0.02\n",
      "iteration: 246190 loss: 0.0022 lr: 0.02\n",
      "iteration: 246200 loss: 0.0015 lr: 0.02\n",
      "iteration: 246210 loss: 0.0017 lr: 0.02\n",
      "iteration: 246220 loss: 0.0015 lr: 0.02\n",
      "iteration: 246230 loss: 0.0017 lr: 0.02\n",
      "iteration: 246240 loss: 0.0016 lr: 0.02\n",
      "iteration: 246250 loss: 0.0019 lr: 0.02\n",
      "iteration: 246260 loss: 0.0019 lr: 0.02\n",
      "iteration: 246270 loss: 0.0020 lr: 0.02\n",
      "iteration: 246280 loss: 0.0026 lr: 0.02\n",
      "iteration: 246290 loss: 0.0022 lr: 0.02\n",
      "iteration: 246300 loss: 0.0015 lr: 0.02\n",
      "iteration: 246310 loss: 0.0017 lr: 0.02\n",
      "iteration: 246320 loss: 0.0019 lr: 0.02\n",
      "iteration: 246330 loss: 0.0020 lr: 0.02\n",
      "iteration: 246340 loss: 0.0021 lr: 0.02\n",
      "iteration: 246350 loss: 0.0015 lr: 0.02\n",
      "iteration: 246360 loss: 0.0016 lr: 0.02\n",
      "iteration: 246370 loss: 0.0023 lr: 0.02\n",
      "iteration: 246380 loss: 0.0024 lr: 0.02\n",
      "iteration: 246390 loss: 0.0015 lr: 0.02\n",
      "iteration: 246400 loss: 0.0016 lr: 0.02\n",
      "iteration: 246410 loss: 0.0019 lr: 0.02\n",
      "iteration: 246420 loss: 0.0016 lr: 0.02\n",
      "iteration: 246430 loss: 0.0020 lr: 0.02\n",
      "iteration: 246440 loss: 0.0017 lr: 0.02\n",
      "iteration: 246450 loss: 0.0025 lr: 0.02\n",
      "iteration: 246460 loss: 0.0015 lr: 0.02\n",
      "iteration: 246470 loss: 0.0015 lr: 0.02\n",
      "iteration: 246480 loss: 0.0018 lr: 0.02\n",
      "iteration: 246490 loss: 0.0017 lr: 0.02\n",
      "iteration: 246500 loss: 0.0015 lr: 0.02\n",
      "iteration: 246510 loss: 0.0017 lr: 0.02\n",
      "iteration: 246520 loss: 0.0015 lr: 0.02\n",
      "iteration: 246530 loss: 0.0020 lr: 0.02\n",
      "iteration: 246540 loss: 0.0017 lr: 0.02\n",
      "iteration: 246550 loss: 0.0019 lr: 0.02\n",
      "iteration: 246560 loss: 0.0021 lr: 0.02\n",
      "iteration: 246570 loss: 0.0016 lr: 0.02\n",
      "iteration: 246580 loss: 0.0023 lr: 0.02\n",
      "iteration: 246590 loss: 0.0015 lr: 0.02\n",
      "iteration: 246600 loss: 0.0020 lr: 0.02\n",
      "iteration: 246610 loss: 0.0017 lr: 0.02\n",
      "iteration: 246620 loss: 0.0014 lr: 0.02\n",
      "iteration: 246630 loss: 0.0019 lr: 0.02\n",
      "iteration: 246640 loss: 0.0032 lr: 0.02\n",
      "iteration: 246650 loss: 0.0024 lr: 0.02\n",
      "iteration: 246660 loss: 0.0027 lr: 0.02\n",
      "iteration: 246670 loss: 0.0016 lr: 0.02\n",
      "iteration: 246680 loss: 0.0013 lr: 0.02\n",
      "iteration: 246690 loss: 0.0023 lr: 0.02\n",
      "iteration: 246700 loss: 0.0020 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 246710 loss: 0.0017 lr: 0.02\n",
      "iteration: 246720 loss: 0.0016 lr: 0.02\n",
      "iteration: 246730 loss: 0.0020 lr: 0.02\n",
      "iteration: 246740 loss: 0.0019 lr: 0.02\n",
      "iteration: 246750 loss: 0.0018 lr: 0.02\n",
      "iteration: 246760 loss: 0.0018 lr: 0.02\n",
      "iteration: 246770 loss: 0.0018 lr: 0.02\n",
      "iteration: 246780 loss: 0.0034 lr: 0.02\n",
      "iteration: 246790 loss: 0.0018 lr: 0.02\n",
      "iteration: 246800 loss: 0.0022 lr: 0.02\n",
      "iteration: 246810 loss: 0.0016 lr: 0.02\n",
      "iteration: 246820 loss: 0.0020 lr: 0.02\n",
      "iteration: 246830 loss: 0.0020 lr: 0.02\n",
      "iteration: 246840 loss: 0.0018 lr: 0.02\n",
      "iteration: 246850 loss: 0.0015 lr: 0.02\n",
      "iteration: 246860 loss: 0.0014 lr: 0.02\n",
      "iteration: 246870 loss: 0.0011 lr: 0.02\n",
      "iteration: 246880 loss: 0.0015 lr: 0.02\n",
      "iteration: 246890 loss: 0.0021 lr: 0.02\n",
      "iteration: 246900 loss: 0.0020 lr: 0.02\n",
      "iteration: 246910 loss: 0.0016 lr: 0.02\n",
      "iteration: 246920 loss: 0.0017 lr: 0.02\n",
      "iteration: 246930 loss: 0.0019 lr: 0.02\n",
      "iteration: 246940 loss: 0.0021 lr: 0.02\n",
      "iteration: 246950 loss: 0.0017 lr: 0.02\n",
      "iteration: 246960 loss: 0.0017 lr: 0.02\n",
      "iteration: 246970 loss: 0.0018 lr: 0.02\n",
      "iteration: 246980 loss: 0.0013 lr: 0.02\n",
      "iteration: 246990 loss: 0.0017 lr: 0.02\n",
      "iteration: 247000 loss: 0.0019 lr: 0.02\n",
      "iteration: 247010 loss: 0.0029 lr: 0.02\n",
      "iteration: 247020 loss: 0.0026 lr: 0.02\n",
      "iteration: 247030 loss: 0.0024 lr: 0.02\n",
      "iteration: 247040 loss: 0.0023 lr: 0.02\n",
      "iteration: 247050 loss: 0.0022 lr: 0.02\n",
      "iteration: 247060 loss: 0.0018 lr: 0.02\n",
      "iteration: 247070 loss: 0.0020 lr: 0.02\n",
      "iteration: 247080 loss: 0.0018 lr: 0.02\n",
      "iteration: 247090 loss: 0.0017 lr: 0.02\n",
      "iteration: 247100 loss: 0.0020 lr: 0.02\n",
      "iteration: 247110 loss: 0.0019 lr: 0.02\n",
      "iteration: 247120 loss: 0.0018 lr: 0.02\n",
      "iteration: 247130 loss: 0.0018 lr: 0.02\n",
      "iteration: 247140 loss: 0.0014 lr: 0.02\n",
      "iteration: 247150 loss: 0.0016 lr: 0.02\n",
      "iteration: 247160 loss: 0.0019 lr: 0.02\n",
      "iteration: 247170 loss: 0.0025 lr: 0.02\n",
      "iteration: 247180 loss: 0.0018 lr: 0.02\n",
      "iteration: 247190 loss: 0.0021 lr: 0.02\n",
      "iteration: 247200 loss: 0.0018 lr: 0.02\n",
      "iteration: 247210 loss: 0.0019 lr: 0.02\n",
      "iteration: 247220 loss: 0.0018 lr: 0.02\n",
      "iteration: 247230 loss: 0.0012 lr: 0.02\n",
      "iteration: 247240 loss: 0.0017 lr: 0.02\n",
      "iteration: 247250 loss: 0.0014 lr: 0.02\n",
      "iteration: 247260 loss: 0.0017 lr: 0.02\n",
      "iteration: 247270 loss: 0.0020 lr: 0.02\n",
      "iteration: 247280 loss: 0.0016 lr: 0.02\n",
      "iteration: 247290 loss: 0.0020 lr: 0.02\n",
      "iteration: 247300 loss: 0.0015 lr: 0.02\n",
      "iteration: 247310 loss: 0.0015 lr: 0.02\n",
      "iteration: 247320 loss: 0.0020 lr: 0.02\n",
      "iteration: 247330 loss: 0.0018 lr: 0.02\n",
      "iteration: 247340 loss: 0.0020 lr: 0.02\n",
      "iteration: 247350 loss: 0.0016 lr: 0.02\n",
      "iteration: 247360 loss: 0.0016 lr: 0.02\n",
      "iteration: 247370 loss: 0.0029 lr: 0.02\n",
      "iteration: 247380 loss: 0.0020 lr: 0.02\n",
      "iteration: 247390 loss: 0.0018 lr: 0.02\n",
      "iteration: 247400 loss: 0.0021 lr: 0.02\n",
      "iteration: 247410 loss: 0.0020 lr: 0.02\n",
      "iteration: 247420 loss: 0.0017 lr: 0.02\n",
      "iteration: 247430 loss: 0.0018 lr: 0.02\n",
      "iteration: 247440 loss: 0.0018 lr: 0.02\n",
      "iteration: 247450 loss: 0.0017 lr: 0.02\n",
      "iteration: 247460 loss: 0.0019 lr: 0.02\n",
      "iteration: 247470 loss: 0.0014 lr: 0.02\n",
      "iteration: 247480 loss: 0.0019 lr: 0.02\n",
      "iteration: 247490 loss: 0.0016 lr: 0.02\n",
      "iteration: 247500 loss: 0.0022 lr: 0.02\n",
      "iteration: 247510 loss: 0.0015 lr: 0.02\n",
      "iteration: 247520 loss: 0.0021 lr: 0.02\n",
      "iteration: 247530 loss: 0.0019 lr: 0.02\n",
      "iteration: 247540 loss: 0.0017 lr: 0.02\n",
      "iteration: 247550 loss: 0.0018 lr: 0.02\n",
      "iteration: 247560 loss: 0.0012 lr: 0.02\n",
      "iteration: 247570 loss: 0.0013 lr: 0.02\n",
      "iteration: 247580 loss: 0.0016 lr: 0.02\n",
      "iteration: 247590 loss: 0.0017 lr: 0.02\n",
      "iteration: 247600 loss: 0.0016 lr: 0.02\n",
      "iteration: 247610 loss: 0.0021 lr: 0.02\n",
      "iteration: 247620 loss: 0.0018 lr: 0.02\n",
      "iteration: 247630 loss: 0.0017 lr: 0.02\n",
      "iteration: 247640 loss: 0.0017 lr: 0.02\n",
      "iteration: 247650 loss: 0.0023 lr: 0.02\n",
      "iteration: 247660 loss: 0.0013 lr: 0.02\n",
      "iteration: 247670 loss: 0.0028 lr: 0.02\n",
      "iteration: 247680 loss: 0.0022 lr: 0.02\n",
      "iteration: 247690 loss: 0.0020 lr: 0.02\n",
      "iteration: 247700 loss: 0.0020 lr: 0.02\n",
      "iteration: 247710 loss: 0.0019 lr: 0.02\n",
      "iteration: 247720 loss: 0.0020 lr: 0.02\n",
      "iteration: 247730 loss: 0.0014 lr: 0.02\n",
      "iteration: 247740 loss: 0.0016 lr: 0.02\n",
      "iteration: 247750 loss: 0.0018 lr: 0.02\n",
      "iteration: 247760 loss: 0.0023 lr: 0.02\n",
      "iteration: 247770 loss: 0.0020 lr: 0.02\n",
      "iteration: 247780 loss: 0.0017 lr: 0.02\n",
      "iteration: 247790 loss: 0.0028 lr: 0.02\n",
      "iteration: 247800 loss: 0.0025 lr: 0.02\n",
      "iteration: 247810 loss: 0.0017 lr: 0.02\n",
      "iteration: 247820 loss: 0.0020 lr: 0.02\n",
      "iteration: 247830 loss: 0.0017 lr: 0.02\n",
      "iteration: 247840 loss: 0.0017 lr: 0.02\n",
      "iteration: 247850 loss: 0.0012 lr: 0.02\n",
      "iteration: 247860 loss: 0.0027 lr: 0.02\n",
      "iteration: 247870 loss: 0.0018 lr: 0.02\n",
      "iteration: 247880 loss: 0.0015 lr: 0.02\n",
      "iteration: 247890 loss: 0.0018 lr: 0.02\n",
      "iteration: 247900 loss: 0.0020 lr: 0.02\n",
      "iteration: 247910 loss: 0.0016 lr: 0.02\n",
      "iteration: 247920 loss: 0.0030 lr: 0.02\n",
      "iteration: 247930 loss: 0.0024 lr: 0.02\n",
      "iteration: 247940 loss: 0.0023 lr: 0.02\n",
      "iteration: 247950 loss: 0.0014 lr: 0.02\n",
      "iteration: 247960 loss: 0.0019 lr: 0.02\n",
      "iteration: 247970 loss: 0.0015 lr: 0.02\n",
      "iteration: 247980 loss: 0.0021 lr: 0.02\n",
      "iteration: 247990 loss: 0.0020 lr: 0.02\n",
      "iteration: 248000 loss: 0.0020 lr: 0.02\n",
      "iteration: 248010 loss: 0.0019 lr: 0.02\n",
      "iteration: 248020 loss: 0.0014 lr: 0.02\n",
      "iteration: 248030 loss: 0.0018 lr: 0.02\n",
      "iteration: 248040 loss: 0.0019 lr: 0.02\n",
      "iteration: 248050 loss: 0.0014 lr: 0.02\n",
      "iteration: 248060 loss: 0.0020 lr: 0.02\n",
      "iteration: 248070 loss: 0.0017 lr: 0.02\n",
      "iteration: 248080 loss: 0.0020 lr: 0.02\n",
      "iteration: 248090 loss: 0.0019 lr: 0.02\n",
      "iteration: 248100 loss: 0.0018 lr: 0.02\n",
      "iteration: 248110 loss: 0.0020 lr: 0.02\n",
      "iteration: 248120 loss: 0.0017 lr: 0.02\n",
      "iteration: 248130 loss: 0.0022 lr: 0.02\n",
      "iteration: 248140 loss: 0.0018 lr: 0.02\n",
      "iteration: 248150 loss: 0.0019 lr: 0.02\n",
      "iteration: 248160 loss: 0.0019 lr: 0.02\n",
      "iteration: 248170 loss: 0.0019 lr: 0.02\n",
      "iteration: 248180 loss: 0.0023 lr: 0.02\n",
      "iteration: 248190 loss: 0.0020 lr: 0.02\n",
      "iteration: 248200 loss: 0.0016 lr: 0.02\n",
      "iteration: 248210 loss: 0.0021 lr: 0.02\n",
      "iteration: 248220 loss: 0.0021 lr: 0.02\n",
      "iteration: 248230 loss: 0.0024 lr: 0.02\n",
      "iteration: 248240 loss: 0.0021 lr: 0.02\n",
      "iteration: 248250 loss: 0.0017 lr: 0.02\n",
      "iteration: 248260 loss: 0.0018 lr: 0.02\n",
      "iteration: 248270 loss: 0.0018 lr: 0.02\n",
      "iteration: 248280 loss: 0.0018 lr: 0.02\n",
      "iteration: 248290 loss: 0.0017 lr: 0.02\n",
      "iteration: 248300 loss: 0.0024 lr: 0.02\n",
      "iteration: 248310 loss: 0.0019 lr: 0.02\n",
      "iteration: 248320 loss: 0.0020 lr: 0.02\n",
      "iteration: 248330 loss: 0.0018 lr: 0.02\n",
      "iteration: 248340 loss: 0.0018 lr: 0.02\n",
      "iteration: 248350 loss: 0.0021 lr: 0.02\n",
      "iteration: 248360 loss: 0.0017 lr: 0.02\n",
      "iteration: 248370 loss: 0.0022 lr: 0.02\n",
      "iteration: 248380 loss: 0.0017 lr: 0.02\n",
      "iteration: 248390 loss: 0.0017 lr: 0.02\n",
      "iteration: 248400 loss: 0.0019 lr: 0.02\n",
      "iteration: 248410 loss: 0.0026 lr: 0.02\n",
      "iteration: 248420 loss: 0.0017 lr: 0.02\n",
      "iteration: 248430 loss: 0.0021 lr: 0.02\n",
      "iteration: 248440 loss: 0.0022 lr: 0.02\n",
      "iteration: 248450 loss: 0.0017 lr: 0.02\n",
      "iteration: 248460 loss: 0.0022 lr: 0.02\n",
      "iteration: 248470 loss: 0.0022 lr: 0.02\n",
      "iteration: 248480 loss: 0.0021 lr: 0.02\n",
      "iteration: 248490 loss: 0.0016 lr: 0.02\n",
      "iteration: 248500 loss: 0.0017 lr: 0.02\n",
      "iteration: 248510 loss: 0.0019 lr: 0.02\n",
      "iteration: 248520 loss: 0.0024 lr: 0.02\n",
      "iteration: 248530 loss: 0.0022 lr: 0.02\n",
      "iteration: 248540 loss: 0.0017 lr: 0.02\n",
      "iteration: 248550 loss: 0.0021 lr: 0.02\n",
      "iteration: 248560 loss: 0.0021 lr: 0.02\n",
      "iteration: 248570 loss: 0.0017 lr: 0.02\n",
      "iteration: 248580 loss: 0.0015 lr: 0.02\n",
      "iteration: 248590 loss: 0.0015 lr: 0.02\n",
      "iteration: 248600 loss: 0.0012 lr: 0.02\n",
      "iteration: 248610 loss: 0.0015 lr: 0.02\n",
      "iteration: 248620 loss: 0.0016 lr: 0.02\n",
      "iteration: 248630 loss: 0.0019 lr: 0.02\n",
      "iteration: 248640 loss: 0.0014 lr: 0.02\n",
      "iteration: 248650 loss: 0.0018 lr: 0.02\n",
      "iteration: 248660 loss: 0.0017 lr: 0.02\n",
      "iteration: 248670 loss: 0.0017 lr: 0.02\n",
      "iteration: 248680 loss: 0.0017 lr: 0.02\n",
      "iteration: 248690 loss: 0.0013 lr: 0.02\n",
      "iteration: 248700 loss: 0.0018 lr: 0.02\n",
      "iteration: 248710 loss: 0.0015 lr: 0.02\n",
      "iteration: 248720 loss: 0.0019 lr: 0.02\n",
      "iteration: 248730 loss: 0.0017 lr: 0.02\n",
      "iteration: 248740 loss: 0.0018 lr: 0.02\n",
      "iteration: 248750 loss: 0.0019 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 248760 loss: 0.0016 lr: 0.02\n",
      "iteration: 248770 loss: 0.0020 lr: 0.02\n",
      "iteration: 248780 loss: 0.0020 lr: 0.02\n",
      "iteration: 248790 loss: 0.0020 lr: 0.02\n",
      "iteration: 248800 loss: 0.0015 lr: 0.02\n",
      "iteration: 248810 loss: 0.0020 lr: 0.02\n",
      "iteration: 248820 loss: 0.0016 lr: 0.02\n",
      "iteration: 248830 loss: 0.0016 lr: 0.02\n",
      "iteration: 248840 loss: 0.0016 lr: 0.02\n",
      "iteration: 248850 loss: 0.0018 lr: 0.02\n",
      "iteration: 248860 loss: 0.0016 lr: 0.02\n",
      "iteration: 248870 loss: 0.0024 lr: 0.02\n",
      "iteration: 248880 loss: 0.0021 lr: 0.02\n",
      "iteration: 248890 loss: 0.0016 lr: 0.02\n",
      "iteration: 248900 loss: 0.0020 lr: 0.02\n",
      "iteration: 248910 loss: 0.0012 lr: 0.02\n",
      "iteration: 248920 loss: 0.0022 lr: 0.02\n",
      "iteration: 248930 loss: 0.0023 lr: 0.02\n",
      "iteration: 248940 loss: 0.0018 lr: 0.02\n",
      "iteration: 248950 loss: 0.0018 lr: 0.02\n",
      "iteration: 248960 loss: 0.0021 lr: 0.02\n",
      "iteration: 248970 loss: 0.0021 lr: 0.02\n",
      "iteration: 248980 loss: 0.0020 lr: 0.02\n",
      "iteration: 248990 loss: 0.0019 lr: 0.02\n",
      "iteration: 249000 loss: 0.0021 lr: 0.02\n",
      "iteration: 249010 loss: 0.0017 lr: 0.02\n",
      "iteration: 249020 loss: 0.0013 lr: 0.02\n",
      "iteration: 249030 loss: 0.0017 lr: 0.02\n",
      "iteration: 249040 loss: 0.0016 lr: 0.02\n",
      "iteration: 249050 loss: 0.0020 lr: 0.02\n",
      "iteration: 249060 loss: 0.0020 lr: 0.02\n",
      "iteration: 249070 loss: 0.0027 lr: 0.02\n",
      "iteration: 249080 loss: 0.0032 lr: 0.02\n",
      "iteration: 249090 loss: 0.0018 lr: 0.02\n",
      "iteration: 249100 loss: 0.0015 lr: 0.02\n",
      "iteration: 249110 loss: 0.0017 lr: 0.02\n",
      "iteration: 249120 loss: 0.0012 lr: 0.02\n",
      "iteration: 249130 loss: 0.0020 lr: 0.02\n",
      "iteration: 249140 loss: 0.0017 lr: 0.02\n",
      "iteration: 249150 loss: 0.0014 lr: 0.02\n",
      "iteration: 249160 loss: 0.0023 lr: 0.02\n",
      "iteration: 249170 loss: 0.0016 lr: 0.02\n",
      "iteration: 249180 loss: 0.0015 lr: 0.02\n",
      "iteration: 249190 loss: 0.0013 lr: 0.02\n",
      "iteration: 249200 loss: 0.0024 lr: 0.02\n",
      "iteration: 249210 loss: 0.0013 lr: 0.02\n",
      "iteration: 249220 loss: 0.0017 lr: 0.02\n",
      "iteration: 249230 loss: 0.0023 lr: 0.02\n",
      "iteration: 249240 loss: 0.0016 lr: 0.02\n",
      "iteration: 249250 loss: 0.0018 lr: 0.02\n",
      "iteration: 249260 loss: 0.0020 lr: 0.02\n",
      "iteration: 249270 loss: 0.0020 lr: 0.02\n",
      "iteration: 249280 loss: 0.0020 lr: 0.02\n",
      "iteration: 249290 loss: 0.0022 lr: 0.02\n",
      "iteration: 249300 loss: 0.0019 lr: 0.02\n",
      "iteration: 249310 loss: 0.0024 lr: 0.02\n",
      "iteration: 249320 loss: 0.0020 lr: 0.02\n",
      "iteration: 249330 loss: 0.0013 lr: 0.02\n",
      "iteration: 249340 loss: 0.0018 lr: 0.02\n",
      "iteration: 249350 loss: 0.0014 lr: 0.02\n",
      "iteration: 249360 loss: 0.0022 lr: 0.02\n",
      "iteration: 249370 loss: 0.0016 lr: 0.02\n",
      "iteration: 249380 loss: 0.0017 lr: 0.02\n",
      "iteration: 249390 loss: 0.0019 lr: 0.02\n",
      "iteration: 249400 loss: 0.0018 lr: 0.02\n",
      "iteration: 249410 loss: 0.0022 lr: 0.02\n",
      "iteration: 249420 loss: 0.0017 lr: 0.02\n",
      "iteration: 249430 loss: 0.0017 lr: 0.02\n",
      "iteration: 249440 loss: 0.0021 lr: 0.02\n",
      "iteration: 249450 loss: 0.0015 lr: 0.02\n",
      "iteration: 249460 loss: 0.0015 lr: 0.02\n",
      "iteration: 249470 loss: 0.0021 lr: 0.02\n",
      "iteration: 249480 loss: 0.0017 lr: 0.02\n",
      "iteration: 249490 loss: 0.0022 lr: 0.02\n",
      "iteration: 249500 loss: 0.0020 lr: 0.02\n",
      "iteration: 249510 loss: 0.0015 lr: 0.02\n",
      "iteration: 249520 loss: 0.0014 lr: 0.02\n",
      "iteration: 249530 loss: 0.0015 lr: 0.02\n",
      "iteration: 249540 loss: 0.0023 lr: 0.02\n",
      "iteration: 249550 loss: 0.0025 lr: 0.02\n",
      "iteration: 249560 loss: 0.0018 lr: 0.02\n",
      "iteration: 249570 loss: 0.0019 lr: 0.02\n",
      "iteration: 249580 loss: 0.0019 lr: 0.02\n",
      "iteration: 249590 loss: 0.0016 lr: 0.02\n",
      "iteration: 249600 loss: 0.0020 lr: 0.02\n",
      "iteration: 249610 loss: 0.0016 lr: 0.02\n",
      "iteration: 249620 loss: 0.0021 lr: 0.02\n",
      "iteration: 249630 loss: 0.0025 lr: 0.02\n",
      "iteration: 249640 loss: 0.0022 lr: 0.02\n",
      "iteration: 249650 loss: 0.0015 lr: 0.02\n",
      "iteration: 249660 loss: 0.0020 lr: 0.02\n",
      "iteration: 249670 loss: 0.0024 lr: 0.02\n",
      "iteration: 249680 loss: 0.0019 lr: 0.02\n",
      "iteration: 249690 loss: 0.0018 lr: 0.02\n",
      "iteration: 249700 loss: 0.0018 lr: 0.02\n",
      "iteration: 249710 loss: 0.0018 lr: 0.02\n",
      "iteration: 249720 loss: 0.0022 lr: 0.02\n",
      "iteration: 249730 loss: 0.0026 lr: 0.02\n",
      "iteration: 249740 loss: 0.0021 lr: 0.02\n",
      "iteration: 249750 loss: 0.0019 lr: 0.02\n",
      "iteration: 249760 loss: 0.0022 lr: 0.02\n",
      "iteration: 249770 loss: 0.0021 lr: 0.02\n",
      "iteration: 249780 loss: 0.0021 lr: 0.02\n",
      "iteration: 249790 loss: 0.0016 lr: 0.02\n",
      "iteration: 249800 loss: 0.0021 lr: 0.02\n",
      "iteration: 249810 loss: 0.0020 lr: 0.02\n",
      "iteration: 249820 loss: 0.0014 lr: 0.02\n",
      "iteration: 249830 loss: 0.0015 lr: 0.02\n",
      "iteration: 249840 loss: 0.0021 lr: 0.02\n",
      "iteration: 249850 loss: 0.0021 lr: 0.02\n",
      "iteration: 249860 loss: 0.0022 lr: 0.02\n",
      "iteration: 249870 loss: 0.0015 lr: 0.02\n",
      "iteration: 249880 loss: 0.0021 lr: 0.02\n",
      "iteration: 249890 loss: 0.0017 lr: 0.02\n",
      "iteration: 249900 loss: 0.0019 lr: 0.02\n",
      "iteration: 249910 loss: 0.0020 lr: 0.02\n",
      "iteration: 249920 loss: 0.0019 lr: 0.02\n",
      "iteration: 249930 loss: 0.0022 lr: 0.02\n",
      "iteration: 249940 loss: 0.0025 lr: 0.02\n",
      "iteration: 249950 loss: 0.0020 lr: 0.02\n",
      "iteration: 249960 loss: 0.0022 lr: 0.02\n",
      "iteration: 249970 loss: 0.0016 lr: 0.02\n",
      "iteration: 249980 loss: 0.0016 lr: 0.02\n",
      "iteration: 249990 loss: 0.0016 lr: 0.02\n",
      "iteration: 250000 loss: 0.0018 lr: 0.02\n",
      "iteration: 250010 loss: 0.0014 lr: 0.02\n",
      "iteration: 250020 loss: 0.0017 lr: 0.02\n",
      "iteration: 250030 loss: 0.0015 lr: 0.02\n",
      "iteration: 250040 loss: 0.0016 lr: 0.02\n",
      "iteration: 250050 loss: 0.0014 lr: 0.02\n",
      "iteration: 250060 loss: 0.0022 lr: 0.02\n",
      "iteration: 250070 loss: 0.0016 lr: 0.02\n",
      "iteration: 250080 loss: 0.0021 lr: 0.02\n",
      "iteration: 250090 loss: 0.0016 lr: 0.02\n",
      "iteration: 250100 loss: 0.0022 lr: 0.02\n",
      "iteration: 250110 loss: 0.0019 lr: 0.02\n",
      "iteration: 250120 loss: 0.0022 lr: 0.02\n",
      "iteration: 250130 loss: 0.0018 lr: 0.02\n",
      "iteration: 250140 loss: 0.0017 lr: 0.02\n",
      "iteration: 250150 loss: 0.0016 lr: 0.02\n",
      "iteration: 250160 loss: 0.0014 lr: 0.02\n",
      "iteration: 250170 loss: 0.0019 lr: 0.02\n",
      "iteration: 250180 loss: 0.0017 lr: 0.02\n",
      "iteration: 250190 loss: 0.0021 lr: 0.02\n",
      "iteration: 250200 loss: 0.0020 lr: 0.02\n",
      "iteration: 250210 loss: 0.0018 lr: 0.02\n",
      "iteration: 250220 loss: 0.0017 lr: 0.02\n",
      "iteration: 250230 loss: 0.0015 lr: 0.02\n",
      "iteration: 250240 loss: 0.0013 lr: 0.02\n",
      "iteration: 250250 loss: 0.0016 lr: 0.02\n",
      "iteration: 250260 loss: 0.0018 lr: 0.02\n",
      "iteration: 250270 loss: 0.0017 lr: 0.02\n",
      "iteration: 250280 loss: 0.0023 lr: 0.02\n",
      "iteration: 250290 loss: 0.0017 lr: 0.02\n",
      "iteration: 250300 loss: 0.0014 lr: 0.02\n",
      "iteration: 250310 loss: 0.0015 lr: 0.02\n",
      "iteration: 250320 loss: 0.0017 lr: 0.02\n",
      "iteration: 250330 loss: 0.0021 lr: 0.02\n",
      "iteration: 250340 loss: 0.0014 lr: 0.02\n",
      "iteration: 250350 loss: 0.0016 lr: 0.02\n",
      "iteration: 250360 loss: 0.0017 lr: 0.02\n",
      "iteration: 250370 loss: 0.0015 lr: 0.02\n",
      "iteration: 250380 loss: 0.0018 lr: 0.02\n",
      "iteration: 250390 loss: 0.0018 lr: 0.02\n",
      "iteration: 250400 loss: 0.0022 lr: 0.02\n",
      "iteration: 250410 loss: 0.0014 lr: 0.02\n",
      "iteration: 250420 loss: 0.0018 lr: 0.02\n",
      "iteration: 250430 loss: 0.0018 lr: 0.02\n",
      "iteration: 250440 loss: 0.0023 lr: 0.02\n",
      "iteration: 250450 loss: 0.0020 lr: 0.02\n",
      "iteration: 250460 loss: 0.0017 lr: 0.02\n",
      "iteration: 250470 loss: 0.0016 lr: 0.02\n",
      "iteration: 250480 loss: 0.0017 lr: 0.02\n",
      "iteration: 250490 loss: 0.0022 lr: 0.02\n",
      "iteration: 250500 loss: 0.0014 lr: 0.02\n",
      "iteration: 250510 loss: 0.0018 lr: 0.02\n",
      "iteration: 250520 loss: 0.0018 lr: 0.02\n",
      "iteration: 250530 loss: 0.0018 lr: 0.02\n",
      "iteration: 250540 loss: 0.0016 lr: 0.02\n",
      "iteration: 250550 loss: 0.0019 lr: 0.02\n",
      "iteration: 250560 loss: 0.0020 lr: 0.02\n",
      "iteration: 250570 loss: 0.0015 lr: 0.02\n",
      "iteration: 250580 loss: 0.0016 lr: 0.02\n",
      "iteration: 250590 loss: 0.0021 lr: 0.02\n",
      "iteration: 250600 loss: 0.0019 lr: 0.02\n",
      "iteration: 250610 loss: 0.0014 lr: 0.02\n",
      "iteration: 250620 loss: 0.0013 lr: 0.02\n",
      "iteration: 250630 loss: 0.0014 lr: 0.02\n",
      "iteration: 250640 loss: 0.0020 lr: 0.02\n",
      "iteration: 250650 loss: 0.0024 lr: 0.02\n",
      "iteration: 250660 loss: 0.0015 lr: 0.02\n",
      "iteration: 250670 loss: 0.0019 lr: 0.02\n",
      "iteration: 250680 loss: 0.0017 lr: 0.02\n",
      "iteration: 250690 loss: 0.0020 lr: 0.02\n",
      "iteration: 250700 loss: 0.0016 lr: 0.02\n",
      "iteration: 250710 loss: 0.0023 lr: 0.02\n",
      "iteration: 250720 loss: 0.0019 lr: 0.02\n",
      "iteration: 250730 loss: 0.0021 lr: 0.02\n",
      "iteration: 250740 loss: 0.0020 lr: 0.02\n",
      "iteration: 250750 loss: 0.0019 lr: 0.02\n",
      "iteration: 250760 loss: 0.0020 lr: 0.02\n",
      "iteration: 250770 loss: 0.0014 lr: 0.02\n",
      "iteration: 250780 loss: 0.0027 lr: 0.02\n",
      "iteration: 250790 loss: 0.0020 lr: 0.02\n",
      "iteration: 250800 loss: 0.0021 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 250810 loss: 0.0017 lr: 0.02\n",
      "iteration: 250820 loss: 0.0014 lr: 0.02\n",
      "iteration: 250830 loss: 0.0014 lr: 0.02\n",
      "iteration: 250840 loss: 0.0024 lr: 0.02\n",
      "iteration: 250850 loss: 0.0020 lr: 0.02\n",
      "iteration: 250860 loss: 0.0016 lr: 0.02\n",
      "iteration: 250870 loss: 0.0022 lr: 0.02\n",
      "iteration: 250880 loss: 0.0016 lr: 0.02\n",
      "iteration: 250890 loss: 0.0019 lr: 0.02\n",
      "iteration: 250900 loss: 0.0019 lr: 0.02\n",
      "iteration: 250910 loss: 0.0017 lr: 0.02\n",
      "iteration: 250920 loss: 0.0015 lr: 0.02\n",
      "iteration: 250930 loss: 0.0015 lr: 0.02\n",
      "iteration: 250940 loss: 0.0019 lr: 0.02\n",
      "iteration: 250950 loss: 0.0016 lr: 0.02\n",
      "iteration: 250960 loss: 0.0018 lr: 0.02\n",
      "iteration: 250970 loss: 0.0017 lr: 0.02\n",
      "iteration: 250980 loss: 0.0018 lr: 0.02\n",
      "iteration: 250990 loss: 0.0016 lr: 0.02\n",
      "iteration: 251000 loss: 0.0019 lr: 0.02\n",
      "iteration: 251010 loss: 0.0019 lr: 0.02\n",
      "iteration: 251020 loss: 0.0016 lr: 0.02\n",
      "iteration: 251030 loss: 0.0015 lr: 0.02\n",
      "iteration: 251040 loss: 0.0020 lr: 0.02\n",
      "iteration: 251050 loss: 0.0018 lr: 0.02\n",
      "iteration: 251060 loss: 0.0019 lr: 0.02\n",
      "iteration: 251070 loss: 0.0017 lr: 0.02\n",
      "iteration: 251080 loss: 0.0019 lr: 0.02\n",
      "iteration: 251090 loss: 0.0019 lr: 0.02\n",
      "iteration: 251100 loss: 0.0020 lr: 0.02\n",
      "iteration: 251110 loss: 0.0017 lr: 0.02\n",
      "iteration: 251120 loss: 0.0018 lr: 0.02\n",
      "iteration: 251130 loss: 0.0021 lr: 0.02\n",
      "iteration: 251140 loss: 0.0019 lr: 0.02\n",
      "iteration: 251150 loss: 0.0017 lr: 0.02\n",
      "iteration: 251160 loss: 0.0015 lr: 0.02\n",
      "iteration: 251170 loss: 0.0015 lr: 0.02\n",
      "iteration: 251180 loss: 0.0017 lr: 0.02\n",
      "iteration: 251190 loss: 0.0018 lr: 0.02\n",
      "iteration: 251200 loss: 0.0015 lr: 0.02\n",
      "iteration: 251210 loss: 0.0024 lr: 0.02\n",
      "iteration: 251220 loss: 0.0022 lr: 0.02\n",
      "iteration: 251230 loss: 0.0016 lr: 0.02\n",
      "iteration: 251240 loss: 0.0018 lr: 0.02\n",
      "iteration: 251250 loss: 0.0022 lr: 0.02\n",
      "iteration: 251260 loss: 0.0023 lr: 0.02\n",
      "iteration: 251270 loss: 0.0017 lr: 0.02\n",
      "iteration: 251280 loss: 0.0018 lr: 0.02\n",
      "iteration: 251290 loss: 0.0026 lr: 0.02\n",
      "iteration: 251300 loss: 0.0016 lr: 0.02\n",
      "iteration: 251310 loss: 0.0020 lr: 0.02\n",
      "iteration: 251320 loss: 0.0017 lr: 0.02\n",
      "iteration: 251330 loss: 0.0019 lr: 0.02\n",
      "iteration: 251340 loss: 0.0017 lr: 0.02\n",
      "iteration: 251350 loss: 0.0015 lr: 0.02\n",
      "iteration: 251360 loss: 0.0015 lr: 0.02\n",
      "iteration: 251370 loss: 0.0026 lr: 0.02\n",
      "iteration: 251380 loss: 0.0015 lr: 0.02\n",
      "iteration: 251390 loss: 0.0016 lr: 0.02\n",
      "iteration: 251400 loss: 0.0017 lr: 0.02\n",
      "iteration: 251410 loss: 0.0018 lr: 0.02\n",
      "iteration: 251420 loss: 0.0025 lr: 0.02\n",
      "iteration: 251430 loss: 0.0016 lr: 0.02\n",
      "iteration: 251440 loss: 0.0020 lr: 0.02\n",
      "iteration: 251450 loss: 0.0019 lr: 0.02\n",
      "iteration: 251460 loss: 0.0024 lr: 0.02\n",
      "iteration: 251470 loss: 0.0021 lr: 0.02\n",
      "iteration: 251480 loss: 0.0015 lr: 0.02\n",
      "iteration: 251490 loss: 0.0020 lr: 0.02\n",
      "iteration: 251500 loss: 0.0018 lr: 0.02\n",
      "iteration: 251510 loss: 0.0017 lr: 0.02\n",
      "iteration: 251520 loss: 0.0017 lr: 0.02\n",
      "iteration: 251530 loss: 0.0018 lr: 0.02\n",
      "iteration: 251540 loss: 0.0014 lr: 0.02\n",
      "iteration: 251550 loss: 0.0026 lr: 0.02\n",
      "iteration: 251560 loss: 0.0024 lr: 0.02\n",
      "iteration: 251570 loss: 0.0018 lr: 0.02\n",
      "iteration: 251580 loss: 0.0022 lr: 0.02\n",
      "iteration: 251590 loss: 0.0020 lr: 0.02\n",
      "iteration: 251600 loss: 0.0023 lr: 0.02\n",
      "iteration: 251610 loss: 0.0018 lr: 0.02\n",
      "iteration: 251620 loss: 0.0014 lr: 0.02\n",
      "iteration: 251630 loss: 0.0021 lr: 0.02\n",
      "iteration: 251640 loss: 0.0014 lr: 0.02\n",
      "iteration: 251650 loss: 0.0018 lr: 0.02\n",
      "iteration: 251660 loss: 0.0017 lr: 0.02\n",
      "iteration: 251670 loss: 0.0017 lr: 0.02\n",
      "iteration: 251680 loss: 0.0021 lr: 0.02\n",
      "iteration: 251690 loss: 0.0017 lr: 0.02\n",
      "iteration: 251700 loss: 0.0020 lr: 0.02\n",
      "iteration: 251710 loss: 0.0019 lr: 0.02\n",
      "iteration: 251720 loss: 0.0018 lr: 0.02\n",
      "iteration: 251730 loss: 0.0019 lr: 0.02\n",
      "iteration: 251740 loss: 0.0020 lr: 0.02\n",
      "iteration: 251750 loss: 0.0014 lr: 0.02\n",
      "iteration: 251760 loss: 0.0023 lr: 0.02\n",
      "iteration: 251770 loss: 0.0014 lr: 0.02\n",
      "iteration: 251780 loss: 0.0020 lr: 0.02\n",
      "iteration: 251790 loss: 0.0016 lr: 0.02\n",
      "iteration: 251800 loss: 0.0027 lr: 0.02\n",
      "iteration: 251810 loss: 0.0026 lr: 0.02\n",
      "iteration: 251820 loss: 0.0025 lr: 0.02\n",
      "iteration: 251830 loss: 0.0021 lr: 0.02\n",
      "iteration: 251840 loss: 0.0017 lr: 0.02\n",
      "iteration: 251850 loss: 0.0016 lr: 0.02\n",
      "iteration: 251860 loss: 0.0020 lr: 0.02\n",
      "iteration: 251870 loss: 0.0020 lr: 0.02\n",
      "iteration: 251880 loss: 0.0021 lr: 0.02\n",
      "iteration: 251890 loss: 0.0014 lr: 0.02\n",
      "iteration: 251900 loss: 0.0015 lr: 0.02\n",
      "iteration: 251910 loss: 0.0024 lr: 0.02\n",
      "iteration: 251920 loss: 0.0022 lr: 0.02\n",
      "iteration: 251930 loss: 0.0013 lr: 0.02\n",
      "iteration: 251940 loss: 0.0022 lr: 0.02\n",
      "iteration: 251950 loss: 0.0021 lr: 0.02\n",
      "iteration: 251960 loss: 0.0019 lr: 0.02\n",
      "iteration: 251970 loss: 0.0018 lr: 0.02\n",
      "iteration: 251980 loss: 0.0022 lr: 0.02\n",
      "iteration: 251990 loss: 0.0020 lr: 0.02\n",
      "iteration: 252000 loss: 0.0015 lr: 0.02\n",
      "iteration: 252010 loss: 0.0018 lr: 0.02\n",
      "iteration: 252020 loss: 0.0016 lr: 0.02\n",
      "iteration: 252030 loss: 0.0014 lr: 0.02\n",
      "iteration: 252040 loss: 0.0015 lr: 0.02\n",
      "iteration: 252050 loss: 0.0026 lr: 0.02\n",
      "iteration: 252060 loss: 0.0016 lr: 0.02\n",
      "iteration: 252070 loss: 0.0017 lr: 0.02\n",
      "iteration: 252080 loss: 0.0022 lr: 0.02\n",
      "iteration: 252090 loss: 0.0018 lr: 0.02\n",
      "iteration: 252100 loss: 0.0018 lr: 0.02\n",
      "iteration: 252110 loss: 0.0015 lr: 0.02\n",
      "iteration: 252120 loss: 0.0024 lr: 0.02\n",
      "iteration: 252130 loss: 0.0019 lr: 0.02\n",
      "iteration: 252140 loss: 0.0018 lr: 0.02\n",
      "iteration: 252150 loss: 0.0023 lr: 0.02\n",
      "iteration: 252160 loss: 0.0020 lr: 0.02\n",
      "iteration: 252170 loss: 0.0021 lr: 0.02\n",
      "iteration: 252180 loss: 0.0017 lr: 0.02\n",
      "iteration: 252190 loss: 0.0013 lr: 0.02\n",
      "iteration: 252200 loss: 0.0018 lr: 0.02\n",
      "iteration: 252210 loss: 0.0023 lr: 0.02\n",
      "iteration: 252220 loss: 0.0024 lr: 0.02\n",
      "iteration: 252230 loss: 0.0022 lr: 0.02\n",
      "iteration: 252240 loss: 0.0016 lr: 0.02\n",
      "iteration: 252250 loss: 0.0018 lr: 0.02\n",
      "iteration: 252260 loss: 0.0017 lr: 0.02\n",
      "iteration: 252270 loss: 0.0021 lr: 0.02\n",
      "iteration: 252280 loss: 0.0020 lr: 0.02\n",
      "iteration: 252290 loss: 0.0016 lr: 0.02\n",
      "iteration: 252300 loss: 0.0014 lr: 0.02\n",
      "iteration: 252310 loss: 0.0016 lr: 0.02\n",
      "iteration: 252320 loss: 0.0017 lr: 0.02\n",
      "iteration: 252330 loss: 0.0020 lr: 0.02\n",
      "iteration: 252340 loss: 0.0025 lr: 0.02\n",
      "iteration: 252350 loss: 0.0018 lr: 0.02\n",
      "iteration: 252360 loss: 0.0016 lr: 0.02\n",
      "iteration: 252370 loss: 0.0023 lr: 0.02\n",
      "iteration: 252380 loss: 0.0017 lr: 0.02\n",
      "iteration: 252390 loss: 0.0019 lr: 0.02\n",
      "iteration: 252400 loss: 0.0024 lr: 0.02\n",
      "iteration: 252410 loss: 0.0023 lr: 0.02\n",
      "iteration: 252420 loss: 0.0017 lr: 0.02\n",
      "iteration: 252430 loss: 0.0022 lr: 0.02\n",
      "iteration: 252440 loss: 0.0018 lr: 0.02\n",
      "iteration: 252450 loss: 0.0018 lr: 0.02\n",
      "iteration: 252460 loss: 0.0017 lr: 0.02\n",
      "iteration: 252470 loss: 0.0019 lr: 0.02\n",
      "iteration: 252480 loss: 0.0014 lr: 0.02\n",
      "iteration: 252490 loss: 0.0020 lr: 0.02\n",
      "iteration: 252500 loss: 0.0017 lr: 0.02\n",
      "iteration: 252510 loss: 0.0016 lr: 0.02\n",
      "iteration: 252520 loss: 0.0019 lr: 0.02\n",
      "iteration: 252530 loss: 0.0022 lr: 0.02\n",
      "iteration: 252540 loss: 0.0014 lr: 0.02\n",
      "iteration: 252550 loss: 0.0018 lr: 0.02\n",
      "iteration: 252560 loss: 0.0020 lr: 0.02\n",
      "iteration: 252570 loss: 0.0016 lr: 0.02\n",
      "iteration: 252580 loss: 0.0024 lr: 0.02\n",
      "iteration: 252590 loss: 0.0017 lr: 0.02\n",
      "iteration: 252600 loss: 0.0017 lr: 0.02\n",
      "iteration: 252610 loss: 0.0020 lr: 0.02\n",
      "iteration: 252620 loss: 0.0018 lr: 0.02\n",
      "iteration: 252630 loss: 0.0014 lr: 0.02\n",
      "iteration: 252640 loss: 0.0021 lr: 0.02\n",
      "iteration: 252650 loss: 0.0020 lr: 0.02\n",
      "iteration: 252660 loss: 0.0019 lr: 0.02\n",
      "iteration: 252670 loss: 0.0020 lr: 0.02\n",
      "iteration: 252680 loss: 0.0017 lr: 0.02\n",
      "iteration: 252690 loss: 0.0017 lr: 0.02\n",
      "iteration: 252700 loss: 0.0023 lr: 0.02\n",
      "iteration: 252710 loss: 0.0022 lr: 0.02\n",
      "iteration: 252720 loss: 0.0015 lr: 0.02\n",
      "iteration: 252730 loss: 0.0016 lr: 0.02\n",
      "iteration: 252740 loss: 0.0021 lr: 0.02\n",
      "iteration: 252750 loss: 0.0017 lr: 0.02\n",
      "iteration: 252760 loss: 0.0019 lr: 0.02\n",
      "iteration: 252770 loss: 0.0017 lr: 0.02\n",
      "iteration: 252780 loss: 0.0020 lr: 0.02\n",
      "iteration: 252790 loss: 0.0015 lr: 0.02\n",
      "iteration: 252800 loss: 0.0014 lr: 0.02\n",
      "iteration: 252810 loss: 0.0015 lr: 0.02\n",
      "iteration: 252820 loss: 0.0017 lr: 0.02\n",
      "iteration: 252830 loss: 0.0017 lr: 0.02\n",
      "iteration: 252840 loss: 0.0022 lr: 0.02\n",
      "iteration: 252850 loss: 0.0019 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 252860 loss: 0.0019 lr: 0.02\n",
      "iteration: 252870 loss: 0.0020 lr: 0.02\n",
      "iteration: 252880 loss: 0.0014 lr: 0.02\n",
      "iteration: 252890 loss: 0.0013 lr: 0.02\n",
      "iteration: 252900 loss: 0.0017 lr: 0.02\n",
      "iteration: 252910 loss: 0.0016 lr: 0.02\n",
      "iteration: 252920 loss: 0.0026 lr: 0.02\n",
      "iteration: 252930 loss: 0.0015 lr: 0.02\n",
      "iteration: 252940 loss: 0.0018 lr: 0.02\n",
      "iteration: 252950 loss: 0.0019 lr: 0.02\n",
      "iteration: 252960 loss: 0.0021 lr: 0.02\n",
      "iteration: 252970 loss: 0.0018 lr: 0.02\n",
      "iteration: 252980 loss: 0.0018 lr: 0.02\n",
      "iteration: 252990 loss: 0.0016 lr: 0.02\n",
      "iteration: 253000 loss: 0.0015 lr: 0.02\n",
      "iteration: 253010 loss: 0.0017 lr: 0.02\n",
      "iteration: 253020 loss: 0.0017 lr: 0.02\n",
      "iteration: 253030 loss: 0.0020 lr: 0.02\n",
      "iteration: 253040 loss: 0.0015 lr: 0.02\n",
      "iteration: 253050 loss: 0.0015 lr: 0.02\n",
      "iteration: 253060 loss: 0.0015 lr: 0.02\n",
      "iteration: 253070 loss: 0.0018 lr: 0.02\n",
      "iteration: 253080 loss: 0.0016 lr: 0.02\n",
      "iteration: 253090 loss: 0.0013 lr: 0.02\n",
      "iteration: 253100 loss: 0.0021 lr: 0.02\n",
      "iteration: 253110 loss: 0.0020 lr: 0.02\n",
      "iteration: 253120 loss: 0.0029 lr: 0.02\n",
      "iteration: 253130 loss: 0.0023 lr: 0.02\n",
      "iteration: 253140 loss: 0.0013 lr: 0.02\n",
      "iteration: 253150 loss: 0.0015 lr: 0.02\n",
      "iteration: 253160 loss: 0.0018 lr: 0.02\n",
      "iteration: 253170 loss: 0.0021 lr: 0.02\n",
      "iteration: 253180 loss: 0.0016 lr: 0.02\n",
      "iteration: 253190 loss: 0.0016 lr: 0.02\n",
      "iteration: 253200 loss: 0.0018 lr: 0.02\n",
      "iteration: 253210 loss: 0.0024 lr: 0.02\n",
      "iteration: 253220 loss: 0.0023 lr: 0.02\n",
      "iteration: 253230 loss: 0.0024 lr: 0.02\n",
      "iteration: 253240 loss: 0.0021 lr: 0.02\n",
      "iteration: 253250 loss: 0.0017 lr: 0.02\n",
      "iteration: 253260 loss: 0.0015 lr: 0.02\n",
      "iteration: 253270 loss: 0.0014 lr: 0.02\n",
      "iteration: 253280 loss: 0.0019 lr: 0.02\n",
      "iteration: 253290 loss: 0.0022 lr: 0.02\n",
      "iteration: 253300 loss: 0.0021 lr: 0.02\n",
      "iteration: 253310 loss: 0.0019 lr: 0.02\n",
      "iteration: 253320 loss: 0.0017 lr: 0.02\n",
      "iteration: 253330 loss: 0.0019 lr: 0.02\n",
      "iteration: 253340 loss: 0.0017 lr: 0.02\n",
      "iteration: 253350 loss: 0.0020 lr: 0.02\n",
      "iteration: 253360 loss: 0.0019 lr: 0.02\n",
      "iteration: 253370 loss: 0.0019 lr: 0.02\n",
      "iteration: 253380 loss: 0.0016 lr: 0.02\n",
      "iteration: 253390 loss: 0.0015 lr: 0.02\n",
      "iteration: 253400 loss: 0.0016 lr: 0.02\n",
      "iteration: 253410 loss: 0.0018 lr: 0.02\n",
      "iteration: 253420 loss: 0.0018 lr: 0.02\n",
      "iteration: 253430 loss: 0.0017 lr: 0.02\n",
      "iteration: 253440 loss: 0.0021 lr: 0.02\n",
      "iteration: 253450 loss: 0.0017 lr: 0.02\n",
      "iteration: 253460 loss: 0.0018 lr: 0.02\n",
      "iteration: 253470 loss: 0.0023 lr: 0.02\n",
      "iteration: 253480 loss: 0.0022 lr: 0.02\n",
      "iteration: 253490 loss: 0.0016 lr: 0.02\n",
      "iteration: 253500 loss: 0.0018 lr: 0.02\n",
      "iteration: 253510 loss: 0.0019 lr: 0.02\n",
      "iteration: 253520 loss: 0.0016 lr: 0.02\n",
      "iteration: 253530 loss: 0.0012 lr: 0.02\n",
      "iteration: 253540 loss: 0.0015 lr: 0.02\n",
      "iteration: 253550 loss: 0.0018 lr: 0.02\n",
      "iteration: 253560 loss: 0.0013 lr: 0.02\n",
      "iteration: 253570 loss: 0.0017 lr: 0.02\n",
      "iteration: 253580 loss: 0.0018 lr: 0.02\n",
      "iteration: 253590 loss: 0.0018 lr: 0.02\n",
      "iteration: 253600 loss: 0.0020 lr: 0.02\n",
      "iteration: 253610 loss: 0.0015 lr: 0.02\n",
      "iteration: 253620 loss: 0.0018 lr: 0.02\n",
      "iteration: 253630 loss: 0.0021 lr: 0.02\n",
      "iteration: 253640 loss: 0.0016 lr: 0.02\n",
      "iteration: 253650 loss: 0.0015 lr: 0.02\n",
      "iteration: 253660 loss: 0.0014 lr: 0.02\n",
      "iteration: 253670 loss: 0.0016 lr: 0.02\n",
      "iteration: 253680 loss: 0.0019 lr: 0.02\n",
      "iteration: 253690 loss: 0.0014 lr: 0.02\n",
      "iteration: 253700 loss: 0.0017 lr: 0.02\n",
      "iteration: 253710 loss: 0.0018 lr: 0.02\n",
      "iteration: 253720 loss: 0.0019 lr: 0.02\n",
      "iteration: 253730 loss: 0.0018 lr: 0.02\n",
      "iteration: 253740 loss: 0.0019 lr: 0.02\n",
      "iteration: 253750 loss: 0.0018 lr: 0.02\n",
      "iteration: 253760 loss: 0.0019 lr: 0.02\n",
      "iteration: 253770 loss: 0.0015 lr: 0.02\n",
      "iteration: 253780 loss: 0.0020 lr: 0.02\n",
      "iteration: 253790 loss: 0.0014 lr: 0.02\n",
      "iteration: 253800 loss: 0.0017 lr: 0.02\n",
      "iteration: 253810 loss: 0.0014 lr: 0.02\n",
      "iteration: 253820 loss: 0.0018 lr: 0.02\n",
      "iteration: 253830 loss: 0.0027 lr: 0.02\n",
      "iteration: 253840 loss: 0.0016 lr: 0.02\n",
      "iteration: 253850 loss: 0.0020 lr: 0.02\n",
      "iteration: 253860 loss: 0.0018 lr: 0.02\n",
      "iteration: 253870 loss: 0.0017 lr: 0.02\n",
      "iteration: 253880 loss: 0.0015 lr: 0.02\n",
      "iteration: 253890 loss: 0.0028 lr: 0.02\n",
      "iteration: 253900 loss: 0.0021 lr: 0.02\n",
      "iteration: 253910 loss: 0.0020 lr: 0.02\n",
      "iteration: 253920 loss: 0.0014 lr: 0.02\n",
      "iteration: 253930 loss: 0.0016 lr: 0.02\n",
      "iteration: 253940 loss: 0.0016 lr: 0.02\n",
      "iteration: 253950 loss: 0.0019 lr: 0.02\n",
      "iteration: 253960 loss: 0.0022 lr: 0.02\n",
      "iteration: 253970 loss: 0.0017 lr: 0.02\n",
      "iteration: 253980 loss: 0.0024 lr: 0.02\n",
      "iteration: 253990 loss: 0.0019 lr: 0.02\n",
      "iteration: 254000 loss: 0.0019 lr: 0.02\n",
      "iteration: 254010 loss: 0.0017 lr: 0.02\n",
      "iteration: 254020 loss: 0.0015 lr: 0.02\n",
      "iteration: 254030 loss: 0.0016 lr: 0.02\n",
      "iteration: 254040 loss: 0.0015 lr: 0.02\n",
      "iteration: 254050 loss: 0.0021 lr: 0.02\n",
      "iteration: 254060 loss: 0.0015 lr: 0.02\n",
      "iteration: 254070 loss: 0.0016 lr: 0.02\n",
      "iteration: 254080 loss: 0.0017 lr: 0.02\n",
      "iteration: 254090 loss: 0.0015 lr: 0.02\n",
      "iteration: 254100 loss: 0.0015 lr: 0.02\n",
      "iteration: 254110 loss: 0.0016 lr: 0.02\n",
      "iteration: 254120 loss: 0.0016 lr: 0.02\n",
      "iteration: 254130 loss: 0.0021 lr: 0.02\n",
      "iteration: 254140 loss: 0.0017 lr: 0.02\n",
      "iteration: 254150 loss: 0.0021 lr: 0.02\n",
      "iteration: 254160 loss: 0.0016 lr: 0.02\n",
      "iteration: 254170 loss: 0.0016 lr: 0.02\n",
      "iteration: 254180 loss: 0.0021 lr: 0.02\n",
      "iteration: 254190 loss: 0.0016 lr: 0.02\n",
      "iteration: 254200 loss: 0.0017 lr: 0.02\n",
      "iteration: 254210 loss: 0.0023 lr: 0.02\n",
      "iteration: 254220 loss: 0.0015 lr: 0.02\n",
      "iteration: 254230 loss: 0.0022 lr: 0.02\n",
      "iteration: 254240 loss: 0.0021 lr: 0.02\n",
      "iteration: 254250 loss: 0.0016 lr: 0.02\n",
      "iteration: 254260 loss: 0.0016 lr: 0.02\n",
      "iteration: 254270 loss: 0.0022 lr: 0.02\n",
      "iteration: 254280 loss: 0.0014 lr: 0.02\n",
      "iteration: 254290 loss: 0.0015 lr: 0.02\n",
      "iteration: 254300 loss: 0.0015 lr: 0.02\n",
      "iteration: 254310 loss: 0.0020 lr: 0.02\n",
      "iteration: 254320 loss: 0.0018 lr: 0.02\n",
      "iteration: 254330 loss: 0.0019 lr: 0.02\n",
      "iteration: 254340 loss: 0.0016 lr: 0.02\n",
      "iteration: 254350 loss: 0.0027 lr: 0.02\n",
      "iteration: 254360 loss: 0.0019 lr: 0.02\n",
      "iteration: 254370 loss: 0.0021 lr: 0.02\n",
      "iteration: 254380 loss: 0.0019 lr: 0.02\n",
      "iteration: 254390 loss: 0.0016 lr: 0.02\n",
      "iteration: 254400 loss: 0.0016 lr: 0.02\n",
      "iteration: 254410 loss: 0.0019 lr: 0.02\n",
      "iteration: 254420 loss: 0.0021 lr: 0.02\n",
      "iteration: 254430 loss: 0.0015 lr: 0.02\n",
      "iteration: 254440 loss: 0.0021 lr: 0.02\n",
      "iteration: 254450 loss: 0.0015 lr: 0.02\n",
      "iteration: 254460 loss: 0.0022 lr: 0.02\n",
      "iteration: 254470 loss: 0.0014 lr: 0.02\n",
      "iteration: 254480 loss: 0.0017 lr: 0.02\n",
      "iteration: 254490 loss: 0.0018 lr: 0.02\n",
      "iteration: 254500 loss: 0.0020 lr: 0.02\n",
      "iteration: 254510 loss: 0.0018 lr: 0.02\n",
      "iteration: 254520 loss: 0.0023 lr: 0.02\n",
      "iteration: 254530 loss: 0.0020 lr: 0.02\n",
      "iteration: 254540 loss: 0.0026 lr: 0.02\n",
      "iteration: 254550 loss: 0.0016 lr: 0.02\n",
      "iteration: 254560 loss: 0.0015 lr: 0.02\n",
      "iteration: 254570 loss: 0.0019 lr: 0.02\n",
      "iteration: 254580 loss: 0.0024 lr: 0.02\n",
      "iteration: 254590 loss: 0.0015 lr: 0.02\n",
      "iteration: 254600 loss: 0.0016 lr: 0.02\n",
      "iteration: 254610 loss: 0.0014 lr: 0.02\n",
      "iteration: 254620 loss: 0.0018 lr: 0.02\n",
      "iteration: 254630 loss: 0.0016 lr: 0.02\n",
      "iteration: 254640 loss: 0.0023 lr: 0.02\n",
      "iteration: 254650 loss: 0.0016 lr: 0.02\n",
      "iteration: 254660 loss: 0.0014 lr: 0.02\n",
      "iteration: 254670 loss: 0.0016 lr: 0.02\n",
      "iteration: 254680 loss: 0.0019 lr: 0.02\n",
      "iteration: 254690 loss: 0.0016 lr: 0.02\n",
      "iteration: 254700 loss: 0.0019 lr: 0.02\n",
      "iteration: 254710 loss: 0.0013 lr: 0.02\n",
      "iteration: 254720 loss: 0.0018 lr: 0.02\n",
      "iteration: 254730 loss: 0.0019 lr: 0.02\n",
      "iteration: 254740 loss: 0.0017 lr: 0.02\n",
      "iteration: 254750 loss: 0.0020 lr: 0.02\n",
      "iteration: 254760 loss: 0.0016 lr: 0.02\n",
      "iteration: 254770 loss: 0.0020 lr: 0.02\n",
      "iteration: 254780 loss: 0.0017 lr: 0.02\n",
      "iteration: 254790 loss: 0.0023 lr: 0.02\n",
      "iteration: 254800 loss: 0.0016 lr: 0.02\n",
      "iteration: 254810 loss: 0.0013 lr: 0.02\n",
      "iteration: 254820 loss: 0.0013 lr: 0.02\n",
      "iteration: 254830 loss: 0.0019 lr: 0.02\n",
      "iteration: 254840 loss: 0.0018 lr: 0.02\n",
      "iteration: 254850 loss: 0.0025 lr: 0.02\n",
      "iteration: 254860 loss: 0.0017 lr: 0.02\n",
      "iteration: 254870 loss: 0.0019 lr: 0.02\n",
      "iteration: 254880 loss: 0.0020 lr: 0.02\n",
      "iteration: 254890 loss: 0.0018 lr: 0.02\n",
      "iteration: 254900 loss: 0.0015 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 254910 loss: 0.0015 lr: 0.02\n",
      "iteration: 254920 loss: 0.0020 lr: 0.02\n",
      "iteration: 254930 loss: 0.0018 lr: 0.02\n",
      "iteration: 254940 loss: 0.0025 lr: 0.02\n",
      "iteration: 254950 loss: 0.0018 lr: 0.02\n",
      "iteration: 254960 loss: 0.0018 lr: 0.02\n",
      "iteration: 254970 loss: 0.0020 lr: 0.02\n",
      "iteration: 254980 loss: 0.0017 lr: 0.02\n",
      "iteration: 254990 loss: 0.0016 lr: 0.02\n",
      "iteration: 255000 loss: 0.0019 lr: 0.02\n",
      "iteration: 255010 loss: 0.0014 lr: 0.02\n",
      "iteration: 255020 loss: 0.0020 lr: 0.02\n",
      "iteration: 255030 loss: 0.0016 lr: 0.02\n",
      "iteration: 255040 loss: 0.0027 lr: 0.02\n",
      "iteration: 255050 loss: 0.0021 lr: 0.02\n",
      "iteration: 255060 loss: 0.0024 lr: 0.02\n",
      "iteration: 255070 loss: 0.0018 lr: 0.02\n",
      "iteration: 255080 loss: 0.0020 lr: 0.02\n",
      "iteration: 255090 loss: 0.0019 lr: 0.02\n",
      "iteration: 255100 loss: 0.0020 lr: 0.02\n",
      "iteration: 255110 loss: 0.0016 lr: 0.02\n",
      "iteration: 255120 loss: 0.0019 lr: 0.02\n",
      "iteration: 255130 loss: 0.0018 lr: 0.02\n",
      "iteration: 255140 loss: 0.0018 lr: 0.02\n",
      "iteration: 255150 loss: 0.0014 lr: 0.02\n",
      "iteration: 255160 loss: 0.0020 lr: 0.02\n",
      "iteration: 255170 loss: 0.0016 lr: 0.02\n",
      "iteration: 255180 loss: 0.0019 lr: 0.02\n",
      "iteration: 255190 loss: 0.0022 lr: 0.02\n",
      "iteration: 255200 loss: 0.0017 lr: 0.02\n",
      "iteration: 255210 loss: 0.0018 lr: 0.02\n",
      "iteration: 255220 loss: 0.0018 lr: 0.02\n",
      "iteration: 255230 loss: 0.0015 lr: 0.02\n",
      "iteration: 255240 loss: 0.0023 lr: 0.02\n",
      "iteration: 255250 loss: 0.0017 lr: 0.02\n",
      "iteration: 255260 loss: 0.0019 lr: 0.02\n",
      "iteration: 255270 loss: 0.0020 lr: 0.02\n",
      "iteration: 255280 loss: 0.0018 lr: 0.02\n",
      "iteration: 255290 loss: 0.0017 lr: 0.02\n",
      "iteration: 255300 loss: 0.0020 lr: 0.02\n",
      "iteration: 255310 loss: 0.0013 lr: 0.02\n",
      "iteration: 255320 loss: 0.0021 lr: 0.02\n",
      "iteration: 255330 loss: 0.0018 lr: 0.02\n",
      "iteration: 255340 loss: 0.0020 lr: 0.02\n",
      "iteration: 255350 loss: 0.0016 lr: 0.02\n",
      "iteration: 255360 loss: 0.0020 lr: 0.02\n",
      "iteration: 255370 loss: 0.0016 lr: 0.02\n",
      "iteration: 255380 loss: 0.0018 lr: 0.02\n",
      "iteration: 255390 loss: 0.0015 lr: 0.02\n",
      "iteration: 255400 loss: 0.0021 lr: 0.02\n",
      "iteration: 255410 loss: 0.0018 lr: 0.02\n",
      "iteration: 255420 loss: 0.0017 lr: 0.02\n",
      "iteration: 255430 loss: 0.0023 lr: 0.02\n",
      "iteration: 255440 loss: 0.0015 lr: 0.02\n",
      "iteration: 255450 loss: 0.0017 lr: 0.02\n",
      "iteration: 255460 loss: 0.0022 lr: 0.02\n",
      "iteration: 255470 loss: 0.0016 lr: 0.02\n",
      "iteration: 255480 loss: 0.0019 lr: 0.02\n",
      "iteration: 255490 loss: 0.0015 lr: 0.02\n",
      "iteration: 255500 loss: 0.0017 lr: 0.02\n",
      "iteration: 255510 loss: 0.0019 lr: 0.02\n",
      "iteration: 255520 loss: 0.0021 lr: 0.02\n",
      "iteration: 255530 loss: 0.0020 lr: 0.02\n",
      "iteration: 255540 loss: 0.0018 lr: 0.02\n",
      "iteration: 255550 loss: 0.0014 lr: 0.02\n",
      "iteration: 255560 loss: 0.0019 lr: 0.02\n",
      "iteration: 255570 loss: 0.0019 lr: 0.02\n",
      "iteration: 255580 loss: 0.0016 lr: 0.02\n",
      "iteration: 255590 loss: 0.0018 lr: 0.02\n",
      "iteration: 255600 loss: 0.0017 lr: 0.02\n",
      "iteration: 255610 loss: 0.0019 lr: 0.02\n",
      "iteration: 255620 loss: 0.0020 lr: 0.02\n",
      "iteration: 255630 loss: 0.0014 lr: 0.02\n",
      "iteration: 255640 loss: 0.0019 lr: 0.02\n",
      "iteration: 255650 loss: 0.0015 lr: 0.02\n",
      "iteration: 255660 loss: 0.0018 lr: 0.02\n",
      "iteration: 255670 loss: 0.0014 lr: 0.02\n",
      "iteration: 255680 loss: 0.0019 lr: 0.02\n",
      "iteration: 255690 loss: 0.0017 lr: 0.02\n",
      "iteration: 255700 loss: 0.0016 lr: 0.02\n",
      "iteration: 255710 loss: 0.0024 lr: 0.02\n",
      "iteration: 255720 loss: 0.0020 lr: 0.02\n",
      "iteration: 255730 loss: 0.0013 lr: 0.02\n",
      "iteration: 255740 loss: 0.0024 lr: 0.02\n",
      "iteration: 255750 loss: 0.0017 lr: 0.02\n",
      "iteration: 255760 loss: 0.0018 lr: 0.02\n",
      "iteration: 255770 loss: 0.0011 lr: 0.02\n",
      "iteration: 255780 loss: 0.0015 lr: 0.02\n",
      "iteration: 255790 loss: 0.0015 lr: 0.02\n",
      "iteration: 255800 loss: 0.0017 lr: 0.02\n",
      "iteration: 255810 loss: 0.0017 lr: 0.02\n",
      "iteration: 255820 loss: 0.0015 lr: 0.02\n",
      "iteration: 255830 loss: 0.0018 lr: 0.02\n",
      "iteration: 255840 loss: 0.0020 lr: 0.02\n",
      "iteration: 255850 loss: 0.0026 lr: 0.02\n",
      "iteration: 255860 loss: 0.0017 lr: 0.02\n",
      "iteration: 255870 loss: 0.0021 lr: 0.02\n",
      "iteration: 255880 loss: 0.0026 lr: 0.02\n",
      "iteration: 255890 loss: 0.0023 lr: 0.02\n",
      "iteration: 255900 loss: 0.0018 lr: 0.02\n",
      "iteration: 255910 loss: 0.0017 lr: 0.02\n",
      "iteration: 255920 loss: 0.0016 lr: 0.02\n",
      "iteration: 255930 loss: 0.0019 lr: 0.02\n",
      "iteration: 255940 loss: 0.0020 lr: 0.02\n",
      "iteration: 255950 loss: 0.0021 lr: 0.02\n",
      "iteration: 255960 loss: 0.0013 lr: 0.02\n",
      "iteration: 255970 loss: 0.0017 lr: 0.02\n",
      "iteration: 255980 loss: 0.0016 lr: 0.02\n",
      "iteration: 255990 loss: 0.0018 lr: 0.02\n",
      "iteration: 256000 loss: 0.0017 lr: 0.02\n",
      "iteration: 256010 loss: 0.0015 lr: 0.02\n",
      "iteration: 256020 loss: 0.0017 lr: 0.02\n",
      "iteration: 256030 loss: 0.0016 lr: 0.02\n",
      "iteration: 256040 loss: 0.0016 lr: 0.02\n",
      "iteration: 256050 loss: 0.0025 lr: 0.02\n",
      "iteration: 256060 loss: 0.0024 lr: 0.02\n",
      "iteration: 256070 loss: 0.0021 lr: 0.02\n",
      "iteration: 256080 loss: 0.0016 lr: 0.02\n",
      "iteration: 256090 loss: 0.0019 lr: 0.02\n",
      "iteration: 256100 loss: 0.0018 lr: 0.02\n",
      "iteration: 256110 loss: 0.0020 lr: 0.02\n",
      "iteration: 256120 loss: 0.0022 lr: 0.02\n",
      "iteration: 256130 loss: 0.0019 lr: 0.02\n",
      "iteration: 256140 loss: 0.0019 lr: 0.02\n",
      "iteration: 256150 loss: 0.0022 lr: 0.02\n",
      "iteration: 256160 loss: 0.0018 lr: 0.02\n",
      "iteration: 256170 loss: 0.0016 lr: 0.02\n",
      "iteration: 256180 loss: 0.0020 lr: 0.02\n",
      "iteration: 256190 loss: 0.0013 lr: 0.02\n",
      "iteration: 256200 loss: 0.0015 lr: 0.02\n",
      "iteration: 256210 loss: 0.0015 lr: 0.02\n",
      "iteration: 256220 loss: 0.0021 lr: 0.02\n",
      "iteration: 256230 loss: 0.0019 lr: 0.02\n",
      "iteration: 256240 loss: 0.0015 lr: 0.02\n",
      "iteration: 256250 loss: 0.0018 lr: 0.02\n",
      "iteration: 256260 loss: 0.0017 lr: 0.02\n",
      "iteration: 256270 loss: 0.0015 lr: 0.02\n",
      "iteration: 256280 loss: 0.0016 lr: 0.02\n",
      "iteration: 256290 loss: 0.0020 lr: 0.02\n",
      "iteration: 256300 loss: 0.0016 lr: 0.02\n",
      "iteration: 256310 loss: 0.0018 lr: 0.02\n",
      "iteration: 256320 loss: 0.0023 lr: 0.02\n",
      "iteration: 256330 loss: 0.0017 lr: 0.02\n",
      "iteration: 256340 loss: 0.0019 lr: 0.02\n",
      "iteration: 256350 loss: 0.0024 lr: 0.02\n",
      "iteration: 256360 loss: 0.0016 lr: 0.02\n",
      "iteration: 256370 loss: 0.0018 lr: 0.02\n",
      "iteration: 256380 loss: 0.0014 lr: 0.02\n",
      "iteration: 256390 loss: 0.0014 lr: 0.02\n",
      "iteration: 256400 loss: 0.0025 lr: 0.02\n",
      "iteration: 256410 loss: 0.0016 lr: 0.02\n",
      "iteration: 256420 loss: 0.0015 lr: 0.02\n",
      "iteration: 256430 loss: 0.0021 lr: 0.02\n",
      "iteration: 256440 loss: 0.0021 lr: 0.02\n",
      "iteration: 256450 loss: 0.0017 lr: 0.02\n",
      "iteration: 256460 loss: 0.0026 lr: 0.02\n",
      "iteration: 256470 loss: 0.0019 lr: 0.02\n",
      "iteration: 256480 loss: 0.0017 lr: 0.02\n",
      "iteration: 256490 loss: 0.0016 lr: 0.02\n",
      "iteration: 256500 loss: 0.0019 lr: 0.02\n",
      "iteration: 256510 loss: 0.0019 lr: 0.02\n",
      "iteration: 256520 loss: 0.0016 lr: 0.02\n",
      "iteration: 256530 loss: 0.0014 lr: 0.02\n",
      "iteration: 256540 loss: 0.0015 lr: 0.02\n",
      "iteration: 256550 loss: 0.0024 lr: 0.02\n",
      "iteration: 256560 loss: 0.0020 lr: 0.02\n",
      "iteration: 256570 loss: 0.0015 lr: 0.02\n",
      "iteration: 256580 loss: 0.0017 lr: 0.02\n",
      "iteration: 256590 loss: 0.0019 lr: 0.02\n",
      "iteration: 256600 loss: 0.0022 lr: 0.02\n",
      "iteration: 256610 loss: 0.0016 lr: 0.02\n",
      "iteration: 256620 loss: 0.0016 lr: 0.02\n",
      "iteration: 256630 loss: 0.0017 lr: 0.02\n",
      "iteration: 256640 loss: 0.0017 lr: 0.02\n",
      "iteration: 256650 loss: 0.0017 lr: 0.02\n",
      "iteration: 256660 loss: 0.0021 lr: 0.02\n",
      "iteration: 256670 loss: 0.0025 lr: 0.02\n",
      "iteration: 256680 loss: 0.0012 lr: 0.02\n",
      "iteration: 256690 loss: 0.0017 lr: 0.02\n",
      "iteration: 256700 loss: 0.0016 lr: 0.02\n",
      "iteration: 256710 loss: 0.0019 lr: 0.02\n",
      "iteration: 256720 loss: 0.0021 lr: 0.02\n",
      "iteration: 256730 loss: 0.0017 lr: 0.02\n",
      "iteration: 256740 loss: 0.0021 lr: 0.02\n",
      "iteration: 256750 loss: 0.0016 lr: 0.02\n",
      "iteration: 256760 loss: 0.0020 lr: 0.02\n",
      "iteration: 256770 loss: 0.0021 lr: 0.02\n",
      "iteration: 256780 loss: 0.0018 lr: 0.02\n",
      "iteration: 256790 loss: 0.0019 lr: 0.02\n",
      "iteration: 256800 loss: 0.0012 lr: 0.02\n",
      "iteration: 256810 loss: 0.0021 lr: 0.02\n",
      "iteration: 256820 loss: 0.0015 lr: 0.02\n",
      "iteration: 256830 loss: 0.0018 lr: 0.02\n",
      "iteration: 256840 loss: 0.0018 lr: 0.02\n",
      "iteration: 256850 loss: 0.0017 lr: 0.02\n",
      "iteration: 256860 loss: 0.0017 lr: 0.02\n",
      "iteration: 256870 loss: 0.0019 lr: 0.02\n",
      "iteration: 256880 loss: 0.0021 lr: 0.02\n",
      "iteration: 256890 loss: 0.0018 lr: 0.02\n",
      "iteration: 256900 loss: 0.0016 lr: 0.02\n",
      "iteration: 256910 loss: 0.0017 lr: 0.02\n",
      "iteration: 256920 loss: 0.0018 lr: 0.02\n",
      "iteration: 256930 loss: 0.0016 lr: 0.02\n",
      "iteration: 256940 loss: 0.0015 lr: 0.02\n",
      "iteration: 256950 loss: 0.0018 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 256960 loss: 0.0016 lr: 0.02\n",
      "iteration: 256970 loss: 0.0016 lr: 0.02\n",
      "iteration: 256980 loss: 0.0019 lr: 0.02\n",
      "iteration: 256990 loss: 0.0017 lr: 0.02\n",
      "iteration: 257000 loss: 0.0016 lr: 0.02\n",
      "iteration: 257010 loss: 0.0016 lr: 0.02\n",
      "iteration: 257020 loss: 0.0013 lr: 0.02\n",
      "iteration: 257030 loss: 0.0019 lr: 0.02\n",
      "iteration: 257040 loss: 0.0020 lr: 0.02\n",
      "iteration: 257050 loss: 0.0015 lr: 0.02\n",
      "iteration: 257060 loss: 0.0014 lr: 0.02\n",
      "iteration: 257070 loss: 0.0020 lr: 0.02\n",
      "iteration: 257080 loss: 0.0021 lr: 0.02\n",
      "iteration: 257090 loss: 0.0017 lr: 0.02\n",
      "iteration: 257100 loss: 0.0015 lr: 0.02\n",
      "iteration: 257110 loss: 0.0014 lr: 0.02\n",
      "iteration: 257120 loss: 0.0017 lr: 0.02\n",
      "iteration: 257130 loss: 0.0019 lr: 0.02\n",
      "iteration: 257140 loss: 0.0018 lr: 0.02\n",
      "iteration: 257150 loss: 0.0019 lr: 0.02\n",
      "iteration: 257160 loss: 0.0020 lr: 0.02\n",
      "iteration: 257170 loss: 0.0026 lr: 0.02\n",
      "iteration: 257180 loss: 0.0018 lr: 0.02\n",
      "iteration: 257190 loss: 0.0017 lr: 0.02\n",
      "iteration: 257200 loss: 0.0016 lr: 0.02\n",
      "iteration: 257210 loss: 0.0014 lr: 0.02\n",
      "iteration: 257220 loss: 0.0022 lr: 0.02\n",
      "iteration: 257230 loss: 0.0020 lr: 0.02\n",
      "iteration: 257240 loss: 0.0019 lr: 0.02\n",
      "iteration: 257250 loss: 0.0018 lr: 0.02\n",
      "iteration: 257260 loss: 0.0020 lr: 0.02\n",
      "iteration: 257270 loss: 0.0015 lr: 0.02\n",
      "iteration: 257280 loss: 0.0018 lr: 0.02\n",
      "iteration: 257290 loss: 0.0020 lr: 0.02\n",
      "iteration: 257300 loss: 0.0017 lr: 0.02\n",
      "iteration: 257310 loss: 0.0016 lr: 0.02\n",
      "iteration: 257320 loss: 0.0023 lr: 0.02\n",
      "iteration: 257330 loss: 0.0016 lr: 0.02\n",
      "iteration: 257340 loss: 0.0013 lr: 0.02\n",
      "iteration: 257350 loss: 0.0017 lr: 0.02\n",
      "iteration: 257360 loss: 0.0017 lr: 0.02\n",
      "iteration: 257370 loss: 0.0024 lr: 0.02\n",
      "iteration: 257380 loss: 0.0015 lr: 0.02\n",
      "iteration: 257390 loss: 0.0019 lr: 0.02\n",
      "iteration: 257400 loss: 0.0016 lr: 0.02\n",
      "iteration: 257410 loss: 0.0014 lr: 0.02\n",
      "iteration: 257420 loss: 0.0017 lr: 0.02\n",
      "iteration: 257430 loss: 0.0017 lr: 0.02\n",
      "iteration: 257440 loss: 0.0017 lr: 0.02\n",
      "iteration: 257450 loss: 0.0021 lr: 0.02\n",
      "iteration: 257460 loss: 0.0014 lr: 0.02\n",
      "iteration: 257470 loss: 0.0022 lr: 0.02\n",
      "iteration: 257480 loss: 0.0017 lr: 0.02\n",
      "iteration: 257490 loss: 0.0016 lr: 0.02\n",
      "iteration: 257500 loss: 0.0020 lr: 0.02\n",
      "iteration: 257510 loss: 0.0018 lr: 0.02\n",
      "iteration: 257520 loss: 0.0013 lr: 0.02\n",
      "iteration: 257530 loss: 0.0017 lr: 0.02\n",
      "iteration: 257540 loss: 0.0015 lr: 0.02\n",
      "iteration: 257550 loss: 0.0019 lr: 0.02\n",
      "iteration: 257560 loss: 0.0021 lr: 0.02\n",
      "iteration: 257570 loss: 0.0019 lr: 0.02\n",
      "iteration: 257580 loss: 0.0016 lr: 0.02\n",
      "iteration: 257590 loss: 0.0018 lr: 0.02\n",
      "iteration: 257600 loss: 0.0016 lr: 0.02\n",
      "iteration: 257610 loss: 0.0015 lr: 0.02\n",
      "iteration: 257620 loss: 0.0015 lr: 0.02\n",
      "iteration: 257630 loss: 0.0016 lr: 0.02\n",
      "iteration: 257640 loss: 0.0016 lr: 0.02\n",
      "iteration: 257650 loss: 0.0019 lr: 0.02\n",
      "iteration: 257660 loss: 0.0016 lr: 0.02\n",
      "iteration: 257670 loss: 0.0019 lr: 0.02\n",
      "iteration: 257680 loss: 0.0021 lr: 0.02\n",
      "iteration: 257690 loss: 0.0021 lr: 0.02\n",
      "iteration: 257700 loss: 0.0014 lr: 0.02\n",
      "iteration: 257710 loss: 0.0018 lr: 0.02\n",
      "iteration: 257720 loss: 0.0018 lr: 0.02\n",
      "iteration: 257730 loss: 0.0020 lr: 0.02\n",
      "iteration: 257740 loss: 0.0020 lr: 0.02\n",
      "iteration: 257750 loss: 0.0012 lr: 0.02\n",
      "iteration: 257760 loss: 0.0016 lr: 0.02\n",
      "iteration: 257770 loss: 0.0017 lr: 0.02\n",
      "iteration: 257780 loss: 0.0018 lr: 0.02\n",
      "iteration: 257790 loss: 0.0019 lr: 0.02\n",
      "iteration: 257800 loss: 0.0022 lr: 0.02\n",
      "iteration: 257810 loss: 0.0015 lr: 0.02\n",
      "iteration: 257820 loss: 0.0020 lr: 0.02\n",
      "iteration: 257830 loss: 0.0018 lr: 0.02\n",
      "iteration: 257840 loss: 0.0019 lr: 0.02\n",
      "iteration: 257850 loss: 0.0018 lr: 0.02\n",
      "iteration: 257860 loss: 0.0017 lr: 0.02\n",
      "iteration: 257870 loss: 0.0014 lr: 0.02\n",
      "iteration: 257880 loss: 0.0022 lr: 0.02\n",
      "iteration: 257890 loss: 0.0018 lr: 0.02\n",
      "iteration: 257900 loss: 0.0017 lr: 0.02\n",
      "iteration: 257910 loss: 0.0014 lr: 0.02\n",
      "iteration: 257920 loss: 0.0016 lr: 0.02\n",
      "iteration: 257930 loss: 0.0020 lr: 0.02\n",
      "iteration: 257940 loss: 0.0019 lr: 0.02\n",
      "iteration: 257950 loss: 0.0015 lr: 0.02\n",
      "iteration: 257960 loss: 0.0023 lr: 0.02\n",
      "iteration: 257970 loss: 0.0018 lr: 0.02\n",
      "iteration: 257980 loss: 0.0017 lr: 0.02\n",
      "iteration: 257990 loss: 0.0013 lr: 0.02\n",
      "iteration: 258000 loss: 0.0013 lr: 0.02\n",
      "iteration: 258010 loss: 0.0015 lr: 0.02\n",
      "iteration: 258020 loss: 0.0021 lr: 0.02\n",
      "iteration: 258030 loss: 0.0022 lr: 0.02\n",
      "iteration: 258040 loss: 0.0022 lr: 0.02\n",
      "iteration: 258050 loss: 0.0019 lr: 0.02\n",
      "iteration: 258060 loss: 0.0020 lr: 0.02\n",
      "iteration: 258070 loss: 0.0016 lr: 0.02\n",
      "iteration: 258080 loss: 0.0023 lr: 0.02\n",
      "iteration: 258090 loss: 0.0019 lr: 0.02\n",
      "iteration: 258100 loss: 0.0014 lr: 0.02\n",
      "iteration: 258110 loss: 0.0017 lr: 0.02\n",
      "iteration: 258120 loss: 0.0019 lr: 0.02\n",
      "iteration: 258130 loss: 0.0016 lr: 0.02\n",
      "iteration: 258140 loss: 0.0016 lr: 0.02\n",
      "iteration: 258150 loss: 0.0015 lr: 0.02\n",
      "iteration: 258160 loss: 0.0017 lr: 0.02\n",
      "iteration: 258170 loss: 0.0017 lr: 0.02\n",
      "iteration: 258180 loss: 0.0023 lr: 0.02\n",
      "iteration: 258190 loss: 0.0016 lr: 0.02\n",
      "iteration: 258200 loss: 0.0015 lr: 0.02\n",
      "iteration: 258210 loss: 0.0016 lr: 0.02\n",
      "iteration: 258220 loss: 0.0024 lr: 0.02\n",
      "iteration: 258230 loss: 0.0019 lr: 0.02\n",
      "iteration: 258240 loss: 0.0015 lr: 0.02\n",
      "iteration: 258250 loss: 0.0016 lr: 0.02\n",
      "iteration: 258260 loss: 0.0013 lr: 0.02\n",
      "iteration: 258270 loss: 0.0021 lr: 0.02\n",
      "iteration: 258280 loss: 0.0016 lr: 0.02\n",
      "iteration: 258290 loss: 0.0016 lr: 0.02\n",
      "iteration: 258300 loss: 0.0014 lr: 0.02\n",
      "iteration: 258310 loss: 0.0014 lr: 0.02\n",
      "iteration: 258320 loss: 0.0016 lr: 0.02\n",
      "iteration: 258330 loss: 0.0018 lr: 0.02\n",
      "iteration: 258340 loss: 0.0018 lr: 0.02\n",
      "iteration: 258350 loss: 0.0019 lr: 0.02\n",
      "iteration: 258360 loss: 0.0013 lr: 0.02\n",
      "iteration: 258370 loss: 0.0019 lr: 0.02\n",
      "iteration: 258380 loss: 0.0020 lr: 0.02\n",
      "iteration: 258390 loss: 0.0018 lr: 0.02\n",
      "iteration: 258400 loss: 0.0016 lr: 0.02\n",
      "iteration: 258410 loss: 0.0018 lr: 0.02\n",
      "iteration: 258420 loss: 0.0023 lr: 0.02\n",
      "iteration: 258430 loss: 0.0014 lr: 0.02\n",
      "iteration: 258440 loss: 0.0025 lr: 0.02\n",
      "iteration: 258450 loss: 0.0018 lr: 0.02\n",
      "iteration: 258460 loss: 0.0018 lr: 0.02\n",
      "iteration: 258470 loss: 0.0016 lr: 0.02\n",
      "iteration: 258480 loss: 0.0020 lr: 0.02\n",
      "iteration: 258490 loss: 0.0020 lr: 0.02\n",
      "iteration: 258500 loss: 0.0020 lr: 0.02\n",
      "iteration: 258510 loss: 0.0018 lr: 0.02\n",
      "iteration: 258520 loss: 0.0015 lr: 0.02\n",
      "iteration: 258530 loss: 0.0018 lr: 0.02\n",
      "iteration: 258540 loss: 0.0018 lr: 0.02\n",
      "iteration: 258550 loss: 0.0016 lr: 0.02\n",
      "iteration: 258560 loss: 0.0016 lr: 0.02\n",
      "iteration: 258570 loss: 0.0023 lr: 0.02\n",
      "iteration: 258580 loss: 0.0018 lr: 0.02\n",
      "iteration: 258590 loss: 0.0021 lr: 0.02\n",
      "iteration: 258600 loss: 0.0015 lr: 0.02\n",
      "iteration: 258610 loss: 0.0018 lr: 0.02\n",
      "iteration: 258620 loss: 0.0016 lr: 0.02\n",
      "iteration: 258630 loss: 0.0016 lr: 0.02\n",
      "iteration: 258640 loss: 0.0017 lr: 0.02\n",
      "iteration: 258650 loss: 0.0023 lr: 0.02\n",
      "iteration: 258660 loss: 0.0016 lr: 0.02\n",
      "iteration: 258670 loss: 0.0018 lr: 0.02\n",
      "iteration: 258680 loss: 0.0020 lr: 0.02\n",
      "iteration: 258690 loss: 0.0016 lr: 0.02\n",
      "iteration: 258700 loss: 0.0032 lr: 0.02\n",
      "iteration: 258710 loss: 0.0022 lr: 0.02\n",
      "iteration: 258720 loss: 0.0026 lr: 0.02\n",
      "iteration: 258730 loss: 0.0024 lr: 0.02\n",
      "iteration: 258740 loss: 0.0019 lr: 0.02\n",
      "iteration: 258750 loss: 0.0017 lr: 0.02\n",
      "iteration: 258760 loss: 0.0020 lr: 0.02\n",
      "iteration: 258770 loss: 0.0016 lr: 0.02\n",
      "iteration: 258780 loss: 0.0014 lr: 0.02\n",
      "iteration: 258790 loss: 0.0024 lr: 0.02\n",
      "iteration: 258800 loss: 0.0018 lr: 0.02\n",
      "iteration: 258810 loss: 0.0019 lr: 0.02\n",
      "iteration: 258820 loss: 0.0031 lr: 0.02\n",
      "iteration: 258830 loss: 0.0020 lr: 0.02\n",
      "iteration: 258840 loss: 0.0016 lr: 0.02\n",
      "iteration: 258850 loss: 0.0019 lr: 0.02\n",
      "iteration: 258860 loss: 0.0020 lr: 0.02\n",
      "iteration: 258870 loss: 0.0016 lr: 0.02\n",
      "iteration: 258880 loss: 0.0020 lr: 0.02\n",
      "iteration: 258890 loss: 0.0020 lr: 0.02\n",
      "iteration: 258900 loss: 0.0017 lr: 0.02\n",
      "iteration: 258910 loss: 0.0019 lr: 0.02\n",
      "iteration: 258920 loss: 0.0013 lr: 0.02\n",
      "iteration: 258930 loss: 0.0016 lr: 0.02\n",
      "iteration: 258940 loss: 0.0021 lr: 0.02\n",
      "iteration: 258950 loss: 0.0021 lr: 0.02\n",
      "iteration: 258960 loss: 0.0015 lr: 0.02\n",
      "iteration: 258970 loss: 0.0020 lr: 0.02\n",
      "iteration: 258980 loss: 0.0016 lr: 0.02\n",
      "iteration: 258990 loss: 0.0018 lr: 0.02\n",
      "iteration: 259000 loss: 0.0018 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 259010 loss: 0.0021 lr: 0.02\n",
      "iteration: 259020 loss: 0.0022 lr: 0.02\n",
      "iteration: 259030 loss: 0.0022 lr: 0.02\n",
      "iteration: 259040 loss: 0.0016 lr: 0.02\n",
      "iteration: 259050 loss: 0.0024 lr: 0.02\n",
      "iteration: 259060 loss: 0.0020 lr: 0.02\n",
      "iteration: 259070 loss: 0.0020 lr: 0.02\n",
      "iteration: 259080 loss: 0.0017 lr: 0.02\n",
      "iteration: 259090 loss: 0.0015 lr: 0.02\n",
      "iteration: 259100 loss: 0.0014 lr: 0.02\n",
      "iteration: 259110 loss: 0.0015 lr: 0.02\n",
      "iteration: 259120 loss: 0.0015 lr: 0.02\n",
      "iteration: 259130 loss: 0.0022 lr: 0.02\n",
      "iteration: 259140 loss: 0.0016 lr: 0.02\n",
      "iteration: 259150 loss: 0.0016 lr: 0.02\n",
      "iteration: 259160 loss: 0.0017 lr: 0.02\n",
      "iteration: 259170 loss: 0.0022 lr: 0.02\n",
      "iteration: 259180 loss: 0.0016 lr: 0.02\n",
      "iteration: 259190 loss: 0.0021 lr: 0.02\n",
      "iteration: 259200 loss: 0.0016 lr: 0.02\n",
      "iteration: 259210 loss: 0.0023 lr: 0.02\n",
      "iteration: 259220 loss: 0.0018 lr: 0.02\n",
      "iteration: 259230 loss: 0.0024 lr: 0.02\n",
      "iteration: 259240 loss: 0.0018 lr: 0.02\n",
      "iteration: 259250 loss: 0.0017 lr: 0.02\n",
      "iteration: 259260 loss: 0.0020 lr: 0.02\n",
      "iteration: 259270 loss: 0.0018 lr: 0.02\n",
      "iteration: 259280 loss: 0.0019 lr: 0.02\n",
      "iteration: 259290 loss: 0.0014 lr: 0.02\n",
      "iteration: 259300 loss: 0.0016 lr: 0.02\n",
      "iteration: 259310 loss: 0.0017 lr: 0.02\n",
      "iteration: 259320 loss: 0.0020 lr: 0.02\n",
      "iteration: 259330 loss: 0.0019 lr: 0.02\n",
      "iteration: 259340 loss: 0.0015 lr: 0.02\n",
      "iteration: 259350 loss: 0.0018 lr: 0.02\n",
      "iteration: 259360 loss: 0.0019 lr: 0.02\n",
      "iteration: 259370 loss: 0.0016 lr: 0.02\n",
      "iteration: 259380 loss: 0.0016 lr: 0.02\n",
      "iteration: 259390 loss: 0.0018 lr: 0.02\n",
      "iteration: 259400 loss: 0.0022 lr: 0.02\n",
      "iteration: 259410 loss: 0.0021 lr: 0.02\n",
      "iteration: 259420 loss: 0.0015 lr: 0.02\n",
      "iteration: 259430 loss: 0.0015 lr: 0.02\n",
      "iteration: 259440 loss: 0.0019 lr: 0.02\n",
      "iteration: 259450 loss: 0.0019 lr: 0.02\n",
      "iteration: 259460 loss: 0.0015 lr: 0.02\n",
      "iteration: 259470 loss: 0.0014 lr: 0.02\n",
      "iteration: 259480 loss: 0.0018 lr: 0.02\n",
      "iteration: 259490 loss: 0.0016 lr: 0.02\n",
      "iteration: 259500 loss: 0.0017 lr: 0.02\n",
      "iteration: 259510 loss: 0.0015 lr: 0.02\n",
      "iteration: 259520 loss: 0.0019 lr: 0.02\n",
      "iteration: 259530 loss: 0.0016 lr: 0.02\n",
      "iteration: 259540 loss: 0.0016 lr: 0.02\n",
      "iteration: 259550 loss: 0.0020 lr: 0.02\n",
      "iteration: 259560 loss: 0.0021 lr: 0.02\n",
      "iteration: 259570 loss: 0.0016 lr: 0.02\n",
      "iteration: 259580 loss: 0.0018 lr: 0.02\n",
      "iteration: 259590 loss: 0.0016 lr: 0.02\n",
      "iteration: 259600 loss: 0.0017 lr: 0.02\n",
      "iteration: 259610 loss: 0.0023 lr: 0.02\n",
      "iteration: 259620 loss: 0.0016 lr: 0.02\n",
      "iteration: 259630 loss: 0.0020 lr: 0.02\n",
      "iteration: 259640 loss: 0.0015 lr: 0.02\n",
      "iteration: 259650 loss: 0.0017 lr: 0.02\n",
      "iteration: 259660 loss: 0.0016 lr: 0.02\n",
      "iteration: 259670 loss: 0.0014 lr: 0.02\n",
      "iteration: 259680 loss: 0.0014 lr: 0.02\n",
      "iteration: 259690 loss: 0.0016 lr: 0.02\n",
      "iteration: 259700 loss: 0.0015 lr: 0.02\n",
      "iteration: 259710 loss: 0.0017 lr: 0.02\n",
      "iteration: 259720 loss: 0.0022 lr: 0.02\n",
      "iteration: 259730 loss: 0.0014 lr: 0.02\n",
      "iteration: 259740 loss: 0.0013 lr: 0.02\n",
      "iteration: 259750 loss: 0.0016 lr: 0.02\n",
      "iteration: 259760 loss: 0.0016 lr: 0.02\n",
      "iteration: 259770 loss: 0.0018 lr: 0.02\n",
      "iteration: 259780 loss: 0.0019 lr: 0.02\n",
      "iteration: 259790 loss: 0.0020 lr: 0.02\n",
      "iteration: 259800 loss: 0.0017 lr: 0.02\n",
      "iteration: 259810 loss: 0.0019 lr: 0.02\n",
      "iteration: 259820 loss: 0.0020 lr: 0.02\n",
      "iteration: 259830 loss: 0.0017 lr: 0.02\n",
      "iteration: 259840 loss: 0.0016 lr: 0.02\n",
      "iteration: 259850 loss: 0.0014 lr: 0.02\n",
      "iteration: 259860 loss: 0.0018 lr: 0.02\n",
      "iteration: 259870 loss: 0.0012 lr: 0.02\n",
      "iteration: 259880 loss: 0.0020 lr: 0.02\n",
      "iteration: 259890 loss: 0.0022 lr: 0.02\n",
      "iteration: 259900 loss: 0.0016 lr: 0.02\n",
      "iteration: 259910 loss: 0.0013 lr: 0.02\n",
      "iteration: 259920 loss: 0.0015 lr: 0.02\n",
      "iteration: 259930 loss: 0.0017 lr: 0.02\n",
      "iteration: 259940 loss: 0.0018 lr: 0.02\n",
      "iteration: 259950 loss: 0.0020 lr: 0.02\n",
      "iteration: 259960 loss: 0.0019 lr: 0.02\n",
      "iteration: 259970 loss: 0.0018 lr: 0.02\n",
      "iteration: 259980 loss: 0.0017 lr: 0.02\n",
      "iteration: 259990 loss: 0.0019 lr: 0.02\n",
      "iteration: 260000 loss: 0.0015 lr: 0.02\n",
      "iteration: 260010 loss: 0.0014 lr: 0.02\n",
      "iteration: 260020 loss: 0.0018 lr: 0.02\n",
      "iteration: 260030 loss: 0.0013 lr: 0.02\n",
      "iteration: 260040 loss: 0.0019 lr: 0.02\n",
      "iteration: 260050 loss: 0.0024 lr: 0.02\n",
      "iteration: 260060 loss: 0.0020 lr: 0.02\n",
      "iteration: 260070 loss: 0.0018 lr: 0.02\n",
      "iteration: 260080 loss: 0.0017 lr: 0.02\n",
      "iteration: 260090 loss: 0.0021 lr: 0.02\n",
      "iteration: 260100 loss: 0.0017 lr: 0.02\n",
      "iteration: 260110 loss: 0.0019 lr: 0.02\n",
      "iteration: 260120 loss: 0.0015 lr: 0.02\n",
      "iteration: 260130 loss: 0.0015 lr: 0.02\n",
      "iteration: 260140 loss: 0.0027 lr: 0.02\n",
      "iteration: 260150 loss: 0.0014 lr: 0.02\n",
      "iteration: 260160 loss: 0.0013 lr: 0.02\n",
      "iteration: 260170 loss: 0.0020 lr: 0.02\n",
      "iteration: 260180 loss: 0.0017 lr: 0.02\n",
      "iteration: 260190 loss: 0.0015 lr: 0.02\n",
      "iteration: 260200 loss: 0.0018 lr: 0.02\n",
      "iteration: 260210 loss: 0.0015 lr: 0.02\n",
      "iteration: 260220 loss: 0.0021 lr: 0.02\n",
      "iteration: 260230 loss: 0.0014 lr: 0.02\n",
      "iteration: 260240 loss: 0.0020 lr: 0.02\n",
      "iteration: 260250 loss: 0.0017 lr: 0.02\n",
      "iteration: 260260 loss: 0.0018 lr: 0.02\n",
      "iteration: 260270 loss: 0.0015 lr: 0.02\n",
      "iteration: 260280 loss: 0.0013 lr: 0.02\n",
      "iteration: 260290 loss: 0.0021 lr: 0.02\n",
      "iteration: 260300 loss: 0.0022 lr: 0.02\n",
      "iteration: 260310 loss: 0.0015 lr: 0.02\n",
      "iteration: 260320 loss: 0.0023 lr: 0.02\n",
      "iteration: 260330 loss: 0.0019 lr: 0.02\n",
      "iteration: 260340 loss: 0.0016 lr: 0.02\n",
      "iteration: 260350 loss: 0.0023 lr: 0.02\n",
      "iteration: 260360 loss: 0.0016 lr: 0.02\n",
      "iteration: 260370 loss: 0.0017 lr: 0.02\n",
      "iteration: 260380 loss: 0.0021 lr: 0.02\n",
      "iteration: 260390 loss: 0.0016 lr: 0.02\n",
      "iteration: 260400 loss: 0.0018 lr: 0.02\n",
      "iteration: 260410 loss: 0.0017 lr: 0.02\n",
      "iteration: 260420 loss: 0.0020 lr: 0.02\n",
      "iteration: 260430 loss: 0.0025 lr: 0.02\n",
      "iteration: 260440 loss: 0.0016 lr: 0.02\n",
      "iteration: 260450 loss: 0.0016 lr: 0.02\n",
      "iteration: 260460 loss: 0.0013 lr: 0.02\n",
      "iteration: 260470 loss: 0.0019 lr: 0.02\n",
      "iteration: 260480 loss: 0.0016 lr: 0.02\n",
      "iteration: 260490 loss: 0.0015 lr: 0.02\n",
      "iteration: 260500 loss: 0.0020 lr: 0.02\n",
      "iteration: 260510 loss: 0.0015 lr: 0.02\n",
      "iteration: 260520 loss: 0.0017 lr: 0.02\n",
      "iteration: 260530 loss: 0.0015 lr: 0.02\n",
      "iteration: 260540 loss: 0.0015 lr: 0.02\n",
      "iteration: 260550 loss: 0.0018 lr: 0.02\n",
      "iteration: 260560 loss: 0.0019 lr: 0.02\n",
      "iteration: 260570 loss: 0.0017 lr: 0.02\n",
      "iteration: 260580 loss: 0.0019 lr: 0.02\n",
      "iteration: 260590 loss: 0.0013 lr: 0.02\n",
      "iteration: 260600 loss: 0.0019 lr: 0.02\n",
      "iteration: 260610 loss: 0.0014 lr: 0.02\n",
      "iteration: 260620 loss: 0.0016 lr: 0.02\n",
      "iteration: 260630 loss: 0.0018 lr: 0.02\n",
      "iteration: 260640 loss: 0.0015 lr: 0.02\n",
      "iteration: 260650 loss: 0.0021 lr: 0.02\n",
      "iteration: 260660 loss: 0.0035 lr: 0.02\n",
      "iteration: 260670 loss: 0.0019 lr: 0.02\n",
      "iteration: 260680 loss: 0.0015 lr: 0.02\n",
      "iteration: 260690 loss: 0.0017 lr: 0.02\n",
      "iteration: 260700 loss: 0.0017 lr: 0.02\n",
      "iteration: 260710 loss: 0.0018 lr: 0.02\n",
      "iteration: 260720 loss: 0.0018 lr: 0.02\n",
      "iteration: 260730 loss: 0.0017 lr: 0.02\n",
      "iteration: 260740 loss: 0.0014 lr: 0.02\n",
      "iteration: 260750 loss: 0.0020 lr: 0.02\n",
      "iteration: 260760 loss: 0.0016 lr: 0.02\n",
      "iteration: 260770 loss: 0.0021 lr: 0.02\n",
      "iteration: 260780 loss: 0.0026 lr: 0.02\n",
      "iteration: 260790 loss: 0.0016 lr: 0.02\n",
      "iteration: 260800 loss: 0.0026 lr: 0.02\n",
      "iteration: 260810 loss: 0.0023 lr: 0.02\n",
      "iteration: 260820 loss: 0.0024 lr: 0.02\n",
      "iteration: 260830 loss: 0.0018 lr: 0.02\n",
      "iteration: 260840 loss: 0.0013 lr: 0.02\n",
      "iteration: 260850 loss: 0.0022 lr: 0.02\n",
      "iteration: 260860 loss: 0.0014 lr: 0.02\n",
      "iteration: 260870 loss: 0.0020 lr: 0.02\n",
      "iteration: 260880 loss: 0.0016 lr: 0.02\n",
      "iteration: 260890 loss: 0.0019 lr: 0.02\n",
      "iteration: 260900 loss: 0.0020 lr: 0.02\n",
      "iteration: 260910 loss: 0.0016 lr: 0.02\n",
      "iteration: 260920 loss: 0.0022 lr: 0.02\n",
      "iteration: 260930 loss: 0.0019 lr: 0.02\n",
      "iteration: 260940 loss: 0.0013 lr: 0.02\n",
      "iteration: 260950 loss: 0.0018 lr: 0.02\n",
      "iteration: 260960 loss: 0.0018 lr: 0.02\n",
      "iteration: 260970 loss: 0.0016 lr: 0.02\n",
      "iteration: 260980 loss: 0.0013 lr: 0.02\n",
      "iteration: 260990 loss: 0.0018 lr: 0.02\n",
      "iteration: 261000 loss: 0.0016 lr: 0.02\n",
      "iteration: 261010 loss: 0.0018 lr: 0.02\n",
      "iteration: 261020 loss: 0.0017 lr: 0.02\n",
      "iteration: 261030 loss: 0.0016 lr: 0.02\n",
      "iteration: 261040 loss: 0.0017 lr: 0.02\n",
      "iteration: 261050 loss: 0.0018 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 261060 loss: 0.0019 lr: 0.02\n",
      "iteration: 261070 loss: 0.0016 lr: 0.02\n",
      "iteration: 261080 loss: 0.0012 lr: 0.02\n",
      "iteration: 261090 loss: 0.0016 lr: 0.02\n",
      "iteration: 261100 loss: 0.0014 lr: 0.02\n",
      "iteration: 261110 loss: 0.0016 lr: 0.02\n",
      "iteration: 261120 loss: 0.0015 lr: 0.02\n",
      "iteration: 261130 loss: 0.0020 lr: 0.02\n",
      "iteration: 261140 loss: 0.0027 lr: 0.02\n",
      "iteration: 261150 loss: 0.0017 lr: 0.02\n",
      "iteration: 261160 loss: 0.0013 lr: 0.02\n",
      "iteration: 261170 loss: 0.0020 lr: 0.02\n",
      "iteration: 261180 loss: 0.0016 lr: 0.02\n",
      "iteration: 261190 loss: 0.0018 lr: 0.02\n",
      "iteration: 261200 loss: 0.0017 lr: 0.02\n",
      "iteration: 261210 loss: 0.0013 lr: 0.02\n",
      "iteration: 261220 loss: 0.0012 lr: 0.02\n",
      "iteration: 261230 loss: 0.0012 lr: 0.02\n",
      "iteration: 261240 loss: 0.0016 lr: 0.02\n",
      "iteration: 261250 loss: 0.0022 lr: 0.02\n",
      "iteration: 261260 loss: 0.0017 lr: 0.02\n",
      "iteration: 261270 loss: 0.0016 lr: 0.02\n",
      "iteration: 261280 loss: 0.0020 lr: 0.02\n",
      "iteration: 261290 loss: 0.0021 lr: 0.02\n",
      "iteration: 261300 loss: 0.0017 lr: 0.02\n",
      "iteration: 261310 loss: 0.0025 lr: 0.02\n",
      "iteration: 261320 loss: 0.0020 lr: 0.02\n",
      "iteration: 261330 loss: 0.0020 lr: 0.02\n",
      "iteration: 261340 loss: 0.0016 lr: 0.02\n",
      "iteration: 261350 loss: 0.0015 lr: 0.02\n",
      "iteration: 261360 loss: 0.0014 lr: 0.02\n",
      "iteration: 261370 loss: 0.0017 lr: 0.02\n",
      "iteration: 261380 loss: 0.0017 lr: 0.02\n",
      "iteration: 261390 loss: 0.0016 lr: 0.02\n",
      "iteration: 261400 loss: 0.0021 lr: 0.02\n",
      "iteration: 261410 loss: 0.0015 lr: 0.02\n",
      "iteration: 261420 loss: 0.0018 lr: 0.02\n",
      "iteration: 261430 loss: 0.0021 lr: 0.02\n",
      "iteration: 261440 loss: 0.0022 lr: 0.02\n",
      "iteration: 261450 loss: 0.0014 lr: 0.02\n",
      "iteration: 261460 loss: 0.0017 lr: 0.02\n",
      "iteration: 261470 loss: 0.0026 lr: 0.02\n",
      "iteration: 261480 loss: 0.0016 lr: 0.02\n",
      "iteration: 261490 loss: 0.0019 lr: 0.02\n",
      "iteration: 261500 loss: 0.0017 lr: 0.02\n",
      "iteration: 261510 loss: 0.0018 lr: 0.02\n",
      "iteration: 261520 loss: 0.0017 lr: 0.02\n",
      "iteration: 261530 loss: 0.0020 lr: 0.02\n",
      "iteration: 261540 loss: 0.0017 lr: 0.02\n",
      "iteration: 261550 loss: 0.0022 lr: 0.02\n",
      "iteration: 261560 loss: 0.0014 lr: 0.02\n",
      "iteration: 261570 loss: 0.0017 lr: 0.02\n",
      "iteration: 261580 loss: 0.0020 lr: 0.02\n",
      "iteration: 261590 loss: 0.0013 lr: 0.02\n",
      "iteration: 261600 loss: 0.0015 lr: 0.02\n",
      "iteration: 261610 loss: 0.0016 lr: 0.02\n",
      "iteration: 261620 loss: 0.0023 lr: 0.02\n",
      "iteration: 261630 loss: 0.0017 lr: 0.02\n",
      "iteration: 261640 loss: 0.0018 lr: 0.02\n",
      "iteration: 261650 loss: 0.0015 lr: 0.02\n",
      "iteration: 261660 loss: 0.0023 lr: 0.02\n",
      "iteration: 261670 loss: 0.0015 lr: 0.02\n",
      "iteration: 261680 loss: 0.0019 lr: 0.02\n",
      "iteration: 261690 loss: 0.0021 lr: 0.02\n",
      "iteration: 261700 loss: 0.0017 lr: 0.02\n",
      "iteration: 261710 loss: 0.0022 lr: 0.02\n",
      "iteration: 261720 loss: 0.0020 lr: 0.02\n",
      "iteration: 261730 loss: 0.0023 lr: 0.02\n",
      "iteration: 261740 loss: 0.0017 lr: 0.02\n",
      "iteration: 261750 loss: 0.0015 lr: 0.02\n",
      "iteration: 261760 loss: 0.0022 lr: 0.02\n",
      "iteration: 261770 loss: 0.0018 lr: 0.02\n",
      "iteration: 261780 loss: 0.0014 lr: 0.02\n",
      "iteration: 261790 loss: 0.0021 lr: 0.02\n",
      "iteration: 261800 loss: 0.0015 lr: 0.02\n",
      "iteration: 261810 loss: 0.0020 lr: 0.02\n",
      "iteration: 261820 loss: 0.0025 lr: 0.02\n",
      "iteration: 261830 loss: 0.0018 lr: 0.02\n",
      "iteration: 261840 loss: 0.0016 lr: 0.02\n",
      "iteration: 261850 loss: 0.0021 lr: 0.02\n",
      "iteration: 261860 loss: 0.0013 lr: 0.02\n",
      "iteration: 261870 loss: 0.0021 lr: 0.02\n",
      "iteration: 261880 loss: 0.0013 lr: 0.02\n",
      "iteration: 261890 loss: 0.0016 lr: 0.02\n",
      "iteration: 261900 loss: 0.0020 lr: 0.02\n",
      "iteration: 261910 loss: 0.0019 lr: 0.02\n",
      "iteration: 261920 loss: 0.0017 lr: 0.02\n",
      "iteration: 261930 loss: 0.0016 lr: 0.02\n",
      "iteration: 261940 loss: 0.0020 lr: 0.02\n",
      "iteration: 261950 loss: 0.0022 lr: 0.02\n",
      "iteration: 261960 loss: 0.0015 lr: 0.02\n",
      "iteration: 261970 loss: 0.0018 lr: 0.02\n",
      "iteration: 261980 loss: 0.0020 lr: 0.02\n",
      "iteration: 261990 loss: 0.0014 lr: 0.02\n",
      "iteration: 262000 loss: 0.0020 lr: 0.02\n",
      "iteration: 262010 loss: 0.0015 lr: 0.02\n",
      "iteration: 262020 loss: 0.0014 lr: 0.02\n",
      "iteration: 262030 loss: 0.0017 lr: 0.02\n",
      "iteration: 262040 loss: 0.0017 lr: 0.02\n",
      "iteration: 262050 loss: 0.0017 lr: 0.02\n",
      "iteration: 262060 loss: 0.0015 lr: 0.02\n",
      "iteration: 262070 loss: 0.0016 lr: 0.02\n",
      "iteration: 262080 loss: 0.0017 lr: 0.02\n",
      "iteration: 262090 loss: 0.0019 lr: 0.02\n",
      "iteration: 262100 loss: 0.0015 lr: 0.02\n",
      "iteration: 262110 loss: 0.0020 lr: 0.02\n",
      "iteration: 262120 loss: 0.0020 lr: 0.02\n",
      "iteration: 262130 loss: 0.0019 lr: 0.02\n",
      "iteration: 262140 loss: 0.0016 lr: 0.02\n",
      "iteration: 262150 loss: 0.0017 lr: 0.02\n",
      "iteration: 262160 loss: 0.0015 lr: 0.02\n",
      "iteration: 262170 loss: 0.0019 lr: 0.02\n",
      "iteration: 262180 loss: 0.0017 lr: 0.02\n",
      "iteration: 262190 loss: 0.0019 lr: 0.02\n",
      "iteration: 262200 loss: 0.0014 lr: 0.02\n",
      "iteration: 262210 loss: 0.0020 lr: 0.02\n",
      "iteration: 262220 loss: 0.0018 lr: 0.02\n",
      "iteration: 262230 loss: 0.0018 lr: 0.02\n",
      "iteration: 262240 loss: 0.0019 lr: 0.02\n",
      "iteration: 262250 loss: 0.0019 lr: 0.02\n",
      "iteration: 262260 loss: 0.0017 lr: 0.02\n",
      "iteration: 262270 loss: 0.0019 lr: 0.02\n",
      "iteration: 262280 loss: 0.0019 lr: 0.02\n",
      "iteration: 262290 loss: 0.0019 lr: 0.02\n",
      "iteration: 262300 loss: 0.0019 lr: 0.02\n",
      "iteration: 262310 loss: 0.0014 lr: 0.02\n",
      "iteration: 262320 loss: 0.0018 lr: 0.02\n",
      "iteration: 262330 loss: 0.0017 lr: 0.02\n",
      "iteration: 262340 loss: 0.0018 lr: 0.02\n",
      "iteration: 262350 loss: 0.0016 lr: 0.02\n",
      "iteration: 262360 loss: 0.0015 lr: 0.02\n",
      "iteration: 262370 loss: 0.0016 lr: 0.02\n",
      "iteration: 262380 loss: 0.0020 lr: 0.02\n",
      "iteration: 262390 loss: 0.0020 lr: 0.02\n",
      "iteration: 262400 loss: 0.0017 lr: 0.02\n",
      "iteration: 262410 loss: 0.0026 lr: 0.02\n",
      "iteration: 262420 loss: 0.0018 lr: 0.02\n",
      "iteration: 262430 loss: 0.0024 lr: 0.02\n",
      "iteration: 262440 loss: 0.0021 lr: 0.02\n",
      "iteration: 262450 loss: 0.0017 lr: 0.02\n",
      "iteration: 262460 loss: 0.0023 lr: 0.02\n",
      "iteration: 262470 loss: 0.0020 lr: 0.02\n",
      "iteration: 262480 loss: 0.0017 lr: 0.02\n",
      "iteration: 262490 loss: 0.0020 lr: 0.02\n",
      "iteration: 262500 loss: 0.0018 lr: 0.02\n",
      "iteration: 262510 loss: 0.0018 lr: 0.02\n",
      "iteration: 262520 loss: 0.0017 lr: 0.02\n",
      "iteration: 262530 loss: 0.0013 lr: 0.02\n",
      "iteration: 262540 loss: 0.0018 lr: 0.02\n",
      "iteration: 262550 loss: 0.0017 lr: 0.02\n",
      "iteration: 262560 loss: 0.0022 lr: 0.02\n",
      "iteration: 262570 loss: 0.0020 lr: 0.02\n",
      "iteration: 262580 loss: 0.0035 lr: 0.02\n",
      "iteration: 262590 loss: 0.0018 lr: 0.02\n",
      "iteration: 262600 loss: 0.0017 lr: 0.02\n",
      "iteration: 262610 loss: 0.0015 lr: 0.02\n",
      "iteration: 262620 loss: 0.0021 lr: 0.02\n",
      "iteration: 262630 loss: 0.0016 lr: 0.02\n",
      "iteration: 262640 loss: 0.0017 lr: 0.02\n",
      "iteration: 262650 loss: 0.0025 lr: 0.02\n",
      "iteration: 262660 loss: 0.0016 lr: 0.02\n",
      "iteration: 262670 loss: 0.0027 lr: 0.02\n",
      "iteration: 262680 loss: 0.0011 lr: 0.02\n",
      "iteration: 262690 loss: 0.0016 lr: 0.02\n",
      "iteration: 262700 loss: 0.0015 lr: 0.02\n",
      "iteration: 262710 loss: 0.0018 lr: 0.02\n",
      "iteration: 262720 loss: 0.0016 lr: 0.02\n",
      "iteration: 262730 loss: 0.0014 lr: 0.02\n",
      "iteration: 262740 loss: 0.0020 lr: 0.02\n",
      "iteration: 262750 loss: 0.0023 lr: 0.02\n",
      "iteration: 262760 loss: 0.0014 lr: 0.02\n",
      "iteration: 262770 loss: 0.0012 lr: 0.02\n",
      "iteration: 262780 loss: 0.0020 lr: 0.02\n",
      "iteration: 262790 loss: 0.0018 lr: 0.02\n",
      "iteration: 262800 loss: 0.0019 lr: 0.02\n",
      "iteration: 262810 loss: 0.0019 lr: 0.02\n",
      "iteration: 262820 loss: 0.0014 lr: 0.02\n",
      "iteration: 262830 loss: 0.0017 lr: 0.02\n",
      "iteration: 262840 loss: 0.0016 lr: 0.02\n",
      "iteration: 262850 loss: 0.0015 lr: 0.02\n",
      "iteration: 262860 loss: 0.0015 lr: 0.02\n",
      "iteration: 262870 loss: 0.0015 lr: 0.02\n",
      "iteration: 262880 loss: 0.0024 lr: 0.02\n",
      "iteration: 262890 loss: 0.0019 lr: 0.02\n",
      "iteration: 262900 loss: 0.0017 lr: 0.02\n",
      "iteration: 262910 loss: 0.0020 lr: 0.02\n",
      "iteration: 262920 loss: 0.0017 lr: 0.02\n",
      "iteration: 262930 loss: 0.0020 lr: 0.02\n",
      "iteration: 262940 loss: 0.0019 lr: 0.02\n",
      "iteration: 262950 loss: 0.0016 lr: 0.02\n",
      "iteration: 262960 loss: 0.0018 lr: 0.02\n",
      "iteration: 262970 loss: 0.0016 lr: 0.02\n",
      "iteration: 262980 loss: 0.0021 lr: 0.02\n",
      "iteration: 262990 loss: 0.0016 lr: 0.02\n",
      "iteration: 263000 loss: 0.0024 lr: 0.02\n",
      "iteration: 263010 loss: 0.0019 lr: 0.02\n",
      "iteration: 263020 loss: 0.0019 lr: 0.02\n",
      "iteration: 263030 loss: 0.0014 lr: 0.02\n",
      "iteration: 263040 loss: 0.0018 lr: 0.02\n",
      "iteration: 263050 loss: 0.0019 lr: 0.02\n",
      "iteration: 263060 loss: 0.0019 lr: 0.02\n",
      "iteration: 263070 loss: 0.0013 lr: 0.02\n",
      "iteration: 263080 loss: 0.0016 lr: 0.02\n",
      "iteration: 263090 loss: 0.0015 lr: 0.02\n",
      "iteration: 263100 loss: 0.0017 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 263110 loss: 0.0016 lr: 0.02\n",
      "iteration: 263120 loss: 0.0018 lr: 0.02\n",
      "iteration: 263130 loss: 0.0017 lr: 0.02\n",
      "iteration: 263140 loss: 0.0021 lr: 0.02\n",
      "iteration: 263150 loss: 0.0019 lr: 0.02\n",
      "iteration: 263160 loss: 0.0024 lr: 0.02\n",
      "iteration: 263170 loss: 0.0019 lr: 0.02\n",
      "iteration: 263180 loss: 0.0016 lr: 0.02\n",
      "iteration: 263190 loss: 0.0015 lr: 0.02\n",
      "iteration: 263200 loss: 0.0018 lr: 0.02\n",
      "iteration: 263210 loss: 0.0016 lr: 0.02\n",
      "iteration: 263220 loss: 0.0015 lr: 0.02\n",
      "iteration: 263230 loss: 0.0022 lr: 0.02\n",
      "iteration: 263240 loss: 0.0017 lr: 0.02\n",
      "iteration: 263250 loss: 0.0019 lr: 0.02\n",
      "iteration: 263260 loss: 0.0020 lr: 0.02\n",
      "iteration: 263270 loss: 0.0020 lr: 0.02\n",
      "iteration: 263280 loss: 0.0019 lr: 0.02\n",
      "iteration: 263290 loss: 0.0017 lr: 0.02\n",
      "iteration: 263300 loss: 0.0017 lr: 0.02\n",
      "iteration: 263310 loss: 0.0017 lr: 0.02\n",
      "iteration: 263320 loss: 0.0017 lr: 0.02\n",
      "iteration: 263330 loss: 0.0018 lr: 0.02\n",
      "iteration: 263340 loss: 0.0014 lr: 0.02\n",
      "iteration: 263350 loss: 0.0013 lr: 0.02\n",
      "iteration: 263360 loss: 0.0018 lr: 0.02\n",
      "iteration: 263370 loss: 0.0016 lr: 0.02\n",
      "iteration: 263380 loss: 0.0015 lr: 0.02\n",
      "iteration: 263390 loss: 0.0019 lr: 0.02\n",
      "iteration: 263400 loss: 0.0015 lr: 0.02\n",
      "iteration: 263410 loss: 0.0017 lr: 0.02\n",
      "iteration: 263420 loss: 0.0021 lr: 0.02\n",
      "iteration: 263430 loss: 0.0015 lr: 0.02\n",
      "iteration: 263440 loss: 0.0019 lr: 0.02\n",
      "iteration: 263450 loss: 0.0018 lr: 0.02\n",
      "iteration: 263460 loss: 0.0017 lr: 0.02\n",
      "iteration: 263470 loss: 0.0021 lr: 0.02\n",
      "iteration: 263480 loss: 0.0022 lr: 0.02\n",
      "iteration: 263490 loss: 0.0023 lr: 0.02\n",
      "iteration: 263500 loss: 0.0027 lr: 0.02\n",
      "iteration: 263510 loss: 0.0015 lr: 0.02\n",
      "iteration: 263520 loss: 0.0020 lr: 0.02\n",
      "iteration: 263530 loss: 0.0016 lr: 0.02\n",
      "iteration: 263540 loss: 0.0018 lr: 0.02\n",
      "iteration: 263550 loss: 0.0014 lr: 0.02\n",
      "iteration: 263560 loss: 0.0018 lr: 0.02\n",
      "iteration: 263570 loss: 0.0016 lr: 0.02\n",
      "iteration: 263580 loss: 0.0014 lr: 0.02\n",
      "iteration: 263590 loss: 0.0018 lr: 0.02\n",
      "iteration: 263600 loss: 0.0016 lr: 0.02\n",
      "iteration: 263610 loss: 0.0019 lr: 0.02\n",
      "iteration: 263620 loss: 0.0018 lr: 0.02\n",
      "iteration: 263630 loss: 0.0020 lr: 0.02\n",
      "iteration: 263640 loss: 0.0018 lr: 0.02\n",
      "iteration: 263650 loss: 0.0017 lr: 0.02\n",
      "iteration: 263660 loss: 0.0018 lr: 0.02\n",
      "iteration: 263670 loss: 0.0018 lr: 0.02\n",
      "iteration: 263680 loss: 0.0023 lr: 0.02\n",
      "iteration: 263690 loss: 0.0018 lr: 0.02\n",
      "iteration: 263700 loss: 0.0019 lr: 0.02\n",
      "iteration: 263710 loss: 0.0015 lr: 0.02\n",
      "iteration: 263720 loss: 0.0016 lr: 0.02\n",
      "iteration: 263730 loss: 0.0018 lr: 0.02\n",
      "iteration: 263740 loss: 0.0017 lr: 0.02\n",
      "iteration: 263750 loss: 0.0024 lr: 0.02\n",
      "iteration: 263760 loss: 0.0014 lr: 0.02\n",
      "iteration: 263770 loss: 0.0016 lr: 0.02\n",
      "iteration: 263780 loss: 0.0023 lr: 0.02\n",
      "iteration: 263790 loss: 0.0017 lr: 0.02\n",
      "iteration: 263800 loss: 0.0019 lr: 0.02\n",
      "iteration: 263810 loss: 0.0020 lr: 0.02\n",
      "iteration: 263820 loss: 0.0018 lr: 0.02\n",
      "iteration: 263830 loss: 0.0018 lr: 0.02\n",
      "iteration: 263840 loss: 0.0014 lr: 0.02\n",
      "iteration: 263850 loss: 0.0015 lr: 0.02\n",
      "iteration: 263860 loss: 0.0019 lr: 0.02\n",
      "iteration: 263870 loss: 0.0020 lr: 0.02\n",
      "iteration: 263880 loss: 0.0016 lr: 0.02\n",
      "iteration: 263890 loss: 0.0020 lr: 0.02\n",
      "iteration: 263900 loss: 0.0022 lr: 0.02\n",
      "iteration: 263910 loss: 0.0018 lr: 0.02\n",
      "iteration: 263920 loss: 0.0022 lr: 0.02\n",
      "iteration: 263930 loss: 0.0012 lr: 0.02\n",
      "iteration: 263940 loss: 0.0018 lr: 0.02\n",
      "iteration: 263950 loss: 0.0016 lr: 0.02\n",
      "iteration: 263960 loss: 0.0020 lr: 0.02\n",
      "iteration: 263970 loss: 0.0014 lr: 0.02\n",
      "iteration: 263980 loss: 0.0021 lr: 0.02\n",
      "iteration: 263990 loss: 0.0022 lr: 0.02\n",
      "iteration: 264000 loss: 0.0016 lr: 0.02\n",
      "iteration: 264010 loss: 0.0018 lr: 0.02\n",
      "iteration: 264020 loss: 0.0023 lr: 0.02\n",
      "iteration: 264030 loss: 0.0018 lr: 0.02\n",
      "iteration: 264040 loss: 0.0021 lr: 0.02\n",
      "iteration: 264050 loss: 0.0017 lr: 0.02\n",
      "iteration: 264060 loss: 0.0012 lr: 0.02\n",
      "iteration: 264070 loss: 0.0019 lr: 0.02\n",
      "iteration: 264080 loss: 0.0017 lr: 0.02\n",
      "iteration: 264090 loss: 0.0018 lr: 0.02\n",
      "iteration: 264100 loss: 0.0015 lr: 0.02\n",
      "iteration: 264110 loss: 0.0021 lr: 0.02\n",
      "iteration: 264120 loss: 0.0012 lr: 0.02\n",
      "iteration: 264130 loss: 0.0018 lr: 0.02\n",
      "iteration: 264140 loss: 0.0015 lr: 0.02\n",
      "iteration: 264150 loss: 0.0016 lr: 0.02\n",
      "iteration: 264160 loss: 0.0014 lr: 0.02\n",
      "iteration: 264170 loss: 0.0028 lr: 0.02\n",
      "iteration: 264180 loss: 0.0020 lr: 0.02\n",
      "iteration: 264190 loss: 0.0017 lr: 0.02\n",
      "iteration: 264200 loss: 0.0016 lr: 0.02\n",
      "iteration: 264210 loss: 0.0018 lr: 0.02\n",
      "iteration: 264220 loss: 0.0019 lr: 0.02\n",
      "iteration: 264230 loss: 0.0020 lr: 0.02\n",
      "iteration: 264240 loss: 0.0015 lr: 0.02\n",
      "iteration: 264250 loss: 0.0022 lr: 0.02\n",
      "iteration: 264260 loss: 0.0019 lr: 0.02\n",
      "iteration: 264270 loss: 0.0018 lr: 0.02\n",
      "iteration: 264280 loss: 0.0019 lr: 0.02\n",
      "iteration: 264290 loss: 0.0033 lr: 0.02\n",
      "iteration: 264300 loss: 0.0019 lr: 0.02\n",
      "iteration: 264310 loss: 0.0017 lr: 0.02\n",
      "iteration: 264320 loss: 0.0022 lr: 0.02\n",
      "iteration: 264330 loss: 0.0015 lr: 0.02\n",
      "iteration: 264340 loss: 0.0016 lr: 0.02\n",
      "iteration: 264350 loss: 0.0016 lr: 0.02\n",
      "iteration: 264360 loss: 0.0016 lr: 0.02\n",
      "iteration: 264370 loss: 0.0016 lr: 0.02\n",
      "iteration: 264380 loss: 0.0014 lr: 0.02\n",
      "iteration: 264390 loss: 0.0023 lr: 0.02\n",
      "iteration: 264400 loss: 0.0020 lr: 0.02\n",
      "iteration: 264410 loss: 0.0017 lr: 0.02\n",
      "iteration: 264420 loss: 0.0018 lr: 0.02\n",
      "iteration: 264430 loss: 0.0017 lr: 0.02\n",
      "iteration: 264440 loss: 0.0015 lr: 0.02\n",
      "iteration: 264450 loss: 0.0016 lr: 0.02\n",
      "iteration: 264460 loss: 0.0018 lr: 0.02\n",
      "iteration: 264470 loss: 0.0017 lr: 0.02\n",
      "iteration: 264480 loss: 0.0019 lr: 0.02\n",
      "iteration: 264490 loss: 0.0025 lr: 0.02\n",
      "iteration: 264500 loss: 0.0017 lr: 0.02\n",
      "iteration: 264510 loss: 0.0016 lr: 0.02\n",
      "iteration: 264520 loss: 0.0015 lr: 0.02\n",
      "iteration: 264530 loss: 0.0017 lr: 0.02\n",
      "iteration: 264540 loss: 0.0018 lr: 0.02\n",
      "iteration: 264550 loss: 0.0015 lr: 0.02\n",
      "iteration: 264560 loss: 0.0029 lr: 0.02\n",
      "iteration: 264570 loss: 0.0018 lr: 0.02\n",
      "iteration: 264580 loss: 0.0015 lr: 0.02\n",
      "iteration: 264590 loss: 0.0018 lr: 0.02\n",
      "iteration: 264600 loss: 0.0020 lr: 0.02\n",
      "iteration: 264610 loss: 0.0021 lr: 0.02\n",
      "iteration: 264620 loss: 0.0013 lr: 0.02\n",
      "iteration: 264630 loss: 0.0018 lr: 0.02\n",
      "iteration: 264640 loss: 0.0018 lr: 0.02\n",
      "iteration: 264650 loss: 0.0025 lr: 0.02\n",
      "iteration: 264660 loss: 0.0017 lr: 0.02\n",
      "iteration: 264670 loss: 0.0021 lr: 0.02\n",
      "iteration: 264680 loss: 0.0017 lr: 0.02\n",
      "iteration: 264690 loss: 0.0016 lr: 0.02\n",
      "iteration: 264700 loss: 0.0016 lr: 0.02\n",
      "iteration: 264710 loss: 0.0018 lr: 0.02\n",
      "iteration: 264720 loss: 0.0020 lr: 0.02\n",
      "iteration: 264730 loss: 0.0020 lr: 0.02\n",
      "iteration: 264740 loss: 0.0017 lr: 0.02\n",
      "iteration: 264750 loss: 0.0024 lr: 0.02\n",
      "iteration: 264760 loss: 0.0016 lr: 0.02\n",
      "iteration: 264770 loss: 0.0020 lr: 0.02\n",
      "iteration: 264780 loss: 0.0020 lr: 0.02\n",
      "iteration: 264790 loss: 0.0014 lr: 0.02\n",
      "iteration: 264800 loss: 0.0017 lr: 0.02\n",
      "iteration: 264810 loss: 0.0018 lr: 0.02\n",
      "iteration: 264820 loss: 0.0019 lr: 0.02\n",
      "iteration: 264830 loss: 0.0018 lr: 0.02\n",
      "iteration: 264840 loss: 0.0016 lr: 0.02\n",
      "iteration: 264850 loss: 0.0014 lr: 0.02\n",
      "iteration: 264860 loss: 0.0014 lr: 0.02\n",
      "iteration: 264870 loss: 0.0017 lr: 0.02\n",
      "iteration: 264880 loss: 0.0016 lr: 0.02\n",
      "iteration: 264890 loss: 0.0014 lr: 0.02\n",
      "iteration: 264900 loss: 0.0024 lr: 0.02\n",
      "iteration: 264910 loss: 0.0020 lr: 0.02\n",
      "iteration: 264920 loss: 0.0021 lr: 0.02\n",
      "iteration: 264930 loss: 0.0019 lr: 0.02\n",
      "iteration: 264940 loss: 0.0023 lr: 0.02\n",
      "iteration: 264950 loss: 0.0017 lr: 0.02\n",
      "iteration: 264960 loss: 0.0018 lr: 0.02\n",
      "iteration: 264970 loss: 0.0018 lr: 0.02\n",
      "iteration: 264980 loss: 0.0020 lr: 0.02\n",
      "iteration: 264990 loss: 0.0020 lr: 0.02\n",
      "iteration: 265000 loss: 0.0016 lr: 0.02\n",
      "iteration: 265010 loss: 0.0020 lr: 0.02\n",
      "iteration: 265020 loss: 0.0016 lr: 0.02\n",
      "iteration: 265030 loss: 0.0019 lr: 0.02\n",
      "iteration: 265040 loss: 0.0018 lr: 0.02\n",
      "iteration: 265050 loss: 0.0024 lr: 0.02\n",
      "iteration: 265060 loss: 0.0016 lr: 0.02\n",
      "iteration: 265070 loss: 0.0021 lr: 0.02\n",
      "iteration: 265080 loss: 0.0021 lr: 0.02\n",
      "iteration: 265090 loss: 0.0019 lr: 0.02\n",
      "iteration: 265100 loss: 0.0018 lr: 0.02\n",
      "iteration: 265110 loss: 0.0021 lr: 0.02\n",
      "iteration: 265120 loss: 0.0014 lr: 0.02\n",
      "iteration: 265130 loss: 0.0018 lr: 0.02\n",
      "iteration: 265140 loss: 0.0020 lr: 0.02\n",
      "iteration: 265150 loss: 0.0017 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 265160 loss: 0.0013 lr: 0.02\n",
      "iteration: 265170 loss: 0.0018 lr: 0.02\n",
      "iteration: 265180 loss: 0.0020 lr: 0.02\n",
      "iteration: 265190 loss: 0.0020 lr: 0.02\n",
      "iteration: 265200 loss: 0.0021 lr: 0.02\n",
      "iteration: 265210 loss: 0.0018 lr: 0.02\n",
      "iteration: 265220 loss: 0.0013 lr: 0.02\n",
      "iteration: 265230 loss: 0.0018 lr: 0.02\n",
      "iteration: 265240 loss: 0.0028 lr: 0.02\n",
      "iteration: 265250 loss: 0.0024 lr: 0.02\n",
      "iteration: 265260 loss: 0.0017 lr: 0.02\n",
      "iteration: 265270 loss: 0.0017 lr: 0.02\n",
      "iteration: 265280 loss: 0.0017 lr: 0.02\n",
      "iteration: 265290 loss: 0.0015 lr: 0.02\n",
      "iteration: 265300 loss: 0.0020 lr: 0.02\n",
      "iteration: 265310 loss: 0.0023 lr: 0.02\n",
      "iteration: 265320 loss: 0.0018 lr: 0.02\n",
      "iteration: 265330 loss: 0.0018 lr: 0.02\n",
      "iteration: 265340 loss: 0.0019 lr: 0.02\n",
      "iteration: 265350 loss: 0.0015 lr: 0.02\n",
      "iteration: 265360 loss: 0.0021 lr: 0.02\n",
      "iteration: 265370 loss: 0.0018 lr: 0.02\n",
      "iteration: 265380 loss: 0.0023 lr: 0.02\n",
      "iteration: 265390 loss: 0.0018 lr: 0.02\n",
      "iteration: 265400 loss: 0.0013 lr: 0.02\n",
      "iteration: 265410 loss: 0.0013 lr: 0.02\n",
      "iteration: 265420 loss: 0.0022 lr: 0.02\n",
      "iteration: 265430 loss: 0.0015 lr: 0.02\n",
      "iteration: 265440 loss: 0.0019 lr: 0.02\n",
      "iteration: 265450 loss: 0.0016 lr: 0.02\n",
      "iteration: 265460 loss: 0.0024 lr: 0.02\n",
      "iteration: 265470 loss: 0.0020 lr: 0.02\n",
      "iteration: 265480 loss: 0.0031 lr: 0.02\n",
      "iteration: 265490 loss: 0.0018 lr: 0.02\n",
      "iteration: 265500 loss: 0.0017 lr: 0.02\n",
      "iteration: 265510 loss: 0.0016 lr: 0.02\n",
      "iteration: 265520 loss: 0.0013 lr: 0.02\n",
      "iteration: 265530 loss: 0.0016 lr: 0.02\n",
      "iteration: 265540 loss: 0.0013 lr: 0.02\n",
      "iteration: 265550 loss: 0.0016 lr: 0.02\n",
      "iteration: 265560 loss: 0.0027 lr: 0.02\n",
      "iteration: 265570 loss: 0.0016 lr: 0.02\n",
      "iteration: 265580 loss: 0.0015 lr: 0.02\n",
      "iteration: 265590 loss: 0.0020 lr: 0.02\n",
      "iteration: 265600 loss: 0.0016 lr: 0.02\n",
      "iteration: 265610 loss: 0.0019 lr: 0.02\n",
      "iteration: 265620 loss: 0.0019 lr: 0.02\n",
      "iteration: 265630 loss: 0.0024 lr: 0.02\n",
      "iteration: 265640 loss: 0.0021 lr: 0.02\n",
      "iteration: 265650 loss: 0.0023 lr: 0.02\n",
      "iteration: 265660 loss: 0.0024 lr: 0.02\n",
      "iteration: 265670 loss: 0.0021 lr: 0.02\n",
      "iteration: 265680 loss: 0.0023 lr: 0.02\n",
      "iteration: 265690 loss: 0.0023 lr: 0.02\n",
      "iteration: 265700 loss: 0.0015 lr: 0.02\n",
      "iteration: 265710 loss: 0.0019 lr: 0.02\n",
      "iteration: 265720 loss: 0.0015 lr: 0.02\n",
      "iteration: 265730 loss: 0.0018 lr: 0.02\n",
      "iteration: 265740 loss: 0.0018 lr: 0.02\n",
      "iteration: 265750 loss: 0.0020 lr: 0.02\n",
      "iteration: 265760 loss: 0.0015 lr: 0.02\n",
      "iteration: 265770 loss: 0.0024 lr: 0.02\n",
      "iteration: 265780 loss: 0.0017 lr: 0.02\n",
      "iteration: 265790 loss: 0.0019 lr: 0.02\n",
      "iteration: 265800 loss: 0.0018 lr: 0.02\n",
      "iteration: 265810 loss: 0.0016 lr: 0.02\n",
      "iteration: 265820 loss: 0.0020 lr: 0.02\n",
      "iteration: 265830 loss: 0.0020 lr: 0.02\n",
      "iteration: 265840 loss: 0.0025 lr: 0.02\n",
      "iteration: 265850 loss: 0.0016 lr: 0.02\n",
      "iteration: 265860 loss: 0.0014 lr: 0.02\n",
      "iteration: 265870 loss: 0.0018 lr: 0.02\n",
      "iteration: 265880 loss: 0.0015 lr: 0.02\n",
      "iteration: 265890 loss: 0.0017 lr: 0.02\n",
      "iteration: 265900 loss: 0.0020 lr: 0.02\n",
      "iteration: 265910 loss: 0.0015 lr: 0.02\n",
      "iteration: 265920 loss: 0.0019 lr: 0.02\n",
      "iteration: 265930 loss: 0.0014 lr: 0.02\n",
      "iteration: 265940 loss: 0.0021 lr: 0.02\n",
      "iteration: 265950 loss: 0.0017 lr: 0.02\n",
      "iteration: 265960 loss: 0.0019 lr: 0.02\n",
      "iteration: 265970 loss: 0.0020 lr: 0.02\n",
      "iteration: 265980 loss: 0.0013 lr: 0.02\n",
      "iteration: 265990 loss: 0.0016 lr: 0.02\n",
      "iteration: 266000 loss: 0.0021 lr: 0.02\n",
      "iteration: 266010 loss: 0.0017 lr: 0.02\n",
      "iteration: 266020 loss: 0.0015 lr: 0.02\n",
      "iteration: 266030 loss: 0.0018 lr: 0.02\n",
      "iteration: 266040 loss: 0.0015 lr: 0.02\n",
      "iteration: 266050 loss: 0.0016 lr: 0.02\n",
      "iteration: 266060 loss: 0.0016 lr: 0.02\n",
      "iteration: 266070 loss: 0.0016 lr: 0.02\n",
      "iteration: 266080 loss: 0.0017 lr: 0.02\n",
      "iteration: 266090 loss: 0.0015 lr: 0.02\n",
      "iteration: 266100 loss: 0.0018 lr: 0.02\n",
      "iteration: 266110 loss: 0.0019 lr: 0.02\n",
      "iteration: 266120 loss: 0.0016 lr: 0.02\n",
      "iteration: 266130 loss: 0.0016 lr: 0.02\n",
      "iteration: 266140 loss: 0.0020 lr: 0.02\n",
      "iteration: 266150 loss: 0.0014 lr: 0.02\n",
      "iteration: 266160 loss: 0.0016 lr: 0.02\n",
      "iteration: 266170 loss: 0.0018 lr: 0.02\n",
      "iteration: 266180 loss: 0.0023 lr: 0.02\n",
      "iteration: 266190 loss: 0.0015 lr: 0.02\n",
      "iteration: 266200 loss: 0.0014 lr: 0.02\n",
      "iteration: 266210 loss: 0.0021 lr: 0.02\n",
      "iteration: 266220 loss: 0.0016 lr: 0.02\n",
      "iteration: 266230 loss: 0.0013 lr: 0.02\n",
      "iteration: 266240 loss: 0.0018 lr: 0.02\n",
      "iteration: 266250 loss: 0.0018 lr: 0.02\n",
      "iteration: 266260 loss: 0.0014 lr: 0.02\n",
      "iteration: 266270 loss: 0.0019 lr: 0.02\n",
      "iteration: 266280 loss: 0.0018 lr: 0.02\n",
      "iteration: 266290 loss: 0.0019 lr: 0.02\n",
      "iteration: 266300 loss: 0.0017 lr: 0.02\n",
      "iteration: 266310 loss: 0.0027 lr: 0.02\n",
      "iteration: 266320 loss: 0.0020 lr: 0.02\n",
      "iteration: 266330 loss: 0.0018 lr: 0.02\n",
      "iteration: 266340 loss: 0.0017 lr: 0.02\n",
      "iteration: 266350 loss: 0.0020 lr: 0.02\n",
      "iteration: 266360 loss: 0.0017 lr: 0.02\n",
      "iteration: 266370 loss: 0.0015 lr: 0.02\n",
      "iteration: 266380 loss: 0.0019 lr: 0.02\n",
      "iteration: 266390 loss: 0.0018 lr: 0.02\n",
      "iteration: 266400 loss: 0.0014 lr: 0.02\n",
      "iteration: 266410 loss: 0.0023 lr: 0.02\n",
      "iteration: 266420 loss: 0.0019 lr: 0.02\n",
      "iteration: 266430 loss: 0.0015 lr: 0.02\n",
      "iteration: 266440 loss: 0.0023 lr: 0.02\n",
      "iteration: 266450 loss: 0.0015 lr: 0.02\n",
      "iteration: 266460 loss: 0.0017 lr: 0.02\n",
      "iteration: 266470 loss: 0.0016 lr: 0.02\n",
      "iteration: 266480 loss: 0.0021 lr: 0.02\n",
      "iteration: 266490 loss: 0.0015 lr: 0.02\n",
      "iteration: 266500 loss: 0.0018 lr: 0.02\n",
      "iteration: 266510 loss: 0.0016 lr: 0.02\n",
      "iteration: 266520 loss: 0.0014 lr: 0.02\n",
      "iteration: 266530 loss: 0.0016 lr: 0.02\n",
      "iteration: 266540 loss: 0.0025 lr: 0.02\n",
      "iteration: 266550 loss: 0.0015 lr: 0.02\n",
      "iteration: 266560 loss: 0.0023 lr: 0.02\n",
      "iteration: 266570 loss: 0.0018 lr: 0.02\n",
      "iteration: 266580 loss: 0.0022 lr: 0.02\n",
      "iteration: 266590 loss: 0.0015 lr: 0.02\n",
      "iteration: 266600 loss: 0.0011 lr: 0.02\n",
      "iteration: 266610 loss: 0.0022 lr: 0.02\n",
      "iteration: 266620 loss: 0.0014 lr: 0.02\n",
      "iteration: 266630 loss: 0.0020 lr: 0.02\n",
      "iteration: 266640 loss: 0.0019 lr: 0.02\n",
      "iteration: 266650 loss: 0.0020 lr: 0.02\n",
      "iteration: 266660 loss: 0.0016 lr: 0.02\n",
      "iteration: 266670 loss: 0.0021 lr: 0.02\n",
      "iteration: 266680 loss: 0.0016 lr: 0.02\n",
      "iteration: 266690 loss: 0.0015 lr: 0.02\n",
      "iteration: 266700 loss: 0.0021 lr: 0.02\n",
      "iteration: 266710 loss: 0.0015 lr: 0.02\n",
      "iteration: 266720 loss: 0.0016 lr: 0.02\n",
      "iteration: 266730 loss: 0.0017 lr: 0.02\n",
      "iteration: 266740 loss: 0.0016 lr: 0.02\n",
      "iteration: 266750 loss: 0.0020 lr: 0.02\n",
      "iteration: 266760 loss: 0.0021 lr: 0.02\n",
      "iteration: 266770 loss: 0.0017 lr: 0.02\n",
      "iteration: 266780 loss: 0.0016 lr: 0.02\n",
      "iteration: 266790 loss: 0.0024 lr: 0.02\n",
      "iteration: 266800 loss: 0.0023 lr: 0.02\n",
      "iteration: 266810 loss: 0.0013 lr: 0.02\n",
      "iteration: 266820 loss: 0.0018 lr: 0.02\n",
      "iteration: 266830 loss: 0.0019 lr: 0.02\n",
      "iteration: 266840 loss: 0.0023 lr: 0.02\n",
      "iteration: 266850 loss: 0.0016 lr: 0.02\n",
      "iteration: 266860 loss: 0.0014 lr: 0.02\n",
      "iteration: 266870 loss: 0.0017 lr: 0.02\n",
      "iteration: 266880 loss: 0.0016 lr: 0.02\n",
      "iteration: 266890 loss: 0.0017 lr: 0.02\n",
      "iteration: 266900 loss: 0.0020 lr: 0.02\n",
      "iteration: 266910 loss: 0.0033 lr: 0.02\n",
      "iteration: 266920 loss: 0.0027 lr: 0.02\n",
      "iteration: 266930 loss: 0.0024 lr: 0.02\n",
      "iteration: 266940 loss: 0.0020 lr: 0.02\n",
      "iteration: 266950 loss: 0.0020 lr: 0.02\n",
      "iteration: 266960 loss: 0.0015 lr: 0.02\n",
      "iteration: 266970 loss: 0.0017 lr: 0.02\n",
      "iteration: 266980 loss: 0.0017 lr: 0.02\n",
      "iteration: 266990 loss: 0.0019 lr: 0.02\n",
      "iteration: 267000 loss: 0.0023 lr: 0.02\n",
      "iteration: 267010 loss: 0.0018 lr: 0.02\n",
      "iteration: 267020 loss: 0.0019 lr: 0.02\n",
      "iteration: 267030 loss: 0.0020 lr: 0.02\n",
      "iteration: 267040 loss: 0.0018 lr: 0.02\n",
      "iteration: 267050 loss: 0.0023 lr: 0.02\n",
      "iteration: 267060 loss: 0.0020 lr: 0.02\n",
      "iteration: 267070 loss: 0.0019 lr: 0.02\n",
      "iteration: 267080 loss: 0.0016 lr: 0.02\n",
      "iteration: 267090 loss: 0.0016 lr: 0.02\n",
      "iteration: 267100 loss: 0.0015 lr: 0.02\n",
      "iteration: 267110 loss: 0.0022 lr: 0.02\n",
      "iteration: 267120 loss: 0.0018 lr: 0.02\n",
      "iteration: 267130 loss: 0.0014 lr: 0.02\n",
      "iteration: 267140 loss: 0.0021 lr: 0.02\n",
      "iteration: 267150 loss: 0.0020 lr: 0.02\n",
      "iteration: 267160 loss: 0.0023 lr: 0.02\n",
      "iteration: 267170 loss: 0.0018 lr: 0.02\n",
      "iteration: 267180 loss: 0.0019 lr: 0.02\n",
      "iteration: 267190 loss: 0.0021 lr: 0.02\n",
      "iteration: 267200 loss: 0.0021 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 267210 loss: 0.0020 lr: 0.02\n",
      "iteration: 267220 loss: 0.0015 lr: 0.02\n",
      "iteration: 267230 loss: 0.0018 lr: 0.02\n",
      "iteration: 267240 loss: 0.0017 lr: 0.02\n",
      "iteration: 267250 loss: 0.0016 lr: 0.02\n",
      "iteration: 267260 loss: 0.0021 lr: 0.02\n",
      "iteration: 267270 loss: 0.0023 lr: 0.02\n",
      "iteration: 267280 loss: 0.0018 lr: 0.02\n",
      "iteration: 267290 loss: 0.0015 lr: 0.02\n",
      "iteration: 267300 loss: 0.0019 lr: 0.02\n",
      "iteration: 267310 loss: 0.0016 lr: 0.02\n",
      "iteration: 267320 loss: 0.0017 lr: 0.02\n",
      "iteration: 267330 loss: 0.0018 lr: 0.02\n",
      "iteration: 267340 loss: 0.0017 lr: 0.02\n",
      "iteration: 267350 loss: 0.0015 lr: 0.02\n",
      "iteration: 267360 loss: 0.0018 lr: 0.02\n",
      "iteration: 267370 loss: 0.0019 lr: 0.02\n",
      "iteration: 267380 loss: 0.0014 lr: 0.02\n",
      "iteration: 267390 loss: 0.0017 lr: 0.02\n",
      "iteration: 267400 loss: 0.0016 lr: 0.02\n",
      "iteration: 267410 loss: 0.0014 lr: 0.02\n",
      "iteration: 267420 loss: 0.0021 lr: 0.02\n",
      "iteration: 267430 loss: 0.0016 lr: 0.02\n",
      "iteration: 267440 loss: 0.0019 lr: 0.02\n",
      "iteration: 267450 loss: 0.0016 lr: 0.02\n",
      "iteration: 267460 loss: 0.0018 lr: 0.02\n",
      "iteration: 267470 loss: 0.0025 lr: 0.02\n",
      "iteration: 267480 loss: 0.0019 lr: 0.02\n",
      "iteration: 267490 loss: 0.0018 lr: 0.02\n",
      "iteration: 267500 loss: 0.0019 lr: 0.02\n",
      "iteration: 267510 loss: 0.0015 lr: 0.02\n",
      "iteration: 267520 loss: 0.0020 lr: 0.02\n",
      "iteration: 267530 loss: 0.0014 lr: 0.02\n",
      "iteration: 267540 loss: 0.0018 lr: 0.02\n",
      "iteration: 267550 loss: 0.0015 lr: 0.02\n",
      "iteration: 267560 loss: 0.0018 lr: 0.02\n",
      "iteration: 267570 loss: 0.0033 lr: 0.02\n",
      "iteration: 267580 loss: 0.0015 lr: 0.02\n",
      "iteration: 267590 loss: 0.0011 lr: 0.02\n",
      "iteration: 267600 loss: 0.0015 lr: 0.02\n",
      "iteration: 267610 loss: 0.0017 lr: 0.02\n",
      "iteration: 267620 loss: 0.0021 lr: 0.02\n",
      "iteration: 267630 loss: 0.0019 lr: 0.02\n",
      "iteration: 267640 loss: 0.0015 lr: 0.02\n",
      "iteration: 267650 loss: 0.0023 lr: 0.02\n",
      "iteration: 267660 loss: 0.0018 lr: 0.02\n",
      "iteration: 267670 loss: 0.0016 lr: 0.02\n",
      "iteration: 267680 loss: 0.0020 lr: 0.02\n",
      "iteration: 267690 loss: 0.0019 lr: 0.02\n",
      "iteration: 267700 loss: 0.0016 lr: 0.02\n",
      "iteration: 267710 loss: 0.0015 lr: 0.02\n",
      "iteration: 267720 loss: 0.0016 lr: 0.02\n",
      "iteration: 267730 loss: 0.0016 lr: 0.02\n",
      "iteration: 267740 loss: 0.0016 lr: 0.02\n",
      "iteration: 267750 loss: 0.0016 lr: 0.02\n",
      "iteration: 267760 loss: 0.0014 lr: 0.02\n",
      "iteration: 267770 loss: 0.0022 lr: 0.02\n",
      "iteration: 267780 loss: 0.0017 lr: 0.02\n",
      "iteration: 267790 loss: 0.0017 lr: 0.02\n",
      "iteration: 267800 loss: 0.0019 lr: 0.02\n",
      "iteration: 267810 loss: 0.0016 lr: 0.02\n",
      "iteration: 267820 loss: 0.0022 lr: 0.02\n",
      "iteration: 267830 loss: 0.0018 lr: 0.02\n",
      "iteration: 267840 loss: 0.0018 lr: 0.02\n",
      "iteration: 267850 loss: 0.0026 lr: 0.02\n",
      "iteration: 267860 loss: 0.0014 lr: 0.02\n",
      "iteration: 267870 loss: 0.0019 lr: 0.02\n",
      "iteration: 267880 loss: 0.0016 lr: 0.02\n",
      "iteration: 267890 loss: 0.0019 lr: 0.02\n",
      "iteration: 267900 loss: 0.0016 lr: 0.02\n",
      "iteration: 267910 loss: 0.0016 lr: 0.02\n",
      "iteration: 267920 loss: 0.0018 lr: 0.02\n",
      "iteration: 267930 loss: 0.0014 lr: 0.02\n",
      "iteration: 267940 loss: 0.0016 lr: 0.02\n",
      "iteration: 267950 loss: 0.0014 lr: 0.02\n",
      "iteration: 267960 loss: 0.0017 lr: 0.02\n",
      "iteration: 267970 loss: 0.0015 lr: 0.02\n",
      "iteration: 267980 loss: 0.0018 lr: 0.02\n",
      "iteration: 267990 loss: 0.0016 lr: 0.02\n",
      "iteration: 268000 loss: 0.0020 lr: 0.02\n",
      "iteration: 268010 loss: 0.0017 lr: 0.02\n",
      "iteration: 268020 loss: 0.0016 lr: 0.02\n",
      "iteration: 268030 loss: 0.0023 lr: 0.02\n",
      "iteration: 268040 loss: 0.0019 lr: 0.02\n",
      "iteration: 268050 loss: 0.0018 lr: 0.02\n",
      "iteration: 268060 loss: 0.0017 lr: 0.02\n",
      "iteration: 268070 loss: 0.0016 lr: 0.02\n",
      "iteration: 268080 loss: 0.0023 lr: 0.02\n",
      "iteration: 268090 loss: 0.0017 lr: 0.02\n",
      "iteration: 268100 loss: 0.0020 lr: 0.02\n",
      "iteration: 268110 loss: 0.0015 lr: 0.02\n",
      "iteration: 268120 loss: 0.0022 lr: 0.02\n",
      "iteration: 268130 loss: 0.0016 lr: 0.02\n",
      "iteration: 268140 loss: 0.0017 lr: 0.02\n",
      "iteration: 268150 loss: 0.0018 lr: 0.02\n",
      "iteration: 268160 loss: 0.0016 lr: 0.02\n",
      "iteration: 268170 loss: 0.0018 lr: 0.02\n",
      "iteration: 268180 loss: 0.0016 lr: 0.02\n",
      "iteration: 268190 loss: 0.0020 lr: 0.02\n",
      "iteration: 268200 loss: 0.0024 lr: 0.02\n",
      "iteration: 268210 loss: 0.0020 lr: 0.02\n",
      "iteration: 268220 loss: 0.0015 lr: 0.02\n",
      "iteration: 268230 loss: 0.0016 lr: 0.02\n",
      "iteration: 268240 loss: 0.0019 lr: 0.02\n",
      "iteration: 268250 loss: 0.0020 lr: 0.02\n",
      "iteration: 268260 loss: 0.0019 lr: 0.02\n",
      "iteration: 268270 loss: 0.0024 lr: 0.02\n",
      "iteration: 268280 loss: 0.0021 lr: 0.02\n",
      "iteration: 268290 loss: 0.0018 lr: 0.02\n",
      "iteration: 268300 loss: 0.0014 lr: 0.02\n",
      "iteration: 268310 loss: 0.0018 lr: 0.02\n",
      "iteration: 268320 loss: 0.0017 lr: 0.02\n",
      "iteration: 268330 loss: 0.0018 lr: 0.02\n",
      "iteration: 268340 loss: 0.0015 lr: 0.02\n",
      "iteration: 268350 loss: 0.0020 lr: 0.02\n",
      "iteration: 268360 loss: 0.0019 lr: 0.02\n",
      "iteration: 268370 loss: 0.0017 lr: 0.02\n",
      "iteration: 268380 loss: 0.0021 lr: 0.02\n",
      "iteration: 268390 loss: 0.0016 lr: 0.02\n",
      "iteration: 268400 loss: 0.0016 lr: 0.02\n",
      "iteration: 268410 loss: 0.0018 lr: 0.02\n",
      "iteration: 268420 loss: 0.0030 lr: 0.02\n",
      "iteration: 268430 loss: 0.0021 lr: 0.02\n",
      "iteration: 268440 loss: 0.0023 lr: 0.02\n",
      "iteration: 268450 loss: 0.0018 lr: 0.02\n",
      "iteration: 268460 loss: 0.0017 lr: 0.02\n",
      "iteration: 268470 loss: 0.0020 lr: 0.02\n",
      "iteration: 268480 loss: 0.0017 lr: 0.02\n",
      "iteration: 268490 loss: 0.0016 lr: 0.02\n",
      "iteration: 268500 loss: 0.0031 lr: 0.02\n",
      "iteration: 268510 loss: 0.0017 lr: 0.02\n",
      "iteration: 268520 loss: 0.0018 lr: 0.02\n",
      "iteration: 268530 loss: 0.0022 lr: 0.02\n",
      "iteration: 268540 loss: 0.0017 lr: 0.02\n",
      "iteration: 268550 loss: 0.0023 lr: 0.02\n",
      "iteration: 268560 loss: 0.0016 lr: 0.02\n",
      "iteration: 268570 loss: 0.0023 lr: 0.02\n",
      "iteration: 268580 loss: 0.0014 lr: 0.02\n",
      "iteration: 268590 loss: 0.0020 lr: 0.02\n",
      "iteration: 268600 loss: 0.0018 lr: 0.02\n",
      "iteration: 268610 loss: 0.0020 lr: 0.02\n",
      "iteration: 268620 loss: 0.0020 lr: 0.02\n",
      "iteration: 268630 loss: 0.0019 lr: 0.02\n",
      "iteration: 268640 loss: 0.0016 lr: 0.02\n",
      "iteration: 268650 loss: 0.0019 lr: 0.02\n",
      "iteration: 268660 loss: 0.0018 lr: 0.02\n",
      "iteration: 268670 loss: 0.0019 lr: 0.02\n",
      "iteration: 268680 loss: 0.0018 lr: 0.02\n",
      "iteration: 268690 loss: 0.0019 lr: 0.02\n",
      "iteration: 268700 loss: 0.0020 lr: 0.02\n",
      "iteration: 268710 loss: 0.0021 lr: 0.02\n",
      "iteration: 268720 loss: 0.0017 lr: 0.02\n",
      "iteration: 268730 loss: 0.0014 lr: 0.02\n",
      "iteration: 268740 loss: 0.0019 lr: 0.02\n",
      "iteration: 268750 loss: 0.0018 lr: 0.02\n",
      "iteration: 268760 loss: 0.0015 lr: 0.02\n",
      "iteration: 268770 loss: 0.0018 lr: 0.02\n",
      "iteration: 268780 loss: 0.0024 lr: 0.02\n",
      "iteration: 268790 loss: 0.0028 lr: 0.02\n",
      "iteration: 268800 loss: 0.0017 lr: 0.02\n",
      "iteration: 268810 loss: 0.0023 lr: 0.02\n",
      "iteration: 268820 loss: 0.0018 lr: 0.02\n",
      "iteration: 268830 loss: 0.0021 lr: 0.02\n",
      "iteration: 268840 loss: 0.0014 lr: 0.02\n",
      "iteration: 268850 loss: 0.0023 lr: 0.02\n",
      "iteration: 268860 loss: 0.0024 lr: 0.02\n",
      "iteration: 268870 loss: 0.0020 lr: 0.02\n",
      "iteration: 268880 loss: 0.0016 lr: 0.02\n",
      "iteration: 268890 loss: 0.0028 lr: 0.02\n",
      "iteration: 268900 loss: 0.0018 lr: 0.02\n",
      "iteration: 268910 loss: 0.0020 lr: 0.02\n",
      "iteration: 268920 loss: 0.0016 lr: 0.02\n",
      "iteration: 268930 loss: 0.0015 lr: 0.02\n",
      "iteration: 268940 loss: 0.0014 lr: 0.02\n",
      "iteration: 268950 loss: 0.0020 lr: 0.02\n",
      "iteration: 268960 loss: 0.0013 lr: 0.02\n",
      "iteration: 268970 loss: 0.0017 lr: 0.02\n",
      "iteration: 268980 loss: 0.0014 lr: 0.02\n",
      "iteration: 268990 loss: 0.0015 lr: 0.02\n",
      "iteration: 269000 loss: 0.0020 lr: 0.02\n",
      "iteration: 269010 loss: 0.0014 lr: 0.02\n",
      "iteration: 269020 loss: 0.0018 lr: 0.02\n",
      "iteration: 269030 loss: 0.0020 lr: 0.02\n",
      "iteration: 269040 loss: 0.0016 lr: 0.02\n",
      "iteration: 269050 loss: 0.0014 lr: 0.02\n",
      "iteration: 269060 loss: 0.0018 lr: 0.02\n",
      "iteration: 269070 loss: 0.0018 lr: 0.02\n",
      "iteration: 269080 loss: 0.0020 lr: 0.02\n",
      "iteration: 269090 loss: 0.0016 lr: 0.02\n",
      "iteration: 269100 loss: 0.0020 lr: 0.02\n",
      "iteration: 269110 loss: 0.0017 lr: 0.02\n",
      "iteration: 269120 loss: 0.0020 lr: 0.02\n",
      "iteration: 269130 loss: 0.0021 lr: 0.02\n",
      "iteration: 269140 loss: 0.0014 lr: 0.02\n",
      "iteration: 269150 loss: 0.0016 lr: 0.02\n",
      "iteration: 269160 loss: 0.0014 lr: 0.02\n",
      "iteration: 269170 loss: 0.0019 lr: 0.02\n",
      "iteration: 269180 loss: 0.0019 lr: 0.02\n",
      "iteration: 269190 loss: 0.0015 lr: 0.02\n",
      "iteration: 269200 loss: 0.0017 lr: 0.02\n",
      "iteration: 269210 loss: 0.0017 lr: 0.02\n",
      "iteration: 269220 loss: 0.0016 lr: 0.02\n",
      "iteration: 269230 loss: 0.0014 lr: 0.02\n",
      "iteration: 269240 loss: 0.0017 lr: 0.02\n",
      "iteration: 269250 loss: 0.0021 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 269260 loss: 0.0023 lr: 0.02\n",
      "iteration: 269270 loss: 0.0016 lr: 0.02\n",
      "iteration: 269280 loss: 0.0016 lr: 0.02\n",
      "iteration: 269290 loss: 0.0033 lr: 0.02\n",
      "iteration: 269300 loss: 0.0021 lr: 0.02\n",
      "iteration: 269310 loss: 0.0019 lr: 0.02\n",
      "iteration: 269320 loss: 0.0014 lr: 0.02\n",
      "iteration: 269330 loss: 0.0017 lr: 0.02\n",
      "iteration: 269340 loss: 0.0017 lr: 0.02\n",
      "iteration: 269350 loss: 0.0017 lr: 0.02\n",
      "iteration: 269360 loss: 0.0013 lr: 0.02\n",
      "iteration: 269370 loss: 0.0016 lr: 0.02\n",
      "iteration: 269380 loss: 0.0017 lr: 0.02\n",
      "iteration: 269390 loss: 0.0019 lr: 0.02\n",
      "iteration: 269400 loss: 0.0030 lr: 0.02\n",
      "iteration: 269410 loss: 0.0020 lr: 0.02\n",
      "iteration: 269420 loss: 0.0025 lr: 0.02\n",
      "iteration: 269430 loss: 0.0017 lr: 0.02\n",
      "iteration: 269440 loss: 0.0019 lr: 0.02\n",
      "iteration: 269450 loss: 0.0020 lr: 0.02\n",
      "iteration: 269460 loss: 0.0016 lr: 0.02\n",
      "iteration: 269470 loss: 0.0015 lr: 0.02\n",
      "iteration: 269480 loss: 0.0015 lr: 0.02\n",
      "iteration: 269490 loss: 0.0017 lr: 0.02\n",
      "iteration: 269500 loss: 0.0016 lr: 0.02\n",
      "iteration: 269510 loss: 0.0019 lr: 0.02\n",
      "iteration: 269520 loss: 0.0016 lr: 0.02\n",
      "iteration: 269530 loss: 0.0016 lr: 0.02\n",
      "iteration: 269540 loss: 0.0015 lr: 0.02\n",
      "iteration: 269550 loss: 0.0016 lr: 0.02\n",
      "iteration: 269560 loss: 0.0020 lr: 0.02\n",
      "iteration: 269570 loss: 0.0021 lr: 0.02\n",
      "iteration: 269580 loss: 0.0019 lr: 0.02\n",
      "iteration: 269590 loss: 0.0021 lr: 0.02\n",
      "iteration: 269600 loss: 0.0018 lr: 0.02\n",
      "iteration: 269610 loss: 0.0019 lr: 0.02\n",
      "iteration: 269620 loss: 0.0017 lr: 0.02\n",
      "iteration: 269630 loss: 0.0013 lr: 0.02\n",
      "iteration: 269640 loss: 0.0018 lr: 0.02\n",
      "iteration: 269650 loss: 0.0015 lr: 0.02\n",
      "iteration: 269660 loss: 0.0024 lr: 0.02\n",
      "iteration: 269670 loss: 0.0021 lr: 0.02\n",
      "iteration: 269680 loss: 0.0018 lr: 0.02\n",
      "iteration: 269690 loss: 0.0021 lr: 0.02\n",
      "iteration: 269700 loss: 0.0016 lr: 0.02\n",
      "iteration: 269710 loss: 0.0014 lr: 0.02\n",
      "iteration: 269720 loss: 0.0028 lr: 0.02\n",
      "iteration: 269730 loss: 0.0017 lr: 0.02\n",
      "iteration: 269740 loss: 0.0027 lr: 0.02\n",
      "iteration: 269750 loss: 0.0023 lr: 0.02\n",
      "iteration: 269760 loss: 0.0022 lr: 0.02\n",
      "iteration: 269770 loss: 0.0015 lr: 0.02\n",
      "iteration: 269780 loss: 0.0014 lr: 0.02\n",
      "iteration: 269790 loss: 0.0021 lr: 0.02\n",
      "iteration: 269800 loss: 0.0017 lr: 0.02\n",
      "iteration: 269810 loss: 0.0020 lr: 0.02\n",
      "iteration: 269820 loss: 0.0015 lr: 0.02\n",
      "iteration: 269830 loss: 0.0015 lr: 0.02\n",
      "iteration: 269840 loss: 0.0017 lr: 0.02\n",
      "iteration: 269850 loss: 0.0016 lr: 0.02\n",
      "iteration: 269860 loss: 0.0018 lr: 0.02\n",
      "iteration: 269870 loss: 0.0016 lr: 0.02\n",
      "iteration: 269880 loss: 0.0015 lr: 0.02\n",
      "iteration: 269890 loss: 0.0018 lr: 0.02\n",
      "iteration: 269900 loss: 0.0022 lr: 0.02\n",
      "iteration: 269910 loss: 0.0019 lr: 0.02\n",
      "iteration: 269920 loss: 0.0019 lr: 0.02\n",
      "iteration: 269930 loss: 0.0018 lr: 0.02\n",
      "iteration: 269940 loss: 0.0015 lr: 0.02\n",
      "iteration: 269950 loss: 0.0019 lr: 0.02\n",
      "iteration: 269960 loss: 0.0014 lr: 0.02\n",
      "iteration: 269970 loss: 0.0016 lr: 0.02\n",
      "iteration: 269980 loss: 0.0017 lr: 0.02\n",
      "iteration: 269990 loss: 0.0019 lr: 0.02\n",
      "iteration: 270000 loss: 0.0019 lr: 0.02\n",
      "iteration: 270010 loss: 0.0023 lr: 0.02\n",
      "iteration: 270020 loss: 0.0023 lr: 0.02\n",
      "iteration: 270030 loss: 0.0020 lr: 0.02\n",
      "iteration: 270040 loss: 0.0021 lr: 0.02\n",
      "iteration: 270050 loss: 0.0022 lr: 0.02\n",
      "iteration: 270060 loss: 0.0014 lr: 0.02\n",
      "iteration: 270070 loss: 0.0018 lr: 0.02\n",
      "iteration: 270080 loss: 0.0019 lr: 0.02\n",
      "iteration: 270090 loss: 0.0018 lr: 0.02\n",
      "iteration: 270100 loss: 0.0018 lr: 0.02\n",
      "iteration: 270110 loss: 0.0014 lr: 0.02\n",
      "iteration: 270120 loss: 0.0017 lr: 0.02\n",
      "iteration: 270130 loss: 0.0019 lr: 0.02\n",
      "iteration: 270140 loss: 0.0016 lr: 0.02\n",
      "iteration: 270150 loss: 0.0018 lr: 0.02\n",
      "iteration: 270160 loss: 0.0019 lr: 0.02\n",
      "iteration: 270170 loss: 0.0018 lr: 0.02\n",
      "iteration: 270180 loss: 0.0015 lr: 0.02\n",
      "iteration: 270190 loss: 0.0015 lr: 0.02\n",
      "iteration: 270200 loss: 0.0019 lr: 0.02\n",
      "iteration: 270210 loss: 0.0017 lr: 0.02\n",
      "iteration: 270220 loss: 0.0013 lr: 0.02\n",
      "iteration: 270230 loss: 0.0016 lr: 0.02\n",
      "iteration: 270240 loss: 0.0014 lr: 0.02\n",
      "iteration: 270250 loss: 0.0018 lr: 0.02\n",
      "iteration: 270260 loss: 0.0016 lr: 0.02\n",
      "iteration: 270270 loss: 0.0021 lr: 0.02\n",
      "iteration: 270280 loss: 0.0015 lr: 0.02\n",
      "iteration: 270290 loss: 0.0011 lr: 0.02\n",
      "iteration: 270300 loss: 0.0017 lr: 0.02\n",
      "iteration: 270310 loss: 0.0017 lr: 0.02\n",
      "iteration: 270320 loss: 0.0020 lr: 0.02\n",
      "iteration: 270330 loss: 0.0019 lr: 0.02\n",
      "iteration: 270340 loss: 0.0017 lr: 0.02\n",
      "iteration: 270350 loss: 0.0017 lr: 0.02\n",
      "iteration: 270360 loss: 0.0018 lr: 0.02\n",
      "iteration: 270370 loss: 0.0018 lr: 0.02\n",
      "iteration: 270380 loss: 0.0022 lr: 0.02\n",
      "iteration: 270390 loss: 0.0024 lr: 0.02\n",
      "iteration: 270400 loss: 0.0015 lr: 0.02\n",
      "iteration: 270410 loss: 0.0020 lr: 0.02\n",
      "iteration: 270420 loss: 0.0024 lr: 0.02\n",
      "iteration: 270430 loss: 0.0027 lr: 0.02\n",
      "iteration: 270440 loss: 0.0023 lr: 0.02\n",
      "iteration: 270450 loss: 0.0018 lr: 0.02\n",
      "iteration: 270460 loss: 0.0018 lr: 0.02\n",
      "iteration: 270470 loss: 0.0026 lr: 0.02\n",
      "iteration: 270480 loss: 0.0017 lr: 0.02\n",
      "iteration: 270490 loss: 0.0015 lr: 0.02\n",
      "iteration: 270500 loss: 0.0016 lr: 0.02\n",
      "iteration: 270510 loss: 0.0017 lr: 0.02\n",
      "iteration: 270520 loss: 0.0018 lr: 0.02\n",
      "iteration: 270530 loss: 0.0021 lr: 0.02\n",
      "iteration: 270540 loss: 0.0019 lr: 0.02\n",
      "iteration: 270550 loss: 0.0019 lr: 0.02\n",
      "iteration: 270560 loss: 0.0015 lr: 0.02\n",
      "iteration: 270570 loss: 0.0016 lr: 0.02\n",
      "iteration: 270580 loss: 0.0015 lr: 0.02\n",
      "iteration: 270590 loss: 0.0016 lr: 0.02\n",
      "iteration: 270600 loss: 0.0016 lr: 0.02\n",
      "iteration: 270610 loss: 0.0015 lr: 0.02\n",
      "iteration: 270620 loss: 0.0015 lr: 0.02\n",
      "iteration: 270630 loss: 0.0018 lr: 0.02\n",
      "iteration: 270640 loss: 0.0017 lr: 0.02\n",
      "iteration: 270650 loss: 0.0018 lr: 0.02\n",
      "iteration: 270660 loss: 0.0021 lr: 0.02\n",
      "iteration: 270670 loss: 0.0015 lr: 0.02\n",
      "iteration: 270680 loss: 0.0013 lr: 0.02\n",
      "iteration: 270690 loss: 0.0020 lr: 0.02\n",
      "iteration: 270700 loss: 0.0020 lr: 0.02\n",
      "iteration: 270710 loss: 0.0032 lr: 0.02\n",
      "iteration: 270720 loss: 0.0020 lr: 0.02\n",
      "iteration: 270730 loss: 0.0017 lr: 0.02\n",
      "iteration: 270740 loss: 0.0020 lr: 0.02\n",
      "iteration: 270750 loss: 0.0016 lr: 0.02\n",
      "iteration: 270760 loss: 0.0014 lr: 0.02\n",
      "iteration: 270770 loss: 0.0017 lr: 0.02\n",
      "iteration: 270780 loss: 0.0019 lr: 0.02\n",
      "iteration: 270790 loss: 0.0018 lr: 0.02\n",
      "iteration: 270800 loss: 0.0015 lr: 0.02\n",
      "iteration: 270810 loss: 0.0022 lr: 0.02\n",
      "iteration: 270820 loss: 0.0021 lr: 0.02\n",
      "iteration: 270830 loss: 0.0018 lr: 0.02\n",
      "iteration: 270840 loss: 0.0018 lr: 0.02\n",
      "iteration: 270850 loss: 0.0014 lr: 0.02\n",
      "iteration: 270860 loss: 0.0018 lr: 0.02\n",
      "iteration: 270870 loss: 0.0016 lr: 0.02\n",
      "iteration: 270880 loss: 0.0018 lr: 0.02\n",
      "iteration: 270890 loss: 0.0012 lr: 0.02\n",
      "iteration: 270900 loss: 0.0017 lr: 0.02\n",
      "iteration: 270910 loss: 0.0016 lr: 0.02\n",
      "iteration: 270920 loss: 0.0016 lr: 0.02\n",
      "iteration: 270930 loss: 0.0024 lr: 0.02\n",
      "iteration: 270940 loss: 0.0015 lr: 0.02\n",
      "iteration: 270950 loss: 0.0017 lr: 0.02\n",
      "iteration: 270960 loss: 0.0016 lr: 0.02\n",
      "iteration: 270970 loss: 0.0014 lr: 0.02\n",
      "iteration: 270980 loss: 0.0025 lr: 0.02\n",
      "iteration: 270990 loss: 0.0014 lr: 0.02\n",
      "iteration: 271000 loss: 0.0020 lr: 0.02\n",
      "iteration: 271010 loss: 0.0015 lr: 0.02\n",
      "iteration: 271020 loss: 0.0017 lr: 0.02\n",
      "iteration: 271030 loss: 0.0015 lr: 0.02\n",
      "iteration: 271040 loss: 0.0020 lr: 0.02\n",
      "iteration: 271050 loss: 0.0023 lr: 0.02\n",
      "iteration: 271060 loss: 0.0019 lr: 0.02\n",
      "iteration: 271070 loss: 0.0016 lr: 0.02\n",
      "iteration: 271080 loss: 0.0022 lr: 0.02\n",
      "iteration: 271090 loss: 0.0021 lr: 0.02\n",
      "iteration: 271100 loss: 0.0019 lr: 0.02\n",
      "iteration: 271110 loss: 0.0019 lr: 0.02\n",
      "iteration: 271120 loss: 0.0018 lr: 0.02\n",
      "iteration: 271130 loss: 0.0017 lr: 0.02\n",
      "iteration: 271140 loss: 0.0019 lr: 0.02\n",
      "iteration: 271150 loss: 0.0021 lr: 0.02\n",
      "iteration: 271160 loss: 0.0022 lr: 0.02\n",
      "iteration: 271170 loss: 0.0021 lr: 0.02\n",
      "iteration: 271180 loss: 0.0026 lr: 0.02\n",
      "iteration: 271190 loss: 0.0017 lr: 0.02\n",
      "iteration: 271200 loss: 0.0021 lr: 0.02\n",
      "iteration: 271210 loss: 0.0024 lr: 0.02\n",
      "iteration: 271220 loss: 0.0018 lr: 0.02\n",
      "iteration: 271230 loss: 0.0016 lr: 0.02\n",
      "iteration: 271240 loss: 0.0016 lr: 0.02\n",
      "iteration: 271250 loss: 0.0018 lr: 0.02\n",
      "iteration: 271260 loss: 0.0016 lr: 0.02\n",
      "iteration: 271270 loss: 0.0018 lr: 0.02\n",
      "iteration: 271280 loss: 0.0017 lr: 0.02\n",
      "iteration: 271290 loss: 0.0016 lr: 0.02\n",
      "iteration: 271300 loss: 0.0021 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 271310 loss: 0.0017 lr: 0.02\n",
      "iteration: 271320 loss: 0.0016 lr: 0.02\n",
      "iteration: 271330 loss: 0.0017 lr: 0.02\n",
      "iteration: 271340 loss: 0.0016 lr: 0.02\n",
      "iteration: 271350 loss: 0.0020 lr: 0.02\n",
      "iteration: 271360 loss: 0.0018 lr: 0.02\n",
      "iteration: 271370 loss: 0.0018 lr: 0.02\n",
      "iteration: 271380 loss: 0.0017 lr: 0.02\n",
      "iteration: 271390 loss: 0.0020 lr: 0.02\n",
      "iteration: 271400 loss: 0.0019 lr: 0.02\n",
      "iteration: 271410 loss: 0.0018 lr: 0.02\n",
      "iteration: 271420 loss: 0.0021 lr: 0.02\n",
      "iteration: 271430 loss: 0.0019 lr: 0.02\n",
      "iteration: 271440 loss: 0.0019 lr: 0.02\n",
      "iteration: 271450 loss: 0.0018 lr: 0.02\n",
      "iteration: 271460 loss: 0.0018 lr: 0.02\n",
      "iteration: 271470 loss: 0.0019 lr: 0.02\n",
      "iteration: 271480 loss: 0.0016 lr: 0.02\n",
      "iteration: 271490 loss: 0.0017 lr: 0.02\n",
      "iteration: 271500 loss: 0.0022 lr: 0.02\n",
      "iteration: 271510 loss: 0.0020 lr: 0.02\n",
      "iteration: 271520 loss: 0.0020 lr: 0.02\n",
      "iteration: 271530 loss: 0.0016 lr: 0.02\n",
      "iteration: 271540 loss: 0.0021 lr: 0.02\n",
      "iteration: 271550 loss: 0.0018 lr: 0.02\n",
      "iteration: 271560 loss: 0.0017 lr: 0.02\n",
      "iteration: 271570 loss: 0.0016 lr: 0.02\n",
      "iteration: 271580 loss: 0.0016 lr: 0.02\n",
      "iteration: 271590 loss: 0.0022 lr: 0.02\n",
      "iteration: 271600 loss: 0.0019 lr: 0.02\n",
      "iteration: 271610 loss: 0.0019 lr: 0.02\n",
      "iteration: 271620 loss: 0.0028 lr: 0.02\n",
      "iteration: 271630 loss: 0.0014 lr: 0.02\n",
      "iteration: 271640 loss: 0.0021 lr: 0.02\n",
      "iteration: 271650 loss: 0.0020 lr: 0.02\n",
      "iteration: 271660 loss: 0.0026 lr: 0.02\n",
      "iteration: 271670 loss: 0.0015 lr: 0.02\n",
      "iteration: 271680 loss: 0.0017 lr: 0.02\n",
      "iteration: 271690 loss: 0.0016 lr: 0.02\n",
      "iteration: 271700 loss: 0.0026 lr: 0.02\n",
      "iteration: 271710 loss: 0.0019 lr: 0.02\n",
      "iteration: 271720 loss: 0.0018 lr: 0.02\n",
      "iteration: 271730 loss: 0.0018 lr: 0.02\n",
      "iteration: 271740 loss: 0.0022 lr: 0.02\n",
      "iteration: 271750 loss: 0.0018 lr: 0.02\n",
      "iteration: 271760 loss: 0.0016 lr: 0.02\n",
      "iteration: 271770 loss: 0.0020 lr: 0.02\n",
      "iteration: 271780 loss: 0.0018 lr: 0.02\n",
      "iteration: 271790 loss: 0.0015 lr: 0.02\n",
      "iteration: 271800 loss: 0.0017 lr: 0.02\n",
      "iteration: 271810 loss: 0.0018 lr: 0.02\n",
      "iteration: 271820 loss: 0.0021 lr: 0.02\n",
      "iteration: 271830 loss: 0.0019 lr: 0.02\n",
      "iteration: 271840 loss: 0.0013 lr: 0.02\n",
      "iteration: 271850 loss: 0.0018 lr: 0.02\n",
      "iteration: 271860 loss: 0.0018 lr: 0.02\n",
      "iteration: 271870 loss: 0.0022 lr: 0.02\n",
      "iteration: 271880 loss: 0.0014 lr: 0.02\n",
      "iteration: 271890 loss: 0.0016 lr: 0.02\n",
      "iteration: 271900 loss: 0.0013 lr: 0.02\n",
      "iteration: 271910 loss: 0.0018 lr: 0.02\n",
      "iteration: 271920 loss: 0.0012 lr: 0.02\n",
      "iteration: 271930 loss: 0.0022 lr: 0.02\n",
      "iteration: 271940 loss: 0.0014 lr: 0.02\n",
      "iteration: 271950 loss: 0.0013 lr: 0.02\n",
      "iteration: 271960 loss: 0.0013 lr: 0.02\n",
      "iteration: 271970 loss: 0.0015 lr: 0.02\n",
      "iteration: 271980 loss: 0.0020 lr: 0.02\n",
      "iteration: 271990 loss: 0.0016 lr: 0.02\n",
      "iteration: 272000 loss: 0.0027 lr: 0.02\n",
      "iteration: 272010 loss: 0.0015 lr: 0.02\n",
      "iteration: 272020 loss: 0.0017 lr: 0.02\n",
      "iteration: 272030 loss: 0.0020 lr: 0.02\n",
      "iteration: 272040 loss: 0.0014 lr: 0.02\n",
      "iteration: 272050 loss: 0.0019 lr: 0.02\n",
      "iteration: 272060 loss: 0.0014 lr: 0.02\n",
      "iteration: 272070 loss: 0.0018 lr: 0.02\n",
      "iteration: 272080 loss: 0.0021 lr: 0.02\n",
      "iteration: 272090 loss: 0.0017 lr: 0.02\n",
      "iteration: 272100 loss: 0.0021 lr: 0.02\n",
      "iteration: 272110 loss: 0.0016 lr: 0.02\n",
      "iteration: 272120 loss: 0.0017 lr: 0.02\n",
      "iteration: 272130 loss: 0.0016 lr: 0.02\n",
      "iteration: 272140 loss: 0.0015 lr: 0.02\n",
      "iteration: 272150 loss: 0.0023 lr: 0.02\n",
      "iteration: 272160 loss: 0.0015 lr: 0.02\n",
      "iteration: 272170 loss: 0.0016 lr: 0.02\n",
      "iteration: 272180 loss: 0.0022 lr: 0.02\n",
      "iteration: 272190 loss: 0.0025 lr: 0.02\n",
      "iteration: 272200 loss: 0.0015 lr: 0.02\n",
      "iteration: 272210 loss: 0.0019 lr: 0.02\n",
      "iteration: 272220 loss: 0.0015 lr: 0.02\n",
      "iteration: 272230 loss: 0.0014 lr: 0.02\n",
      "iteration: 272240 loss: 0.0013 lr: 0.02\n",
      "iteration: 272250 loss: 0.0015 lr: 0.02\n",
      "iteration: 272260 loss: 0.0019 lr: 0.02\n",
      "iteration: 272270 loss: 0.0017 lr: 0.02\n",
      "iteration: 272280 loss: 0.0021 lr: 0.02\n",
      "iteration: 272290 loss: 0.0017 lr: 0.02\n",
      "iteration: 272300 loss: 0.0018 lr: 0.02\n",
      "iteration: 272310 loss: 0.0020 lr: 0.02\n",
      "iteration: 272320 loss: 0.0016 lr: 0.02\n",
      "iteration: 272330 loss: 0.0022 lr: 0.02\n",
      "iteration: 272340 loss: 0.0018 lr: 0.02\n",
      "iteration: 272350 loss: 0.0013 lr: 0.02\n",
      "iteration: 272360 loss: 0.0021 lr: 0.02\n",
      "iteration: 272370 loss: 0.0016 lr: 0.02\n",
      "iteration: 272380 loss: 0.0021 lr: 0.02\n",
      "iteration: 272390 loss: 0.0019 lr: 0.02\n",
      "iteration: 272400 loss: 0.0017 lr: 0.02\n",
      "iteration: 272410 loss: 0.0019 lr: 0.02\n",
      "iteration: 272420 loss: 0.0018 lr: 0.02\n",
      "iteration: 272430 loss: 0.0021 lr: 0.02\n",
      "iteration: 272440 loss: 0.0017 lr: 0.02\n",
      "iteration: 272450 loss: 0.0018 lr: 0.02\n",
      "iteration: 272460 loss: 0.0020 lr: 0.02\n",
      "iteration: 272470 loss: 0.0023 lr: 0.02\n",
      "iteration: 272480 loss: 0.0017 lr: 0.02\n",
      "iteration: 272490 loss: 0.0017 lr: 0.02\n",
      "iteration: 272500 loss: 0.0018 lr: 0.02\n",
      "iteration: 272510 loss: 0.0020 lr: 0.02\n",
      "iteration: 272520 loss: 0.0016 lr: 0.02\n",
      "iteration: 272530 loss: 0.0019 lr: 0.02\n",
      "iteration: 272540 loss: 0.0016 lr: 0.02\n",
      "iteration: 272550 loss: 0.0017 lr: 0.02\n",
      "iteration: 272560 loss: 0.0012 lr: 0.02\n",
      "iteration: 272570 loss: 0.0016 lr: 0.02\n",
      "iteration: 272580 loss: 0.0024 lr: 0.02\n",
      "iteration: 272590 loss: 0.0023 lr: 0.02\n",
      "iteration: 272600 loss: 0.0025 lr: 0.02\n",
      "iteration: 272610 loss: 0.0021 lr: 0.02\n",
      "iteration: 272620 loss: 0.0014 lr: 0.02\n",
      "iteration: 272630 loss: 0.0018 lr: 0.02\n",
      "iteration: 272640 loss: 0.0018 lr: 0.02\n",
      "iteration: 272650 loss: 0.0019 lr: 0.02\n",
      "iteration: 272660 loss: 0.0016 lr: 0.02\n",
      "iteration: 272670 loss: 0.0017 lr: 0.02\n",
      "iteration: 272680 loss: 0.0021 lr: 0.02\n",
      "iteration: 272690 loss: 0.0016 lr: 0.02\n",
      "iteration: 272700 loss: 0.0020 lr: 0.02\n",
      "iteration: 272710 loss: 0.0018 lr: 0.02\n",
      "iteration: 272720 loss: 0.0016 lr: 0.02\n",
      "iteration: 272730 loss: 0.0018 lr: 0.02\n",
      "iteration: 272740 loss: 0.0014 lr: 0.02\n",
      "iteration: 272750 loss: 0.0019 lr: 0.02\n",
      "iteration: 272760 loss: 0.0019 lr: 0.02\n",
      "iteration: 272770 loss: 0.0015 lr: 0.02\n",
      "iteration: 272780 loss: 0.0015 lr: 0.02\n",
      "iteration: 272790 loss: 0.0019 lr: 0.02\n",
      "iteration: 272800 loss: 0.0020 lr: 0.02\n",
      "iteration: 272810 loss: 0.0016 lr: 0.02\n",
      "iteration: 272820 loss: 0.0014 lr: 0.02\n",
      "iteration: 272830 loss: 0.0015 lr: 0.02\n",
      "iteration: 272840 loss: 0.0017 lr: 0.02\n",
      "iteration: 272850 loss: 0.0015 lr: 0.02\n",
      "iteration: 272860 loss: 0.0018 lr: 0.02\n",
      "iteration: 272870 loss: 0.0017 lr: 0.02\n",
      "iteration: 272880 loss: 0.0018 lr: 0.02\n",
      "iteration: 272890 loss: 0.0021 lr: 0.02\n",
      "iteration: 272900 loss: 0.0017 lr: 0.02\n",
      "iteration: 272910 loss: 0.0021 lr: 0.02\n",
      "iteration: 272920 loss: 0.0020 lr: 0.02\n",
      "iteration: 272930 loss: 0.0017 lr: 0.02\n",
      "iteration: 272940 loss: 0.0020 lr: 0.02\n",
      "iteration: 272950 loss: 0.0017 lr: 0.02\n",
      "iteration: 272960 loss: 0.0014 lr: 0.02\n",
      "iteration: 272970 loss: 0.0019 lr: 0.02\n",
      "iteration: 272980 loss: 0.0016 lr: 0.02\n",
      "iteration: 272990 loss: 0.0015 lr: 0.02\n",
      "iteration: 273000 loss: 0.0012 lr: 0.02\n",
      "iteration: 273010 loss: 0.0015 lr: 0.02\n",
      "iteration: 273020 loss: 0.0017 lr: 0.02\n",
      "iteration: 273030 loss: 0.0031 lr: 0.02\n",
      "iteration: 273040 loss: 0.0016 lr: 0.02\n",
      "iteration: 273050 loss: 0.0012 lr: 0.02\n",
      "iteration: 273060 loss: 0.0018 lr: 0.02\n",
      "iteration: 273070 loss: 0.0016 lr: 0.02\n",
      "iteration: 273080 loss: 0.0026 lr: 0.02\n",
      "iteration: 273090 loss: 0.0018 lr: 0.02\n",
      "iteration: 273100 loss: 0.0016 lr: 0.02\n",
      "iteration: 273110 loss: 0.0016 lr: 0.02\n",
      "iteration: 273120 loss: 0.0023 lr: 0.02\n",
      "iteration: 273130 loss: 0.0020 lr: 0.02\n",
      "iteration: 273140 loss: 0.0015 lr: 0.02\n",
      "iteration: 273150 loss: 0.0026 lr: 0.02\n",
      "iteration: 273160 loss: 0.0016 lr: 0.02\n",
      "iteration: 273170 loss: 0.0022 lr: 0.02\n",
      "iteration: 273180 loss: 0.0023 lr: 0.02\n",
      "iteration: 273190 loss: 0.0019 lr: 0.02\n",
      "iteration: 273200 loss: 0.0014 lr: 0.02\n",
      "iteration: 273210 loss: 0.0015 lr: 0.02\n",
      "iteration: 273220 loss: 0.0015 lr: 0.02\n",
      "iteration: 273230 loss: 0.0017 lr: 0.02\n",
      "iteration: 273240 loss: 0.0019 lr: 0.02\n",
      "iteration: 273250 loss: 0.0017 lr: 0.02\n",
      "iteration: 273260 loss: 0.0016 lr: 0.02\n",
      "iteration: 273270 loss: 0.0017 lr: 0.02\n",
      "iteration: 273280 loss: 0.0023 lr: 0.02\n",
      "iteration: 273290 loss: 0.0019 lr: 0.02\n",
      "iteration: 273300 loss: 0.0016 lr: 0.02\n",
      "iteration: 273310 loss: 0.0016 lr: 0.02\n",
      "iteration: 273320 loss: 0.0017 lr: 0.02\n",
      "iteration: 273330 loss: 0.0029 lr: 0.02\n",
      "iteration: 273340 loss: 0.0017 lr: 0.02\n",
      "iteration: 273350 loss: 0.0017 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 273360 loss: 0.0016 lr: 0.02\n",
      "iteration: 273370 loss: 0.0013 lr: 0.02\n",
      "iteration: 273380 loss: 0.0022 lr: 0.02\n",
      "iteration: 273390 loss: 0.0016 lr: 0.02\n",
      "iteration: 273400 loss: 0.0015 lr: 0.02\n",
      "iteration: 273410 loss: 0.0021 lr: 0.02\n",
      "iteration: 273420 loss: 0.0016 lr: 0.02\n",
      "iteration: 273430 loss: 0.0019 lr: 0.02\n",
      "iteration: 273440 loss: 0.0019 lr: 0.02\n",
      "iteration: 273450 loss: 0.0016 lr: 0.02\n",
      "iteration: 273460 loss: 0.0012 lr: 0.02\n",
      "iteration: 273470 loss: 0.0021 lr: 0.02\n",
      "iteration: 273480 loss: 0.0022 lr: 0.02\n",
      "iteration: 273490 loss: 0.0020 lr: 0.02\n",
      "iteration: 273500 loss: 0.0015 lr: 0.02\n",
      "iteration: 273510 loss: 0.0023 lr: 0.02\n",
      "iteration: 273520 loss: 0.0018 lr: 0.02\n",
      "iteration: 273530 loss: 0.0013 lr: 0.02\n",
      "iteration: 273540 loss: 0.0017 lr: 0.02\n",
      "iteration: 273550 loss: 0.0019 lr: 0.02\n",
      "iteration: 273560 loss: 0.0015 lr: 0.02\n",
      "iteration: 273570 loss: 0.0020 lr: 0.02\n",
      "iteration: 273580 loss: 0.0023 lr: 0.02\n",
      "iteration: 273590 loss: 0.0016 lr: 0.02\n",
      "iteration: 273600 loss: 0.0016 lr: 0.02\n",
      "iteration: 273610 loss: 0.0016 lr: 0.02\n",
      "iteration: 273620 loss: 0.0021 lr: 0.02\n",
      "iteration: 273630 loss: 0.0018 lr: 0.02\n",
      "iteration: 273640 loss: 0.0025 lr: 0.02\n",
      "iteration: 273650 loss: 0.0016 lr: 0.02\n",
      "iteration: 273660 loss: 0.0013 lr: 0.02\n",
      "iteration: 273670 loss: 0.0018 lr: 0.02\n",
      "iteration: 273680 loss: 0.0016 lr: 0.02\n",
      "iteration: 273690 loss: 0.0019 lr: 0.02\n",
      "iteration: 273700 loss: 0.0016 lr: 0.02\n",
      "iteration: 273710 loss: 0.0019 lr: 0.02\n",
      "iteration: 273720 loss: 0.0016 lr: 0.02\n",
      "iteration: 273730 loss: 0.0019 lr: 0.02\n",
      "iteration: 273740 loss: 0.0014 lr: 0.02\n",
      "iteration: 273750 loss: 0.0020 lr: 0.02\n",
      "iteration: 273760 loss: 0.0014 lr: 0.02\n",
      "iteration: 273770 loss: 0.0022 lr: 0.02\n",
      "iteration: 273780 loss: 0.0016 lr: 0.02\n",
      "iteration: 273790 loss: 0.0019 lr: 0.02\n",
      "iteration: 273800 loss: 0.0023 lr: 0.02\n",
      "iteration: 273810 loss: 0.0015 lr: 0.02\n",
      "iteration: 273820 loss: 0.0017 lr: 0.02\n",
      "iteration: 273830 loss: 0.0024 lr: 0.02\n",
      "iteration: 273840 loss: 0.0021 lr: 0.02\n",
      "iteration: 273850 loss: 0.0015 lr: 0.02\n",
      "iteration: 273860 loss: 0.0012 lr: 0.02\n",
      "iteration: 273870 loss: 0.0019 lr: 0.02\n",
      "iteration: 273880 loss: 0.0012 lr: 0.02\n",
      "iteration: 273890 loss: 0.0019 lr: 0.02\n",
      "iteration: 273900 loss: 0.0013 lr: 0.02\n",
      "iteration: 273910 loss: 0.0018 lr: 0.02\n",
      "iteration: 273920 loss: 0.0018 lr: 0.02\n",
      "iteration: 273930 loss: 0.0014 lr: 0.02\n",
      "iteration: 273940 loss: 0.0018 lr: 0.02\n",
      "iteration: 273950 loss: 0.0016 lr: 0.02\n",
      "iteration: 273960 loss: 0.0014 lr: 0.02\n",
      "iteration: 273970 loss: 0.0017 lr: 0.02\n",
      "iteration: 273980 loss: 0.0018 lr: 0.02\n",
      "iteration: 273990 loss: 0.0021 lr: 0.02\n",
      "iteration: 274000 loss: 0.0020 lr: 0.02\n",
      "iteration: 274010 loss: 0.0014 lr: 0.02\n",
      "iteration: 274020 loss: 0.0018 lr: 0.02\n",
      "iteration: 274030 loss: 0.0019 lr: 0.02\n",
      "iteration: 274040 loss: 0.0016 lr: 0.02\n",
      "iteration: 274050 loss: 0.0020 lr: 0.02\n",
      "iteration: 274060 loss: 0.0019 lr: 0.02\n",
      "iteration: 274070 loss: 0.0017 lr: 0.02\n",
      "iteration: 274080 loss: 0.0016 lr: 0.02\n",
      "iteration: 274090 loss: 0.0019 lr: 0.02\n",
      "iteration: 274100 loss: 0.0016 lr: 0.02\n",
      "iteration: 274110 loss: 0.0019 lr: 0.02\n",
      "iteration: 274120 loss: 0.0015 lr: 0.02\n",
      "iteration: 274130 loss: 0.0018 lr: 0.02\n",
      "iteration: 274140 loss: 0.0019 lr: 0.02\n",
      "iteration: 274150 loss: 0.0017 lr: 0.02\n",
      "iteration: 274160 loss: 0.0025 lr: 0.02\n",
      "iteration: 274170 loss: 0.0012 lr: 0.02\n",
      "iteration: 274180 loss: 0.0023 lr: 0.02\n",
      "iteration: 274190 loss: 0.0021 lr: 0.02\n",
      "iteration: 274200 loss: 0.0019 lr: 0.02\n",
      "iteration: 274210 loss: 0.0019 lr: 0.02\n",
      "iteration: 274220 loss: 0.0014 lr: 0.02\n",
      "iteration: 274230 loss: 0.0022 lr: 0.02\n",
      "iteration: 274240 loss: 0.0016 lr: 0.02\n",
      "iteration: 274250 loss: 0.0020 lr: 0.02\n",
      "iteration: 274260 loss: 0.0016 lr: 0.02\n",
      "iteration: 274270 loss: 0.0018 lr: 0.02\n",
      "iteration: 274280 loss: 0.0018 lr: 0.02\n",
      "iteration: 274290 loss: 0.0014 lr: 0.02\n",
      "iteration: 274300 loss: 0.0015 lr: 0.02\n",
      "iteration: 274310 loss: 0.0019 lr: 0.02\n",
      "iteration: 274320 loss: 0.0017 lr: 0.02\n",
      "iteration: 274330 loss: 0.0017 lr: 0.02\n",
      "iteration: 274340 loss: 0.0019 lr: 0.02\n",
      "iteration: 274350 loss: 0.0015 lr: 0.02\n",
      "iteration: 274360 loss: 0.0015 lr: 0.02\n",
      "iteration: 274370 loss: 0.0024 lr: 0.02\n",
      "iteration: 274380 loss: 0.0018 lr: 0.02\n",
      "iteration: 274390 loss: 0.0016 lr: 0.02\n",
      "iteration: 274400 loss: 0.0020 lr: 0.02\n",
      "iteration: 274410 loss: 0.0016 lr: 0.02\n",
      "iteration: 274420 loss: 0.0017 lr: 0.02\n",
      "iteration: 274430 loss: 0.0015 lr: 0.02\n",
      "iteration: 274440 loss: 0.0016 lr: 0.02\n",
      "iteration: 274450 loss: 0.0015 lr: 0.02\n",
      "iteration: 274460 loss: 0.0013 lr: 0.02\n",
      "iteration: 274470 loss: 0.0015 lr: 0.02\n",
      "iteration: 274480 loss: 0.0018 lr: 0.02\n",
      "iteration: 274490 loss: 0.0014 lr: 0.02\n",
      "iteration: 274500 loss: 0.0014 lr: 0.02\n",
      "iteration: 274510 loss: 0.0013 lr: 0.02\n",
      "iteration: 274520 loss: 0.0017 lr: 0.02\n",
      "iteration: 274530 loss: 0.0014 lr: 0.02\n",
      "iteration: 274540 loss: 0.0020 lr: 0.02\n",
      "iteration: 274550 loss: 0.0016 lr: 0.02\n",
      "iteration: 274560 loss: 0.0019 lr: 0.02\n",
      "iteration: 274570 loss: 0.0023 lr: 0.02\n",
      "iteration: 274580 loss: 0.0020 lr: 0.02\n",
      "iteration: 274590 loss: 0.0017 lr: 0.02\n",
      "iteration: 274600 loss: 0.0018 lr: 0.02\n",
      "iteration: 274610 loss: 0.0016 lr: 0.02\n",
      "iteration: 274620 loss: 0.0016 lr: 0.02\n",
      "iteration: 274630 loss: 0.0018 lr: 0.02\n",
      "iteration: 274640 loss: 0.0016 lr: 0.02\n",
      "iteration: 274650 loss: 0.0021 lr: 0.02\n",
      "iteration: 274660 loss: 0.0026 lr: 0.02\n",
      "iteration: 274670 loss: 0.0025 lr: 0.02\n",
      "iteration: 274680 loss: 0.0021 lr: 0.02\n",
      "iteration: 274690 loss: 0.0019 lr: 0.02\n",
      "iteration: 274700 loss: 0.0018 lr: 0.02\n",
      "iteration: 274710 loss: 0.0017 lr: 0.02\n",
      "iteration: 274720 loss: 0.0021 lr: 0.02\n",
      "iteration: 274730 loss: 0.0017 lr: 0.02\n",
      "iteration: 274740 loss: 0.0019 lr: 0.02\n",
      "iteration: 274750 loss: 0.0017 lr: 0.02\n",
      "iteration: 274760 loss: 0.0018 lr: 0.02\n",
      "iteration: 274770 loss: 0.0018 lr: 0.02\n",
      "iteration: 274780 loss: 0.0019 lr: 0.02\n",
      "iteration: 274790 loss: 0.0024 lr: 0.02\n",
      "iteration: 274800 loss: 0.0017 lr: 0.02\n",
      "iteration: 274810 loss: 0.0024 lr: 0.02\n",
      "iteration: 274820 loss: 0.0018 lr: 0.02\n",
      "iteration: 274830 loss: 0.0026 lr: 0.02\n",
      "iteration: 274840 loss: 0.0016 lr: 0.02\n",
      "iteration: 274850 loss: 0.0021 lr: 0.02\n",
      "iteration: 274860 loss: 0.0014 lr: 0.02\n",
      "iteration: 274870 loss: 0.0018 lr: 0.02\n",
      "iteration: 274880 loss: 0.0017 lr: 0.02\n",
      "iteration: 274890 loss: 0.0019 lr: 0.02\n",
      "iteration: 274900 loss: 0.0020 lr: 0.02\n",
      "iteration: 274910 loss: 0.0017 lr: 0.02\n",
      "iteration: 274920 loss: 0.0021 lr: 0.02\n",
      "iteration: 274930 loss: 0.0023 lr: 0.02\n",
      "iteration: 274940 loss: 0.0016 lr: 0.02\n",
      "iteration: 274950 loss: 0.0018 lr: 0.02\n",
      "iteration: 274960 loss: 0.0015 lr: 0.02\n",
      "iteration: 274970 loss: 0.0020 lr: 0.02\n",
      "iteration: 274980 loss: 0.0016 lr: 0.02\n",
      "iteration: 274990 loss: 0.0016 lr: 0.02\n",
      "iteration: 275000 loss: 0.0015 lr: 0.02\n",
      "iteration: 275010 loss: 0.0015 lr: 0.02\n",
      "iteration: 275020 loss: 0.0017 lr: 0.02\n",
      "iteration: 275030 loss: 0.0017 lr: 0.02\n",
      "iteration: 275040 loss: 0.0016 lr: 0.02\n",
      "iteration: 275050 loss: 0.0016 lr: 0.02\n",
      "iteration: 275060 loss: 0.0019 lr: 0.02\n",
      "iteration: 275070 loss: 0.0021 lr: 0.02\n",
      "iteration: 275080 loss: 0.0020 lr: 0.02\n",
      "iteration: 275090 loss: 0.0019 lr: 0.02\n",
      "iteration: 275100 loss: 0.0020 lr: 0.02\n",
      "iteration: 275110 loss: 0.0016 lr: 0.02\n",
      "iteration: 275120 loss: 0.0023 lr: 0.02\n",
      "iteration: 275130 loss: 0.0017 lr: 0.02\n",
      "iteration: 275140 loss: 0.0021 lr: 0.02\n",
      "iteration: 275150 loss: 0.0017 lr: 0.02\n",
      "iteration: 275160 loss: 0.0018 lr: 0.02\n",
      "iteration: 275170 loss: 0.0016 lr: 0.02\n",
      "iteration: 275180 loss: 0.0018 lr: 0.02\n",
      "iteration: 275190 loss: 0.0017 lr: 0.02\n",
      "iteration: 275200 loss: 0.0012 lr: 0.02\n",
      "iteration: 275210 loss: 0.0018 lr: 0.02\n",
      "iteration: 275220 loss: 0.0021 lr: 0.02\n",
      "iteration: 275230 loss: 0.0015 lr: 0.02\n",
      "iteration: 275240 loss: 0.0018 lr: 0.02\n",
      "iteration: 275250 loss: 0.0019 lr: 0.02\n",
      "iteration: 275260 loss: 0.0017 lr: 0.02\n",
      "iteration: 275270 loss: 0.0015 lr: 0.02\n",
      "iteration: 275280 loss: 0.0018 lr: 0.02\n",
      "iteration: 275290 loss: 0.0017 lr: 0.02\n",
      "iteration: 275300 loss: 0.0017 lr: 0.02\n",
      "iteration: 275310 loss: 0.0019 lr: 0.02\n",
      "iteration: 275320 loss: 0.0019 lr: 0.02\n",
      "iteration: 275330 loss: 0.0015 lr: 0.02\n",
      "iteration: 275340 loss: 0.0019 lr: 0.02\n",
      "iteration: 275350 loss: 0.0018 lr: 0.02\n",
      "iteration: 275360 loss: 0.0021 lr: 0.02\n",
      "iteration: 275370 loss: 0.0014 lr: 0.02\n",
      "iteration: 275380 loss: 0.0020 lr: 0.02\n",
      "iteration: 275390 loss: 0.0015 lr: 0.02\n",
      "iteration: 275400 loss: 0.0022 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 275410 loss: 0.0017 lr: 0.02\n",
      "iteration: 275420 loss: 0.0015 lr: 0.02\n",
      "iteration: 275430 loss: 0.0022 lr: 0.02\n",
      "iteration: 275440 loss: 0.0022 lr: 0.02\n",
      "iteration: 275450 loss: 0.0027 lr: 0.02\n",
      "iteration: 275460 loss: 0.0021 lr: 0.02\n",
      "iteration: 275470 loss: 0.0025 lr: 0.02\n",
      "iteration: 275480 loss: 0.0020 lr: 0.02\n",
      "iteration: 275490 loss: 0.0021 lr: 0.02\n",
      "iteration: 275500 loss: 0.0019 lr: 0.02\n",
      "iteration: 275510 loss: 0.0017 lr: 0.02\n",
      "iteration: 275520 loss: 0.0016 lr: 0.02\n",
      "iteration: 275530 loss: 0.0018 lr: 0.02\n",
      "iteration: 275540 loss: 0.0017 lr: 0.02\n",
      "iteration: 275550 loss: 0.0020 lr: 0.02\n",
      "iteration: 275560 loss: 0.0017 lr: 0.02\n",
      "iteration: 275570 loss: 0.0016 lr: 0.02\n",
      "iteration: 275580 loss: 0.0019 lr: 0.02\n",
      "iteration: 275590 loss: 0.0015 lr: 0.02\n",
      "iteration: 275600 loss: 0.0015 lr: 0.02\n",
      "iteration: 275610 loss: 0.0028 lr: 0.02\n",
      "iteration: 275620 loss: 0.0017 lr: 0.02\n",
      "iteration: 275630 loss: 0.0020 lr: 0.02\n",
      "iteration: 275640 loss: 0.0017 lr: 0.02\n",
      "iteration: 275650 loss: 0.0019 lr: 0.02\n",
      "iteration: 275660 loss: 0.0018 lr: 0.02\n",
      "iteration: 275670 loss: 0.0021 lr: 0.02\n",
      "iteration: 275680 loss: 0.0017 lr: 0.02\n",
      "iteration: 275690 loss: 0.0019 lr: 0.02\n",
      "iteration: 275700 loss: 0.0014 lr: 0.02\n",
      "iteration: 275710 loss: 0.0025 lr: 0.02\n",
      "iteration: 275720 loss: 0.0019 lr: 0.02\n",
      "iteration: 275730 loss: 0.0018 lr: 0.02\n",
      "iteration: 275740 loss: 0.0019 lr: 0.02\n",
      "iteration: 275750 loss: 0.0017 lr: 0.02\n",
      "iteration: 275760 loss: 0.0015 lr: 0.02\n",
      "iteration: 275770 loss: 0.0014 lr: 0.02\n",
      "iteration: 275780 loss: 0.0015 lr: 0.02\n",
      "iteration: 275790 loss: 0.0020 lr: 0.02\n",
      "iteration: 275800 loss: 0.0020 lr: 0.02\n",
      "iteration: 275810 loss: 0.0018 lr: 0.02\n",
      "iteration: 275820 loss: 0.0014 lr: 0.02\n",
      "iteration: 275830 loss: 0.0017 lr: 0.02\n",
      "iteration: 275840 loss: 0.0021 lr: 0.02\n",
      "iteration: 275850 loss: 0.0015 lr: 0.02\n",
      "iteration: 275860 loss: 0.0016 lr: 0.02\n",
      "iteration: 275870 loss: 0.0017 lr: 0.02\n",
      "iteration: 275880 loss: 0.0016 lr: 0.02\n",
      "iteration: 275890 loss: 0.0017 lr: 0.02\n",
      "iteration: 275900 loss: 0.0015 lr: 0.02\n",
      "iteration: 275910 loss: 0.0017 lr: 0.02\n",
      "iteration: 275920 loss: 0.0020 lr: 0.02\n",
      "iteration: 275930 loss: 0.0014 lr: 0.02\n",
      "iteration: 275940 loss: 0.0017 lr: 0.02\n",
      "iteration: 275950 loss: 0.0015 lr: 0.02\n",
      "iteration: 275960 loss: 0.0014 lr: 0.02\n",
      "iteration: 275970 loss: 0.0015 lr: 0.02\n",
      "iteration: 275980 loss: 0.0016 lr: 0.02\n",
      "iteration: 275990 loss: 0.0019 lr: 0.02\n",
      "iteration: 276000 loss: 0.0018 lr: 0.02\n",
      "iteration: 276010 loss: 0.0017 lr: 0.02\n",
      "iteration: 276020 loss: 0.0017 lr: 0.02\n",
      "iteration: 276030 loss: 0.0031 lr: 0.02\n",
      "iteration: 276040 loss: 0.0018 lr: 0.02\n",
      "iteration: 276050 loss: 0.0022 lr: 0.02\n",
      "iteration: 276060 loss: 0.0018 lr: 0.02\n",
      "iteration: 276070 loss: 0.0019 lr: 0.02\n",
      "iteration: 276080 loss: 0.0017 lr: 0.02\n",
      "iteration: 276090 loss: 0.0017 lr: 0.02\n",
      "iteration: 276100 loss: 0.0015 lr: 0.02\n",
      "iteration: 276110 loss: 0.0018 lr: 0.02\n",
      "iteration: 276120 loss: 0.0013 lr: 0.02\n",
      "iteration: 276130 loss: 0.0022 lr: 0.02\n",
      "iteration: 276140 loss: 0.0015 lr: 0.02\n",
      "iteration: 276150 loss: 0.0017 lr: 0.02\n",
      "iteration: 276160 loss: 0.0020 lr: 0.02\n",
      "iteration: 276170 loss: 0.0021 lr: 0.02\n",
      "iteration: 276180 loss: 0.0016 lr: 0.02\n",
      "iteration: 276190 loss: 0.0018 lr: 0.02\n",
      "iteration: 276200 loss: 0.0021 lr: 0.02\n",
      "iteration: 276210 loss: 0.0020 lr: 0.02\n",
      "iteration: 276220 loss: 0.0019 lr: 0.02\n",
      "iteration: 276230 loss: 0.0015 lr: 0.02\n",
      "iteration: 276240 loss: 0.0015 lr: 0.02\n",
      "iteration: 276250 loss: 0.0019 lr: 0.02\n",
      "iteration: 276260 loss: 0.0014 lr: 0.02\n",
      "iteration: 276270 loss: 0.0022 lr: 0.02\n",
      "iteration: 276280 loss: 0.0021 lr: 0.02\n",
      "iteration: 276290 loss: 0.0016 lr: 0.02\n",
      "iteration: 276300 loss: 0.0015 lr: 0.02\n",
      "iteration: 276310 loss: 0.0018 lr: 0.02\n",
      "iteration: 276320 loss: 0.0013 lr: 0.02\n",
      "iteration: 276330 loss: 0.0016 lr: 0.02\n",
      "iteration: 276340 loss: 0.0014 lr: 0.02\n",
      "iteration: 276350 loss: 0.0018 lr: 0.02\n",
      "iteration: 276360 loss: 0.0016 lr: 0.02\n",
      "iteration: 276370 loss: 0.0020 lr: 0.02\n",
      "iteration: 276380 loss: 0.0018 lr: 0.02\n",
      "iteration: 276390 loss: 0.0018 lr: 0.02\n",
      "iteration: 276400 loss: 0.0017 lr: 0.02\n",
      "iteration: 276410 loss: 0.0016 lr: 0.02\n",
      "iteration: 276420 loss: 0.0019 lr: 0.02\n",
      "iteration: 276430 loss: 0.0021 lr: 0.02\n",
      "iteration: 276440 loss: 0.0019 lr: 0.02\n",
      "iteration: 276450 loss: 0.0015 lr: 0.02\n",
      "iteration: 276460 loss: 0.0016 lr: 0.02\n",
      "iteration: 276470 loss: 0.0020 lr: 0.02\n",
      "iteration: 276480 loss: 0.0023 lr: 0.02\n",
      "iteration: 276490 loss: 0.0016 lr: 0.02\n",
      "iteration: 276500 loss: 0.0018 lr: 0.02\n",
      "iteration: 276510 loss: 0.0017 lr: 0.02\n",
      "iteration: 276520 loss: 0.0023 lr: 0.02\n",
      "iteration: 276530 loss: 0.0014 lr: 0.02\n",
      "iteration: 276540 loss: 0.0014 lr: 0.02\n",
      "iteration: 276550 loss: 0.0018 lr: 0.02\n",
      "iteration: 276560 loss: 0.0016 lr: 0.02\n",
      "iteration: 276570 loss: 0.0016 lr: 0.02\n",
      "iteration: 276580 loss: 0.0021 lr: 0.02\n",
      "iteration: 276590 loss: 0.0013 lr: 0.02\n",
      "iteration: 276600 loss: 0.0021 lr: 0.02\n",
      "iteration: 276610 loss: 0.0014 lr: 0.02\n",
      "iteration: 276620 loss: 0.0017 lr: 0.02\n",
      "iteration: 276630 loss: 0.0019 lr: 0.02\n",
      "iteration: 276640 loss: 0.0022 lr: 0.02\n",
      "iteration: 276650 loss: 0.0023 lr: 0.02\n",
      "iteration: 276660 loss: 0.0016 lr: 0.02\n",
      "iteration: 276670 loss: 0.0018 lr: 0.02\n",
      "iteration: 276680 loss: 0.0020 lr: 0.02\n",
      "iteration: 276690 loss: 0.0030 lr: 0.02\n",
      "iteration: 276700 loss: 0.0014 lr: 0.02\n",
      "iteration: 276710 loss: 0.0027 lr: 0.02\n",
      "iteration: 276720 loss: 0.0018 lr: 0.02\n",
      "iteration: 276730 loss: 0.0019 lr: 0.02\n",
      "iteration: 276740 loss: 0.0020 lr: 0.02\n",
      "iteration: 276750 loss: 0.0027 lr: 0.02\n",
      "iteration: 276760 loss: 0.0015 lr: 0.02\n",
      "iteration: 276770 loss: 0.0018 lr: 0.02\n",
      "iteration: 276780 loss: 0.0018 lr: 0.02\n",
      "iteration: 276790 loss: 0.0018 lr: 0.02\n",
      "iteration: 276800 loss: 0.0017 lr: 0.02\n",
      "iteration: 276810 loss: 0.0020 lr: 0.02\n",
      "iteration: 276820 loss: 0.0018 lr: 0.02\n",
      "iteration: 276830 loss: 0.0019 lr: 0.02\n",
      "iteration: 276840 loss: 0.0023 lr: 0.02\n",
      "iteration: 276850 loss: 0.0020 lr: 0.02\n",
      "iteration: 276860 loss: 0.0022 lr: 0.02\n",
      "iteration: 276870 loss: 0.0018 lr: 0.02\n",
      "iteration: 276880 loss: 0.0023 lr: 0.02\n",
      "iteration: 276890 loss: 0.0019 lr: 0.02\n",
      "iteration: 276900 loss: 0.0019 lr: 0.02\n",
      "iteration: 276910 loss: 0.0017 lr: 0.02\n",
      "iteration: 276920 loss: 0.0020 lr: 0.02\n",
      "iteration: 276930 loss: 0.0018 lr: 0.02\n",
      "iteration: 276940 loss: 0.0017 lr: 0.02\n",
      "iteration: 276950 loss: 0.0015 lr: 0.02\n",
      "iteration: 276960 loss: 0.0023 lr: 0.02\n",
      "iteration: 276970 loss: 0.0020 lr: 0.02\n",
      "iteration: 276980 loss: 0.0016 lr: 0.02\n",
      "iteration: 276990 loss: 0.0020 lr: 0.02\n",
      "iteration: 277000 loss: 0.0014 lr: 0.02\n",
      "iteration: 277010 loss: 0.0022 lr: 0.02\n",
      "iteration: 277020 loss: 0.0013 lr: 0.02\n",
      "iteration: 277030 loss: 0.0018 lr: 0.02\n",
      "iteration: 277040 loss: 0.0018 lr: 0.02\n",
      "iteration: 277050 loss: 0.0020 lr: 0.02\n",
      "iteration: 277060 loss: 0.0020 lr: 0.02\n",
      "iteration: 277070 loss: 0.0018 lr: 0.02\n",
      "iteration: 277080 loss: 0.0022 lr: 0.02\n",
      "iteration: 277090 loss: 0.0017 lr: 0.02\n",
      "iteration: 277100 loss: 0.0024 lr: 0.02\n",
      "iteration: 277110 loss: 0.0018 lr: 0.02\n",
      "iteration: 277120 loss: 0.0018 lr: 0.02\n",
      "iteration: 277130 loss: 0.0019 lr: 0.02\n",
      "iteration: 277140 loss: 0.0017 lr: 0.02\n",
      "iteration: 277150 loss: 0.0023 lr: 0.02\n",
      "iteration: 277160 loss: 0.0019 lr: 0.02\n",
      "iteration: 277170 loss: 0.0018 lr: 0.02\n",
      "iteration: 277180 loss: 0.0018 lr: 0.02\n",
      "iteration: 277190 loss: 0.0016 lr: 0.02\n",
      "iteration: 277200 loss: 0.0018 lr: 0.02\n",
      "iteration: 277210 loss: 0.0015 lr: 0.02\n",
      "iteration: 277220 loss: 0.0018 lr: 0.02\n",
      "iteration: 277230 loss: 0.0017 lr: 0.02\n",
      "iteration: 277240 loss: 0.0015 lr: 0.02\n",
      "iteration: 277250 loss: 0.0015 lr: 0.02\n",
      "iteration: 277260 loss: 0.0014 lr: 0.02\n",
      "iteration: 277270 loss: 0.0019 lr: 0.02\n",
      "iteration: 277280 loss: 0.0030 lr: 0.02\n",
      "iteration: 277290 loss: 0.0014 lr: 0.02\n",
      "iteration: 277300 loss: 0.0018 lr: 0.02\n",
      "iteration: 277310 loss: 0.0021 lr: 0.02\n",
      "iteration: 277320 loss: 0.0019 lr: 0.02\n",
      "iteration: 277330 loss: 0.0017 lr: 0.02\n",
      "iteration: 277340 loss: 0.0018 lr: 0.02\n",
      "iteration: 277350 loss: 0.0014 lr: 0.02\n",
      "iteration: 277360 loss: 0.0014 lr: 0.02\n",
      "iteration: 277370 loss: 0.0020 lr: 0.02\n",
      "iteration: 277380 loss: 0.0021 lr: 0.02\n",
      "iteration: 277390 loss: 0.0015 lr: 0.02\n",
      "iteration: 277400 loss: 0.0019 lr: 0.02\n",
      "iteration: 277410 loss: 0.0016 lr: 0.02\n",
      "iteration: 277420 loss: 0.0021 lr: 0.02\n",
      "iteration: 277430 loss: 0.0015 lr: 0.02\n",
      "iteration: 277440 loss: 0.0020 lr: 0.02\n",
      "iteration: 277450 loss: 0.0017 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 277460 loss: 0.0017 lr: 0.02\n",
      "iteration: 277470 loss: 0.0017 lr: 0.02\n",
      "iteration: 277480 loss: 0.0017 lr: 0.02\n",
      "iteration: 277490 loss: 0.0022 lr: 0.02\n",
      "iteration: 277500 loss: 0.0023 lr: 0.02\n",
      "iteration: 277510 loss: 0.0020 lr: 0.02\n",
      "iteration: 277520 loss: 0.0021 lr: 0.02\n",
      "iteration: 277530 loss: 0.0019 lr: 0.02\n",
      "iteration: 277540 loss: 0.0014 lr: 0.02\n",
      "iteration: 277550 loss: 0.0014 lr: 0.02\n",
      "iteration: 277560 loss: 0.0019 lr: 0.02\n",
      "iteration: 277570 loss: 0.0019 lr: 0.02\n",
      "iteration: 277580 loss: 0.0018 lr: 0.02\n",
      "iteration: 277590 loss: 0.0019 lr: 0.02\n",
      "iteration: 277600 loss: 0.0020 lr: 0.02\n",
      "iteration: 277610 loss: 0.0014 lr: 0.02\n",
      "iteration: 277620 loss: 0.0017 lr: 0.02\n",
      "iteration: 277630 loss: 0.0019 lr: 0.02\n",
      "iteration: 277640 loss: 0.0015 lr: 0.02\n",
      "iteration: 277650 loss: 0.0019 lr: 0.02\n",
      "iteration: 277660 loss: 0.0018 lr: 0.02\n",
      "iteration: 277670 loss: 0.0014 lr: 0.02\n",
      "iteration: 277680 loss: 0.0015 lr: 0.02\n",
      "iteration: 277690 loss: 0.0016 lr: 0.02\n",
      "iteration: 277700 loss: 0.0017 lr: 0.02\n",
      "iteration: 277710 loss: 0.0021 lr: 0.02\n",
      "iteration: 277720 loss: 0.0020 lr: 0.02\n",
      "iteration: 277730 loss: 0.0017 lr: 0.02\n",
      "iteration: 277740 loss: 0.0017 lr: 0.02\n",
      "iteration: 277750 loss: 0.0017 lr: 0.02\n",
      "iteration: 277760 loss: 0.0024 lr: 0.02\n",
      "iteration: 277770 loss: 0.0020 lr: 0.02\n",
      "iteration: 277780 loss: 0.0016 lr: 0.02\n",
      "iteration: 277790 loss: 0.0018 lr: 0.02\n",
      "iteration: 277800 loss: 0.0021 lr: 0.02\n",
      "iteration: 277810 loss: 0.0017 lr: 0.02\n",
      "iteration: 277820 loss: 0.0018 lr: 0.02\n",
      "iteration: 277830 loss: 0.0017 lr: 0.02\n",
      "iteration: 277840 loss: 0.0017 lr: 0.02\n",
      "iteration: 277850 loss: 0.0015 lr: 0.02\n",
      "iteration: 277860 loss: 0.0024 lr: 0.02\n",
      "iteration: 277870 loss: 0.0023 lr: 0.02\n",
      "iteration: 277880 loss: 0.0017 lr: 0.02\n",
      "iteration: 277890 loss: 0.0016 lr: 0.02\n",
      "iteration: 277900 loss: 0.0015 lr: 0.02\n",
      "iteration: 277910 loss: 0.0013 lr: 0.02\n",
      "iteration: 277920 loss: 0.0021 lr: 0.02\n",
      "iteration: 277930 loss: 0.0017 lr: 0.02\n",
      "iteration: 277940 loss: 0.0014 lr: 0.02\n",
      "iteration: 277950 loss: 0.0019 lr: 0.02\n",
      "iteration: 277960 loss: 0.0017 lr: 0.02\n",
      "iteration: 277970 loss: 0.0021 lr: 0.02\n",
      "iteration: 277980 loss: 0.0014 lr: 0.02\n",
      "iteration: 277990 loss: 0.0021 lr: 0.02\n",
      "iteration: 278000 loss: 0.0016 lr: 0.02\n",
      "iteration: 278010 loss: 0.0016 lr: 0.02\n",
      "iteration: 278020 loss: 0.0019 lr: 0.02\n",
      "iteration: 278030 loss: 0.0016 lr: 0.02\n",
      "iteration: 278040 loss: 0.0016 lr: 0.02\n",
      "iteration: 278050 loss: 0.0022 lr: 0.02\n",
      "iteration: 278060 loss: 0.0020 lr: 0.02\n",
      "iteration: 278070 loss: 0.0019 lr: 0.02\n",
      "iteration: 278080 loss: 0.0022 lr: 0.02\n",
      "iteration: 278090 loss: 0.0015 lr: 0.02\n",
      "iteration: 278100 loss: 0.0018 lr: 0.02\n",
      "iteration: 278110 loss: 0.0014 lr: 0.02\n",
      "iteration: 278120 loss: 0.0019 lr: 0.02\n",
      "iteration: 278130 loss: 0.0018 lr: 0.02\n",
      "iteration: 278140 loss: 0.0014 lr: 0.02\n",
      "iteration: 278150 loss: 0.0018 lr: 0.02\n",
      "iteration: 278160 loss: 0.0020 lr: 0.02\n",
      "iteration: 278170 loss: 0.0016 lr: 0.02\n",
      "iteration: 278180 loss: 0.0019 lr: 0.02\n",
      "iteration: 278190 loss: 0.0024 lr: 0.02\n",
      "iteration: 278200 loss: 0.0019 lr: 0.02\n",
      "iteration: 278210 loss: 0.0017 lr: 0.02\n",
      "iteration: 278220 loss: 0.0021 lr: 0.02\n",
      "iteration: 278230 loss: 0.0018 lr: 0.02\n",
      "iteration: 278240 loss: 0.0018 lr: 0.02\n",
      "iteration: 278250 loss: 0.0020 lr: 0.02\n",
      "iteration: 278260 loss: 0.0027 lr: 0.02\n",
      "iteration: 278270 loss: 0.0013 lr: 0.02\n",
      "iteration: 278280 loss: 0.0014 lr: 0.02\n",
      "iteration: 278290 loss: 0.0020 lr: 0.02\n",
      "iteration: 278300 loss: 0.0016 lr: 0.02\n",
      "iteration: 278310 loss: 0.0013 lr: 0.02\n",
      "iteration: 278320 loss: 0.0018 lr: 0.02\n",
      "iteration: 278330 loss: 0.0017 lr: 0.02\n",
      "iteration: 278340 loss: 0.0017 lr: 0.02\n",
      "iteration: 278350 loss: 0.0019 lr: 0.02\n",
      "iteration: 278360 loss: 0.0021 lr: 0.02\n",
      "iteration: 278370 loss: 0.0017 lr: 0.02\n",
      "iteration: 278380 loss: 0.0019 lr: 0.02\n",
      "iteration: 278390 loss: 0.0018 lr: 0.02\n",
      "iteration: 278400 loss: 0.0016 lr: 0.02\n",
      "iteration: 278410 loss: 0.0018 lr: 0.02\n",
      "iteration: 278420 loss: 0.0020 lr: 0.02\n",
      "iteration: 278430 loss: 0.0020 lr: 0.02\n",
      "iteration: 278440 loss: 0.0018 lr: 0.02\n",
      "iteration: 278450 loss: 0.0017 lr: 0.02\n",
      "iteration: 278460 loss: 0.0014 lr: 0.02\n",
      "iteration: 278470 loss: 0.0016 lr: 0.02\n",
      "iteration: 278480 loss: 0.0015 lr: 0.02\n",
      "iteration: 278490 loss: 0.0013 lr: 0.02\n",
      "iteration: 278500 loss: 0.0024 lr: 0.02\n",
      "iteration: 278510 loss: 0.0017 lr: 0.02\n",
      "iteration: 278520 loss: 0.0016 lr: 0.02\n",
      "iteration: 278530 loss: 0.0021 lr: 0.02\n",
      "iteration: 278540 loss: 0.0018 lr: 0.02\n",
      "iteration: 278550 loss: 0.0019 lr: 0.02\n",
      "iteration: 278560 loss: 0.0016 lr: 0.02\n",
      "iteration: 278570 loss: 0.0015 lr: 0.02\n",
      "iteration: 278580 loss: 0.0017 lr: 0.02\n",
      "iteration: 278590 loss: 0.0021 lr: 0.02\n",
      "iteration: 278600 loss: 0.0016 lr: 0.02\n",
      "iteration: 278610 loss: 0.0018 lr: 0.02\n",
      "iteration: 278620 loss: 0.0022 lr: 0.02\n",
      "iteration: 278630 loss: 0.0018 lr: 0.02\n",
      "iteration: 278640 loss: 0.0020 lr: 0.02\n",
      "iteration: 278650 loss: 0.0017 lr: 0.02\n",
      "iteration: 278660 loss: 0.0016 lr: 0.02\n",
      "iteration: 278670 loss: 0.0016 lr: 0.02\n",
      "iteration: 278680 loss: 0.0014 lr: 0.02\n",
      "iteration: 278690 loss: 0.0015 lr: 0.02\n",
      "iteration: 278700 loss: 0.0023 lr: 0.02\n",
      "iteration: 278710 loss: 0.0019 lr: 0.02\n",
      "iteration: 278720 loss: 0.0015 lr: 0.02\n",
      "iteration: 278730 loss: 0.0019 lr: 0.02\n",
      "iteration: 278740 loss: 0.0026 lr: 0.02\n",
      "iteration: 278750 loss: 0.0015 lr: 0.02\n",
      "iteration: 278760 loss: 0.0016 lr: 0.02\n",
      "iteration: 278770 loss: 0.0015 lr: 0.02\n",
      "iteration: 278780 loss: 0.0027 lr: 0.02\n",
      "iteration: 278790 loss: 0.0016 lr: 0.02\n",
      "iteration: 278800 loss: 0.0018 lr: 0.02\n",
      "iteration: 278810 loss: 0.0021 lr: 0.02\n",
      "iteration: 278820 loss: 0.0018 lr: 0.02\n",
      "iteration: 278830 loss: 0.0011 lr: 0.02\n",
      "iteration: 278840 loss: 0.0019 lr: 0.02\n",
      "iteration: 278850 loss: 0.0018 lr: 0.02\n",
      "iteration: 278860 loss: 0.0017 lr: 0.02\n",
      "iteration: 278870 loss: 0.0017 lr: 0.02\n",
      "iteration: 278880 loss: 0.0013 lr: 0.02\n",
      "iteration: 278890 loss: 0.0016 lr: 0.02\n",
      "iteration: 278900 loss: 0.0021 lr: 0.02\n",
      "iteration: 278910 loss: 0.0022 lr: 0.02\n",
      "iteration: 278920 loss: 0.0019 lr: 0.02\n",
      "iteration: 278930 loss: 0.0021 lr: 0.02\n",
      "iteration: 278940 loss: 0.0015 lr: 0.02\n",
      "iteration: 278950 loss: 0.0014 lr: 0.02\n",
      "iteration: 278960 loss: 0.0018 lr: 0.02\n",
      "iteration: 278970 loss: 0.0019 lr: 0.02\n",
      "iteration: 278980 loss: 0.0017 lr: 0.02\n",
      "iteration: 278990 loss: 0.0013 lr: 0.02\n",
      "iteration: 279000 loss: 0.0021 lr: 0.02\n",
      "iteration: 279010 loss: 0.0013 lr: 0.02\n",
      "iteration: 279020 loss: 0.0014 lr: 0.02\n",
      "iteration: 279030 loss: 0.0016 lr: 0.02\n",
      "iteration: 279040 loss: 0.0019 lr: 0.02\n",
      "iteration: 279050 loss: 0.0017 lr: 0.02\n",
      "iteration: 279060 loss: 0.0018 lr: 0.02\n",
      "iteration: 279070 loss: 0.0020 lr: 0.02\n",
      "iteration: 279080 loss: 0.0016 lr: 0.02\n",
      "iteration: 279090 loss: 0.0021 lr: 0.02\n",
      "iteration: 279100 loss: 0.0019 lr: 0.02\n",
      "iteration: 279110 loss: 0.0016 lr: 0.02\n",
      "iteration: 279120 loss: 0.0017 lr: 0.02\n",
      "iteration: 279130 loss: 0.0014 lr: 0.02\n",
      "iteration: 279140 loss: 0.0015 lr: 0.02\n",
      "iteration: 279150 loss: 0.0015 lr: 0.02\n",
      "iteration: 279160 loss: 0.0015 lr: 0.02\n",
      "iteration: 279170 loss: 0.0018 lr: 0.02\n",
      "iteration: 279180 loss: 0.0018 lr: 0.02\n",
      "iteration: 279190 loss: 0.0015 lr: 0.02\n",
      "iteration: 279200 loss: 0.0020 lr: 0.02\n",
      "iteration: 279210 loss: 0.0014 lr: 0.02\n",
      "iteration: 279220 loss: 0.0022 lr: 0.02\n",
      "iteration: 279230 loss: 0.0016 lr: 0.02\n",
      "iteration: 279240 loss: 0.0015 lr: 0.02\n",
      "iteration: 279250 loss: 0.0019 lr: 0.02\n",
      "iteration: 279260 loss: 0.0017 lr: 0.02\n",
      "iteration: 279270 loss: 0.0014 lr: 0.02\n",
      "iteration: 279280 loss: 0.0016 lr: 0.02\n",
      "iteration: 279290 loss: 0.0017 lr: 0.02\n",
      "iteration: 279300 loss: 0.0013 lr: 0.02\n",
      "iteration: 279310 loss: 0.0015 lr: 0.02\n",
      "iteration: 279320 loss: 0.0015 lr: 0.02\n",
      "iteration: 279330 loss: 0.0019 lr: 0.02\n",
      "iteration: 279340 loss: 0.0017 lr: 0.02\n",
      "iteration: 279350 loss: 0.0015 lr: 0.02\n",
      "iteration: 279360 loss: 0.0022 lr: 0.02\n",
      "iteration: 279370 loss: 0.0021 lr: 0.02\n",
      "iteration: 279380 loss: 0.0018 lr: 0.02\n",
      "iteration: 279390 loss: 0.0017 lr: 0.02\n",
      "iteration: 279400 loss: 0.0013 lr: 0.02\n",
      "iteration: 279410 loss: 0.0015 lr: 0.02\n",
      "iteration: 279420 loss: 0.0019 lr: 0.02\n",
      "iteration: 279430 loss: 0.0016 lr: 0.02\n",
      "iteration: 279440 loss: 0.0018 lr: 0.02\n",
      "iteration: 279450 loss: 0.0016 lr: 0.02\n",
      "iteration: 279460 loss: 0.0023 lr: 0.02\n",
      "iteration: 279470 loss: 0.0021 lr: 0.02\n",
      "iteration: 279480 loss: 0.0020 lr: 0.02\n",
      "iteration: 279490 loss: 0.0024 lr: 0.02\n",
      "iteration: 279500 loss: 0.0016 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 279510 loss: 0.0017 lr: 0.02\n",
      "iteration: 279520 loss: 0.0019 lr: 0.02\n",
      "iteration: 279530 loss: 0.0018 lr: 0.02\n",
      "iteration: 279540 loss: 0.0018 lr: 0.02\n",
      "iteration: 279550 loss: 0.0013 lr: 0.02\n",
      "iteration: 279560 loss: 0.0016 lr: 0.02\n",
      "iteration: 279570 loss: 0.0017 lr: 0.02\n",
      "iteration: 279580 loss: 0.0023 lr: 0.02\n",
      "iteration: 279590 loss: 0.0020 lr: 0.02\n",
      "iteration: 279600 loss: 0.0018 lr: 0.02\n",
      "iteration: 279610 loss: 0.0017 lr: 0.02\n",
      "iteration: 279620 loss: 0.0017 lr: 0.02\n",
      "iteration: 279630 loss: 0.0020 lr: 0.02\n",
      "iteration: 279640 loss: 0.0020 lr: 0.02\n",
      "iteration: 279650 loss: 0.0019 lr: 0.02\n",
      "iteration: 279660 loss: 0.0023 lr: 0.02\n",
      "iteration: 279670 loss: 0.0024 lr: 0.02\n",
      "iteration: 279680 loss: 0.0016 lr: 0.02\n",
      "iteration: 279690 loss: 0.0017 lr: 0.02\n",
      "iteration: 279700 loss: 0.0020 lr: 0.02\n",
      "iteration: 279710 loss: 0.0019 lr: 0.02\n",
      "iteration: 279720 loss: 0.0016 lr: 0.02\n",
      "iteration: 279730 loss: 0.0019 lr: 0.02\n",
      "iteration: 279740 loss: 0.0018 lr: 0.02\n",
      "iteration: 279750 loss: 0.0014 lr: 0.02\n",
      "iteration: 279760 loss: 0.0023 lr: 0.02\n",
      "iteration: 279770 loss: 0.0016 lr: 0.02\n",
      "iteration: 279780 loss: 0.0017 lr: 0.02\n",
      "iteration: 279790 loss: 0.0018 lr: 0.02\n",
      "iteration: 279800 loss: 0.0023 lr: 0.02\n",
      "iteration: 279810 loss: 0.0019 lr: 0.02\n",
      "iteration: 279820 loss: 0.0020 lr: 0.02\n",
      "iteration: 279830 loss: 0.0014 lr: 0.02\n",
      "iteration: 279840 loss: 0.0014 lr: 0.02\n",
      "iteration: 279850 loss: 0.0022 lr: 0.02\n",
      "iteration: 279860 loss: 0.0015 lr: 0.02\n",
      "iteration: 279870 loss: 0.0015 lr: 0.02\n",
      "iteration: 279880 loss: 0.0019 lr: 0.02\n",
      "iteration: 279890 loss: 0.0013 lr: 0.02\n",
      "iteration: 279900 loss: 0.0013 lr: 0.02\n",
      "iteration: 279910 loss: 0.0016 lr: 0.02\n",
      "iteration: 279920 loss: 0.0021 lr: 0.02\n",
      "iteration: 279930 loss: 0.0020 lr: 0.02\n",
      "iteration: 279940 loss: 0.0018 lr: 0.02\n",
      "iteration: 279950 loss: 0.0016 lr: 0.02\n",
      "iteration: 279960 loss: 0.0019 lr: 0.02\n",
      "iteration: 279970 loss: 0.0018 lr: 0.02\n",
      "iteration: 279980 loss: 0.0016 lr: 0.02\n",
      "iteration: 279990 loss: 0.0020 lr: 0.02\n",
      "iteration: 280000 loss: 0.0021 lr: 0.02\n",
      "iteration: 280010 loss: 0.0018 lr: 0.02\n",
      "iteration: 280020 loss: 0.0018 lr: 0.02\n",
      "iteration: 280030 loss: 0.0017 lr: 0.02\n",
      "iteration: 280040 loss: 0.0016 lr: 0.02\n",
      "iteration: 280050 loss: 0.0017 lr: 0.02\n",
      "iteration: 280060 loss: 0.0016 lr: 0.02\n",
      "iteration: 280070 loss: 0.0019 lr: 0.02\n",
      "iteration: 280080 loss: 0.0017 lr: 0.02\n",
      "iteration: 280090 loss: 0.0015 lr: 0.02\n",
      "iteration: 280100 loss: 0.0018 lr: 0.02\n",
      "iteration: 280110 loss: 0.0013 lr: 0.02\n",
      "iteration: 280120 loss: 0.0019 lr: 0.02\n",
      "iteration: 280130 loss: 0.0024 lr: 0.02\n",
      "iteration: 280140 loss: 0.0019 lr: 0.02\n",
      "iteration: 280150 loss: 0.0017 lr: 0.02\n",
      "iteration: 280160 loss: 0.0020 lr: 0.02\n",
      "iteration: 280170 loss: 0.0018 lr: 0.02\n",
      "iteration: 280180 loss: 0.0017 lr: 0.02\n",
      "iteration: 280190 loss: 0.0014 lr: 0.02\n",
      "iteration: 280200 loss: 0.0019 lr: 0.02\n",
      "iteration: 280210 loss: 0.0018 lr: 0.02\n",
      "iteration: 280220 loss: 0.0016 lr: 0.02\n",
      "iteration: 280230 loss: 0.0019 lr: 0.02\n",
      "iteration: 280240 loss: 0.0015 lr: 0.02\n",
      "iteration: 280250 loss: 0.0016 lr: 0.02\n",
      "iteration: 280260 loss: 0.0023 lr: 0.02\n",
      "iteration: 280270 loss: 0.0018 lr: 0.02\n",
      "iteration: 280280 loss: 0.0022 lr: 0.02\n",
      "iteration: 280290 loss: 0.0020 lr: 0.02\n",
      "iteration: 280300 loss: 0.0018 lr: 0.02\n",
      "iteration: 280310 loss: 0.0015 lr: 0.02\n",
      "iteration: 280320 loss: 0.0019 lr: 0.02\n",
      "iteration: 280330 loss: 0.0017 lr: 0.02\n",
      "iteration: 280340 loss: 0.0015 lr: 0.02\n",
      "iteration: 280350 loss: 0.0027 lr: 0.02\n",
      "iteration: 280360 loss: 0.0024 lr: 0.02\n",
      "iteration: 280370 loss: 0.0020 lr: 0.02\n",
      "iteration: 280380 loss: 0.0019 lr: 0.02\n",
      "iteration: 280390 loss: 0.0015 lr: 0.02\n",
      "iteration: 280400 loss: 0.0016 lr: 0.02\n",
      "iteration: 280410 loss: 0.0015 lr: 0.02\n",
      "iteration: 280420 loss: 0.0018 lr: 0.02\n",
      "iteration: 280430 loss: 0.0023 lr: 0.02\n",
      "iteration: 280440 loss: 0.0015 lr: 0.02\n",
      "iteration: 280450 loss: 0.0017 lr: 0.02\n",
      "iteration: 280460 loss: 0.0017 lr: 0.02\n",
      "iteration: 280470 loss: 0.0017 lr: 0.02\n",
      "iteration: 280480 loss: 0.0016 lr: 0.02\n",
      "iteration: 280490 loss: 0.0017 lr: 0.02\n",
      "iteration: 280500 loss: 0.0017 lr: 0.02\n",
      "iteration: 280510 loss: 0.0015 lr: 0.02\n",
      "iteration: 280520 loss: 0.0022 lr: 0.02\n",
      "iteration: 280530 loss: 0.0018 lr: 0.02\n",
      "iteration: 280540 loss: 0.0016 lr: 0.02\n",
      "iteration: 280550 loss: 0.0016 lr: 0.02\n",
      "iteration: 280560 loss: 0.0016 lr: 0.02\n",
      "iteration: 280570 loss: 0.0023 lr: 0.02\n",
      "iteration: 280580 loss: 0.0020 lr: 0.02\n",
      "iteration: 280590 loss: 0.0016 lr: 0.02\n",
      "iteration: 280600 loss: 0.0017 lr: 0.02\n",
      "iteration: 280610 loss: 0.0015 lr: 0.02\n",
      "iteration: 280620 loss: 0.0014 lr: 0.02\n",
      "iteration: 280630 loss: 0.0020 lr: 0.02\n",
      "iteration: 280640 loss: 0.0021 lr: 0.02\n",
      "iteration: 280650 loss: 0.0023 lr: 0.02\n",
      "iteration: 280660 loss: 0.0021 lr: 0.02\n",
      "iteration: 280670 loss: 0.0019 lr: 0.02\n",
      "iteration: 280680 loss: 0.0022 lr: 0.02\n",
      "iteration: 280690 loss: 0.0017 lr: 0.02\n",
      "iteration: 280700 loss: 0.0017 lr: 0.02\n",
      "iteration: 280710 loss: 0.0014 lr: 0.02\n",
      "iteration: 280720 loss: 0.0016 lr: 0.02\n",
      "iteration: 280730 loss: 0.0017 lr: 0.02\n",
      "iteration: 280740 loss: 0.0017 lr: 0.02\n",
      "iteration: 280750 loss: 0.0018 lr: 0.02\n",
      "iteration: 280760 loss: 0.0014 lr: 0.02\n",
      "iteration: 280770 loss: 0.0015 lr: 0.02\n",
      "iteration: 280780 loss: 0.0018 lr: 0.02\n",
      "iteration: 280790 loss: 0.0018 lr: 0.02\n",
      "iteration: 280800 loss: 0.0018 lr: 0.02\n",
      "iteration: 280810 loss: 0.0019 lr: 0.02\n",
      "iteration: 280820 loss: 0.0017 lr: 0.02\n",
      "iteration: 280830 loss: 0.0017 lr: 0.02\n",
      "iteration: 280840 loss: 0.0017 lr: 0.02\n",
      "iteration: 280850 loss: 0.0017 lr: 0.02\n",
      "iteration: 280860 loss: 0.0021 lr: 0.02\n",
      "iteration: 280870 loss: 0.0015 lr: 0.02\n",
      "iteration: 280880 loss: 0.0017 lr: 0.02\n",
      "iteration: 280890 loss: 0.0016 lr: 0.02\n",
      "iteration: 280900 loss: 0.0020 lr: 0.02\n",
      "iteration: 280910 loss: 0.0014 lr: 0.02\n",
      "iteration: 280920 loss: 0.0017 lr: 0.02\n",
      "iteration: 280930 loss: 0.0015 lr: 0.02\n",
      "iteration: 280940 loss: 0.0030 lr: 0.02\n",
      "iteration: 280950 loss: 0.0016 lr: 0.02\n",
      "iteration: 280960 loss: 0.0015 lr: 0.02\n",
      "iteration: 280970 loss: 0.0021 lr: 0.02\n",
      "iteration: 280980 loss: 0.0017 lr: 0.02\n",
      "iteration: 280990 loss: 0.0013 lr: 0.02\n",
      "iteration: 281000 loss: 0.0024 lr: 0.02\n",
      "iteration: 281010 loss: 0.0017 lr: 0.02\n",
      "iteration: 281020 loss: 0.0017 lr: 0.02\n",
      "iteration: 281030 loss: 0.0018 lr: 0.02\n",
      "iteration: 281040 loss: 0.0017 lr: 0.02\n",
      "iteration: 281050 loss: 0.0025 lr: 0.02\n",
      "iteration: 281060 loss: 0.0017 lr: 0.02\n",
      "iteration: 281070 loss: 0.0023 lr: 0.02\n",
      "iteration: 281080 loss: 0.0018 lr: 0.02\n",
      "iteration: 281090 loss: 0.0016 lr: 0.02\n",
      "iteration: 281100 loss: 0.0018 lr: 0.02\n",
      "iteration: 281110 loss: 0.0022 lr: 0.02\n",
      "iteration: 281120 loss: 0.0013 lr: 0.02\n",
      "iteration: 281130 loss: 0.0014 lr: 0.02\n",
      "iteration: 281140 loss: 0.0015 lr: 0.02\n",
      "iteration: 281150 loss: 0.0013 lr: 0.02\n",
      "iteration: 281160 loss: 0.0014 lr: 0.02\n",
      "iteration: 281170 loss: 0.0023 lr: 0.02\n",
      "iteration: 281180 loss: 0.0019 lr: 0.02\n",
      "iteration: 281190 loss: 0.0015 lr: 0.02\n",
      "iteration: 281200 loss: 0.0016 lr: 0.02\n",
      "iteration: 281210 loss: 0.0016 lr: 0.02\n",
      "iteration: 281220 loss: 0.0016 lr: 0.02\n",
      "iteration: 281230 loss: 0.0014 lr: 0.02\n",
      "iteration: 281240 loss: 0.0017 lr: 0.02\n",
      "iteration: 281250 loss: 0.0016 lr: 0.02\n",
      "iteration: 281260 loss: 0.0013 lr: 0.02\n",
      "iteration: 281270 loss: 0.0020 lr: 0.02\n",
      "iteration: 281280 loss: 0.0021 lr: 0.02\n",
      "iteration: 281290 loss: 0.0016 lr: 0.02\n",
      "iteration: 281300 loss: 0.0017 lr: 0.02\n",
      "iteration: 281310 loss: 0.0021 lr: 0.02\n",
      "iteration: 281320 loss: 0.0018 lr: 0.02\n",
      "iteration: 281330 loss: 0.0016 lr: 0.02\n",
      "iteration: 281340 loss: 0.0012 lr: 0.02\n",
      "iteration: 281350 loss: 0.0016 lr: 0.02\n",
      "iteration: 281360 loss: 0.0014 lr: 0.02\n",
      "iteration: 281370 loss: 0.0015 lr: 0.02\n",
      "iteration: 281380 loss: 0.0020 lr: 0.02\n",
      "iteration: 281390 loss: 0.0016 lr: 0.02\n",
      "iteration: 281400 loss: 0.0019 lr: 0.02\n",
      "iteration: 281410 loss: 0.0028 lr: 0.02\n",
      "iteration: 281420 loss: 0.0016 lr: 0.02\n",
      "iteration: 281430 loss: 0.0021 lr: 0.02\n",
      "iteration: 281440 loss: 0.0013 lr: 0.02\n",
      "iteration: 281450 loss: 0.0017 lr: 0.02\n",
      "iteration: 281460 loss: 0.0018 lr: 0.02\n",
      "iteration: 281470 loss: 0.0015 lr: 0.02\n",
      "iteration: 281480 loss: 0.0020 lr: 0.02\n",
      "iteration: 281490 loss: 0.0019 lr: 0.02\n",
      "iteration: 281500 loss: 0.0020 lr: 0.02\n",
      "iteration: 281510 loss: 0.0017 lr: 0.02\n",
      "iteration: 281520 loss: 0.0018 lr: 0.02\n",
      "iteration: 281530 loss: 0.0017 lr: 0.02\n",
      "iteration: 281540 loss: 0.0020 lr: 0.02\n",
      "iteration: 281550 loss: 0.0015 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 281560 loss: 0.0015 lr: 0.02\n",
      "iteration: 281570 loss: 0.0015 lr: 0.02\n",
      "iteration: 281580 loss: 0.0020 lr: 0.02\n",
      "iteration: 281590 loss: 0.0017 lr: 0.02\n",
      "iteration: 281600 loss: 0.0020 lr: 0.02\n",
      "iteration: 281610 loss: 0.0019 lr: 0.02\n",
      "iteration: 281620 loss: 0.0019 lr: 0.02\n",
      "iteration: 281630 loss: 0.0018 lr: 0.02\n",
      "iteration: 281640 loss: 0.0024 lr: 0.02\n",
      "iteration: 281650 loss: 0.0014 lr: 0.02\n",
      "iteration: 281660 loss: 0.0012 lr: 0.02\n",
      "iteration: 281670 loss: 0.0023 lr: 0.02\n",
      "iteration: 281680 loss: 0.0014 lr: 0.02\n",
      "iteration: 281690 loss: 0.0019 lr: 0.02\n",
      "iteration: 281700 loss: 0.0016 lr: 0.02\n",
      "iteration: 281710 loss: 0.0014 lr: 0.02\n",
      "iteration: 281720 loss: 0.0019 lr: 0.02\n",
      "iteration: 281730 loss: 0.0015 lr: 0.02\n",
      "iteration: 281740 loss: 0.0015 lr: 0.02\n",
      "iteration: 281750 loss: 0.0012 lr: 0.02\n",
      "iteration: 281760 loss: 0.0014 lr: 0.02\n",
      "iteration: 281770 loss: 0.0016 lr: 0.02\n",
      "iteration: 281780 loss: 0.0017 lr: 0.02\n",
      "iteration: 281790 loss: 0.0019 lr: 0.02\n",
      "iteration: 281800 loss: 0.0020 lr: 0.02\n",
      "iteration: 281810 loss: 0.0018 lr: 0.02\n",
      "iteration: 281820 loss: 0.0019 lr: 0.02\n",
      "iteration: 281830 loss: 0.0017 lr: 0.02\n",
      "iteration: 281840 loss: 0.0016 lr: 0.02\n",
      "iteration: 281850 loss: 0.0022 lr: 0.02\n",
      "iteration: 281860 loss: 0.0019 lr: 0.02\n",
      "iteration: 281870 loss: 0.0017 lr: 0.02\n",
      "iteration: 281880 loss: 0.0016 lr: 0.02\n",
      "iteration: 281890 loss: 0.0019 lr: 0.02\n",
      "iteration: 281900 loss: 0.0012 lr: 0.02\n",
      "iteration: 281910 loss: 0.0019 lr: 0.02\n",
      "iteration: 281920 loss: 0.0019 lr: 0.02\n",
      "iteration: 281930 loss: 0.0018 lr: 0.02\n",
      "iteration: 281940 loss: 0.0023 lr: 0.02\n",
      "iteration: 281950 loss: 0.0014 lr: 0.02\n",
      "iteration: 281960 loss: 0.0016 lr: 0.02\n",
      "iteration: 281970 loss: 0.0016 lr: 0.02\n",
      "iteration: 281980 loss: 0.0019 lr: 0.02\n",
      "iteration: 281990 loss: 0.0015 lr: 0.02\n",
      "iteration: 282000 loss: 0.0013 lr: 0.02\n",
      "iteration: 282010 loss: 0.0021 lr: 0.02\n",
      "iteration: 282020 loss: 0.0012 lr: 0.02\n",
      "iteration: 282030 loss: 0.0023 lr: 0.02\n",
      "iteration: 282040 loss: 0.0018 lr: 0.02\n",
      "iteration: 282050 loss: 0.0017 lr: 0.02\n",
      "iteration: 282060 loss: 0.0019 lr: 0.02\n",
      "iteration: 282070 loss: 0.0017 lr: 0.02\n",
      "iteration: 282080 loss: 0.0018 lr: 0.02\n",
      "iteration: 282090 loss: 0.0015 lr: 0.02\n",
      "iteration: 282100 loss: 0.0023 lr: 0.02\n",
      "iteration: 282110 loss: 0.0015 lr: 0.02\n",
      "iteration: 282120 loss: 0.0018 lr: 0.02\n",
      "iteration: 282130 loss: 0.0021 lr: 0.02\n",
      "iteration: 282140 loss: 0.0018 lr: 0.02\n",
      "iteration: 282150 loss: 0.0015 lr: 0.02\n",
      "iteration: 282160 loss: 0.0018 lr: 0.02\n",
      "iteration: 282170 loss: 0.0013 lr: 0.02\n",
      "iteration: 282180 loss: 0.0018 lr: 0.02\n",
      "iteration: 282190 loss: 0.0019 lr: 0.02\n",
      "iteration: 282200 loss: 0.0017 lr: 0.02\n",
      "iteration: 282210 loss: 0.0015 lr: 0.02\n",
      "iteration: 282220 loss: 0.0018 lr: 0.02\n",
      "iteration: 282230 loss: 0.0019 lr: 0.02\n",
      "iteration: 282240 loss: 0.0014 lr: 0.02\n",
      "iteration: 282250 loss: 0.0021 lr: 0.02\n",
      "iteration: 282260 loss: 0.0017 lr: 0.02\n",
      "iteration: 282270 loss: 0.0015 lr: 0.02\n",
      "iteration: 282280 loss: 0.0016 lr: 0.02\n",
      "iteration: 282290 loss: 0.0015 lr: 0.02\n",
      "iteration: 282300 loss: 0.0017 lr: 0.02\n",
      "iteration: 282310 loss: 0.0017 lr: 0.02\n",
      "iteration: 282320 loss: 0.0018 lr: 0.02\n",
      "iteration: 282330 loss: 0.0014 lr: 0.02\n",
      "iteration: 282340 loss: 0.0015 lr: 0.02\n",
      "iteration: 282350 loss: 0.0015 lr: 0.02\n",
      "iteration: 282360 loss: 0.0015 lr: 0.02\n",
      "iteration: 282370 loss: 0.0018 lr: 0.02\n",
      "iteration: 282380 loss: 0.0017 lr: 0.02\n",
      "iteration: 282390 loss: 0.0022 lr: 0.02\n",
      "iteration: 282400 loss: 0.0023 lr: 0.02\n",
      "iteration: 282410 loss: 0.0018 lr: 0.02\n",
      "iteration: 282420 loss: 0.0016 lr: 0.02\n",
      "iteration: 282430 loss: 0.0020 lr: 0.02\n",
      "iteration: 282440 loss: 0.0018 lr: 0.02\n",
      "iteration: 282450 loss: 0.0018 lr: 0.02\n",
      "iteration: 282460 loss: 0.0015 lr: 0.02\n",
      "iteration: 282470 loss: 0.0020 lr: 0.02\n",
      "iteration: 282480 loss: 0.0019 lr: 0.02\n",
      "iteration: 282490 loss: 0.0018 lr: 0.02\n",
      "iteration: 282500 loss: 0.0019 lr: 0.02\n",
      "iteration: 282510 loss: 0.0016 lr: 0.02\n",
      "iteration: 282520 loss: 0.0018 lr: 0.02\n",
      "iteration: 282530 loss: 0.0018 lr: 0.02\n",
      "iteration: 282540 loss: 0.0018 lr: 0.02\n",
      "iteration: 282550 loss: 0.0016 lr: 0.02\n",
      "iteration: 282560 loss: 0.0014 lr: 0.02\n",
      "iteration: 282570 loss: 0.0019 lr: 0.02\n",
      "iteration: 282580 loss: 0.0019 lr: 0.02\n",
      "iteration: 282590 loss: 0.0017 lr: 0.02\n",
      "iteration: 282600 loss: 0.0018 lr: 0.02\n",
      "iteration: 282610 loss: 0.0022 lr: 0.02\n",
      "iteration: 282620 loss: 0.0021 lr: 0.02\n",
      "iteration: 282630 loss: 0.0013 lr: 0.02\n",
      "iteration: 282640 loss: 0.0015 lr: 0.02\n",
      "iteration: 282650 loss: 0.0016 lr: 0.02\n",
      "iteration: 282660 loss: 0.0019 lr: 0.02\n",
      "iteration: 282670 loss: 0.0017 lr: 0.02\n",
      "iteration: 282680 loss: 0.0020 lr: 0.02\n",
      "iteration: 282690 loss: 0.0020 lr: 0.02\n",
      "iteration: 282700 loss: 0.0014 lr: 0.02\n",
      "iteration: 282710 loss: 0.0017 lr: 0.02\n",
      "iteration: 282720 loss: 0.0018 lr: 0.02\n",
      "iteration: 282730 loss: 0.0018 lr: 0.02\n",
      "iteration: 282740 loss: 0.0021 lr: 0.02\n",
      "iteration: 282750 loss: 0.0014 lr: 0.02\n",
      "iteration: 282760 loss: 0.0018 lr: 0.02\n",
      "iteration: 282770 loss: 0.0017 lr: 0.02\n",
      "iteration: 282780 loss: 0.0016 lr: 0.02\n",
      "iteration: 282790 loss: 0.0017 lr: 0.02\n",
      "iteration: 282800 loss: 0.0018 lr: 0.02\n",
      "iteration: 282810 loss: 0.0021 lr: 0.02\n",
      "iteration: 282820 loss: 0.0020 lr: 0.02\n",
      "iteration: 282830 loss: 0.0017 lr: 0.02\n",
      "iteration: 282840 loss: 0.0016 lr: 0.02\n",
      "iteration: 282850 loss: 0.0014 lr: 0.02\n",
      "iteration: 282860 loss: 0.0019 lr: 0.02\n",
      "iteration: 282870 loss: 0.0014 lr: 0.02\n",
      "iteration: 282880 loss: 0.0013 lr: 0.02\n",
      "iteration: 282890 loss: 0.0019 lr: 0.02\n",
      "iteration: 282900 loss: 0.0017 lr: 0.02\n",
      "iteration: 282910 loss: 0.0017 lr: 0.02\n",
      "iteration: 282920 loss: 0.0021 lr: 0.02\n",
      "iteration: 282930 loss: 0.0018 lr: 0.02\n",
      "iteration: 282940 loss: 0.0016 lr: 0.02\n",
      "iteration: 282950 loss: 0.0020 lr: 0.02\n",
      "iteration: 282960 loss: 0.0015 lr: 0.02\n",
      "iteration: 282970 loss: 0.0017 lr: 0.02\n",
      "iteration: 282980 loss: 0.0014 lr: 0.02\n",
      "iteration: 282990 loss: 0.0016 lr: 0.02\n",
      "iteration: 283000 loss: 0.0019 lr: 0.02\n",
      "iteration: 283010 loss: 0.0019 lr: 0.02\n",
      "iteration: 283020 loss: 0.0015 lr: 0.02\n",
      "iteration: 283030 loss: 0.0017 lr: 0.02\n",
      "iteration: 283040 loss: 0.0016 lr: 0.02\n",
      "iteration: 283050 loss: 0.0021 lr: 0.02\n",
      "iteration: 283060 loss: 0.0016 lr: 0.02\n",
      "iteration: 283070 loss: 0.0019 lr: 0.02\n",
      "iteration: 283080 loss: 0.0018 lr: 0.02\n",
      "iteration: 283090 loss: 0.0020 lr: 0.02\n",
      "iteration: 283100 loss: 0.0012 lr: 0.02\n",
      "iteration: 283110 loss: 0.0022 lr: 0.02\n",
      "iteration: 283120 loss: 0.0023 lr: 0.02\n",
      "iteration: 283130 loss: 0.0018 lr: 0.02\n",
      "iteration: 283140 loss: 0.0014 lr: 0.02\n",
      "iteration: 283150 loss: 0.0018 lr: 0.02\n",
      "iteration: 283160 loss: 0.0018 lr: 0.02\n",
      "iteration: 283170 loss: 0.0015 lr: 0.02\n",
      "iteration: 283180 loss: 0.0017 lr: 0.02\n",
      "iteration: 283190 loss: 0.0022 lr: 0.02\n",
      "iteration: 283200 loss: 0.0024 lr: 0.02\n",
      "iteration: 283210 loss: 0.0018 lr: 0.02\n",
      "iteration: 283220 loss: 0.0017 lr: 0.02\n",
      "iteration: 283230 loss: 0.0021 lr: 0.02\n",
      "iteration: 283240 loss: 0.0022 lr: 0.02\n",
      "iteration: 283250 loss: 0.0018 lr: 0.02\n",
      "iteration: 283260 loss: 0.0018 lr: 0.02\n",
      "iteration: 283270 loss: 0.0013 lr: 0.02\n",
      "iteration: 283280 loss: 0.0015 lr: 0.02\n",
      "iteration: 283290 loss: 0.0015 lr: 0.02\n",
      "iteration: 283300 loss: 0.0015 lr: 0.02\n",
      "iteration: 283310 loss: 0.0019 lr: 0.02\n",
      "iteration: 283320 loss: 0.0017 lr: 0.02\n",
      "iteration: 283330 loss: 0.0023 lr: 0.02\n",
      "iteration: 283340 loss: 0.0020 lr: 0.02\n",
      "iteration: 283350 loss: 0.0021 lr: 0.02\n",
      "iteration: 283360 loss: 0.0019 lr: 0.02\n",
      "iteration: 283370 loss: 0.0014 lr: 0.02\n",
      "iteration: 283380 loss: 0.0016 lr: 0.02\n",
      "iteration: 283390 loss: 0.0018 lr: 0.02\n",
      "iteration: 283400 loss: 0.0020 lr: 0.02\n",
      "iteration: 283410 loss: 0.0019 lr: 0.02\n",
      "iteration: 283420 loss: 0.0018 lr: 0.02\n",
      "iteration: 283430 loss: 0.0026 lr: 0.02\n",
      "iteration: 283440 loss: 0.0016 lr: 0.02\n",
      "iteration: 283450 loss: 0.0013 lr: 0.02\n",
      "iteration: 283460 loss: 0.0024 lr: 0.02\n",
      "iteration: 283470 loss: 0.0016 lr: 0.02\n",
      "iteration: 283480 loss: 0.0019 lr: 0.02\n",
      "iteration: 283490 loss: 0.0016 lr: 0.02\n",
      "iteration: 283500 loss: 0.0016 lr: 0.02\n",
      "iteration: 283510 loss: 0.0018 lr: 0.02\n",
      "iteration: 283520 loss: 0.0025 lr: 0.02\n",
      "iteration: 283530 loss: 0.0016 lr: 0.02\n",
      "iteration: 283540 loss: 0.0015 lr: 0.02\n",
      "iteration: 283550 loss: 0.0021 lr: 0.02\n",
      "iteration: 283560 loss: 0.0023 lr: 0.02\n",
      "iteration: 283570 loss: 0.0024 lr: 0.02\n",
      "iteration: 283580 loss: 0.0013 lr: 0.02\n",
      "iteration: 283590 loss: 0.0014 lr: 0.02\n",
      "iteration: 283600 loss: 0.0017 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 283610 loss: 0.0019 lr: 0.02\n",
      "iteration: 283620 loss: 0.0016 lr: 0.02\n",
      "iteration: 283630 loss: 0.0022 lr: 0.02\n",
      "iteration: 283640 loss: 0.0016 lr: 0.02\n",
      "iteration: 283650 loss: 0.0017 lr: 0.02\n",
      "iteration: 283660 loss: 0.0017 lr: 0.02\n",
      "iteration: 283670 loss: 0.0015 lr: 0.02\n",
      "iteration: 283680 loss: 0.0019 lr: 0.02\n",
      "iteration: 283690 loss: 0.0015 lr: 0.02\n",
      "iteration: 283700 loss: 0.0014 lr: 0.02\n",
      "iteration: 283710 loss: 0.0022 lr: 0.02\n",
      "iteration: 283720 loss: 0.0020 lr: 0.02\n",
      "iteration: 283730 loss: 0.0017 lr: 0.02\n",
      "iteration: 283740 loss: 0.0014 lr: 0.02\n",
      "iteration: 283750 loss: 0.0016 lr: 0.02\n",
      "iteration: 283760 loss: 0.0018 lr: 0.02\n",
      "iteration: 283770 loss: 0.0023 lr: 0.02\n",
      "iteration: 283780 loss: 0.0020 lr: 0.02\n",
      "iteration: 283790 loss: 0.0022 lr: 0.02\n",
      "iteration: 283800 loss: 0.0015 lr: 0.02\n",
      "iteration: 283810 loss: 0.0016 lr: 0.02\n",
      "iteration: 283820 loss: 0.0016 lr: 0.02\n",
      "iteration: 283830 loss: 0.0014 lr: 0.02\n",
      "iteration: 283840 loss: 0.0016 lr: 0.02\n",
      "iteration: 283850 loss: 0.0017 lr: 0.02\n",
      "iteration: 283860 loss: 0.0020 lr: 0.02\n",
      "iteration: 283870 loss: 0.0020 lr: 0.02\n",
      "iteration: 283880 loss: 0.0019 lr: 0.02\n",
      "iteration: 283890 loss: 0.0020 lr: 0.02\n",
      "iteration: 283900 loss: 0.0017 lr: 0.02\n",
      "iteration: 283910 loss: 0.0019 lr: 0.02\n",
      "iteration: 283920 loss: 0.0016 lr: 0.02\n",
      "iteration: 283930 loss: 0.0012 lr: 0.02\n",
      "iteration: 283940 loss: 0.0015 lr: 0.02\n",
      "iteration: 283950 loss: 0.0014 lr: 0.02\n",
      "iteration: 283960 loss: 0.0015 lr: 0.02\n",
      "iteration: 283970 loss: 0.0020 lr: 0.02\n",
      "iteration: 283980 loss: 0.0021 lr: 0.02\n",
      "iteration: 283990 loss: 0.0014 lr: 0.02\n",
      "iteration: 284000 loss: 0.0018 lr: 0.02\n",
      "iteration: 284010 loss: 0.0019 lr: 0.02\n",
      "iteration: 284020 loss: 0.0020 lr: 0.02\n",
      "iteration: 284030 loss: 0.0016 lr: 0.02\n",
      "iteration: 284040 loss: 0.0015 lr: 0.02\n",
      "iteration: 284050 loss: 0.0019 lr: 0.02\n",
      "iteration: 284060 loss: 0.0018 lr: 0.02\n",
      "iteration: 284070 loss: 0.0016 lr: 0.02\n",
      "iteration: 284080 loss: 0.0016 lr: 0.02\n",
      "iteration: 284090 loss: 0.0016 lr: 0.02\n",
      "iteration: 284100 loss: 0.0018 lr: 0.02\n",
      "iteration: 284110 loss: 0.0019 lr: 0.02\n",
      "iteration: 284120 loss: 0.0016 lr: 0.02\n",
      "iteration: 284130 loss: 0.0023 lr: 0.02\n",
      "iteration: 284140 loss: 0.0023 lr: 0.02\n",
      "iteration: 284150 loss: 0.0013 lr: 0.02\n",
      "iteration: 284160 loss: 0.0015 lr: 0.02\n",
      "iteration: 284170 loss: 0.0015 lr: 0.02\n",
      "iteration: 284180 loss: 0.0020 lr: 0.02\n",
      "iteration: 284190 loss: 0.0018 lr: 0.02\n",
      "iteration: 284200 loss: 0.0021 lr: 0.02\n",
      "iteration: 284210 loss: 0.0013 lr: 0.02\n",
      "iteration: 284220 loss: 0.0017 lr: 0.02\n",
      "iteration: 284230 loss: 0.0015 lr: 0.02\n",
      "iteration: 284240 loss: 0.0015 lr: 0.02\n",
      "iteration: 284250 loss: 0.0016 lr: 0.02\n",
      "iteration: 284260 loss: 0.0016 lr: 0.02\n",
      "iteration: 284270 loss: 0.0014 lr: 0.02\n",
      "iteration: 284280 loss: 0.0019 lr: 0.02\n",
      "iteration: 284290 loss: 0.0019 lr: 0.02\n",
      "iteration: 284300 loss: 0.0018 lr: 0.02\n",
      "iteration: 284310 loss: 0.0018 lr: 0.02\n",
      "iteration: 284320 loss: 0.0017 lr: 0.02\n",
      "iteration: 284330 loss: 0.0024 lr: 0.02\n",
      "iteration: 284340 loss: 0.0019 lr: 0.02\n",
      "iteration: 284350 loss: 0.0023 lr: 0.02\n",
      "iteration: 284360 loss: 0.0022 lr: 0.02\n",
      "iteration: 284370 loss: 0.0020 lr: 0.02\n",
      "iteration: 284380 loss: 0.0017 lr: 0.02\n",
      "iteration: 284390 loss: 0.0016 lr: 0.02\n",
      "iteration: 284400 loss: 0.0014 lr: 0.02\n",
      "iteration: 284410 loss: 0.0016 lr: 0.02\n",
      "iteration: 284420 loss: 0.0021 lr: 0.02\n",
      "iteration: 284430 loss: 0.0014 lr: 0.02\n",
      "iteration: 284440 loss: 0.0017 lr: 0.02\n",
      "iteration: 284450 loss: 0.0020 lr: 0.02\n",
      "iteration: 284460 loss: 0.0018 lr: 0.02\n",
      "iteration: 284470 loss: 0.0015 lr: 0.02\n",
      "iteration: 284480 loss: 0.0018 lr: 0.02\n",
      "iteration: 284490 loss: 0.0016 lr: 0.02\n",
      "iteration: 284500 loss: 0.0015 lr: 0.02\n",
      "iteration: 284510 loss: 0.0019 lr: 0.02\n",
      "iteration: 284520 loss: 0.0014 lr: 0.02\n",
      "iteration: 284530 loss: 0.0019 lr: 0.02\n",
      "iteration: 284540 loss: 0.0019 lr: 0.02\n",
      "iteration: 284550 loss: 0.0016 lr: 0.02\n",
      "iteration: 284560 loss: 0.0022 lr: 0.02\n",
      "iteration: 284570 loss: 0.0016 lr: 0.02\n",
      "iteration: 284580 loss: 0.0017 lr: 0.02\n",
      "iteration: 284590 loss: 0.0024 lr: 0.02\n",
      "iteration: 284600 loss: 0.0025 lr: 0.02\n",
      "iteration: 284610 loss: 0.0018 lr: 0.02\n",
      "iteration: 284620 loss: 0.0018 lr: 0.02\n",
      "iteration: 284630 loss: 0.0022 lr: 0.02\n",
      "iteration: 284640 loss: 0.0016 lr: 0.02\n",
      "iteration: 284650 loss: 0.0018 lr: 0.02\n",
      "iteration: 284660 loss: 0.0023 lr: 0.02\n",
      "iteration: 284670 loss: 0.0015 lr: 0.02\n",
      "iteration: 284680 loss: 0.0018 lr: 0.02\n",
      "iteration: 284690 loss: 0.0016 lr: 0.02\n",
      "iteration: 284700 loss: 0.0023 lr: 0.02\n",
      "iteration: 284710 loss: 0.0017 lr: 0.02\n",
      "iteration: 284720 loss: 0.0022 lr: 0.02\n",
      "iteration: 284730 loss: 0.0015 lr: 0.02\n",
      "iteration: 284740 loss: 0.0016 lr: 0.02\n",
      "iteration: 284750 loss: 0.0019 lr: 0.02\n",
      "iteration: 284760 loss: 0.0016 lr: 0.02\n",
      "iteration: 284770 loss: 0.0017 lr: 0.02\n",
      "iteration: 284780 loss: 0.0015 lr: 0.02\n",
      "iteration: 284790 loss: 0.0015 lr: 0.02\n",
      "iteration: 284800 loss: 0.0018 lr: 0.02\n",
      "iteration: 284810 loss: 0.0015 lr: 0.02\n",
      "iteration: 284820 loss: 0.0016 lr: 0.02\n",
      "iteration: 284830 loss: 0.0019 lr: 0.02\n",
      "iteration: 284840 loss: 0.0017 lr: 0.02\n",
      "iteration: 284850 loss: 0.0021 lr: 0.02\n",
      "iteration: 284860 loss: 0.0017 lr: 0.02\n",
      "iteration: 284870 loss: 0.0014 lr: 0.02\n",
      "iteration: 284880 loss: 0.0021 lr: 0.02\n",
      "iteration: 284890 loss: 0.0014 lr: 0.02\n",
      "iteration: 284900 loss: 0.0015 lr: 0.02\n",
      "iteration: 284910 loss: 0.0015 lr: 0.02\n",
      "iteration: 284920 loss: 0.0014 lr: 0.02\n",
      "iteration: 284930 loss: 0.0026 lr: 0.02\n",
      "iteration: 284940 loss: 0.0015 lr: 0.02\n",
      "iteration: 284950 loss: 0.0012 lr: 0.02\n",
      "iteration: 284960 loss: 0.0012 lr: 0.02\n",
      "iteration: 284970 loss: 0.0016 lr: 0.02\n",
      "iteration: 284980 loss: 0.0020 lr: 0.02\n",
      "iteration: 284990 loss: 0.0015 lr: 0.02\n",
      "iteration: 285000 loss: 0.0015 lr: 0.02\n",
      "iteration: 285010 loss: 0.0016 lr: 0.02\n",
      "iteration: 285020 loss: 0.0011 lr: 0.02\n",
      "iteration: 285030 loss: 0.0019 lr: 0.02\n",
      "iteration: 285040 loss: 0.0016 lr: 0.02\n",
      "iteration: 285050 loss: 0.0017 lr: 0.02\n",
      "iteration: 285060 loss: 0.0024 lr: 0.02\n",
      "iteration: 285070 loss: 0.0018 lr: 0.02\n",
      "iteration: 285080 loss: 0.0019 lr: 0.02\n",
      "iteration: 285090 loss: 0.0017 lr: 0.02\n",
      "iteration: 285100 loss: 0.0020 lr: 0.02\n",
      "iteration: 285110 loss: 0.0019 lr: 0.02\n",
      "iteration: 285120 loss: 0.0013 lr: 0.02\n",
      "iteration: 285130 loss: 0.0022 lr: 0.02\n",
      "iteration: 285140 loss: 0.0022 lr: 0.02\n",
      "iteration: 285150 loss: 0.0026 lr: 0.02\n",
      "iteration: 285160 loss: 0.0020 lr: 0.02\n",
      "iteration: 285170 loss: 0.0023 lr: 0.02\n",
      "iteration: 285180 loss: 0.0021 lr: 0.02\n",
      "iteration: 285190 loss: 0.0022 lr: 0.02\n",
      "iteration: 285200 loss: 0.0014 lr: 0.02\n",
      "iteration: 285210 loss: 0.0019 lr: 0.02\n",
      "iteration: 285220 loss: 0.0016 lr: 0.02\n",
      "iteration: 285230 loss: 0.0017 lr: 0.02\n",
      "iteration: 285240 loss: 0.0022 lr: 0.02\n",
      "iteration: 285250 loss: 0.0014 lr: 0.02\n",
      "iteration: 285260 loss: 0.0021 lr: 0.02\n",
      "iteration: 285270 loss: 0.0017 lr: 0.02\n",
      "iteration: 285280 loss: 0.0019 lr: 0.02\n",
      "iteration: 285290 loss: 0.0017 lr: 0.02\n",
      "iteration: 285300 loss: 0.0014 lr: 0.02\n",
      "iteration: 285310 loss: 0.0018 lr: 0.02\n",
      "iteration: 285320 loss: 0.0013 lr: 0.02\n",
      "iteration: 285330 loss: 0.0024 lr: 0.02\n",
      "iteration: 285340 loss: 0.0017 lr: 0.02\n",
      "iteration: 285350 loss: 0.0019 lr: 0.02\n",
      "iteration: 285360 loss: 0.0016 lr: 0.02\n",
      "iteration: 285370 loss: 0.0015 lr: 0.02\n",
      "iteration: 285380 loss: 0.0016 lr: 0.02\n",
      "iteration: 285390 loss: 0.0015 lr: 0.02\n",
      "iteration: 285400 loss: 0.0018 lr: 0.02\n",
      "iteration: 285410 loss: 0.0017 lr: 0.02\n",
      "iteration: 285420 loss: 0.0016 lr: 0.02\n",
      "iteration: 285430 loss: 0.0019 lr: 0.02\n",
      "iteration: 285440 loss: 0.0020 lr: 0.02\n",
      "iteration: 285450 loss: 0.0017 lr: 0.02\n",
      "iteration: 285460 loss: 0.0018 lr: 0.02\n",
      "iteration: 285470 loss: 0.0019 lr: 0.02\n",
      "iteration: 285480 loss: 0.0019 lr: 0.02\n",
      "iteration: 285490 loss: 0.0016 lr: 0.02\n",
      "iteration: 285500 loss: 0.0016 lr: 0.02\n",
      "iteration: 285510 loss: 0.0025 lr: 0.02\n",
      "iteration: 285520 loss: 0.0019 lr: 0.02\n",
      "iteration: 285530 loss: 0.0013 lr: 0.02\n",
      "iteration: 285540 loss: 0.0014 lr: 0.02\n",
      "iteration: 285550 loss: 0.0018 lr: 0.02\n",
      "iteration: 285560 loss: 0.0015 lr: 0.02\n",
      "iteration: 285570 loss: 0.0013 lr: 0.02\n",
      "iteration: 285580 loss: 0.0021 lr: 0.02\n",
      "iteration: 285590 loss: 0.0019 lr: 0.02\n",
      "iteration: 285600 loss: 0.0014 lr: 0.02\n",
      "iteration: 285610 loss: 0.0011 lr: 0.02\n",
      "iteration: 285620 loss: 0.0017 lr: 0.02\n",
      "iteration: 285630 loss: 0.0017 lr: 0.02\n",
      "iteration: 285640 loss: 0.0024 lr: 0.02\n",
      "iteration: 285650 loss: 0.0014 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 285660 loss: 0.0022 lr: 0.02\n",
      "iteration: 285670 loss: 0.0017 lr: 0.02\n",
      "iteration: 285680 loss: 0.0019 lr: 0.02\n",
      "iteration: 285690 loss: 0.0018 lr: 0.02\n",
      "iteration: 285700 loss: 0.0016 lr: 0.02\n",
      "iteration: 285710 loss: 0.0014 lr: 0.02\n",
      "iteration: 285720 loss: 0.0018 lr: 0.02\n",
      "iteration: 285730 loss: 0.0019 lr: 0.02\n",
      "iteration: 285740 loss: 0.0015 lr: 0.02\n",
      "iteration: 285750 loss: 0.0019 lr: 0.02\n",
      "iteration: 285760 loss: 0.0017 lr: 0.02\n",
      "iteration: 285770 loss: 0.0014 lr: 0.02\n",
      "iteration: 285780 loss: 0.0017 lr: 0.02\n",
      "iteration: 285790 loss: 0.0016 lr: 0.02\n",
      "iteration: 285800 loss: 0.0020 lr: 0.02\n",
      "iteration: 285810 loss: 0.0016 lr: 0.02\n",
      "iteration: 285820 loss: 0.0016 lr: 0.02\n",
      "iteration: 285830 loss: 0.0022 lr: 0.02\n",
      "iteration: 285840 loss: 0.0019 lr: 0.02\n",
      "iteration: 285850 loss: 0.0015 lr: 0.02\n",
      "iteration: 285860 loss: 0.0018 lr: 0.02\n",
      "iteration: 285870 loss: 0.0018 lr: 0.02\n",
      "iteration: 285880 loss: 0.0014 lr: 0.02\n",
      "iteration: 285890 loss: 0.0017 lr: 0.02\n",
      "iteration: 285900 loss: 0.0017 lr: 0.02\n",
      "iteration: 285910 loss: 0.0017 lr: 0.02\n",
      "iteration: 285920 loss: 0.0019 lr: 0.02\n",
      "iteration: 285930 loss: 0.0019 lr: 0.02\n",
      "iteration: 285940 loss: 0.0017 lr: 0.02\n",
      "iteration: 285950 loss: 0.0022 lr: 0.02\n",
      "iteration: 285960 loss: 0.0022 lr: 0.02\n",
      "iteration: 285970 loss: 0.0019 lr: 0.02\n",
      "iteration: 285980 loss: 0.0024 lr: 0.02\n",
      "iteration: 285990 loss: 0.0021 lr: 0.02\n",
      "iteration: 286000 loss: 0.0019 lr: 0.02\n",
      "iteration: 286010 loss: 0.0018 lr: 0.02\n",
      "iteration: 286020 loss: 0.0021 lr: 0.02\n",
      "iteration: 286030 loss: 0.0022 lr: 0.02\n",
      "iteration: 286040 loss: 0.0026 lr: 0.02\n",
      "iteration: 286050 loss: 0.0018 lr: 0.02\n",
      "iteration: 286060 loss: 0.0016 lr: 0.02\n",
      "iteration: 286070 loss: 0.0017 lr: 0.02\n",
      "iteration: 286080 loss: 0.0016 lr: 0.02\n",
      "iteration: 286090 loss: 0.0021 lr: 0.02\n",
      "iteration: 286100 loss: 0.0020 lr: 0.02\n",
      "iteration: 286110 loss: 0.0015 lr: 0.02\n",
      "iteration: 286120 loss: 0.0015 lr: 0.02\n",
      "iteration: 286130 loss: 0.0020 lr: 0.02\n",
      "iteration: 286140 loss: 0.0014 lr: 0.02\n",
      "iteration: 286150 loss: 0.0023 lr: 0.02\n",
      "iteration: 286160 loss: 0.0015 lr: 0.02\n",
      "iteration: 286170 loss: 0.0018 lr: 0.02\n",
      "iteration: 286180 loss: 0.0016 lr: 0.02\n",
      "iteration: 286190 loss: 0.0019 lr: 0.02\n",
      "iteration: 286200 loss: 0.0020 lr: 0.02\n",
      "iteration: 286210 loss: 0.0018 lr: 0.02\n",
      "iteration: 286220 loss: 0.0018 lr: 0.02\n",
      "iteration: 286230 loss: 0.0016 lr: 0.02\n",
      "iteration: 286240 loss: 0.0021 lr: 0.02\n",
      "iteration: 286250 loss: 0.0022 lr: 0.02\n",
      "iteration: 286260 loss: 0.0019 lr: 0.02\n",
      "iteration: 286270 loss: 0.0021 lr: 0.02\n",
      "iteration: 286280 loss: 0.0014 lr: 0.02\n",
      "iteration: 286290 loss: 0.0023 lr: 0.02\n",
      "iteration: 286300 loss: 0.0014 lr: 0.02\n",
      "iteration: 286310 loss: 0.0012 lr: 0.02\n",
      "iteration: 286320 loss: 0.0020 lr: 0.02\n",
      "iteration: 286330 loss: 0.0019 lr: 0.02\n",
      "iteration: 286340 loss: 0.0018 lr: 0.02\n",
      "iteration: 286350 loss: 0.0018 lr: 0.02\n",
      "iteration: 286360 loss: 0.0019 lr: 0.02\n",
      "iteration: 286370 loss: 0.0017 lr: 0.02\n",
      "iteration: 286380 loss: 0.0016 lr: 0.02\n",
      "iteration: 286390 loss: 0.0015 lr: 0.02\n",
      "iteration: 286400 loss: 0.0016 lr: 0.02\n",
      "iteration: 286410 loss: 0.0018 lr: 0.02\n",
      "iteration: 286420 loss: 0.0015 lr: 0.02\n",
      "iteration: 286430 loss: 0.0016 lr: 0.02\n",
      "iteration: 286440 loss: 0.0018 lr: 0.02\n",
      "iteration: 286450 loss: 0.0024 lr: 0.02\n",
      "iteration: 286460 loss: 0.0017 lr: 0.02\n",
      "iteration: 286470 loss: 0.0018 lr: 0.02\n",
      "iteration: 286480 loss: 0.0026 lr: 0.02\n",
      "iteration: 286490 loss: 0.0016 lr: 0.02\n",
      "iteration: 286500 loss: 0.0032 lr: 0.02\n",
      "iteration: 286510 loss: 0.0021 lr: 0.02\n",
      "iteration: 286520 loss: 0.0021 lr: 0.02\n",
      "iteration: 286530 loss: 0.0013 lr: 0.02\n",
      "iteration: 286540 loss: 0.0016 lr: 0.02\n",
      "iteration: 286550 loss: 0.0014 lr: 0.02\n",
      "iteration: 286560 loss: 0.0017 lr: 0.02\n",
      "iteration: 286570 loss: 0.0015 lr: 0.02\n",
      "iteration: 286580 loss: 0.0016 lr: 0.02\n",
      "iteration: 286590 loss: 0.0015 lr: 0.02\n",
      "iteration: 286600 loss: 0.0015 lr: 0.02\n",
      "iteration: 286610 loss: 0.0016 lr: 0.02\n",
      "iteration: 286620 loss: 0.0017 lr: 0.02\n",
      "iteration: 286630 loss: 0.0021 lr: 0.02\n",
      "iteration: 286640 loss: 0.0020 lr: 0.02\n",
      "iteration: 286650 loss: 0.0018 lr: 0.02\n",
      "iteration: 286660 loss: 0.0014 lr: 0.02\n",
      "iteration: 286670 loss: 0.0018 lr: 0.02\n",
      "iteration: 286680 loss: 0.0019 lr: 0.02\n",
      "iteration: 286690 loss: 0.0017 lr: 0.02\n",
      "iteration: 286700 loss: 0.0016 lr: 0.02\n",
      "iteration: 286710 loss: 0.0021 lr: 0.02\n",
      "iteration: 286720 loss: 0.0019 lr: 0.02\n",
      "iteration: 286730 loss: 0.0014 lr: 0.02\n",
      "iteration: 286740 loss: 0.0016 lr: 0.02\n",
      "iteration: 286750 loss: 0.0018 lr: 0.02\n",
      "iteration: 286760 loss: 0.0018 lr: 0.02\n",
      "iteration: 286770 loss: 0.0015 lr: 0.02\n",
      "iteration: 286780 loss: 0.0016 lr: 0.02\n",
      "iteration: 286790 loss: 0.0020 lr: 0.02\n",
      "iteration: 286800 loss: 0.0018 lr: 0.02\n",
      "iteration: 286810 loss: 0.0020 lr: 0.02\n",
      "iteration: 286820 loss: 0.0014 lr: 0.02\n",
      "iteration: 286830 loss: 0.0022 lr: 0.02\n",
      "iteration: 286840 loss: 0.0018 lr: 0.02\n",
      "iteration: 286850 loss: 0.0018 lr: 0.02\n",
      "iteration: 286860 loss: 0.0018 lr: 0.02\n",
      "iteration: 286870 loss: 0.0016 lr: 0.02\n",
      "iteration: 286880 loss: 0.0017 lr: 0.02\n",
      "iteration: 286890 loss: 0.0017 lr: 0.02\n",
      "iteration: 286900 loss: 0.0017 lr: 0.02\n",
      "iteration: 286910 loss: 0.0018 lr: 0.02\n",
      "iteration: 286920 loss: 0.0016 lr: 0.02\n",
      "iteration: 286930 loss: 0.0015 lr: 0.02\n",
      "iteration: 286940 loss: 0.0019 lr: 0.02\n",
      "iteration: 286950 loss: 0.0017 lr: 0.02\n",
      "iteration: 286960 loss: 0.0016 lr: 0.02\n",
      "iteration: 286970 loss: 0.0033 lr: 0.02\n",
      "iteration: 286980 loss: 0.0022 lr: 0.02\n",
      "iteration: 286990 loss: 0.0018 lr: 0.02\n",
      "iteration: 287000 loss: 0.0017 lr: 0.02\n",
      "iteration: 287010 loss: 0.0020 lr: 0.02\n",
      "iteration: 287020 loss: 0.0015 lr: 0.02\n",
      "iteration: 287030 loss: 0.0016 lr: 0.02\n",
      "iteration: 287040 loss: 0.0019 lr: 0.02\n",
      "iteration: 287050 loss: 0.0027 lr: 0.02\n",
      "iteration: 287060 loss: 0.0021 lr: 0.02\n",
      "iteration: 287070 loss: 0.0016 lr: 0.02\n",
      "iteration: 287080 loss: 0.0029 lr: 0.02\n",
      "iteration: 287090 loss: 0.0020 lr: 0.02\n",
      "iteration: 287100 loss: 0.0020 lr: 0.02\n",
      "iteration: 287110 loss: 0.0020 lr: 0.02\n",
      "iteration: 287120 loss: 0.0022 lr: 0.02\n",
      "iteration: 287130 loss: 0.0022 lr: 0.02\n",
      "iteration: 287140 loss: 0.0016 lr: 0.02\n",
      "iteration: 287150 loss: 0.0013 lr: 0.02\n",
      "iteration: 287160 loss: 0.0016 lr: 0.02\n",
      "iteration: 287170 loss: 0.0020 lr: 0.02\n",
      "iteration: 287180 loss: 0.0019 lr: 0.02\n",
      "iteration: 287190 loss: 0.0023 lr: 0.02\n",
      "iteration: 287200 loss: 0.0016 lr: 0.02\n",
      "iteration: 287210 loss: 0.0017 lr: 0.02\n",
      "iteration: 287220 loss: 0.0015 lr: 0.02\n",
      "iteration: 287230 loss: 0.0019 lr: 0.02\n",
      "iteration: 287240 loss: 0.0020 lr: 0.02\n",
      "iteration: 287250 loss: 0.0014 lr: 0.02\n",
      "iteration: 287260 loss: 0.0013 lr: 0.02\n",
      "iteration: 287270 loss: 0.0019 lr: 0.02\n",
      "iteration: 287280 loss: 0.0017 lr: 0.02\n",
      "iteration: 287290 loss: 0.0014 lr: 0.02\n",
      "iteration: 287300 loss: 0.0019 lr: 0.02\n",
      "iteration: 287310 loss: 0.0016 lr: 0.02\n",
      "iteration: 287320 loss: 0.0019 lr: 0.02\n",
      "iteration: 287330 loss: 0.0021 lr: 0.02\n",
      "iteration: 287340 loss: 0.0021 lr: 0.02\n",
      "iteration: 287350 loss: 0.0026 lr: 0.02\n",
      "iteration: 287360 loss: 0.0017 lr: 0.02\n",
      "iteration: 287370 loss: 0.0014 lr: 0.02\n",
      "iteration: 287380 loss: 0.0024 lr: 0.02\n",
      "iteration: 287390 loss: 0.0012 lr: 0.02\n",
      "iteration: 287400 loss: 0.0017 lr: 0.02\n",
      "iteration: 287410 loss: 0.0017 lr: 0.02\n",
      "iteration: 287420 loss: 0.0018 lr: 0.02\n",
      "iteration: 287430 loss: 0.0016 lr: 0.02\n",
      "iteration: 287440 loss: 0.0018 lr: 0.02\n",
      "iteration: 287450 loss: 0.0017 lr: 0.02\n",
      "iteration: 287460 loss: 0.0021 lr: 0.02\n",
      "iteration: 287470 loss: 0.0024 lr: 0.02\n",
      "iteration: 287480 loss: 0.0014 lr: 0.02\n",
      "iteration: 287490 loss: 0.0018 lr: 0.02\n",
      "iteration: 287500 loss: 0.0020 lr: 0.02\n",
      "iteration: 287510 loss: 0.0016 lr: 0.02\n",
      "iteration: 287520 loss: 0.0019 lr: 0.02\n",
      "iteration: 287530 loss: 0.0013 lr: 0.02\n",
      "iteration: 287540 loss: 0.0019 lr: 0.02\n",
      "iteration: 287550 loss: 0.0015 lr: 0.02\n",
      "iteration: 287560 loss: 0.0020 lr: 0.02\n",
      "iteration: 287570 loss: 0.0016 lr: 0.02\n",
      "iteration: 287580 loss: 0.0020 lr: 0.02\n",
      "iteration: 287590 loss: 0.0017 lr: 0.02\n",
      "iteration: 287600 loss: 0.0016 lr: 0.02\n",
      "iteration: 287610 loss: 0.0017 lr: 0.02\n",
      "iteration: 287620 loss: 0.0015 lr: 0.02\n",
      "iteration: 287630 loss: 0.0013 lr: 0.02\n",
      "iteration: 287640 loss: 0.0014 lr: 0.02\n",
      "iteration: 287650 loss: 0.0014 lr: 0.02\n",
      "iteration: 287660 loss: 0.0013 lr: 0.02\n",
      "iteration: 287670 loss: 0.0017 lr: 0.02\n",
      "iteration: 287680 loss: 0.0016 lr: 0.02\n",
      "iteration: 287690 loss: 0.0019 lr: 0.02\n",
      "iteration: 287700 loss: 0.0019 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 287710 loss: 0.0017 lr: 0.02\n",
      "iteration: 287720 loss: 0.0018 lr: 0.02\n",
      "iteration: 287730 loss: 0.0018 lr: 0.02\n",
      "iteration: 287740 loss: 0.0016 lr: 0.02\n",
      "iteration: 287750 loss: 0.0014 lr: 0.02\n",
      "iteration: 287760 loss: 0.0019 lr: 0.02\n",
      "iteration: 287770 loss: 0.0023 lr: 0.02\n",
      "iteration: 287780 loss: 0.0021 lr: 0.02\n",
      "iteration: 287790 loss: 0.0023 lr: 0.02\n",
      "iteration: 287800 loss: 0.0021 lr: 0.02\n",
      "iteration: 287810 loss: 0.0019 lr: 0.02\n",
      "iteration: 287820 loss: 0.0018 lr: 0.02\n",
      "iteration: 287830 loss: 0.0019 lr: 0.02\n",
      "iteration: 287840 loss: 0.0022 lr: 0.02\n",
      "iteration: 287850 loss: 0.0017 lr: 0.02\n",
      "iteration: 287860 loss: 0.0017 lr: 0.02\n",
      "iteration: 287870 loss: 0.0012 lr: 0.02\n",
      "iteration: 287880 loss: 0.0016 lr: 0.02\n",
      "iteration: 287890 loss: 0.0019 lr: 0.02\n",
      "iteration: 287900 loss: 0.0019 lr: 0.02\n",
      "iteration: 287910 loss: 0.0020 lr: 0.02\n",
      "iteration: 287920 loss: 0.0014 lr: 0.02\n",
      "iteration: 287930 loss: 0.0016 lr: 0.02\n",
      "iteration: 287940 loss: 0.0019 lr: 0.02\n",
      "iteration: 287950 loss: 0.0019 lr: 0.02\n",
      "iteration: 287960 loss: 0.0017 lr: 0.02\n",
      "iteration: 287970 loss: 0.0015 lr: 0.02\n",
      "iteration: 287980 loss: 0.0014 lr: 0.02\n",
      "iteration: 287990 loss: 0.0018 lr: 0.02\n",
      "iteration: 288000 loss: 0.0013 lr: 0.02\n",
      "iteration: 288010 loss: 0.0020 lr: 0.02\n",
      "iteration: 288020 loss: 0.0022 lr: 0.02\n",
      "iteration: 288030 loss: 0.0015 lr: 0.02\n",
      "iteration: 288040 loss: 0.0014 lr: 0.02\n",
      "iteration: 288050 loss: 0.0018 lr: 0.02\n",
      "iteration: 288060 loss: 0.0019 lr: 0.02\n",
      "iteration: 288070 loss: 0.0017 lr: 0.02\n",
      "iteration: 288080 loss: 0.0019 lr: 0.02\n",
      "iteration: 288090 loss: 0.0021 lr: 0.02\n",
      "iteration: 288100 loss: 0.0018 lr: 0.02\n",
      "iteration: 288110 loss: 0.0021 lr: 0.02\n",
      "iteration: 288120 loss: 0.0012 lr: 0.02\n",
      "iteration: 288130 loss: 0.0012 lr: 0.02\n",
      "iteration: 288140 loss: 0.0016 lr: 0.02\n",
      "iteration: 288150 loss: 0.0015 lr: 0.02\n",
      "iteration: 288160 loss: 0.0015 lr: 0.02\n",
      "iteration: 288170 loss: 0.0020 lr: 0.02\n",
      "iteration: 288180 loss: 0.0015 lr: 0.02\n",
      "iteration: 288190 loss: 0.0015 lr: 0.02\n",
      "iteration: 288200 loss: 0.0012 lr: 0.02\n",
      "iteration: 288210 loss: 0.0018 lr: 0.02\n",
      "iteration: 288220 loss: 0.0021 lr: 0.02\n",
      "iteration: 288230 loss: 0.0018 lr: 0.02\n",
      "iteration: 288240 loss: 0.0018 lr: 0.02\n",
      "iteration: 288250 loss: 0.0020 lr: 0.02\n",
      "iteration: 288260 loss: 0.0021 lr: 0.02\n",
      "iteration: 288270 loss: 0.0019 lr: 0.02\n",
      "iteration: 288280 loss: 0.0016 lr: 0.02\n",
      "iteration: 288290 loss: 0.0021 lr: 0.02\n",
      "iteration: 288300 loss: 0.0016 lr: 0.02\n",
      "iteration: 288310 loss: 0.0016 lr: 0.02\n",
      "iteration: 288320 loss: 0.0018 lr: 0.02\n",
      "iteration: 288330 loss: 0.0015 lr: 0.02\n",
      "iteration: 288340 loss: 0.0017 lr: 0.02\n",
      "iteration: 288350 loss: 0.0018 lr: 0.02\n",
      "iteration: 288360 loss: 0.0017 lr: 0.02\n",
      "iteration: 288370 loss: 0.0023 lr: 0.02\n",
      "iteration: 288380 loss: 0.0020 lr: 0.02\n",
      "iteration: 288390 loss: 0.0018 lr: 0.02\n",
      "iteration: 288400 loss: 0.0017 lr: 0.02\n",
      "iteration: 288410 loss: 0.0019 lr: 0.02\n",
      "iteration: 288420 loss: 0.0013 lr: 0.02\n",
      "iteration: 288430 loss: 0.0021 lr: 0.02\n",
      "iteration: 288440 loss: 0.0015 lr: 0.02\n",
      "iteration: 288450 loss: 0.0019 lr: 0.02\n",
      "iteration: 288460 loss: 0.0015 lr: 0.02\n",
      "iteration: 288470 loss: 0.0016 lr: 0.02\n",
      "iteration: 288480 loss: 0.0016 lr: 0.02\n",
      "iteration: 288490 loss: 0.0013 lr: 0.02\n",
      "iteration: 288500 loss: 0.0017 lr: 0.02\n",
      "iteration: 288510 loss: 0.0016 lr: 0.02\n",
      "iteration: 288520 loss: 0.0015 lr: 0.02\n",
      "iteration: 288530 loss: 0.0020 lr: 0.02\n",
      "iteration: 288540 loss: 0.0020 lr: 0.02\n",
      "iteration: 288550 loss: 0.0016 lr: 0.02\n",
      "iteration: 288560 loss: 0.0024 lr: 0.02\n",
      "iteration: 288570 loss: 0.0022 lr: 0.02\n",
      "iteration: 288580 loss: 0.0025 lr: 0.02\n",
      "iteration: 288590 loss: 0.0019 lr: 0.02\n",
      "iteration: 288600 loss: 0.0018 lr: 0.02\n",
      "iteration: 288610 loss: 0.0016 lr: 0.02\n",
      "iteration: 288620 loss: 0.0030 lr: 0.02\n",
      "iteration: 288630 loss: 0.0020 lr: 0.02\n",
      "iteration: 288640 loss: 0.0016 lr: 0.02\n",
      "iteration: 288650 loss: 0.0022 lr: 0.02\n",
      "iteration: 288660 loss: 0.0018 lr: 0.02\n",
      "iteration: 288670 loss: 0.0018 lr: 0.02\n",
      "iteration: 288680 loss: 0.0013 lr: 0.02\n",
      "iteration: 288690 loss: 0.0014 lr: 0.02\n",
      "iteration: 288700 loss: 0.0016 lr: 0.02\n",
      "iteration: 288710 loss: 0.0021 lr: 0.02\n",
      "iteration: 288720 loss: 0.0018 lr: 0.02\n",
      "iteration: 288730 loss: 0.0016 lr: 0.02\n",
      "iteration: 288740 loss: 0.0018 lr: 0.02\n",
      "iteration: 288750 loss: 0.0014 lr: 0.02\n",
      "iteration: 288760 loss: 0.0017 lr: 0.02\n",
      "iteration: 288770 loss: 0.0017 lr: 0.02\n",
      "iteration: 288780 loss: 0.0014 lr: 0.02\n",
      "iteration: 288790 loss: 0.0021 lr: 0.02\n",
      "iteration: 288800 loss: 0.0021 lr: 0.02\n",
      "iteration: 288810 loss: 0.0018 lr: 0.02\n",
      "iteration: 288820 loss: 0.0019 lr: 0.02\n",
      "iteration: 288830 loss: 0.0019 lr: 0.02\n",
      "iteration: 288840 loss: 0.0016 lr: 0.02\n",
      "iteration: 288850 loss: 0.0016 lr: 0.02\n",
      "iteration: 288860 loss: 0.0015 lr: 0.02\n",
      "iteration: 288870 loss: 0.0019 lr: 0.02\n",
      "iteration: 288880 loss: 0.0025 lr: 0.02\n",
      "iteration: 288890 loss: 0.0019 lr: 0.02\n",
      "iteration: 288900 loss: 0.0015 lr: 0.02\n",
      "iteration: 288910 loss: 0.0018 lr: 0.02\n",
      "iteration: 288920 loss: 0.0023 lr: 0.02\n",
      "iteration: 288930 loss: 0.0020 lr: 0.02\n",
      "iteration: 288940 loss: 0.0019 lr: 0.02\n",
      "iteration: 288950 loss: 0.0017 lr: 0.02\n",
      "iteration: 288960 loss: 0.0021 lr: 0.02\n",
      "iteration: 288970 loss: 0.0015 lr: 0.02\n",
      "iteration: 288980 loss: 0.0017 lr: 0.02\n",
      "iteration: 288990 loss: 0.0018 lr: 0.02\n",
      "iteration: 289000 loss: 0.0023 lr: 0.02\n",
      "iteration: 289010 loss: 0.0017 lr: 0.02\n",
      "iteration: 289020 loss: 0.0015 lr: 0.02\n",
      "iteration: 289030 loss: 0.0016 lr: 0.02\n",
      "iteration: 289040 loss: 0.0021 lr: 0.02\n",
      "iteration: 289050 loss: 0.0017 lr: 0.02\n",
      "iteration: 289060 loss: 0.0015 lr: 0.02\n",
      "iteration: 289070 loss: 0.0018 lr: 0.02\n",
      "iteration: 289080 loss: 0.0019 lr: 0.02\n",
      "iteration: 289090 loss: 0.0021 lr: 0.02\n",
      "iteration: 289100 loss: 0.0020 lr: 0.02\n",
      "iteration: 289110 loss: 0.0026 lr: 0.02\n",
      "iteration: 289120 loss: 0.0016 lr: 0.02\n",
      "iteration: 289130 loss: 0.0015 lr: 0.02\n",
      "iteration: 289140 loss: 0.0018 lr: 0.02\n",
      "iteration: 289150 loss: 0.0017 lr: 0.02\n",
      "iteration: 289160 loss: 0.0019 lr: 0.02\n",
      "iteration: 289170 loss: 0.0019 lr: 0.02\n",
      "iteration: 289180 loss: 0.0014 lr: 0.02\n",
      "iteration: 289190 loss: 0.0020 lr: 0.02\n",
      "iteration: 289200 loss: 0.0016 lr: 0.02\n",
      "iteration: 289210 loss: 0.0019 lr: 0.02\n",
      "iteration: 289220 loss: 0.0017 lr: 0.02\n",
      "iteration: 289230 loss: 0.0014 lr: 0.02\n",
      "iteration: 289240 loss: 0.0026 lr: 0.02\n",
      "iteration: 289250 loss: 0.0020 lr: 0.02\n",
      "iteration: 289260 loss: 0.0018 lr: 0.02\n",
      "iteration: 289270 loss: 0.0017 lr: 0.02\n",
      "iteration: 289280 loss: 0.0017 lr: 0.02\n",
      "iteration: 289290 loss: 0.0013 lr: 0.02\n",
      "iteration: 289300 loss: 0.0018 lr: 0.02\n",
      "iteration: 289310 loss: 0.0019 lr: 0.02\n",
      "iteration: 289320 loss: 0.0015 lr: 0.02\n",
      "iteration: 289330 loss: 0.0015 lr: 0.02\n",
      "iteration: 289340 loss: 0.0019 lr: 0.02\n",
      "iteration: 289350 loss: 0.0021 lr: 0.02\n",
      "iteration: 289360 loss: 0.0016 lr: 0.02\n",
      "iteration: 289370 loss: 0.0017 lr: 0.02\n",
      "iteration: 289380 loss: 0.0021 lr: 0.02\n",
      "iteration: 289390 loss: 0.0018 lr: 0.02\n",
      "iteration: 289400 loss: 0.0017 lr: 0.02\n",
      "iteration: 289410 loss: 0.0021 lr: 0.02\n",
      "iteration: 289420 loss: 0.0021 lr: 0.02\n",
      "iteration: 289430 loss: 0.0019 lr: 0.02\n",
      "iteration: 289440 loss: 0.0022 lr: 0.02\n",
      "iteration: 289450 loss: 0.0020 lr: 0.02\n",
      "iteration: 289460 loss: 0.0017 lr: 0.02\n",
      "iteration: 289470 loss: 0.0017 lr: 0.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_877760/3584634975.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Lancement de l'entrainement pour au moins 200 000 iterations et plus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplayiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgputouse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Selecting single-animal trainer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             train(\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mdisplayiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcurrent_lr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         [_, loss_val, summary] = sess.run(\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_summaries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    958\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1181\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1359\u001b[0m                            run_metadata)\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1350\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1439\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1440\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1441\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m                                             run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lancement de l'entrainement pour au moins 200 000 iterations et plus\n",
    "\n",
    "deeplabcut.train_network(pathConfig, shuffle=1, displayiters=10, saveiters=500, gputouse=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8cda41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
